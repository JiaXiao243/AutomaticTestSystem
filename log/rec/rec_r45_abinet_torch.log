[2022-07-04 12:10:45,106 main.py:215 INFO train-abinet] ModelConfig(
	(0): dataset_case_sensitive = False
	(1): dataset_charset_path = data/charset_36.txt
	(2): dataset_data_aug = True
	(3): dataset_eval_case_sensitive = False
	(4): dataset_image_height = 32
	(5): dataset_image_width = 128
	(6): dataset_max_length = 25
	(7): dataset_multiscales = False
	(8): dataset_num_workers = 14
	(9): dataset_one_hot_y = True
	(10): dataset_pin_memory = True
	(11): dataset_smooth_factor = 0.1
	(12): dataset_smooth_label = False
	(13): dataset_test_batch_size = 384
	(14): dataset_test_roots = ['data/evaluation/IIIT5k_3000', 'data/evaluation/SVT', 'data/evaluation/SVTP', 'data/evaluation/IC13_857', 'data/evaluation/IC15_1811', 'data/evaluation/CUTE80']
	(15): dataset_train_batch_size = 384
	(16): dataset_train_roots = ['data/training/MJ/MJ_train/', 'data/training/MJ/MJ_test/', 'data/training/MJ/MJ_valid/', 'data/training/ST']
	(17): dataset_use_sm = False
	(18): global_name = train-abinet
	(19): global_phase = train
	(20): global_seed = None
	(21): global_stage = train-super
	(22): global_workdir = workdir/train-abinet
	(23): model_alignment_loss_weight = 1.0
	(24): model_checkpoint = None
	(25): model_ensemble = 
	(26): model_iter_size = 3
	(27): model_language_checkpoint = workdir/pretrain-language-model/pretrain-language-model.pth
	(28): model_language_detach = True
	(29): model_language_loss_weight = 1.0
	(30): model_language_num_layers = 4
	(31): model_language_use_self_attn = False
	(32): model_name = modules.model_abinet_iter.ABINetIterModel
	(33): model_strict = True
	(34): model_use_vision = False
	(35): model_vision_attention = position
	(36): model_vision_backbone = transformer
	(37): model_vision_backbone_ln = 3
	(38): model_vision_checkpoint = workdir/pretrain-vision-model/best-pretrain-vision-model.pth
	(39): model_vision_loss_weight = 1.0
	(40): optimizer_args_betas = (0.9, 0.999)
	(41): optimizer_bn_wd = False
	(42): optimizer_clip_grad = 20
	(43): optimizer_lr = 0.0001
	(44): optimizer_scheduler_gamma = 0.1
	(45): optimizer_scheduler_periods = [6, 4]
	(46): optimizer_true_wd = False
	(47): optimizer_type = Adam
	(48): optimizer_wd = 0.0
	(49): training_epochs = 10
	(50): training_eval_iters = 3000
	(51): training_save_iters = 3000
	(52): training_show_iters = 50
	(53): training_start_iters = 0
	(54): training_stats_iters = 100000
)
[2022-07-04 12:10:45,106 main.py:222 INFO train-abinet] Construct dataset.
[2022-07-04 12:10:45,110 main.py:92 INFO train-abinet] 15895356 training items found.
[2022-07-04 12:10:45,110 main.py:94 INFO train-abinet] 7248 valid items found.
[2022-07-04 12:10:45,110 main.py:226 INFO train-abinet] Construct model.
[2022-07-04 12:10:46,502 model_vision.py:37 INFO train-abinet] Read vision model from workdir/pretrain-vision-model/best-pretrain-vision-model.pth.
[2022-07-04 12:10:55,586 model_language.py:38 INFO train-abinet] Read language model from workdir/pretrain-language-model/pretrain-language-model.pth.
[2022-07-04 12:10:56,823 main.py:104 INFO train-abinet] ABINetIterModel(
  (vision): BaseVision(
    (backbone): ResTranformer(
      (resnet): ResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (pos_encoder): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (linear1): Linear(in_features=512, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=512, bias=True)
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (linear1): Linear(in_features=512, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=512, bias=True)
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (linear1): Linear(in_features=512, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=512, bias=True)
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (attention): PositionAttention(
      (k_encoder): Sequential(
        (0): Sequential(
          (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (3): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (k_decoder): Sequential(
        (0): Sequential(
          (0): Upsample(scale_factor=2.0, mode=nearest)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): Upsample(scale_factor=2.0, mode=nearest)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): Upsample(scale_factor=2.0, mode=nearest)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (3): Sequential(
          (0): Upsample(size=(8, 32), mode=nearest)
          (1): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
      )
      (pos_encoder): PositionalEncoding(
        (dropout): Dropout(p=0, inplace=False)
      )
      (project): Linear(in_features=512, out_features=512, bias=True)
    )
    (cls): Linear(in_features=512, out_features=37, bias=True)
  )
  (language): BCNLanguage(
    (proj): Linear(in_features=37, out_features=512, bias=False)
    (token_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0, inplace=False)
    )
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0): TransformerDecoderLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (1): TransformerDecoderLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (2): TransformerDecoderLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (3): TransformerDecoderLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (cls): Linear(in_features=512, out_features=37, bias=True)
  )
  (alignment): BaseAlignment(
    (w_att): Linear(in_features=1024, out_features=512, bias=True)
    (cls): Linear(in_features=512, out_features=37, bias=True)
  )
)
[2022-07-04 12:10:56,828 main.py:229 INFO train-abinet] Construct learner.
[2022-07-04 12:10:56,970 main.py:162 INFO train-abinet] Use 4 GPUs.
[2022-07-04 12:10:56,971 main.py:233 INFO train-abinet] Start training.
██[2022-07-04 12:12:25,220 callbacks.py:105 INFO train-abinet] epoch 0 iter 50: loss = 1.7447,  smooth loss = 4.4040
[2022-07-04 12:13:08,872 callbacks.py:105 INFO train-abinet] epoch 0 iter 100: loss = 1.3595,  smooth loss = 2.2478
[2022-07-04 12:13:51,276 callbacks.py:105 INFO train-abinet] epoch 0 iter 150: loss = 1.2701,  smooth loss = 1.5805
[2022-07-04 12:14:33,641 callbacks.py:105 INFO train-abinet] epoch 0 iter 200: loss = 1.2223,  smooth loss = 1.3144
[2022-07-04 12:15:17,314 callbacks.py:105 INFO train-abinet] epoch 0 iter 250: loss = 0.9862,  smooth loss = 1.1739
[2022-07-04 12:15:59,807 callbacks.py:105 INFO train-abinet] epoch 0 iter 300: loss = 0.8988,  smooth loss = 1.1095
[2022-07-04 12:16:42,131 callbacks.py:105 INFO train-abinet] epoch 0 iter 350: loss = 0.8426,  smooth loss = 1.0838
[2022-07-04 12:17:24,947 callbacks.py:105 INFO train-abinet] epoch 0 iter 400: loss = 1.1901,  smooth loss = 1.0788
[2022-07-04 12:18:08,096 callbacks.py:105 INFO train-abinet] epoch 0 iter 450: loss = 0.8947,  smooth loss = 1.0279
[2022-07-04 12:18:50,455 callbacks.py:105 INFO train-abinet] epoch 0 iter 500: loss = 1.0144,  smooth loss = 0.9992
[2022-07-04 12:19:33,164 callbacks.py:105 INFO train-abinet] epoch 0 iter 550: loss = 0.9381,  smooth loss = 0.9699
[2022-07-04 12:20:15,232 callbacks.py:105 INFO train-abinet] epoch 0 iter 600: loss = 0.9261,  smooth loss = 0.9611
[2022-07-04 12:20:57,838 callbacks.py:105 INFO train-abinet] epoch 0 iter 650: loss = 1.0503,  smooth loss = 0.9618
[2022-07-04 12:21:39,643 callbacks.py:105 INFO train-abinet] epoch 0 iter 700: loss = 0.7837,  smooth loss = 0.9639
[2022-07-04 12:22:21,493 callbacks.py:105 INFO train-abinet] epoch 0 iter 750: loss = 0.8644,  smooth loss = 0.9734
[2022-07-04 12:23:04,251 callbacks.py:105 INFO train-abinet] epoch 0 iter 800: loss = 0.8753,  smooth loss = 0.9379
[2022-07-04 12:23:46,828 callbacks.py:105 INFO train-abinet] epoch 0 iter 850: loss = 0.8437,  smooth loss = 0.9313
[2022-07-04 12:24:28,371 callbacks.py:105 INFO train-abinet] epoch 0 iter 900: loss = 1.0559,  smooth loss = 0.9379
[2022-07-04 12:25:10,916 callbacks.py:105 INFO train-abinet] epoch 0 iter 950: loss = 0.8760,  smooth loss = 0.9166
[2022-07-04 12:25:54,246 callbacks.py:105 INFO train-abinet] epoch 0 iter 1000: loss = 0.9187,  smooth loss = 0.9061
[2022-07-04 12:26:36,556 callbacks.py:105 INFO train-abinet] epoch 0 iter 1050: loss = 0.9614,  smooth loss = 0.9020
[2022-07-04 12:27:18,699 callbacks.py:105 INFO train-abinet] epoch 0 iter 1100: loss = 0.8468,  smooth loss = 0.9070
[2022-07-04 12:28:00,519 callbacks.py:105 INFO train-abinet] epoch 0 iter 1150: loss = 0.9873,  smooth loss = 0.9076
[2022-07-04 12:28:43,092 callbacks.py:105 INFO train-abinet] epoch 0 iter 1200: loss = 1.0312,  smooth loss = 0.9086
[2022-07-04 12:29:26,217 callbacks.py:105 INFO train-abinet] epoch 0 iter 1250: loss = 0.9107,  smooth loss = 0.9063
[2022-07-04 12:30:08,593 callbacks.py:105 INFO train-abinet] epoch 0 iter 1300: loss = 0.7606,  smooth loss = 0.8924
[2022-07-04 12:30:50,544 callbacks.py:105 INFO train-abinet] epoch 0 iter 1350: loss = 0.8664,  smooth loss = 0.8844
[2022-07-04 12:31:32,599 callbacks.py:105 INFO train-abinet] epoch 0 iter 1400: loss = 1.1463,  smooth loss = 0.8885
[2022-07-04 12:32:14,516 callbacks.py:105 INFO train-abinet] epoch 0 iter 1450: loss = 0.8655,  smooth loss = 0.8919
[2022-07-04 12:32:56,976 callbacks.py:105 INFO train-abinet] epoch 0 iter 1500: loss = 0.8461,  smooth loss = 0.8770
[2022-07-04 12:33:39,341 callbacks.py:105 INFO train-abinet] epoch 0 iter 1550: loss = 0.9674,  smooth loss = 0.8723
[2022-07-04 12:34:20,546 callbacks.py:105 INFO train-abinet] epoch 0 iter 1600: loss = 0.7440,  smooth loss = 0.8680
[2022-07-04 12:35:02,811 callbacks.py:105 INFO train-abinet] epoch 0 iter 1650: loss = 0.7748,  smooth loss = 0.8740
[2022-07-04 12:35:45,481 callbacks.py:105 INFO train-abinet] epoch 0 iter 1700: loss = 0.8694,  smooth loss = 0.8685
[2022-07-04 12:36:28,056 callbacks.py:105 INFO train-abinet] epoch 0 iter 1750: loss = 0.8413,  smooth loss = 0.8515
[2022-07-04 12:37:09,916 callbacks.py:105 INFO train-abinet] epoch 0 iter 1800: loss = 0.9454,  smooth loss = 0.8666
[2022-07-04 12:37:52,177 callbacks.py:105 INFO train-abinet] epoch 0 iter 1850: loss = 0.8362,  smooth loss = 0.8706
[2022-07-04 12:38:34,641 callbacks.py:105 INFO train-abinet] epoch 0 iter 1900: loss = 0.8367,  smooth loss = 0.8695
[2022-07-04 12:39:16,047 callbacks.py:105 INFO train-abinet] epoch 0 iter 1950: loss = 0.8043,  smooth loss = 0.8573
[2022-07-04 12:39:58,502 callbacks.py:105 INFO train-abinet] epoch 0 iter 2000: loss = 0.6843,  smooth loss = 0.8629
[2022-07-04 12:40:40,810 callbacks.py:105 INFO train-abinet] epoch 0 iter 2050: loss = 0.8354,  smooth loss = 0.8435
[2022-07-04 12:41:21,817 callbacks.py:105 INFO train-abinet] epoch 0 iter 2100: loss = 0.9761,  smooth loss = 0.8405
[2022-07-04 12:42:03,626 callbacks.py:105 INFO train-abinet] epoch 0 iter 2150: loss = 0.8599,  smooth loss = 0.8325
[2022-07-04 12:42:45,861 callbacks.py:105 INFO train-abinet] epoch 0 iter 2200: loss = 0.9145,  smooth loss = 0.8378
[2022-07-04 12:43:28,519 callbacks.py:105 INFO train-abinet] epoch 0 iter 2250: loss = 0.8885,  smooth loss = 0.8482
[2022-07-04 12:44:10,329 callbacks.py:105 INFO train-abinet] epoch 0 iter 2300: loss = 0.7771,  smooth loss = 0.8399
[2022-07-04 12:44:52,627 callbacks.py:105 INFO train-abinet] epoch 0 iter 2350: loss = 0.8201,  smooth loss = 0.8398
[2022-07-04 12:45:35,935 callbacks.py:105 INFO train-abinet] epoch 0 iter 2400: loss = 0.6844,  smooth loss = 0.8353
[2022-07-04 12:46:18,706 callbacks.py:105 INFO train-abinet] epoch 0 iter 2450: loss = 0.6858,  smooth loss = 0.8170
[2022-07-04 12:47:00,449 callbacks.py:105 INFO train-abinet] epoch 0 iter 2500: loss = 0.8493,  smooth loss = 0.8083
[2022-07-04 12:47:42,632 callbacks.py:105 INFO train-abinet] epoch 0 iter 2550: loss = 0.7386,  smooth loss = 0.8118
[2022-07-04 12:48:25,096 callbacks.py:105 INFO train-abinet] epoch 0 iter 2600: loss = 0.9167,  smooth loss = 0.8146
[2022-07-04 12:49:06,848 callbacks.py:105 INFO train-abinet] epoch 0 iter 2650: loss = 0.7678,  smooth loss = 0.8129
[2022-07-04 12:49:49,687 callbacks.py:105 INFO train-abinet] epoch 0 iter 2700: loss = 0.7590,  smooth loss = 0.8170
[2022-07-04 12:50:32,139 callbacks.py:105 INFO train-abinet] epoch 0 iter 2750: loss = 0.7157,  smooth loss = 0.8172
[2022-07-04 12:51:14,609 callbacks.py:105 INFO train-abinet] epoch 0 iter 2800: loss = 0.7639,  smooth loss = 0.8049
[2022-07-04 12:51:56,676 callbacks.py:105 INFO train-abinet] epoch 0 iter 2850: loss = 0.7337,  smooth loss = 0.8089
[2022-07-04 12:52:39,392 callbacks.py:105 INFO train-abinet] epoch 0 iter 2900: loss = 0.7482,  smooth loss = 0.8071
[2022-07-04 12:53:22,154 callbacks.py:105 INFO train-abinet] epoch 0 iter 2950: loss = 1.0098,  smooth loss = 0.8104
[2022-07-04 12:54:03,807 callbacks.py:105 INFO train-abinet] epoch 0 iter 3000: loss = 0.8620,  smooth loss = 0.7926
[2022-07-04 12:54:03,808 callbacks.py:114 INFO train-abinet] average data time = 0.0190s, average running time = 0.8432s
█[2022-07-04 12:54:19,832 callbacks.py:123 INFO train-abinet] epoch 0 iter 3000: eval loss = 1.1477,  ccr = 0.9538,  cwr = 0.9002,  ted = 1529.0000,  ned = 291.1695,  ted/w = 0.2110, 
[2022-07-04 12:54:19,834 callbacks.py:130 INFO train-abinet] Better model found at epoch 0, iter 3000 with accuracy value: 0.9002.
[2022-07-04 12:54:20,977 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_3000
[2022-07-04 12:55:04,456 callbacks.py:105 INFO train-abinet] epoch 0 iter 3050: loss = 0.7560,  smooth loss = 0.7978
[2022-07-04 12:55:47,882 callbacks.py:105 INFO train-abinet] epoch 0 iter 3100: loss = 0.7772,  smooth loss = 0.7921
[2022-07-04 12:56:30,450 callbacks.py:105 INFO train-abinet] epoch 0 iter 3150: loss = 0.9529,  smooth loss = 0.7989
[2022-07-04 12:57:12,792 callbacks.py:105 INFO train-abinet] epoch 0 iter 3200: loss = 0.7939,  smooth loss = 0.7902
[2022-07-04 12:57:55,307 callbacks.py:105 INFO train-abinet] epoch 0 iter 3250: loss = 0.8197,  smooth loss = 0.7872
[2022-07-04 12:58:37,955 callbacks.py:105 INFO train-abinet] epoch 0 iter 3300: loss = 0.7515,  smooth loss = 0.7875
[2022-07-04 12:59:20,088 callbacks.py:105 INFO train-abinet] epoch 0 iter 3350: loss = 0.6746,  smooth loss = 0.7895
[2022-07-04 13:00:01,781 callbacks.py:105 INFO train-abinet] epoch 0 iter 3400: loss = 0.6907,  smooth loss = 0.7924
[2022-07-04 13:00:44,598 callbacks.py:105 INFO train-abinet] epoch 0 iter 3450: loss = 0.8985,  smooth loss = 0.8021
[2022-07-04 13:01:26,395 callbacks.py:105 INFO train-abinet] epoch 0 iter 3500: loss = 0.6245,  smooth loss = 0.7770
[2022-07-04 13:02:08,901 callbacks.py:105 INFO train-abinet] epoch 0 iter 3550: loss = 0.8243,  smooth loss = 0.7788
[2022-07-04 13:02:50,387 callbacks.py:105 INFO train-abinet] epoch 0 iter 3600: loss = 0.7211,  smooth loss = 0.7766
[2022-07-04 13:03:32,503 callbacks.py:105 INFO train-abinet] epoch 0 iter 3650: loss = 0.7180,  smooth loss = 0.7841
[2022-07-04 13:04:14,421 callbacks.py:105 INFO train-abinet] epoch 0 iter 3700: loss = 0.6231,  smooth loss = 0.7852
[2022-07-04 13:04:57,142 callbacks.py:105 INFO train-abinet] epoch 0 iter 3750: loss = 0.8718,  smooth loss = 0.7799
[2022-07-04 13:05:39,500 callbacks.py:105 INFO train-abinet] epoch 0 iter 3800: loss = 0.6152,  smooth loss = 0.7793
[2022-07-04 13:06:22,448 callbacks.py:105 INFO train-abinet] epoch 0 iter 3850: loss = 0.6631,  smooth loss = 0.7948
[2022-07-04 13:07:05,122 callbacks.py:105 INFO train-abinet] epoch 0 iter 3900: loss = 0.6132,  smooth loss = 0.7948
[2022-07-04 13:07:47,474 callbacks.py:105 INFO train-abinet] epoch 0 iter 3950: loss = 0.7141,  smooth loss = 0.7893
[2022-07-04 13:08:30,657 callbacks.py:105 INFO train-abinet] epoch 0 iter 4000: loss = 0.6394,  smooth loss = 0.7768
[2022-07-04 13:09:12,201 callbacks.py:105 INFO train-abinet] epoch 0 iter 4050: loss = 0.8012,  smooth loss = 0.7936
[2022-07-04 13:09:55,163 callbacks.py:105 INFO train-abinet] epoch 0 iter 4100: loss = 0.7706,  smooth loss = 0.7877
[2022-07-04 13:10:45,939 callbacks.py:105 INFO train-abinet] epoch 0 iter 4150: loss = 0.7772,  smooth loss = 0.8008
[2022-07-04 13:11:37,732 callbacks.py:105 INFO train-abinet] epoch 0 iter 4200: loss = 0.8944,  smooth loss = 0.7787
[2022-07-04 13:12:19,997 callbacks.py:105 INFO train-abinet] epoch 0 iter 4250: loss = 0.9732,  smooth loss = 0.7791
[2022-07-04 13:13:03,813 callbacks.py:105 INFO train-abinet] epoch 0 iter 4300: loss = 0.7046,  smooth loss = 0.7732
[2022-07-04 13:13:45,367 callbacks.py:105 INFO train-abinet] epoch 0 iter 4350: loss = 0.8604,  smooth loss = 0.7790
[2022-07-04 13:14:27,986 callbacks.py:105 INFO train-abinet] epoch 0 iter 4400: loss = 0.8224,  smooth loss = 0.7673
[2022-07-04 13:15:10,846 callbacks.py:105 INFO train-abinet] epoch 0 iter 4450: loss = 0.8661,  smooth loss = 0.7651
[2022-07-04 13:15:53,655 callbacks.py:105 INFO train-abinet] epoch 0 iter 4500: loss = 0.7463,  smooth loss = 0.7586
[2022-07-04 13:16:36,553 callbacks.py:105 INFO train-abinet] epoch 0 iter 4550: loss = 0.9835,  smooth loss = 0.7663
[2022-07-04 13:17:19,233 callbacks.py:105 INFO train-abinet] epoch 0 iter 4600: loss = 0.7097,  smooth loss = 0.7563
[2022-07-04 13:18:02,456 callbacks.py:105 INFO train-abinet] epoch 0 iter 4650: loss = 0.8753,  smooth loss = 0.7833
[2022-07-04 13:18:46,976 callbacks.py:105 INFO train-abinet] epoch 0 iter 4700: loss = 0.8604,  smooth loss = 0.7699
[2022-07-04 13:19:30,541 callbacks.py:105 INFO train-abinet] epoch 0 iter 4750: loss = 0.7156,  smooth loss = 0.7752
[2022-07-04 13:20:13,257 callbacks.py:105 INFO train-abinet] epoch 0 iter 4800: loss = 0.8721,  smooth loss = 0.7636
[2022-07-04 13:20:55,651 callbacks.py:105 INFO train-abinet] epoch 0 iter 4850: loss = 0.8461,  smooth loss = 0.7697
[2022-07-04 13:21:39,457 callbacks.py:105 INFO train-abinet] epoch 0 iter 4900: loss = 0.6502,  smooth loss = 0.7498
[2022-07-04 13:22:22,499 callbacks.py:105 INFO train-abinet] epoch 0 iter 4950: loss = 0.7861,  smooth loss = 0.7486
[2022-07-04 13:23:05,194 callbacks.py:105 INFO train-abinet] epoch 0 iter 5000: loss = 0.5043,  smooth loss = 0.7495
[2022-07-04 13:23:47,889 callbacks.py:105 INFO train-abinet] epoch 0 iter 5050: loss = 0.6223,  smooth loss = 0.7617
[2022-07-04 13:24:33,959 callbacks.py:105 INFO train-abinet] epoch 0 iter 5100: loss = 0.6786,  smooth loss = 0.7687
[2022-07-04 13:25:16,778 callbacks.py:105 INFO train-abinet] epoch 0 iter 5150: loss = 0.5750,  smooth loss = 0.7469
[2022-07-04 13:25:58,864 callbacks.py:105 INFO train-abinet] epoch 0 iter 5200: loss = 0.8601,  smooth loss = 0.7630
[2022-07-04 13:26:41,045 callbacks.py:105 INFO train-abinet] epoch 0 iter 5250: loss = 0.8631,  smooth loss = 0.7545
[2022-07-04 13:27:22,786 callbacks.py:105 INFO train-abinet] epoch 0 iter 5300: loss = 0.5752,  smooth loss = 0.7525
[2022-07-04 13:28:04,948 callbacks.py:105 INFO train-abinet] epoch 0 iter 5350: loss = 0.6651,  smooth loss = 0.7566
[2022-07-04 13:28:47,465 callbacks.py:105 INFO train-abinet] epoch 0 iter 5400: loss = 0.8093,  smooth loss = 0.7552
[2022-07-04 13:29:30,297 callbacks.py:105 INFO train-abinet] epoch 0 iter 5450: loss = 0.6794,  smooth loss = 0.7523
[2022-07-04 13:30:12,662 callbacks.py:105 INFO train-abinet] epoch 0 iter 5500: loss = 0.8636,  smooth loss = 0.7482
[2022-07-04 13:30:55,910 callbacks.py:105 INFO train-abinet] epoch 0 iter 5550: loss = 0.7743,  smooth loss = 0.7408
[2022-07-04 13:31:38,658 callbacks.py:105 INFO train-abinet] epoch 0 iter 5600: loss = 0.7416,  smooth loss = 0.7404
[2022-07-04 13:32:21,632 callbacks.py:105 INFO train-abinet] epoch 0 iter 5650: loss = 0.7305,  smooth loss = 0.7384
[2022-07-04 13:33:04,341 callbacks.py:105 INFO train-abinet] epoch 0 iter 5700: loss = 0.6768,  smooth loss = 0.7541
[2022-07-04 13:33:46,290 callbacks.py:105 INFO train-abinet] epoch 0 iter 5750: loss = 0.8902,  smooth loss = 0.7406
[2022-07-04 13:34:28,086 callbacks.py:105 INFO train-abinet] epoch 0 iter 5800: loss = 0.7705,  smooth loss = 0.7484
[2022-07-04 13:35:10,031 callbacks.py:105 INFO train-abinet] epoch 0 iter 5850: loss = 0.8462,  smooth loss = 0.7444
[2022-07-04 13:35:52,735 callbacks.py:105 INFO train-abinet] epoch 0 iter 5900: loss = 0.6899,  smooth loss = 0.7416
[2022-07-04 13:36:34,895 callbacks.py:105 INFO train-abinet] epoch 0 iter 5950: loss = 0.7738,  smooth loss = 0.7636
[2022-07-04 13:37:16,868 callbacks.py:105 INFO train-abinet] epoch 0 iter 6000: loss = 0.7184,  smooth loss = 0.7519
[2022-07-04 13:37:16,868 callbacks.py:114 INFO train-abinet] average data time = 0.0116s, average running time = 0.8517s
█[2022-07-04 13:37:32,668 callbacks.py:123 INFO train-abinet] epoch 0 iter 6000: eval loss = 1.1403,  ccr = 0.9554,  cwr = 0.9100,  ted = 1474.0000,  ned = 281.5952,  ted/w = 0.2034, 
[2022-07-04 13:37:32,670 callbacks.py:130 INFO train-abinet] Better model found at epoch 0, iter 6000 with accuracy value: 0.9100.
[2022-07-04 13:37:33,717 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_6000
[2022-07-04 13:38:17,485 callbacks.py:105 INFO train-abinet] epoch 0 iter 6050: loss = 0.8073,  smooth loss = 0.7395
[2022-07-04 13:39:00,267 callbacks.py:105 INFO train-abinet] epoch 0 iter 6100: loss = 0.7503,  smooth loss = 0.7431
[2022-07-04 13:39:42,717 callbacks.py:105 INFO train-abinet] epoch 0 iter 6150: loss = 0.6762,  smooth loss = 0.7420
[2022-07-04 13:40:24,254 callbacks.py:105 INFO train-abinet] epoch 0 iter 6200: loss = 0.6910,  smooth loss = 0.7469
[2022-07-04 13:41:05,642 callbacks.py:105 INFO train-abinet] epoch 0 iter 6250: loss = 0.9097,  smooth loss = 0.7552
[2022-07-04 13:41:47,470 callbacks.py:105 INFO train-abinet] epoch 0 iter 6300: loss = 0.8758,  smooth loss = 0.7543
[2022-07-04 13:42:29,130 callbacks.py:105 INFO train-abinet] epoch 0 iter 6350: loss = 0.7657,  smooth loss = 0.7498
[2022-07-04 13:43:10,775 callbacks.py:105 INFO train-abinet] epoch 0 iter 6400: loss = 0.7299,  smooth loss = 0.7377
[2022-07-04 13:43:52,827 callbacks.py:105 INFO train-abinet] epoch 0 iter 6450: loss = 0.6292,  smooth loss = 0.7304
[2022-07-04 13:44:34,442 callbacks.py:105 INFO train-abinet] epoch 0 iter 6500: loss = 0.7051,  smooth loss = 0.7334
[2022-07-04 13:45:15,909 callbacks.py:105 INFO train-abinet] epoch 0 iter 6550: loss = 0.7514,  smooth loss = 0.7459
[2022-07-04 13:45:57,788 callbacks.py:105 INFO train-abinet] epoch 0 iter 6600: loss = 0.8082,  smooth loss = 0.7368
[2022-07-04 13:46:41,013 callbacks.py:105 INFO train-abinet] epoch 0 iter 6650: loss = 0.6355,  smooth loss = 0.7349
[2022-07-04 13:47:22,897 callbacks.py:105 INFO train-abinet] epoch 0 iter 6700: loss = 0.8597,  smooth loss = 0.7311
[2022-07-04 13:48:04,374 callbacks.py:105 INFO train-abinet] epoch 0 iter 6750: loss = 0.7746,  smooth loss = 0.7373
[2022-07-04 13:48:45,661 callbacks.py:105 INFO train-abinet] epoch 0 iter 6800: loss = 0.8332,  smooth loss = 0.7321
[2022-07-04 13:49:27,361 callbacks.py:105 INFO train-abinet] epoch 0 iter 6850: loss = 0.7752,  smooth loss = 0.7437
[2022-07-04 13:50:09,802 callbacks.py:105 INFO train-abinet] epoch 0 iter 6900: loss = 0.7403,  smooth loss = 0.7351
[2022-07-04 13:50:51,604 callbacks.py:105 INFO train-abinet] epoch 0 iter 6950: loss = 0.7534,  smooth loss = 0.7430
[2022-07-04 13:51:34,651 callbacks.py:105 INFO train-abinet] epoch 0 iter 7000: loss = 0.8592,  smooth loss = 0.7318
[2022-07-04 13:52:16,539 callbacks.py:105 INFO train-abinet] epoch 0 iter 7050: loss = 0.6774,  smooth loss = 0.7285
[2022-07-04 13:52:59,368 callbacks.py:105 INFO train-abinet] epoch 0 iter 7100: loss = 0.6982,  smooth loss = 0.7325
[2022-07-04 13:53:41,359 callbacks.py:105 INFO train-abinet] epoch 0 iter 7150: loss = 0.5662,  smooth loss = 0.7350
[2022-07-04 13:54:22,915 callbacks.py:105 INFO train-abinet] epoch 0 iter 7200: loss = 0.5549,  smooth loss = 0.7267
[2022-07-04 13:55:05,597 callbacks.py:105 INFO train-abinet] epoch 0 iter 7250: loss = 0.8381,  smooth loss = 0.7324
[2022-07-04 13:55:47,442 callbacks.py:105 INFO train-abinet] epoch 0 iter 7300: loss = 0.7581,  smooth loss = 0.7263
[2022-07-04 13:56:28,602 callbacks.py:105 INFO train-abinet] epoch 0 iter 7350: loss = 0.6069,  smooth loss = 0.7356
[2022-07-04 13:57:10,181 callbacks.py:105 INFO train-abinet] epoch 0 iter 7400: loss = 0.9038,  smooth loss = 0.7355
[2022-07-04 13:57:51,762 callbacks.py:105 INFO train-abinet] epoch 0 iter 7450: loss = 0.7769,  smooth loss = 0.7354
[2022-07-04 13:58:33,593 callbacks.py:105 INFO train-abinet] epoch 0 iter 7500: loss = 0.7797,  smooth loss = 0.7291
[2022-07-04 13:59:15,439 callbacks.py:105 INFO train-abinet] epoch 0 iter 7550: loss = 0.7360,  smooth loss = 0.7372
[2022-07-04 13:59:56,888 callbacks.py:105 INFO train-abinet] epoch 0 iter 7600: loss = 0.6642,  smooth loss = 0.7299
[2022-07-04 14:00:38,301 callbacks.py:105 INFO train-abinet] epoch 0 iter 7650: loss = 0.5989,  smooth loss = 0.7258
[2022-07-04 14:01:20,611 callbacks.py:105 INFO train-abinet] epoch 0 iter 7700: loss = 0.6374,  smooth loss = 0.7202
[2022-07-04 14:02:01,668 callbacks.py:105 INFO train-abinet] epoch 0 iter 7750: loss = 0.6055,  smooth loss = 0.7482
[2022-07-04 14:02:44,490 callbacks.py:105 INFO train-abinet] epoch 0 iter 7800: loss = 0.7264,  smooth loss = 0.7296
[2022-07-04 14:03:26,692 callbacks.py:105 INFO train-abinet] epoch 0 iter 7850: loss = 0.8507,  smooth loss = 0.7329
[2022-07-04 14:04:09,012 callbacks.py:105 INFO train-abinet] epoch 0 iter 7900: loss = 0.7078,  smooth loss = 0.7389
[2022-07-04 14:04:51,003 callbacks.py:105 INFO train-abinet] epoch 0 iter 7950: loss = 0.7284,  smooth loss = 0.7272
[2022-07-04 14:05:33,064 callbacks.py:105 INFO train-abinet] epoch 0 iter 8000: loss = 0.7020,  smooth loss = 0.7448
[2022-07-04 14:06:14,455 callbacks.py:105 INFO train-abinet] epoch 0 iter 8050: loss = 0.7819,  smooth loss = 0.7443
[2022-07-04 14:06:56,560 callbacks.py:105 INFO train-abinet] epoch 0 iter 8100: loss = 0.8397,  smooth loss = 0.7156
[2022-07-04 14:07:39,033 callbacks.py:105 INFO train-abinet] epoch 0 iter 8150: loss = 0.8060,  smooth loss = 0.7218
[2022-07-04 14:08:21,183 callbacks.py:105 INFO train-abinet] epoch 0 iter 8200: loss = 0.7276,  smooth loss = 0.7251
[2022-07-04 14:09:02,819 callbacks.py:105 INFO train-abinet] epoch 0 iter 8250: loss = 0.6594,  smooth loss = 0.7253
[2022-07-04 14:09:45,408 callbacks.py:105 INFO train-abinet] epoch 0 iter 8300: loss = 0.8195,  smooth loss = 0.7119
[2022-07-04 14:10:27,820 callbacks.py:105 INFO train-abinet] epoch 0 iter 8350: loss = 0.8739,  smooth loss = 0.7194
[2022-07-04 14:11:09,544 callbacks.py:105 INFO train-abinet] epoch 0 iter 8400: loss = 0.8531,  smooth loss = 0.7376
[2022-07-04 14:11:51,792 callbacks.py:105 INFO train-abinet] epoch 0 iter 8450: loss = 0.6758,  smooth loss = 0.7193
[2022-07-04 14:12:33,499 callbacks.py:105 INFO train-abinet] epoch 0 iter 8500: loss = 0.6905,  smooth loss = 0.7350
[2022-07-04 14:13:14,902 callbacks.py:105 INFO train-abinet] epoch 0 iter 8550: loss = 0.7533,  smooth loss = 0.7345
[2022-07-04 14:13:55,896 callbacks.py:105 INFO train-abinet] epoch 0 iter 8600: loss = 0.7389,  smooth loss = 0.7415
[2022-07-04 14:14:37,745 callbacks.py:105 INFO train-abinet] epoch 0 iter 8650: loss = 0.7172,  smooth loss = 0.7377
[2022-07-04 14:15:20,049 callbacks.py:105 INFO train-abinet] epoch 0 iter 8700: loss = 0.7274,  smooth loss = 0.7339
[2022-07-04 14:16:02,016 callbacks.py:105 INFO train-abinet] epoch 0 iter 8750: loss = 0.8180,  smooth loss = 0.7234
[2022-07-04 14:16:43,175 callbacks.py:105 INFO train-abinet] epoch 0 iter 8800: loss = 0.8396,  smooth loss = 0.7306
[2022-07-04 14:17:24,679 callbacks.py:105 INFO train-abinet] epoch 0 iter 8850: loss = 0.6155,  smooth loss = 0.7322
[2022-07-04 14:18:06,325 callbacks.py:105 INFO train-abinet] epoch 0 iter 8900: loss = 0.7232,  smooth loss = 0.7320
[2022-07-04 14:18:48,077 callbacks.py:105 INFO train-abinet] epoch 0 iter 8950: loss = 0.7367,  smooth loss = 0.7249
[2022-07-04 14:19:29,240 callbacks.py:105 INFO train-abinet] epoch 0 iter 9000: loss = 0.7093,  smooth loss = 0.7204
[2022-07-04 14:19:29,240 callbacks.py:114 INFO train-abinet] average data time = 0.0090s, average running time = 0.8479s
█[2022-07-04 14:19:44,155 callbacks.py:123 INFO train-abinet] epoch 0 iter 9000: eval loss = 1.1427,  ccr = 0.9539,  cwr = 0.9077,  ted = 1476.0000,  ned = 292.7943,  ted/w = 0.2036, 
[2022-07-04 14:19:44,156 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_9000
[2022-07-04 14:20:26,778 callbacks.py:105 INFO train-abinet] epoch 0 iter 9050: loss = 0.6582,  smooth loss = 0.7150
[2022-07-04 14:21:09,154 callbacks.py:105 INFO train-abinet] epoch 0 iter 9100: loss = 0.5205,  smooth loss = 0.7198
[2022-07-04 14:21:51,334 callbacks.py:105 INFO train-abinet] epoch 0 iter 9150: loss = 0.7641,  smooth loss = 0.7266
[2022-07-04 14:22:34,496 callbacks.py:105 INFO train-abinet] epoch 0 iter 9200: loss = 0.6403,  smooth loss = 0.7270
[2022-07-04 14:23:16,647 callbacks.py:105 INFO train-abinet] epoch 0 iter 9250: loss = 0.6290,  smooth loss = 0.7145
[2022-07-04 14:24:00,459 callbacks.py:105 INFO train-abinet] epoch 0 iter 9300: loss = 0.7571,  smooth loss = 0.7162
[2022-07-04 14:24:43,539 callbacks.py:105 INFO train-abinet] epoch 0 iter 9350: loss = 0.5897,  smooth loss = 0.7115
[2022-07-04 14:25:26,040 callbacks.py:105 INFO train-abinet] epoch 0 iter 9400: loss = 0.6269,  smooth loss = 0.7235
[2022-07-04 14:26:09,128 callbacks.py:105 INFO train-abinet] epoch 0 iter 9450: loss = 0.5907,  smooth loss = 0.7204
[2022-07-04 14:26:52,515 callbacks.py:105 INFO train-abinet] epoch 0 iter 9500: loss = 0.6048,  smooth loss = 0.7173
[2022-07-04 14:27:35,161 callbacks.py:105 INFO train-abinet] epoch 0 iter 9550: loss = 0.7126,  smooth loss = 0.7306
[2022-07-04 14:28:17,585 callbacks.py:105 INFO train-abinet] epoch 0 iter 9600: loss = 0.6983,  smooth loss = 0.7135
[2022-07-04 14:28:59,820 callbacks.py:105 INFO train-abinet] epoch 0 iter 9650: loss = 0.7904,  smooth loss = 0.7168
[2022-07-04 14:29:41,080 callbacks.py:105 INFO train-abinet] epoch 0 iter 9700: loss = 0.6341,  smooth loss = 0.7132
[2022-07-04 14:30:23,851 callbacks.py:105 INFO train-abinet] epoch 0 iter 9750: loss = 0.8548,  smooth loss = 0.7241
[2022-07-04 14:31:06,042 callbacks.py:105 INFO train-abinet] epoch 0 iter 9800: loss = 0.7237,  smooth loss = 0.7177
[2022-07-04 14:31:48,314 callbacks.py:105 INFO train-abinet] epoch 0 iter 9850: loss = 0.8738,  smooth loss = 0.7196
[2022-07-04 14:32:30,546 callbacks.py:105 INFO train-abinet] epoch 0 iter 9900: loss = 0.6721,  smooth loss = 0.7162
[2022-07-04 14:33:13,679 callbacks.py:105 INFO train-abinet] epoch 0 iter 9950: loss = 0.6846,  smooth loss = 0.7159
[2022-07-04 14:33:56,895 callbacks.py:105 INFO train-abinet] epoch 0 iter 10000: loss = 0.6956,  smooth loss = 0.7063
[2022-07-04 14:34:38,785 callbacks.py:105 INFO train-abinet] epoch 0 iter 10050: loss = 0.7563,  smooth loss = 0.7073
[2022-07-04 14:35:21,554 callbacks.py:105 INFO train-abinet] epoch 0 iter 10100: loss = 0.5394,  smooth loss = 0.6936
[2022-07-04 14:36:04,256 callbacks.py:105 INFO train-abinet] epoch 0 iter 10150: loss = 0.7426,  smooth loss = 0.7097
[2022-07-04 14:36:46,210 callbacks.py:105 INFO train-abinet] epoch 0 iter 10200: loss = 0.7753,  smooth loss = 0.7099
[2022-07-04 14:37:28,893 callbacks.py:105 INFO train-abinet] epoch 0 iter 10250: loss = 0.7883,  smooth loss = 0.7102
[2022-07-04 14:38:11,856 callbacks.py:105 INFO train-abinet] epoch 0 iter 10300: loss = 0.8071,  smooth loss = 0.7161
[2022-07-04 14:38:55,146 callbacks.py:105 INFO train-abinet] epoch 0 iter 10350: loss = 0.7334,  smooth loss = 0.7184
[2022-07-04 14:39:37,084 callbacks.py:105 INFO train-abinet] epoch 0 iter 10400: loss = 0.6540,  smooth loss = 0.7264
[2022-07-04 14:40:18,589 callbacks.py:105 INFO train-abinet] epoch 0 iter 10450: loss = 0.6532,  smooth loss = 0.7113
[2022-07-04 14:41:00,855 callbacks.py:105 INFO train-abinet] epoch 0 iter 10500: loss = 0.7989,  smooth loss = 0.7104
[2022-07-04 14:41:42,712 callbacks.py:105 INFO train-abinet] epoch 0 iter 10550: loss = 0.7665,  smooth loss = 0.7127
[2022-07-04 14:42:25,717 callbacks.py:105 INFO train-abinet] epoch 0 iter 10600: loss = 0.7917,  smooth loss = 0.7142
[2022-07-04 14:43:08,095 callbacks.py:105 INFO train-abinet] epoch 0 iter 10650: loss = 0.6571,  smooth loss = 0.7176
[2022-07-04 14:43:50,757 callbacks.py:105 INFO train-abinet] epoch 0 iter 10700: loss = 0.6657,  smooth loss = 0.7111
[2022-07-04 14:44:34,365 callbacks.py:105 INFO train-abinet] epoch 0 iter 10750: loss = 0.6538,  smooth loss = 0.7064
[2022-07-04 14:45:17,089 callbacks.py:105 INFO train-abinet] epoch 0 iter 10800: loss = 0.9241,  smooth loss = 0.7019
[2022-07-04 14:45:59,685 callbacks.py:105 INFO train-abinet] epoch 0 iter 10850: loss = 0.7835,  smooth loss = 0.7160
[2022-07-04 14:46:42,827 callbacks.py:105 INFO train-abinet] epoch 0 iter 10900: loss = 0.6902,  smooth loss = 0.7108
[2022-07-04 14:47:24,862 callbacks.py:105 INFO train-abinet] epoch 0 iter 10950: loss = 0.8410,  smooth loss = 0.7194
[2022-07-04 14:48:07,693 callbacks.py:105 INFO train-abinet] epoch 0 iter 11000: loss = 0.7675,  smooth loss = 0.6872
[2022-07-04 14:48:51,138 callbacks.py:105 INFO train-abinet] epoch 0 iter 11050: loss = 0.8550,  smooth loss = 0.6937
[2022-07-04 14:49:32,465 callbacks.py:105 INFO train-abinet] epoch 0 iter 11100: loss = 0.6008,  smooth loss = 0.7066
[2022-07-04 14:50:14,135 callbacks.py:105 INFO train-abinet] epoch 0 iter 11150: loss = 0.6065,  smooth loss = 0.6944
[2022-07-04 14:50:55,912 callbacks.py:105 INFO train-abinet] epoch 0 iter 11200: loss = 0.5903,  smooth loss = 0.6890
[2022-07-04 14:51:37,666 callbacks.py:105 INFO train-abinet] epoch 0 iter 11250: loss = 0.7307,  smooth loss = 0.6922
[2022-07-04 14:52:19,806 callbacks.py:105 INFO train-abinet] epoch 0 iter 11300: loss = 0.7669,  smooth loss = 0.6988
[2022-07-04 14:53:02,336 callbacks.py:105 INFO train-abinet] epoch 0 iter 11350: loss = 0.6502,  smooth loss = 0.7017
[2022-07-04 14:53:45,042 callbacks.py:105 INFO train-abinet] epoch 0 iter 11400: loss = 0.5259,  smooth loss = 0.6872
[2022-07-04 14:54:27,983 callbacks.py:105 INFO train-abinet] epoch 0 iter 11450: loss = 0.5782,  smooth loss = 0.6975
[2022-07-04 14:55:10,713 callbacks.py:105 INFO train-abinet] epoch 0 iter 11500: loss = 0.8991,  smooth loss = 0.7113
[2022-07-04 14:55:53,165 callbacks.py:105 INFO train-abinet] epoch 0 iter 11550: loss = 0.5949,  smooth loss = 0.7106
[2022-07-04 14:56:35,586 callbacks.py:105 INFO train-abinet] epoch 0 iter 11600: loss = 0.6049,  smooth loss = 0.7071
[2022-07-04 14:57:18,630 callbacks.py:105 INFO train-abinet] epoch 0 iter 11650: loss = 0.6914,  smooth loss = 0.7010
[2022-07-04 14:58:01,875 callbacks.py:105 INFO train-abinet] epoch 0 iter 11700: loss = 0.7211,  smooth loss = 0.7064
[2022-07-04 14:58:45,156 callbacks.py:105 INFO train-abinet] epoch 0 iter 11750: loss = 0.7408,  smooth loss = 0.7163
[2022-07-04 14:59:27,592 callbacks.py:105 INFO train-abinet] epoch 0 iter 11800: loss = 0.6343,  smooth loss = 0.7034
[2022-07-04 15:00:10,827 callbacks.py:105 INFO train-abinet] epoch 0 iter 11850: loss = 0.6532,  smooth loss = 0.6936
[2022-07-04 15:00:53,200 callbacks.py:105 INFO train-abinet] epoch 0 iter 11900: loss = 0.6361,  smooth loss = 0.7104
[2022-07-04 15:01:36,275 callbacks.py:105 INFO train-abinet] epoch 0 iter 11950: loss = 0.7086,  smooth loss = 0.7145
[2022-07-04 15:02:19,426 callbacks.py:105 INFO train-abinet] epoch 0 iter 12000: loss = 0.5666,  smooth loss = 0.7012
[2022-07-04 15:02:19,426 callbacks.py:114 INFO train-abinet] average data time = 0.0078s, average running time = 0.8491s
█[2022-07-04 15:02:34,052 callbacks.py:123 INFO train-abinet] epoch 0 iter 12000: eval loss = 1.1687,  ccr = 0.9526,  cwr = 0.9094,  ted = 1484.0000,  ned = 283.9638,  ted/w = 0.2047, 
[2022-07-04 15:02:34,054 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_12000
[2022-07-04 15:03:18,010 callbacks.py:105 INFO train-abinet] epoch 0 iter 12050: loss = 0.8337,  smooth loss = 0.6921
[2022-07-04 15:04:00,827 callbacks.py:105 INFO train-abinet] epoch 0 iter 12100: loss = 0.6454,  smooth loss = 0.6971
[2022-07-04 15:04:43,562 callbacks.py:105 INFO train-abinet] epoch 0 iter 12150: loss = 0.6757,  smooth loss = 0.6941
[2022-07-04 15:05:25,851 callbacks.py:105 INFO train-abinet] epoch 0 iter 12200: loss = 0.7206,  smooth loss = 0.6913
[2022-07-04 15:06:08,148 callbacks.py:105 INFO train-abinet] epoch 0 iter 12250: loss = 0.6018,  smooth loss = 0.6995
[2022-07-04 15:06:50,484 callbacks.py:105 INFO train-abinet] epoch 0 iter 12300: loss = 0.7316,  smooth loss = 0.7041
[2022-07-04 15:07:33,153 callbacks.py:105 INFO train-abinet] epoch 0 iter 12350: loss = 0.8183,  smooth loss = 0.7057
[2022-07-04 15:08:15,542 callbacks.py:105 INFO train-abinet] epoch 0 iter 12400: loss = 0.7926,  smooth loss = 0.7187
[2022-07-04 15:08:59,033 callbacks.py:105 INFO train-abinet] epoch 0 iter 12450: loss = 0.6371,  smooth loss = 0.6901
[2022-07-04 15:09:41,785 callbacks.py:105 INFO train-abinet] epoch 0 iter 12500: loss = 0.8368,  smooth loss = 0.7014
[2022-07-04 15:10:24,526 callbacks.py:105 INFO train-abinet] epoch 0 iter 12550: loss = 0.9275,  smooth loss = 0.6904
[2022-07-04 15:11:07,013 callbacks.py:105 INFO train-abinet] epoch 0 iter 12600: loss = 0.6932,  smooth loss = 0.6925
[2022-07-04 15:11:49,347 callbacks.py:105 INFO train-abinet] epoch 0 iter 12650: loss = 0.5837,  smooth loss = 0.6999
[2022-07-04 15:12:32,214 callbacks.py:105 INFO train-abinet] epoch 0 iter 12700: loss = 0.6279,  smooth loss = 0.6875
[2022-07-04 15:13:15,654 callbacks.py:105 INFO train-abinet] epoch 0 iter 12750: loss = 0.6250,  smooth loss = 0.6958
[2022-07-04 15:13:58,489 callbacks.py:105 INFO train-abinet] epoch 0 iter 12800: loss = 0.6448,  smooth loss = 0.7046
[2022-07-04 15:14:41,488 callbacks.py:105 INFO train-abinet] epoch 0 iter 12850: loss = 0.6419,  smooth loss = 0.6887
[2022-07-04 15:15:23,919 callbacks.py:105 INFO train-abinet] epoch 0 iter 12900: loss = 0.6346,  smooth loss = 0.7113
[2022-07-04 15:16:05,943 callbacks.py:105 INFO train-abinet] epoch 0 iter 12950: loss = 0.6903,  smooth loss = 0.6938
[2022-07-04 15:16:48,044 callbacks.py:105 INFO train-abinet] epoch 0 iter 13000: loss = 0.7858,  smooth loss = 0.6899
[2022-07-04 15:17:31,134 callbacks.py:105 INFO train-abinet] epoch 0 iter 13050: loss = 0.6506,  smooth loss = 0.6940
[2022-07-04 15:18:13,264 callbacks.py:105 INFO train-abinet] epoch 0 iter 13100: loss = 0.8470,  smooth loss = 0.7054
[2022-07-04 15:18:55,660 callbacks.py:105 INFO train-abinet] epoch 0 iter 13150: loss = 0.7093,  smooth loss = 0.6861
[2022-07-04 15:19:38,694 callbacks.py:105 INFO train-abinet] epoch 0 iter 13200: loss = 0.4843,  smooth loss = 0.6811
[2022-07-04 15:20:21,223 callbacks.py:105 INFO train-abinet] epoch 0 iter 13250: loss = 0.7310,  smooth loss = 0.6911
[2022-07-04 15:21:03,146 callbacks.py:105 INFO train-abinet] epoch 0 iter 13300: loss = 0.6536,  smooth loss = 0.7058
[2022-07-04 15:21:45,813 callbacks.py:105 INFO train-abinet] epoch 0 iter 13350: loss = 0.8076,  smooth loss = 0.6949
[2022-07-04 15:22:28,449 callbacks.py:105 INFO train-abinet] epoch 0 iter 13400: loss = 0.7748,  smooth loss = 0.6969
[2022-07-04 15:23:10,348 callbacks.py:105 INFO train-abinet] epoch 0 iter 13450: loss = 0.5933,  smooth loss = 0.7003
[2022-07-04 15:23:52,239 callbacks.py:105 INFO train-abinet] epoch 0 iter 13500: loss = 0.5887,  smooth loss = 0.7069
[2022-07-04 15:24:34,763 callbacks.py:105 INFO train-abinet] epoch 0 iter 13550: loss = 0.6536,  smooth loss = 0.6931
[2022-07-04 15:25:16,062 callbacks.py:105 INFO train-abinet] epoch 0 iter 13600: loss = 0.7656,  smooth loss = 0.6966
[2022-07-04 15:25:58,044 callbacks.py:105 INFO train-abinet] epoch 0 iter 13650: loss = 0.4892,  smooth loss = 0.7096
[2022-07-04 15:26:41,434 callbacks.py:105 INFO train-abinet] epoch 0 iter 13700: loss = 0.7337,  smooth loss = 0.7094
[2022-07-04 15:27:24,030 callbacks.py:105 INFO train-abinet] epoch 0 iter 13750: loss = 0.7892,  smooth loss = 0.7121
[2022-07-04 15:28:06,372 callbacks.py:105 INFO train-abinet] epoch 0 iter 13800: loss = 0.7948,  smooth loss = 0.7064
[2022-07-04 15:28:48,867 callbacks.py:105 INFO train-abinet] epoch 0 iter 13850: loss = 0.6103,  smooth loss = 0.7090
[2022-07-04 15:29:31,416 callbacks.py:105 INFO train-abinet] epoch 0 iter 13900: loss = 0.7432,  smooth loss = 0.6984
[2022-07-04 15:30:14,197 callbacks.py:105 INFO train-abinet] epoch 0 iter 13950: loss = 0.7081,  smooth loss = 0.6925
[2022-07-04 15:30:57,215 callbacks.py:105 INFO train-abinet] epoch 0 iter 14000: loss = 0.7733,  smooth loss = 0.6879
[2022-07-04 15:31:39,342 callbacks.py:105 INFO train-abinet] epoch 0 iter 14050: loss = 0.7750,  smooth loss = 0.6881
[2022-07-04 15:32:22,060 callbacks.py:105 INFO train-abinet] epoch 0 iter 14100: loss = 0.5557,  smooth loss = 0.7015
[2022-07-04 15:33:04,596 callbacks.py:105 INFO train-abinet] epoch 0 iter 14150: loss = 0.5763,  smooth loss = 0.6787
[2022-07-04 15:33:46,645 callbacks.py:105 INFO train-abinet] epoch 0 iter 14200: loss = 0.8186,  smooth loss = 0.6896
[2022-07-04 15:34:28,746 callbacks.py:105 INFO train-abinet] epoch 0 iter 14250: loss = 0.6371,  smooth loss = 0.6882
[2022-07-04 15:35:11,310 callbacks.py:105 INFO train-abinet] epoch 0 iter 14300: loss = 0.9373,  smooth loss = 0.7156
[2022-07-04 15:35:54,059 callbacks.py:105 INFO train-abinet] epoch 0 iter 14350: loss = 0.7189,  smooth loss = 0.7059
[2022-07-04 15:36:36,785 callbacks.py:105 INFO train-abinet] epoch 0 iter 14400: loss = 0.6227,  smooth loss = 0.6896
[2022-07-04 15:37:19,105 callbacks.py:105 INFO train-abinet] epoch 0 iter 14450: loss = 0.7086,  smooth loss = 0.7035
[2022-07-04 15:38:00,270 callbacks.py:105 INFO train-abinet] epoch 0 iter 14500: loss = 0.6236,  smooth loss = 0.6970
[2022-07-04 15:38:43,203 callbacks.py:105 INFO train-abinet] epoch 0 iter 14550: loss = 0.7026,  smooth loss = 0.7114
[2022-07-04 15:39:25,326 callbacks.py:105 INFO train-abinet] epoch 0 iter 14600: loss = 0.5242,  smooth loss = 0.6851
[2022-07-04 15:40:06,573 callbacks.py:105 INFO train-abinet] epoch 0 iter 14650: loss = 0.7289,  smooth loss = 0.6900
[2022-07-04 15:40:48,574 callbacks.py:105 INFO train-abinet] epoch 0 iter 14700: loss = 0.8400,  smooth loss = 0.6877
[2022-07-04 15:41:30,007 callbacks.py:105 INFO train-abinet] epoch 0 iter 14750: loss = 0.6365,  smooth loss = 0.6802
[2022-07-04 15:42:11,628 callbacks.py:105 INFO train-abinet] epoch 0 iter 14800: loss = 0.5786,  smooth loss = 0.6747
[2022-07-04 15:42:52,620 callbacks.py:105 INFO train-abinet] epoch 0 iter 14850: loss = 0.6222,  smooth loss = 0.6869
[2022-07-04 15:43:33,763 callbacks.py:105 INFO train-abinet] epoch 0 iter 14900: loss = 0.6275,  smooth loss = 0.6818
[2022-07-04 15:44:14,979 callbacks.py:105 INFO train-abinet] epoch 0 iter 14950: loss = 0.6214,  smooth loss = 0.6858
[2022-07-04 15:44:56,613 callbacks.py:105 INFO train-abinet] epoch 0 iter 15000: loss = 0.7765,  smooth loss = 0.6932
[2022-07-04 15:44:56,613 callbacks.py:114 INFO train-abinet] average data time = 0.0070s, average running time = 0.8489s
█[2022-07-04 15:45:10,849 callbacks.py:123 INFO train-abinet] epoch 0 iter 15000: eval loss = 1.1459,  ccr = 0.9546,  cwr = 0.9070,  ted = 1513.0000,  ned = 294.1881,  ted/w = 0.2087, 
[2022-07-04 15:45:10,849 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_15000
[2022-07-04 15:45:53,358 callbacks.py:105 INFO train-abinet] epoch 0 iter 15050: loss = 0.6604,  smooth loss = 0.6883
[2022-07-04 15:46:36,162 callbacks.py:105 INFO train-abinet] epoch 0 iter 15100: loss = 0.6460,  smooth loss = 0.6883
[2022-07-04 15:47:18,013 callbacks.py:105 INFO train-abinet] epoch 0 iter 15150: loss = 0.6953,  smooth loss = 0.6806
[2022-07-04 15:47:59,927 callbacks.py:105 INFO train-abinet] epoch 0 iter 15200: loss = 0.6380,  smooth loss = 0.6838
[2022-07-04 15:48:41,599 callbacks.py:105 INFO train-abinet] epoch 0 iter 15250: loss = 0.5917,  smooth loss = 0.6850
[2022-07-04 15:49:23,172 callbacks.py:105 INFO train-abinet] epoch 0 iter 15300: loss = 0.6308,  smooth loss = 0.6930
[2022-07-04 15:50:04,452 callbacks.py:105 INFO train-abinet] epoch 0 iter 15350: loss = 0.5932,  smooth loss = 0.6719
[2022-07-04 15:50:45,684 callbacks.py:105 INFO train-abinet] epoch 0 iter 15400: loss = 0.6893,  smooth loss = 0.6894
[2022-07-04 15:51:27,936 callbacks.py:105 INFO train-abinet] epoch 0 iter 15450: loss = 0.5910,  smooth loss = 0.6749
[2022-07-04 15:52:08,942 callbacks.py:105 INFO train-abinet] epoch 0 iter 15500: loss = 0.6421,  smooth loss = 0.6801
[2022-07-04 15:52:51,325 callbacks.py:105 INFO train-abinet] epoch 0 iter 15550: loss = 0.7270,  smooth loss = 0.6934
[2022-07-04 15:53:33,465 callbacks.py:105 INFO train-abinet] epoch 0 iter 15600: loss = 0.6729,  smooth loss = 0.6765
[2022-07-04 15:54:14,985 callbacks.py:105 INFO train-abinet] epoch 0 iter 15650: loss = 0.7406,  smooth loss = 0.6749
[2022-07-04 15:54:57,499 callbacks.py:105 INFO train-abinet] epoch 0 iter 15700: loss = 0.6623,  smooth loss = 0.6939
[2022-07-04 15:55:39,876 callbacks.py:105 INFO train-abinet] epoch 0 iter 15750: loss = 0.8012,  smooth loss = 0.6970
[2022-07-04 15:56:20,936 callbacks.py:105 INFO train-abinet] epoch 0 iter 15800: loss = 0.5416,  smooth loss = 0.6861
[2022-07-04 15:57:02,994 callbacks.py:105 INFO train-abinet] epoch 0 iter 15850: loss = 0.7950,  smooth loss = 0.6883
[2022-07-04 15:57:43,911 callbacks.py:105 INFO train-abinet] epoch 0 iter 15900: loss = 0.6088,  smooth loss = 0.6881
[2022-07-04 15:58:25,838 callbacks.py:105 INFO train-abinet] epoch 0 iter 15950: loss = 0.7014,  smooth loss = 0.6927
[2022-07-04 15:59:07,973 callbacks.py:105 INFO train-abinet] epoch 0 iter 16000: loss = 0.7120,  smooth loss = 0.6785
[2022-07-04 15:59:49,940 callbacks.py:105 INFO train-abinet] epoch 0 iter 16050: loss = 0.8073,  smooth loss = 0.6953
[2022-07-04 16:00:31,035 callbacks.py:105 INFO train-abinet] epoch 0 iter 16100: loss = 0.5852,  smooth loss = 0.7019
[2022-07-04 16:01:12,620 callbacks.py:105 INFO train-abinet] epoch 0 iter 16150: loss = 0.7207,  smooth loss = 0.6874
[2022-07-04 16:01:54,595 callbacks.py:105 INFO train-abinet] epoch 0 iter 16200: loss = 0.6916,  smooth loss = 0.6966
[2022-07-04 16:02:35,019 callbacks.py:105 INFO train-abinet] epoch 0 iter 16250: loss = 0.5857,  smooth loss = 0.6845
[2022-07-04 16:03:16,074 callbacks.py:105 INFO train-abinet] epoch 0 iter 16300: loss = 0.6767,  smooth loss = 0.6811
[2022-07-04 16:03:57,133 callbacks.py:105 INFO train-abinet] epoch 0 iter 16350: loss = 0.7428,  smooth loss = 0.6936
[2022-07-04 16:04:38,632 callbacks.py:105 INFO train-abinet] epoch 0 iter 16400: loss = 0.7340,  smooth loss = 0.6940
[2022-07-04 16:05:19,527 callbacks.py:105 INFO train-abinet] epoch 0 iter 16450: loss = 0.6796,  smooth loss = 0.6804
[2022-07-04 16:06:00,837 callbacks.py:105 INFO train-abinet] epoch 0 iter 16500: loss = 0.6966,  smooth loss = 0.6904
[2022-07-04 16:06:42,128 callbacks.py:105 INFO train-abinet] epoch 0 iter 16550: loss = 0.5566,  smooth loss = 0.6767
[2022-07-04 16:07:23,705 callbacks.py:105 INFO train-abinet] epoch 0 iter 16600: loss = 0.6579,  smooth loss = 0.6874
[2022-07-04 16:08:04,974 callbacks.py:105 INFO train-abinet] epoch 0 iter 16650: loss = 0.6521,  smooth loss = 0.6741
[2022-07-04 16:08:46,926 callbacks.py:105 INFO train-abinet] epoch 0 iter 16700: loss = 0.6795,  smooth loss = 0.6892
[2022-07-04 16:09:28,287 callbacks.py:105 INFO train-abinet] epoch 0 iter 16750: loss = 0.6059,  smooth loss = 0.6907
[2022-07-04 16:10:10,259 callbacks.py:105 INFO train-abinet] epoch 0 iter 16800: loss = 0.5826,  smooth loss = 0.6848
[2022-07-04 16:10:51,128 callbacks.py:105 INFO train-abinet] epoch 0 iter 16850: loss = 0.5855,  smooth loss = 0.6891
[2022-07-04 16:11:32,419 callbacks.py:105 INFO train-abinet] epoch 0 iter 16900: loss = 0.6122,  smooth loss = 0.6729
[2022-07-04 16:12:13,596 callbacks.py:105 INFO train-abinet] epoch 0 iter 16950: loss = 0.6660,  smooth loss = 0.6891
[2022-07-04 16:12:54,972 callbacks.py:105 INFO train-abinet] epoch 0 iter 17000: loss = 0.7094,  smooth loss = 0.6770
[2022-07-04 16:13:35,761 callbacks.py:105 INFO train-abinet] epoch 0 iter 17050: loss = 0.7172,  smooth loss = 0.6899
[2022-07-04 16:14:17,965 callbacks.py:105 INFO train-abinet] epoch 0 iter 17100: loss = 0.5845,  smooth loss = 0.6742
[2022-07-04 16:14:59,938 callbacks.py:105 INFO train-abinet] epoch 0 iter 17150: loss = 0.6478,  smooth loss = 0.6805
[2022-07-04 16:15:41,481 callbacks.py:105 INFO train-abinet] epoch 0 iter 17200: loss = 0.7537,  smooth loss = 0.6867
[2022-07-04 16:16:23,104 callbacks.py:105 INFO train-abinet] epoch 0 iter 17250: loss = 0.7739,  smooth loss = 0.6661
[2022-07-04 16:17:04,924 callbacks.py:105 INFO train-abinet] epoch 0 iter 17300: loss = 0.7890,  smooth loss = 0.6707
[2022-07-04 16:17:46,924 callbacks.py:105 INFO train-abinet] epoch 0 iter 17350: loss = 0.6911,  smooth loss = 0.6805
[2022-07-04 16:18:28,553 callbacks.py:105 INFO train-abinet] epoch 0 iter 17400: loss = 0.6270,  smooth loss = 0.6831
[2022-07-04 16:19:10,447 callbacks.py:105 INFO train-abinet] epoch 0 iter 17450: loss = 0.6250,  smooth loss = 0.6819
[2022-07-04 16:19:52,379 callbacks.py:105 INFO train-abinet] epoch 0 iter 17500: loss = 0.8297,  smooth loss = 0.6850
[2022-07-04 16:20:34,460 callbacks.py:105 INFO train-abinet] epoch 0 iter 17550: loss = 0.6177,  smooth loss = 0.6967
[2022-07-04 16:21:15,504 callbacks.py:105 INFO train-abinet] epoch 0 iter 17600: loss = 0.6094,  smooth loss = 0.6723
[2022-07-04 16:21:56,972 callbacks.py:105 INFO train-abinet] epoch 0 iter 17650: loss = 0.7898,  smooth loss = 0.6840
[2022-07-04 16:22:38,533 callbacks.py:105 INFO train-abinet] epoch 0 iter 17700: loss = 0.6218,  smooth loss = 0.6808
[2022-07-04 16:23:19,417 callbacks.py:105 INFO train-abinet] epoch 0 iter 17750: loss = 0.7380,  smooth loss = 0.6777
[2022-07-04 16:24:02,020 callbacks.py:105 INFO train-abinet] epoch 0 iter 17800: loss = 0.6768,  smooth loss = 0.6968
[2022-07-04 16:24:43,250 callbacks.py:105 INFO train-abinet] epoch 0 iter 17850: loss = 0.6700,  smooth loss = 0.6935
[2022-07-04 16:25:25,163 callbacks.py:105 INFO train-abinet] epoch 0 iter 17900: loss = 0.6411,  smooth loss = 0.6720
[2022-07-04 16:26:06,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 17950: loss = 0.6695,  smooth loss = 0.6849
[2022-07-04 16:26:47,971 callbacks.py:105 INFO train-abinet] epoch 0 iter 18000: loss = 0.5909,  smooth loss = 0.6719
[2022-07-04 16:26:47,972 callbacks.py:114 INFO train-abinet] average data time = 0.0065s, average running time = 0.8463s
█[2022-07-04 16:27:02,586 callbacks.py:123 INFO train-abinet] epoch 0 iter 18000: eval loss = 1.1567,  ccr = 0.9547,  cwr = 0.9099,  ted = 1453.0000,  ned = 285.8021,  ted/w = 0.2005, 
[2022-07-04 16:27:02,587 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_18000
[2022-07-04 16:27:44,560 callbacks.py:105 INFO train-abinet] epoch 0 iter 18050: loss = 0.7417,  smooth loss = 0.6845
[2022-07-04 16:28:26,489 callbacks.py:105 INFO train-abinet] epoch 0 iter 18100: loss = 0.7571,  smooth loss = 0.6708
[2022-07-04 16:29:08,011 callbacks.py:105 INFO train-abinet] epoch 0 iter 18150: loss = 0.5943,  smooth loss = 0.6641
[2022-07-04 16:29:49,897 callbacks.py:105 INFO train-abinet] epoch 0 iter 18200: loss = 0.6667,  smooth loss = 0.6635
[2022-07-04 16:30:31,707 callbacks.py:105 INFO train-abinet] epoch 0 iter 18250: loss = 0.6803,  smooth loss = 0.6717
[2022-07-04 16:31:13,057 callbacks.py:105 INFO train-abinet] epoch 0 iter 18300: loss = 0.7487,  smooth loss = 0.6813
[2022-07-04 16:31:54,256 callbacks.py:105 INFO train-abinet] epoch 0 iter 18350: loss = 0.7133,  smooth loss = 0.6804
[2022-07-04 16:32:35,882 callbacks.py:105 INFO train-abinet] epoch 0 iter 18400: loss = 0.5869,  smooth loss = 0.6708
[2022-07-04 16:33:17,083 callbacks.py:105 INFO train-abinet] epoch 0 iter 18450: loss = 0.8708,  smooth loss = 0.6741
[2022-07-04 16:33:58,721 callbacks.py:105 INFO train-abinet] epoch 0 iter 18500: loss = 0.6569,  smooth loss = 0.6909
[2022-07-04 16:34:40,663 callbacks.py:105 INFO train-abinet] epoch 0 iter 18550: loss = 0.8139,  smooth loss = 0.6772
[2022-07-04 16:35:21,775 callbacks.py:105 INFO train-abinet] epoch 0 iter 18600: loss = 0.6621,  smooth loss = 0.6951
[2022-07-04 16:36:02,948 callbacks.py:105 INFO train-abinet] epoch 0 iter 18650: loss = 0.5825,  smooth loss = 0.6761
[2022-07-04 16:36:44,102 callbacks.py:105 INFO train-abinet] epoch 0 iter 18700: loss = 0.6254,  smooth loss = 0.6631
[2022-07-04 16:37:25,088 callbacks.py:105 INFO train-abinet] epoch 0 iter 18750: loss = 0.7866,  smooth loss = 0.6763
[2022-07-04 16:38:06,497 callbacks.py:105 INFO train-abinet] epoch 0 iter 18800: loss = 0.6957,  smooth loss = 0.6620
[2022-07-04 16:38:48,182 callbacks.py:105 INFO train-abinet] epoch 0 iter 18850: loss = 0.7105,  smooth loss = 0.6793
[2022-07-04 16:39:30,128 callbacks.py:105 INFO train-abinet] epoch 0 iter 18900: loss = 0.6284,  smooth loss = 0.6707
[2022-07-04 16:40:12,223 callbacks.py:105 INFO train-abinet] epoch 0 iter 18950: loss = 0.6107,  smooth loss = 0.6667
[2022-07-04 16:40:53,640 callbacks.py:105 INFO train-abinet] epoch 0 iter 19000: loss = 0.6363,  smooth loss = 0.6814
[2022-07-04 16:41:34,736 callbacks.py:105 INFO train-abinet] epoch 0 iter 19050: loss = 0.5942,  smooth loss = 0.6725
[2022-07-04 16:42:16,487 callbacks.py:105 INFO train-abinet] epoch 0 iter 19100: loss = 0.6864,  smooth loss = 0.6891
[2022-07-04 16:42:58,555 callbacks.py:105 INFO train-abinet] epoch 0 iter 19150: loss = 0.7013,  smooth loss = 0.6790
[2022-07-04 16:43:39,878 callbacks.py:105 INFO train-abinet] epoch 0 iter 19200: loss = 0.7821,  smooth loss = 0.6759
[2022-07-04 16:44:21,005 callbacks.py:105 INFO train-abinet] epoch 0 iter 19250: loss = 0.8376,  smooth loss = 0.6663
[2022-07-04 16:45:02,918 callbacks.py:105 INFO train-abinet] epoch 0 iter 19300: loss = 0.7081,  smooth loss = 0.6693
[2022-07-04 16:45:44,576 callbacks.py:105 INFO train-abinet] epoch 0 iter 19350: loss = 0.5151,  smooth loss = 0.6766
[2022-07-04 16:46:26,608 callbacks.py:105 INFO train-abinet] epoch 0 iter 19400: loss = 0.6133,  smooth loss = 0.6775
[2022-07-04 16:47:08,025 callbacks.py:105 INFO train-abinet] epoch 0 iter 19450: loss = 0.5870,  smooth loss = 0.6775
[2022-07-04 16:47:49,599 callbacks.py:105 INFO train-abinet] epoch 0 iter 19500: loss = 0.6072,  smooth loss = 0.6879
[2022-07-04 16:48:31,637 callbacks.py:105 INFO train-abinet] epoch 0 iter 19550: loss = 0.5217,  smooth loss = 0.6768
[2022-07-04 16:49:12,861 callbacks.py:105 INFO train-abinet] epoch 0 iter 19600: loss = 0.7736,  smooth loss = 0.6815
[2022-07-04 16:49:55,400 callbacks.py:105 INFO train-abinet] epoch 0 iter 19650: loss = 0.5980,  smooth loss = 0.6677
[2022-07-04 16:50:37,075 callbacks.py:105 INFO train-abinet] epoch 0 iter 19700: loss = 0.8232,  smooth loss = 0.6750
[2022-07-04 16:51:18,701 callbacks.py:105 INFO train-abinet] epoch 0 iter 19750: loss = 0.6719,  smooth loss = 0.6833
[2022-07-04 16:52:00,651 callbacks.py:105 INFO train-abinet] epoch 0 iter 19800: loss = 0.6832,  smooth loss = 0.6782
[2022-07-04 16:52:42,202 callbacks.py:105 INFO train-abinet] epoch 0 iter 19850: loss = 0.7660,  smooth loss = 0.6878
[2022-07-04 16:53:23,277 callbacks.py:105 INFO train-abinet] epoch 0 iter 19900: loss = 0.6189,  smooth loss = 0.6622
[2022-07-04 16:54:05,203 callbacks.py:105 INFO train-abinet] epoch 0 iter 19950: loss = 0.5485,  smooth loss = 0.6661
[2022-07-04 16:54:46,953 callbacks.py:105 INFO train-abinet] epoch 0 iter 20000: loss = 0.5347,  smooth loss = 0.6635
[2022-07-04 16:55:29,101 callbacks.py:105 INFO train-abinet] epoch 0 iter 20050: loss = 0.6387,  smooth loss = 0.6686
[2022-07-04 16:56:09,833 callbacks.py:105 INFO train-abinet] epoch 0 iter 20100: loss = 0.8072,  smooth loss = 0.6742
[2022-07-04 16:56:51,260 callbacks.py:105 INFO train-abinet] epoch 0 iter 20150: loss = 0.5611,  smooth loss = 0.6821
[2022-07-04 16:57:33,877 callbacks.py:105 INFO train-abinet] epoch 0 iter 20200: loss = 0.6005,  smooth loss = 0.6676
[2022-07-04 16:58:16,088 callbacks.py:105 INFO train-abinet] epoch 0 iter 20250: loss = 0.5862,  smooth loss = 0.6785
[2022-07-04 16:58:57,571 callbacks.py:105 INFO train-abinet] epoch 0 iter 20300: loss = 0.5796,  smooth loss = 0.6758
[2022-07-04 16:59:39,035 callbacks.py:105 INFO train-abinet] epoch 0 iter 20350: loss = 0.6056,  smooth loss = 0.6750
[2022-07-04 17:00:20,645 callbacks.py:105 INFO train-abinet] epoch 0 iter 20400: loss = 0.5917,  smooth loss = 0.6662
[2022-07-04 17:01:01,602 callbacks.py:105 INFO train-abinet] epoch 0 iter 20450: loss = 0.7234,  smooth loss = 0.6663
[2022-07-04 17:01:43,010 callbacks.py:105 INFO train-abinet] epoch 0 iter 20500: loss = 0.5812,  smooth loss = 0.6689
[2022-07-04 17:02:24,509 callbacks.py:105 INFO train-abinet] epoch 0 iter 20550: loss = 0.5015,  smooth loss = 0.6719
[2022-07-04 17:03:06,636 callbacks.py:105 INFO train-abinet] epoch 0 iter 20600: loss = 0.6387,  smooth loss = 0.6672
[2022-07-04 17:03:48,736 callbacks.py:105 INFO train-abinet] epoch 0 iter 20650: loss = 0.6226,  smooth loss = 0.6681
[2022-07-04 17:04:30,015 callbacks.py:105 INFO train-abinet] epoch 0 iter 20700: loss = 0.6059,  smooth loss = 0.6573
[2022-07-04 17:05:11,477 callbacks.py:105 INFO train-abinet] epoch 0 iter 20750: loss = 0.6228,  smooth loss = 0.6710
[2022-07-04 17:05:52,653 callbacks.py:105 INFO train-abinet] epoch 0 iter 20800: loss = 0.5628,  smooth loss = 0.6724
[2022-07-04 17:06:33,888 callbacks.py:105 INFO train-abinet] epoch 0 iter 20850: loss = 0.6729,  smooth loss = 0.6685
[2022-07-04 17:07:15,078 callbacks.py:105 INFO train-abinet] epoch 0 iter 20900: loss = 0.7376,  smooth loss = 0.6776
[2022-07-04 17:07:57,337 callbacks.py:105 INFO train-abinet] epoch 0 iter 20950: loss = 0.7752,  smooth loss = 0.6834
[2022-07-04 17:08:39,469 callbacks.py:105 INFO train-abinet] epoch 0 iter 21000: loss = 0.9268,  smooth loss = 0.6815
[2022-07-04 17:08:39,469 callbacks.py:114 INFO train-abinet] average data time = 0.0062s, average running time = 0.8444s
█[2022-07-04 17:08:53,930 callbacks.py:123 INFO train-abinet] epoch 0 iter 21000: eval loss = 1.1577,  ccr = 0.9557,  cwr = 0.9089,  ted = 1470.0000,  ned = 294.9817,  ted/w = 0.2028, 
[2022-07-04 17:08:53,933 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_21000
[2022-07-04 17:09:37,053 callbacks.py:105 INFO train-abinet] epoch 0 iter 21050: loss = 0.5609,  smooth loss = 0.6561
[2022-07-04 17:10:18,205 callbacks.py:105 INFO train-abinet] epoch 0 iter 21100: loss = 0.5623,  smooth loss = 0.6614
[2022-07-04 17:11:00,256 callbacks.py:105 INFO train-abinet] epoch 0 iter 21150: loss = 0.7208,  smooth loss = 0.6649
[2022-07-04 17:11:42,176 callbacks.py:105 INFO train-abinet] epoch 0 iter 21200: loss = 0.8360,  smooth loss = 0.6763
[2022-07-04 17:12:24,647 callbacks.py:105 INFO train-abinet] epoch 0 iter 21250: loss = 0.7063,  smooth loss = 0.6714
[2022-07-04 17:13:05,887 callbacks.py:105 INFO train-abinet] epoch 0 iter 21300: loss = 0.7618,  smooth loss = 0.6675
[2022-07-04 17:13:47,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 21350: loss = 0.5629,  smooth loss = 0.6615
[2022-07-04 17:14:29,560 callbacks.py:105 INFO train-abinet] epoch 0 iter 21400: loss = 0.7329,  smooth loss = 0.6560
[2022-07-04 17:15:11,808 callbacks.py:105 INFO train-abinet] epoch 0 iter 21450: loss = 0.5302,  smooth loss = 0.6538
[2022-07-04 17:15:53,504 callbacks.py:105 INFO train-abinet] epoch 0 iter 21500: loss = 0.6436,  smooth loss = 0.6518
[2022-07-04 17:16:34,988 callbacks.py:105 INFO train-abinet] epoch 0 iter 21550: loss = 0.6318,  smooth loss = 0.6659
[2022-07-04 17:17:16,542 callbacks.py:105 INFO train-abinet] epoch 0 iter 21600: loss = 0.7123,  smooth loss = 0.6589
[2022-07-04 17:17:57,459 callbacks.py:105 INFO train-abinet] epoch 0 iter 21650: loss = 0.8375,  smooth loss = 0.6627
[2022-07-04 17:18:39,307 callbacks.py:105 INFO train-abinet] epoch 0 iter 21700: loss = 0.7794,  smooth loss = 0.6638
[2022-07-04 17:19:21,864 callbacks.py:105 INFO train-abinet] epoch 0 iter 21750: loss = 0.5770,  smooth loss = 0.6741
[2022-07-04 17:20:03,031 callbacks.py:105 INFO train-abinet] epoch 0 iter 21800: loss = 0.7417,  smooth loss = 0.6731
[2022-07-04 17:20:44,505 callbacks.py:105 INFO train-abinet] epoch 0 iter 21850: loss = 0.6094,  smooth loss = 0.6582
[2022-07-04 17:21:25,178 callbacks.py:105 INFO train-abinet] epoch 0 iter 21900: loss = 0.6867,  smooth loss = 0.6789
[2022-07-04 17:22:07,360 callbacks.py:105 INFO train-abinet] epoch 0 iter 21950: loss = 0.8128,  smooth loss = 0.6780
[2022-07-04 17:22:48,831 callbacks.py:105 INFO train-abinet] epoch 0 iter 22000: loss = 0.6176,  smooth loss = 0.6729
[2022-07-04 17:23:29,844 callbacks.py:105 INFO train-abinet] epoch 0 iter 22050: loss = 0.6341,  smooth loss = 0.6599
[2022-07-04 17:24:11,720 callbacks.py:105 INFO train-abinet] epoch 0 iter 22100: loss = 0.6009,  smooth loss = 0.6598
[2022-07-04 17:24:53,270 callbacks.py:105 INFO train-abinet] epoch 0 iter 22150: loss = 0.8337,  smooth loss = 0.6729
[2022-07-04 17:25:34,633 callbacks.py:105 INFO train-abinet] epoch 0 iter 22200: loss = 0.6504,  smooth loss = 0.6665
[2022-07-04 17:26:16,270 callbacks.py:105 INFO train-abinet] epoch 0 iter 22250: loss = 0.5242,  smooth loss = 0.6712
[2022-07-04 17:26:58,161 callbacks.py:105 INFO train-abinet] epoch 0 iter 22300: loss = 0.6288,  smooth loss = 0.6724
[2022-07-04 17:27:39,677 callbacks.py:105 INFO train-abinet] epoch 0 iter 22350: loss = 0.5151,  smooth loss = 0.6709
[2022-07-04 17:28:22,129 callbacks.py:105 INFO train-abinet] epoch 0 iter 22400: loss = 0.5690,  smooth loss = 0.6630
[2022-07-04 17:29:03,710 callbacks.py:105 INFO train-abinet] epoch 0 iter 22450: loss = 0.5679,  smooth loss = 0.6645
[2022-07-04 17:29:45,724 callbacks.py:105 INFO train-abinet] epoch 0 iter 22500: loss = 0.6391,  smooth loss = 0.6754
[2022-07-04 17:30:27,401 callbacks.py:105 INFO train-abinet] epoch 0 iter 22550: loss = 0.7456,  smooth loss = 0.6728
[2022-07-04 17:31:09,024 callbacks.py:105 INFO train-abinet] epoch 0 iter 22600: loss = 0.7127,  smooth loss = 0.6725
[2022-07-04 17:31:50,617 callbacks.py:105 INFO train-abinet] epoch 0 iter 22650: loss = 0.6360,  smooth loss = 0.6755
[2022-07-04 17:32:32,085 callbacks.py:105 INFO train-abinet] epoch 0 iter 22700: loss = 0.6913,  smooth loss = 0.6812
[2022-07-04 17:33:14,352 callbacks.py:105 INFO train-abinet] epoch 0 iter 22750: loss = 0.8632,  smooth loss = 0.6691
[2022-07-04 17:33:56,939 callbacks.py:105 INFO train-abinet] epoch 0 iter 22800: loss = 0.8259,  smooth loss = 0.6918
[2022-07-04 17:34:38,176 callbacks.py:105 INFO train-abinet] epoch 0 iter 22850: loss = 0.6238,  smooth loss = 0.6831
[2022-07-04 17:35:20,046 callbacks.py:105 INFO train-abinet] epoch 0 iter 22900: loss = 0.6357,  smooth loss = 0.6690
[2022-07-04 17:36:03,255 callbacks.py:105 INFO train-abinet] epoch 0 iter 22950: loss = 0.8017,  smooth loss = 0.6587
[2022-07-04 17:36:45,859 callbacks.py:105 INFO train-abinet] epoch 0 iter 23000: loss = 0.7558,  smooth loss = 0.6886
[2022-07-04 17:37:27,769 callbacks.py:105 INFO train-abinet] epoch 0 iter 23050: loss = 0.5937,  smooth loss = 0.6672
[2022-07-04 17:38:09,182 callbacks.py:105 INFO train-abinet] epoch 0 iter 23100: loss = 0.7359,  smooth loss = 0.6688
[2022-07-04 17:38:51,194 callbacks.py:105 INFO train-abinet] epoch 0 iter 23150: loss = 0.6743,  smooth loss = 0.6589
[2022-07-04 17:39:33,789 callbacks.py:105 INFO train-abinet] epoch 0 iter 23200: loss = 0.5835,  smooth loss = 0.6586
[2022-07-04 17:40:15,353 callbacks.py:105 INFO train-abinet] epoch 0 iter 23250: loss = 0.7026,  smooth loss = 0.6542
[2022-07-04 17:40:56,976 callbacks.py:105 INFO train-abinet] epoch 0 iter 23300: loss = 0.6345,  smooth loss = 0.6594
[2022-07-04 17:41:39,387 callbacks.py:105 INFO train-abinet] epoch 0 iter 23350: loss = 0.5487,  smooth loss = 0.6792
[2022-07-04 17:42:21,413 callbacks.py:105 INFO train-abinet] epoch 0 iter 23400: loss = 0.6855,  smooth loss = 0.6719
[2022-07-04 17:43:04,129 callbacks.py:105 INFO train-abinet] epoch 0 iter 23450: loss = 0.7382,  smooth loss = 0.6786
[2022-07-04 17:43:46,164 callbacks.py:105 INFO train-abinet] epoch 0 iter 23500: loss = 0.6107,  smooth loss = 0.6725
[2022-07-04 17:44:29,320 callbacks.py:105 INFO train-abinet] epoch 0 iter 23550: loss = 0.5982,  smooth loss = 0.6670
[2022-07-04 17:45:10,890 callbacks.py:105 INFO train-abinet] epoch 0 iter 23600: loss = 0.7039,  smooth loss = 0.6794
[2022-07-04 17:45:53,254 callbacks.py:105 INFO train-abinet] epoch 0 iter 23650: loss = 0.5990,  smooth loss = 0.6637
[2022-07-04 17:46:35,515 callbacks.py:105 INFO train-abinet] epoch 0 iter 23700: loss = 0.6411,  smooth loss = 0.6692
[2022-07-04 17:47:18,066 callbacks.py:105 INFO train-abinet] epoch 0 iter 23750: loss = 0.6498,  smooth loss = 0.6558
[2022-07-04 17:48:00,440 callbacks.py:105 INFO train-abinet] epoch 0 iter 23800: loss = 0.7382,  smooth loss = 0.6698
[2022-07-04 17:48:42,366 callbacks.py:105 INFO train-abinet] epoch 0 iter 23850: loss = 0.6201,  smooth loss = 0.6658
[2022-07-04 17:49:24,796 callbacks.py:105 INFO train-abinet] epoch 0 iter 23900: loss = 0.6035,  smooth loss = 0.6570
[2022-07-04 17:50:06,819 callbacks.py:105 INFO train-abinet] epoch 0 iter 23950: loss = 0.5219,  smooth loss = 0.6708
[2022-07-04 17:50:48,697 callbacks.py:105 INFO train-abinet] epoch 0 iter 24000: loss = 0.7456,  smooth loss = 0.6687
[2022-07-04 17:50:48,698 callbacks.py:114 INFO train-abinet] average data time = 0.0059s, average running time = 0.8437s
█[2022-07-04 17:51:03,564 callbacks.py:123 INFO train-abinet] epoch 0 iter 24000: eval loss = 1.1445,  ccr = 0.9568,  cwr = 0.9106,  ted = 1484.0000,  ned = 288.5832,  ted/w = 0.2047, 
[2022-07-04 17:51:03,565 callbacks.py:130 INFO train-abinet] Better model found at epoch 0, iter 24000 with accuracy value: 0.9106.
[2022-07-04 17:51:04,870 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_24000
[2022-07-04 17:51:47,376 callbacks.py:105 INFO train-abinet] epoch 0 iter 24050: loss = 0.6227,  smooth loss = 0.6671
[2022-07-04 17:52:29,718 callbacks.py:105 INFO train-abinet] epoch 0 iter 24100: loss = 0.7597,  smooth loss = 0.6630
[2022-07-04 17:53:11,616 callbacks.py:105 INFO train-abinet] epoch 0 iter 24150: loss = 0.5789,  smooth loss = 0.6711
[2022-07-04 17:53:53,798 callbacks.py:105 INFO train-abinet] epoch 0 iter 24200: loss = 0.5953,  smooth loss = 0.6662
[2022-07-04 17:54:36,844 callbacks.py:105 INFO train-abinet] epoch 0 iter 24250: loss = 0.6530,  smooth loss = 0.6663
[2022-07-04 17:55:18,864 callbacks.py:105 INFO train-abinet] epoch 0 iter 24300: loss = 0.7277,  smooth loss = 0.6612
[2022-07-04 17:56:01,140 callbacks.py:105 INFO train-abinet] epoch 0 iter 24350: loss = 0.6665,  smooth loss = 0.6587
[2022-07-04 17:56:43,530 callbacks.py:105 INFO train-abinet] epoch 0 iter 24400: loss = 0.6173,  smooth loss = 0.6577
[2022-07-04 17:57:25,944 callbacks.py:105 INFO train-abinet] epoch 0 iter 24450: loss = 0.6379,  smooth loss = 0.6751
[2022-07-04 17:58:07,846 callbacks.py:105 INFO train-abinet] epoch 0 iter 24500: loss = 0.7205,  smooth loss = 0.6609
[2022-07-04 17:58:49,222 callbacks.py:105 INFO train-abinet] epoch 0 iter 24550: loss = 0.6304,  smooth loss = 0.6575
[2022-07-04 17:59:31,510 callbacks.py:105 INFO train-abinet] epoch 0 iter 24600: loss = 0.6149,  smooth loss = 0.6678
[2022-07-04 18:00:13,379 callbacks.py:105 INFO train-abinet] epoch 0 iter 24650: loss = 0.6176,  smooth loss = 0.6672
[2022-07-04 18:00:55,614 callbacks.py:105 INFO train-abinet] epoch 0 iter 24700: loss = 0.7113,  smooth loss = 0.6796
[2022-07-04 18:01:37,862 callbacks.py:105 INFO train-abinet] epoch 0 iter 24750: loss = 0.5917,  smooth loss = 0.6743
[2022-07-04 18:02:19,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 24800: loss = 0.6590,  smooth loss = 0.6750
[2022-07-04 18:03:02,813 callbacks.py:105 INFO train-abinet] epoch 0 iter 24850: loss = 0.4840,  smooth loss = 0.6641
[2022-07-04 18:03:45,165 callbacks.py:105 INFO train-abinet] epoch 0 iter 24900: loss = 0.7068,  smooth loss = 0.6571
[2022-07-04 18:04:27,384 callbacks.py:105 INFO train-abinet] epoch 0 iter 24950: loss = 0.8014,  smooth loss = 0.6572
[2022-07-04 18:05:09,522 callbacks.py:105 INFO train-abinet] epoch 0 iter 25000: loss = 0.5955,  smooth loss = 0.6618
[2022-07-04 18:05:51,504 callbacks.py:105 INFO train-abinet] epoch 0 iter 25050: loss = 0.5919,  smooth loss = 0.6676
[2022-07-04 18:06:33,799 callbacks.py:105 INFO train-abinet] epoch 0 iter 25100: loss = 0.7164,  smooth loss = 0.6540
[2022-07-04 18:07:15,966 callbacks.py:105 INFO train-abinet] epoch 0 iter 25150: loss = 0.6189,  smooth loss = 0.6590
[2022-07-04 18:07:57,605 callbacks.py:105 INFO train-abinet] epoch 0 iter 25200: loss = 0.7087,  smooth loss = 0.6470
[2022-07-04 18:08:40,224 callbacks.py:105 INFO train-abinet] epoch 0 iter 25250: loss = 0.5531,  smooth loss = 0.6538
[2022-07-04 18:09:21,745 callbacks.py:105 INFO train-abinet] epoch 0 iter 25300: loss = 0.7380,  smooth loss = 0.6696
[2022-07-04 18:10:04,082 callbacks.py:105 INFO train-abinet] epoch 0 iter 25350: loss = 0.8034,  smooth loss = 0.6764
[2022-07-04 18:10:46,189 callbacks.py:105 INFO train-abinet] epoch 0 iter 25400: loss = 0.6774,  smooth loss = 0.6702
[2022-07-04 18:11:27,568 callbacks.py:105 INFO train-abinet] epoch 0 iter 25450: loss = 0.7234,  smooth loss = 0.6538
[2022-07-04 18:12:09,883 callbacks.py:105 INFO train-abinet] epoch 0 iter 25500: loss = 0.7617,  smooth loss = 0.6445
[2022-07-04 18:12:51,940 callbacks.py:105 INFO train-abinet] epoch 0 iter 25550: loss = 0.5311,  smooth loss = 0.6588
[2022-07-04 18:13:34,537 callbacks.py:105 INFO train-abinet] epoch 0 iter 25600: loss = 0.6294,  smooth loss = 0.6621
[2022-07-04 18:14:16,585 callbacks.py:105 INFO train-abinet] epoch 0 iter 25650: loss = 0.5842,  smooth loss = 0.6661
[2022-07-04 18:14:58,337 callbacks.py:105 INFO train-abinet] epoch 0 iter 25700: loss = 0.6503,  smooth loss = 0.6678
[2022-07-04 18:15:40,563 callbacks.py:105 INFO train-abinet] epoch 0 iter 25750: loss = 0.4761,  smooth loss = 0.6639
[2022-07-04 18:16:22,892 callbacks.py:105 INFO train-abinet] epoch 0 iter 25800: loss = 0.5934,  smooth loss = 0.6716
[2022-07-04 18:17:04,389 callbacks.py:105 INFO train-abinet] epoch 0 iter 25850: loss = 0.5544,  smooth loss = 0.6741
[2022-07-04 18:17:45,830 callbacks.py:105 INFO train-abinet] epoch 0 iter 25900: loss = 0.7268,  smooth loss = 0.6575
[2022-07-04 18:18:27,378 callbacks.py:105 INFO train-abinet] epoch 0 iter 25950: loss = 0.6199,  smooth loss = 0.6562
[2022-07-04 18:19:09,108 callbacks.py:105 INFO train-abinet] epoch 0 iter 26000: loss = 0.6939,  smooth loss = 0.6770
[2022-07-04 18:19:51,216 callbacks.py:105 INFO train-abinet] epoch 0 iter 26050: loss = 0.8290,  smooth loss = 0.6799
[2022-07-04 18:20:32,948 callbacks.py:105 INFO train-abinet] epoch 0 iter 26100: loss = 0.6523,  smooth loss = 0.6641
[2022-07-04 18:21:14,114 callbacks.py:105 INFO train-abinet] epoch 0 iter 26150: loss = 0.5576,  smooth loss = 0.6541
[2022-07-04 18:21:55,634 callbacks.py:105 INFO train-abinet] epoch 0 iter 26200: loss = 0.8018,  smooth loss = 0.6480
[2022-07-04 18:22:36,546 callbacks.py:105 INFO train-abinet] epoch 0 iter 26250: loss = 0.6517,  smooth loss = 0.6506
[2022-07-04 18:23:18,850 callbacks.py:105 INFO train-abinet] epoch 0 iter 26300: loss = 0.6996,  smooth loss = 0.6499
[2022-07-04 18:24:01,028 callbacks.py:105 INFO train-abinet] epoch 0 iter 26350: loss = 0.6600,  smooth loss = 0.6579
[2022-07-04 18:24:43,626 callbacks.py:105 INFO train-abinet] epoch 0 iter 26400: loss = 0.8545,  smooth loss = 0.6637
[2022-07-04 18:25:25,247 callbacks.py:105 INFO train-abinet] epoch 0 iter 26450: loss = 0.6143,  smooth loss = 0.6698
[2022-07-04 18:26:07,185 callbacks.py:105 INFO train-abinet] epoch 0 iter 26500: loss = 0.6600,  smooth loss = 0.6650
[2022-07-04 18:26:49,034 callbacks.py:105 INFO train-abinet] epoch 0 iter 26550: loss = 0.5238,  smooth loss = 0.6629
[2022-07-04 18:27:31,578 callbacks.py:105 INFO train-abinet] epoch 0 iter 26600: loss = 0.6682,  smooth loss = 0.6686
[2022-07-04 18:28:14,104 callbacks.py:105 INFO train-abinet] epoch 0 iter 26650: loss = 0.7326,  smooth loss = 0.6769
[2022-07-04 18:28:56,209 callbacks.py:105 INFO train-abinet] epoch 0 iter 26700: loss = 0.6847,  smooth loss = 0.6792
[2022-07-04 18:29:38,064 callbacks.py:105 INFO train-abinet] epoch 0 iter 26750: loss = 0.5758,  smooth loss = 0.6532
[2022-07-04 18:30:20,509 callbacks.py:105 INFO train-abinet] epoch 0 iter 26800: loss = 0.5223,  smooth loss = 0.6471
[2022-07-04 18:31:02,443 callbacks.py:105 INFO train-abinet] epoch 0 iter 26850: loss = 0.6963,  smooth loss = 0.6422
[2022-07-04 18:31:44,411 callbacks.py:105 INFO train-abinet] epoch 0 iter 26900: loss = 0.7102,  smooth loss = 0.6450
[2022-07-04 18:32:26,378 callbacks.py:105 INFO train-abinet] epoch 0 iter 26950: loss = 0.7656,  smooth loss = 0.6391
[2022-07-04 18:33:08,664 callbacks.py:105 INFO train-abinet] epoch 0 iter 27000: loss = 0.6437,  smooth loss = 0.6458
[2022-07-04 18:33:08,665 callbacks.py:114 INFO train-abinet] average data time = 0.0057s, average running time = 0.8436s
█[2022-07-04 18:33:24,110 callbacks.py:123 INFO train-abinet] epoch 0 iter 27000: eval loss = 1.1631,  ccr = 0.9546,  cwr = 0.9114,  ted = 1429.0000,  ned = 278.1132,  ted/w = 0.1972, 
[2022-07-04 18:33:24,111 callbacks.py:130 INFO train-abinet] Better model found at epoch 0, iter 27000 with accuracy value: 0.9114.
[2022-07-04 18:33:25,383 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_27000
[2022-07-04 18:34:08,723 callbacks.py:105 INFO train-abinet] epoch 0 iter 27050: loss = 0.6577,  smooth loss = 0.6616
[2022-07-04 18:34:50,751 callbacks.py:105 INFO train-abinet] epoch 0 iter 27100: loss = 0.5652,  smooth loss = 0.6493
[2022-07-04 18:35:32,857 callbacks.py:105 INFO train-abinet] epoch 0 iter 27150: loss = 0.6263,  smooth loss = 0.6708
[2022-07-04 18:36:15,787 callbacks.py:105 INFO train-abinet] epoch 0 iter 27200: loss = 0.6131,  smooth loss = 0.6858
[2022-07-04 18:36:58,520 callbacks.py:105 INFO train-abinet] epoch 0 iter 27250: loss = 0.5522,  smooth loss = 0.6674
[2022-07-04 18:37:40,157 callbacks.py:105 INFO train-abinet] epoch 0 iter 27300: loss = 0.6464,  smooth loss = 0.6824
[2022-07-04 18:38:22,319 callbacks.py:105 INFO train-abinet] epoch 0 iter 27350: loss = 0.4949,  smooth loss = 0.6611
[2022-07-04 18:39:04,906 callbacks.py:105 INFO train-abinet] epoch 0 iter 27400: loss = 0.7712,  smooth loss = 0.6666
[2022-07-04 18:39:46,144 callbacks.py:105 INFO train-abinet] epoch 0 iter 27450: loss = 0.5813,  smooth loss = 0.6651
[2022-07-04 18:40:28,356 callbacks.py:105 INFO train-abinet] epoch 0 iter 27500: loss = 0.6011,  smooth loss = 0.6743
[2022-07-04 18:41:10,311 callbacks.py:105 INFO train-abinet] epoch 0 iter 27550: loss = 0.6861,  smooth loss = 0.6621
[2022-07-04 18:41:51,901 callbacks.py:105 INFO train-abinet] epoch 0 iter 27600: loss = 0.8787,  smooth loss = 0.6728
[2022-07-04 18:42:34,408 callbacks.py:105 INFO train-abinet] epoch 0 iter 27650: loss = 0.6608,  smooth loss = 0.6711
[2022-07-04 18:43:16,395 callbacks.py:105 INFO train-abinet] epoch 0 iter 27700: loss = 0.6262,  smooth loss = 0.6619
[2022-07-04 18:43:59,195 callbacks.py:105 INFO train-abinet] epoch 0 iter 27750: loss = 0.6158,  smooth loss = 0.6491
[2022-07-04 18:44:41,286 callbacks.py:105 INFO train-abinet] epoch 0 iter 27800: loss = 0.5943,  smooth loss = 0.6552
[2022-07-04 18:45:22,962 callbacks.py:105 INFO train-abinet] epoch 0 iter 27850: loss = 0.6700,  smooth loss = 0.6685
[2022-07-04 18:46:04,663 callbacks.py:105 INFO train-abinet] epoch 0 iter 27900: loss = 0.7368,  smooth loss = 0.6539
[2022-07-04 18:46:47,454 callbacks.py:105 INFO train-abinet] epoch 0 iter 27950: loss = 0.5282,  smooth loss = 0.6504
[2022-07-04 18:47:30,222 callbacks.py:105 INFO train-abinet] epoch 0 iter 28000: loss = 0.6565,  smooth loss = 0.6636
[2022-07-04 18:48:12,969 callbacks.py:105 INFO train-abinet] epoch 0 iter 28050: loss = 0.5283,  smooth loss = 0.6506
[2022-07-04 18:48:55,299 callbacks.py:105 INFO train-abinet] epoch 0 iter 28100: loss = 0.8267,  smooth loss = 0.6469
[2022-07-04 18:49:36,985 callbacks.py:105 INFO train-abinet] epoch 0 iter 28150: loss = 0.7381,  smooth loss = 0.6690
[2022-07-04 18:50:18,337 callbacks.py:105 INFO train-abinet] epoch 0 iter 28200: loss = 0.5999,  smooth loss = 0.6655
[2022-07-04 18:51:00,479 callbacks.py:105 INFO train-abinet] epoch 0 iter 28250: loss = 0.6790,  smooth loss = 0.6622
[2022-07-04 18:51:42,068 callbacks.py:105 INFO train-abinet] epoch 0 iter 28300: loss = 0.5637,  smooth loss = 0.6577
[2022-07-04 18:52:23,750 callbacks.py:105 INFO train-abinet] epoch 0 iter 28350: loss = 0.5311,  smooth loss = 0.6576
[2022-07-04 18:53:05,284 callbacks.py:105 INFO train-abinet] epoch 0 iter 28400: loss = 0.5875,  smooth loss = 0.6484
[2022-07-04 18:53:46,975 callbacks.py:105 INFO train-abinet] epoch 0 iter 28450: loss = 0.5316,  smooth loss = 0.6488
[2022-07-04 18:54:29,327 callbacks.py:105 INFO train-abinet] epoch 0 iter 28500: loss = 0.6243,  smooth loss = 0.6476
[2022-07-04 18:55:11,749 callbacks.py:105 INFO train-abinet] epoch 0 iter 28550: loss = 0.5768,  smooth loss = 0.6535
[2022-07-04 18:55:53,866 callbacks.py:105 INFO train-abinet] epoch 0 iter 28600: loss = 0.7735,  smooth loss = 0.6737
[2022-07-04 18:56:35,584 callbacks.py:105 INFO train-abinet] epoch 0 iter 28650: loss = 0.4827,  smooth loss = 0.6590
[2022-07-04 18:57:17,894 callbacks.py:105 INFO train-abinet] epoch 0 iter 28700: loss = 0.6267,  smooth loss = 0.6420
[2022-07-04 18:57:59,621 callbacks.py:105 INFO train-abinet] epoch 0 iter 28750: loss = 0.6505,  smooth loss = 0.6357
[2022-07-04 18:58:42,369 callbacks.py:105 INFO train-abinet] epoch 0 iter 28800: loss = 0.6735,  smooth loss = 0.6533
[2022-07-04 18:59:24,164 callbacks.py:105 INFO train-abinet] epoch 0 iter 28850: loss = 0.5450,  smooth loss = 0.6508
[2022-07-04 19:00:07,168 callbacks.py:105 INFO train-abinet] epoch 0 iter 28900: loss = 0.5875,  smooth loss = 0.6553
[2022-07-04 19:00:48,738 callbacks.py:105 INFO train-abinet] epoch 0 iter 28950: loss = 0.6373,  smooth loss = 0.6645
[2022-07-04 19:01:31,037 callbacks.py:105 INFO train-abinet] epoch 0 iter 29000: loss = 0.6386,  smooth loss = 0.6491
[2022-07-04 19:02:12,719 callbacks.py:105 INFO train-abinet] epoch 0 iter 29050: loss = 0.8519,  smooth loss = 0.6496
[2022-07-04 19:02:54,668 callbacks.py:105 INFO train-abinet] epoch 0 iter 29100: loss = 0.7506,  smooth loss = 0.6623
[2022-07-04 19:03:37,021 callbacks.py:105 INFO train-abinet] epoch 0 iter 29150: loss = 0.6677,  smooth loss = 0.6526
[2022-07-04 19:04:19,706 callbacks.py:105 INFO train-abinet] epoch 0 iter 29200: loss = 0.6795,  smooth loss = 0.6692
[2022-07-04 19:05:03,182 callbacks.py:105 INFO train-abinet] epoch 0 iter 29250: loss = 0.6021,  smooth loss = 0.6428
[2022-07-04 19:05:45,355 callbacks.py:105 INFO train-abinet] epoch 0 iter 29300: loss = 0.6768,  smooth loss = 0.6347
[2022-07-04 19:06:28,288 callbacks.py:105 INFO train-abinet] epoch 0 iter 29350: loss = 0.6620,  smooth loss = 0.6489
[2022-07-04 19:07:09,857 callbacks.py:105 INFO train-abinet] epoch 0 iter 29400: loss = 0.5986,  smooth loss = 0.6483
[2022-07-04 19:07:52,723 callbacks.py:105 INFO train-abinet] epoch 0 iter 29450: loss = 0.6629,  smooth loss = 0.6451
[2022-07-04 19:08:35,305 callbacks.py:105 INFO train-abinet] epoch 0 iter 29500: loss = 0.6845,  smooth loss = 0.6528
[2022-07-04 19:09:18,151 callbacks.py:105 INFO train-abinet] epoch 0 iter 29550: loss = 0.6849,  smooth loss = 0.6527
[2022-07-04 19:10:00,097 callbacks.py:105 INFO train-abinet] epoch 0 iter 29600: loss = 0.6103,  smooth loss = 0.6541
[2022-07-04 19:10:43,318 callbacks.py:105 INFO train-abinet] epoch 0 iter 29650: loss = 0.8397,  smooth loss = 0.6683
[2022-07-04 19:11:26,187 callbacks.py:105 INFO train-abinet] epoch 0 iter 29700: loss = 0.5519,  smooth loss = 0.6527
[2022-07-04 19:12:07,905 callbacks.py:105 INFO train-abinet] epoch 0 iter 29750: loss = 0.5875,  smooth loss = 0.6541
[2022-07-04 19:12:50,674 callbacks.py:105 INFO train-abinet] epoch 0 iter 29800: loss = 0.5403,  smooth loss = 0.6486
[2022-07-04 19:13:33,111 callbacks.py:105 INFO train-abinet] epoch 0 iter 29850: loss = 0.6349,  smooth loss = 0.6607
[2022-07-04 19:14:15,789 callbacks.py:105 INFO train-abinet] epoch 0 iter 29900: loss = 0.5038,  smooth loss = 0.6464
[2022-07-04 19:14:57,104 callbacks.py:105 INFO train-abinet] epoch 0 iter 29950: loss = 0.6503,  smooth loss = 0.6605
[2022-07-04 19:15:38,138 callbacks.py:105 INFO train-abinet] epoch 0 iter 30000: loss = 0.6635,  smooth loss = 0.6583
[2022-07-04 19:15:38,138 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8438s
█[2022-07-04 19:15:53,011 callbacks.py:123 INFO train-abinet] epoch 0 iter 30000: eval loss = 1.1390,  ccr = 0.9550,  cwr = 0.9081,  ted = 1505.0000,  ned = 290.5768,  ted/w = 0.2076, 
[2022-07-04 19:15:53,012 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_30000
[2022-07-04 19:16:36,286 callbacks.py:105 INFO train-abinet] epoch 0 iter 30050: loss = 0.6085,  smooth loss = 0.6727
[2022-07-04 19:17:18,765 callbacks.py:105 INFO train-abinet] epoch 0 iter 30100: loss = 0.7310,  smooth loss = 0.6585
[2022-07-04 19:18:00,433 callbacks.py:105 INFO train-abinet] epoch 0 iter 30150: loss = 0.5724,  smooth loss = 0.6535
[2022-07-04 19:18:42,212 callbacks.py:105 INFO train-abinet] epoch 0 iter 30200: loss = 0.6175,  smooth loss = 0.6563
[2022-07-04 19:19:24,604 callbacks.py:105 INFO train-abinet] epoch 0 iter 30250: loss = 0.7431,  smooth loss = 0.6519
[2022-07-04 19:20:06,735 callbacks.py:105 INFO train-abinet] epoch 0 iter 30300: loss = 0.7419,  smooth loss = 0.6517
[2022-07-04 19:20:49,214 callbacks.py:105 INFO train-abinet] epoch 0 iter 30350: loss = 0.5400,  smooth loss = 0.6365
[2022-07-04 19:21:31,356 callbacks.py:105 INFO train-abinet] epoch 0 iter 30400: loss = 0.4748,  smooth loss = 0.6358
[2022-07-04 19:22:13,308 callbacks.py:105 INFO train-abinet] epoch 0 iter 30450: loss = 0.6035,  smooth loss = 0.6397
[2022-07-04 19:22:55,222 callbacks.py:105 INFO train-abinet] epoch 0 iter 30500: loss = 0.6220,  smooth loss = 0.6433
[2022-07-04 19:23:37,525 callbacks.py:105 INFO train-abinet] epoch 0 iter 30550: loss = 0.6837,  smooth loss = 0.6597
[2022-07-04 19:24:19,294 callbacks.py:105 INFO train-abinet] epoch 0 iter 30600: loss = 0.7096,  smooth loss = 0.6737
[2022-07-04 19:25:01,428 callbacks.py:105 INFO train-abinet] epoch 0 iter 30650: loss = 0.7399,  smooth loss = 0.6623
[2022-07-04 19:25:43,096 callbacks.py:105 INFO train-abinet] epoch 0 iter 30700: loss = 0.6909,  smooth loss = 0.6464
[2022-07-04 19:26:25,262 callbacks.py:105 INFO train-abinet] epoch 0 iter 30750: loss = 0.6487,  smooth loss = 0.6525
[2022-07-04 19:27:06,369 callbacks.py:105 INFO train-abinet] epoch 0 iter 30800: loss = 0.7171,  smooth loss = 0.6402
[2022-07-04 19:27:48,038 callbacks.py:105 INFO train-abinet] epoch 0 iter 30850: loss = 0.5624,  smooth loss = 0.6450
[2022-07-04 19:28:30,239 callbacks.py:105 INFO train-abinet] epoch 0 iter 30900: loss = 0.6387,  smooth loss = 0.6483
[2022-07-04 19:29:12,409 callbacks.py:105 INFO train-abinet] epoch 0 iter 30950: loss = 0.6806,  smooth loss = 0.6437
[2022-07-04 19:29:54,658 callbacks.py:105 INFO train-abinet] epoch 0 iter 31000: loss = 0.6122,  smooth loss = 0.6487
[2022-07-04 19:30:38,110 callbacks.py:105 INFO train-abinet] epoch 0 iter 31050: loss = 0.7317,  smooth loss = 0.6411
[2022-07-04 19:31:20,370 callbacks.py:105 INFO train-abinet] epoch 0 iter 31100: loss = 0.6781,  smooth loss = 0.6478
[2022-07-04 19:32:01,859 callbacks.py:105 INFO train-abinet] epoch 0 iter 31150: loss = 0.5780,  smooth loss = 0.6596
[2022-07-04 19:32:43,837 callbacks.py:105 INFO train-abinet] epoch 0 iter 31200: loss = 0.6277,  smooth loss = 0.6577
[2022-07-04 19:33:26,537 callbacks.py:105 INFO train-abinet] epoch 0 iter 31250: loss = 0.6684,  smooth loss = 0.6623
[2022-07-04 19:34:09,111 callbacks.py:105 INFO train-abinet] epoch 0 iter 31300: loss = 0.6776,  smooth loss = 0.6574
[2022-07-04 19:34:51,245 callbacks.py:105 INFO train-abinet] epoch 0 iter 31350: loss = 0.7594,  smooth loss = 0.6523
[2022-07-04 19:35:33,351 callbacks.py:105 INFO train-abinet] epoch 0 iter 31400: loss = 0.7285,  smooth loss = 0.6566
[2022-07-04 19:36:15,742 callbacks.py:105 INFO train-abinet] epoch 0 iter 31450: loss = 0.6529,  smooth loss = 0.6735
[2022-07-04 19:36:57,345 callbacks.py:105 INFO train-abinet] epoch 0 iter 31500: loss = 0.6722,  smooth loss = 0.6668
[2022-07-04 19:37:39,445 callbacks.py:105 INFO train-abinet] epoch 0 iter 31550: loss = 0.5309,  smooth loss = 0.6637
[2022-07-04 19:38:21,288 callbacks.py:105 INFO train-abinet] epoch 0 iter 31600: loss = 0.6043,  smooth loss = 0.6420
[2022-07-04 19:39:03,962 callbacks.py:105 INFO train-abinet] epoch 0 iter 31650: loss = 0.4956,  smooth loss = 0.6539
[2022-07-04 19:39:45,962 callbacks.py:105 INFO train-abinet] epoch 0 iter 31700: loss = 0.5086,  smooth loss = 0.6504
[2022-07-04 19:40:27,896 callbacks.py:105 INFO train-abinet] epoch 0 iter 31750: loss = 0.6169,  smooth loss = 0.6589
[2022-07-04 19:41:09,407 callbacks.py:105 INFO train-abinet] epoch 0 iter 31800: loss = 0.5461,  smooth loss = 0.6548
[2022-07-04 19:41:51,712 callbacks.py:105 INFO train-abinet] epoch 0 iter 31850: loss = 0.6802,  smooth loss = 0.6608
[2022-07-04 19:42:33,352 callbacks.py:105 INFO train-abinet] epoch 0 iter 31900: loss = 0.5957,  smooth loss = 0.6656
[2022-07-04 19:43:15,082 callbacks.py:105 INFO train-abinet] epoch 0 iter 31950: loss = 0.6408,  smooth loss = 0.6549
[2022-07-04 19:43:57,413 callbacks.py:105 INFO train-abinet] epoch 0 iter 32000: loss = 0.6539,  smooth loss = 0.6514
[2022-07-04 19:44:39,775 callbacks.py:105 INFO train-abinet] epoch 0 iter 32050: loss = 0.9043,  smooth loss = 0.6633
[2022-07-04 19:45:21,661 callbacks.py:105 INFO train-abinet] epoch 0 iter 32100: loss = 0.8128,  smooth loss = 0.6571
[2022-07-04 19:46:04,401 callbacks.py:105 INFO train-abinet] epoch 0 iter 32150: loss = 0.6384,  smooth loss = 0.6523
[2022-07-04 19:46:46,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 32200: loss = 0.7558,  smooth loss = 0.6320
[2022-07-04 19:47:29,474 callbacks.py:105 INFO train-abinet] epoch 0 iter 32250: loss = 0.7694,  smooth loss = 0.6278
[2022-07-04 19:48:12,664 callbacks.py:105 INFO train-abinet] epoch 0 iter 32300: loss = 0.6037,  smooth loss = 0.6331
[2022-07-04 19:48:53,921 callbacks.py:105 INFO train-abinet] epoch 0 iter 32350: loss = 0.7290,  smooth loss = 0.6429
[2022-07-04 19:49:36,501 callbacks.py:105 INFO train-abinet] epoch 0 iter 32400: loss = 0.5386,  smooth loss = 0.6563
[2022-07-04 19:50:18,217 callbacks.py:105 INFO train-abinet] epoch 0 iter 32450: loss = 0.6704,  smooth loss = 0.6598
[2022-07-04 19:50:59,863 callbacks.py:105 INFO train-abinet] epoch 0 iter 32500: loss = 0.8288,  smooth loss = 0.6547
[2022-07-04 19:51:42,505 callbacks.py:105 INFO train-abinet] epoch 0 iter 32550: loss = 0.8574,  smooth loss = 0.6415
[2022-07-04 19:52:25,049 callbacks.py:105 INFO train-abinet] epoch 0 iter 32600: loss = 0.6864,  smooth loss = 0.6566
[2022-07-04 19:53:06,483 callbacks.py:105 INFO train-abinet] epoch 0 iter 32650: loss = 0.6947,  smooth loss = 0.6528
[2022-07-04 19:53:47,794 callbacks.py:105 INFO train-abinet] epoch 0 iter 32700: loss = 0.5778,  smooth loss = 0.6503
[2022-07-04 19:54:29,618 callbacks.py:105 INFO train-abinet] epoch 0 iter 32750: loss = 0.6786,  smooth loss = 0.6609
[2022-07-04 19:55:10,727 callbacks.py:105 INFO train-abinet] epoch 0 iter 32800: loss = 0.5964,  smooth loss = 0.6608
[2022-07-04 19:55:52,365 callbacks.py:105 INFO train-abinet] epoch 0 iter 32850: loss = 0.4178,  smooth loss = 0.6356
[2022-07-04 19:56:33,914 callbacks.py:105 INFO train-abinet] epoch 0 iter 32900: loss = 0.7340,  smooth loss = 0.6320
[2022-07-04 19:57:15,683 callbacks.py:105 INFO train-abinet] epoch 0 iter 32950: loss = 0.7083,  smooth loss = 0.6425
[2022-07-04 19:57:57,530 callbacks.py:105 INFO train-abinet] epoch 0 iter 33000: loss = 0.5415,  smooth loss = 0.6492
[2022-07-04 19:57:57,531 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8436s
█[2022-07-04 19:58:12,049 callbacks.py:123 INFO train-abinet] epoch 0 iter 33000: eval loss = 1.1732,  ccr = 0.9535,  cwr = 0.9096,  ted = 1523.0000,  ned = 299.9744,  ted/w = 0.2101, 
[2022-07-04 19:58:12,051 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_33000
[2022-07-04 19:58:54,729 callbacks.py:105 INFO train-abinet] epoch 0 iter 33050: loss = 0.6075,  smooth loss = 0.6567
[2022-07-04 19:59:36,682 callbacks.py:105 INFO train-abinet] epoch 0 iter 33100: loss = 0.6820,  smooth loss = 0.6579
[2022-07-04 20:00:18,702 callbacks.py:105 INFO train-abinet] epoch 0 iter 33150: loss = 0.5562,  smooth loss = 0.6565
[2022-07-04 20:01:00,437 callbacks.py:105 INFO train-abinet] epoch 0 iter 33200: loss = 0.6932,  smooth loss = 0.6565
[2022-07-04 20:01:42,664 callbacks.py:105 INFO train-abinet] epoch 0 iter 33250: loss = 0.7428,  smooth loss = 0.6382
[2022-07-04 20:02:24,439 callbacks.py:105 INFO train-abinet] epoch 0 iter 33300: loss = 0.5979,  smooth loss = 0.6523
[2022-07-04 20:03:06,786 callbacks.py:105 INFO train-abinet] epoch 0 iter 33350: loss = 0.7624,  smooth loss = 0.6537
[2022-07-04 20:03:48,179 callbacks.py:105 INFO train-abinet] epoch 0 iter 33400: loss = 0.6965,  smooth loss = 0.6458
[2022-07-04 20:04:30,007 callbacks.py:105 INFO train-abinet] epoch 0 iter 33450: loss = 0.9040,  smooth loss = 0.6470
[2022-07-04 20:05:11,692 callbacks.py:105 INFO train-abinet] epoch 0 iter 33500: loss = 0.6661,  smooth loss = 0.6323
[2022-07-04 20:05:52,943 callbacks.py:105 INFO train-abinet] epoch 0 iter 33550: loss = 0.5783,  smooth loss = 0.6311
[2022-07-04 20:06:34,538 callbacks.py:105 INFO train-abinet] epoch 0 iter 33600: loss = 0.5648,  smooth loss = 0.6474
[2022-07-04 20:07:16,141 callbacks.py:105 INFO train-abinet] epoch 0 iter 33650: loss = 0.7076,  smooth loss = 0.6426
[2022-07-04 20:07:58,119 callbacks.py:105 INFO train-abinet] epoch 0 iter 33700: loss = 0.6888,  smooth loss = 0.6476
[2022-07-04 20:08:40,047 callbacks.py:105 INFO train-abinet] epoch 0 iter 33750: loss = 0.7011,  smooth loss = 0.6444
[2022-07-04 20:09:22,023 callbacks.py:105 INFO train-abinet] epoch 0 iter 33800: loss = 0.7445,  smooth loss = 0.6369
[2022-07-04 20:10:04,223 callbacks.py:105 INFO train-abinet] epoch 0 iter 33850: loss = 0.6768,  smooth loss = 0.6529
[2022-07-04 20:10:46,629 callbacks.py:105 INFO train-abinet] epoch 0 iter 33900: loss = 0.5769,  smooth loss = 0.6431
[2022-07-04 20:11:29,472 callbacks.py:105 INFO train-abinet] epoch 0 iter 33950: loss = 0.6923,  smooth loss = 0.6498
[2022-07-04 20:12:10,822 callbacks.py:105 INFO train-abinet] epoch 0 iter 34000: loss = 0.7440,  smooth loss = 0.6501
[2022-07-04 20:12:52,632 callbacks.py:105 INFO train-abinet] epoch 0 iter 34050: loss = 0.6322,  smooth loss = 0.6516
[2022-07-04 20:13:34,897 callbacks.py:105 INFO train-abinet] epoch 0 iter 34100: loss = 0.8061,  smooth loss = 0.6523
[2022-07-04 20:14:16,707 callbacks.py:105 INFO train-abinet] epoch 0 iter 34150: loss = 0.6844,  smooth loss = 0.6426
[2022-07-04 20:14:58,524 callbacks.py:105 INFO train-abinet] epoch 0 iter 34200: loss = 0.6233,  smooth loss = 0.6470
[2022-07-04 20:15:40,707 callbacks.py:105 INFO train-abinet] epoch 0 iter 34250: loss = 0.6985,  smooth loss = 0.6618
[2022-07-04 20:16:21,970 callbacks.py:105 INFO train-abinet] epoch 0 iter 34300: loss = 0.6329,  smooth loss = 0.6626
[2022-07-04 20:17:04,063 callbacks.py:105 INFO train-abinet] epoch 0 iter 34350: loss = 0.6623,  smooth loss = 0.6526
[2022-07-04 20:17:45,681 callbacks.py:105 INFO train-abinet] epoch 0 iter 34400: loss = 0.7057,  smooth loss = 0.6534
[2022-07-04 20:18:27,500 callbacks.py:105 INFO train-abinet] epoch 0 iter 34450: loss = 0.7715,  smooth loss = 0.6617
[2022-07-04 20:19:09,428 callbacks.py:105 INFO train-abinet] epoch 0 iter 34500: loss = 0.5321,  smooth loss = 0.6622
[2022-07-04 20:19:51,286 callbacks.py:105 INFO train-abinet] epoch 0 iter 34550: loss = 0.6273,  smooth loss = 0.6482
[2022-07-04 20:20:33,339 callbacks.py:105 INFO train-abinet] epoch 0 iter 34600: loss = 0.7050,  smooth loss = 0.6422
[2022-07-04 20:21:15,337 callbacks.py:105 INFO train-abinet] epoch 0 iter 34650: loss = 0.5635,  smooth loss = 0.6430
[2022-07-04 20:21:57,117 callbacks.py:105 INFO train-abinet] epoch 0 iter 34700: loss = 0.7808,  smooth loss = 0.6490
[2022-07-04 20:22:38,816 callbacks.py:105 INFO train-abinet] epoch 0 iter 34750: loss = 0.6103,  smooth loss = 0.6496
[2022-07-04 20:23:20,559 callbacks.py:105 INFO train-abinet] epoch 0 iter 34800: loss = 0.5626,  smooth loss = 0.6429
[2022-07-04 20:24:02,322 callbacks.py:105 INFO train-abinet] epoch 0 iter 34850: loss = 0.6259,  smooth loss = 0.6450
[2022-07-04 20:24:43,563 callbacks.py:105 INFO train-abinet] epoch 0 iter 34900: loss = 0.5124,  smooth loss = 0.6385
[2022-07-04 20:25:25,246 callbacks.py:105 INFO train-abinet] epoch 0 iter 34950: loss = 0.5767,  smooth loss = 0.6400
[2022-07-04 20:26:06,854 callbacks.py:105 INFO train-abinet] epoch 0 iter 35000: loss = 0.7319,  smooth loss = 0.6420
[2022-07-04 20:26:48,624 callbacks.py:105 INFO train-abinet] epoch 0 iter 35050: loss = 0.7658,  smooth loss = 0.6580
[2022-07-04 20:27:30,027 callbacks.py:105 INFO train-abinet] epoch 0 iter 35100: loss = 0.6913,  smooth loss = 0.6561
[2022-07-04 20:28:11,568 callbacks.py:105 INFO train-abinet] epoch 0 iter 35150: loss = 0.6417,  smooth loss = 0.6451
[2022-07-04 20:28:53,367 callbacks.py:105 INFO train-abinet] epoch 0 iter 35200: loss = 0.5173,  smooth loss = 0.6554
[2022-07-04 20:29:34,861 callbacks.py:105 INFO train-abinet] epoch 0 iter 35250: loss = 0.5388,  smooth loss = 0.6437
[2022-07-04 20:30:16,561 callbacks.py:105 INFO train-abinet] epoch 0 iter 35300: loss = 0.7581,  smooth loss = 0.6574
[2022-07-04 20:30:58,466 callbacks.py:105 INFO train-abinet] epoch 0 iter 35350: loss = 0.8007,  smooth loss = 0.6433
[2022-07-04 20:31:41,063 callbacks.py:105 INFO train-abinet] epoch 0 iter 35400: loss = 0.7699,  smooth loss = 0.6465
[2022-07-04 20:32:23,177 callbacks.py:105 INFO train-abinet] epoch 0 iter 35450: loss = 0.6452,  smooth loss = 0.6368
[2022-07-04 20:33:05,831 callbacks.py:105 INFO train-abinet] epoch 0 iter 35500: loss = 0.6380,  smooth loss = 0.6410
[2022-07-04 20:33:47,352 callbacks.py:105 INFO train-abinet] epoch 0 iter 35550: loss = 0.5795,  smooth loss = 0.6355
[2022-07-04 20:34:29,095 callbacks.py:105 INFO train-abinet] epoch 0 iter 35600: loss = 0.5714,  smooth loss = 0.6686
[2022-07-04 20:35:10,488 callbacks.py:105 INFO train-abinet] epoch 0 iter 35650: loss = 0.5883,  smooth loss = 0.6586
[2022-07-04 20:35:53,008 callbacks.py:105 INFO train-abinet] epoch 0 iter 35700: loss = 0.5643,  smooth loss = 0.6495
[2022-07-04 20:36:35,429 callbacks.py:105 INFO train-abinet] epoch 0 iter 35750: loss = 0.5615,  smooth loss = 0.6386
[2022-07-04 20:37:17,417 callbacks.py:105 INFO train-abinet] epoch 0 iter 35800: loss = 0.7247,  smooth loss = 0.6335
[2022-07-04 20:37:59,383 callbacks.py:105 INFO train-abinet] epoch 0 iter 35850: loss = 0.5929,  smooth loss = 0.6319
[2022-07-04 20:38:41,424 callbacks.py:105 INFO train-abinet] epoch 0 iter 35900: loss = 0.7234,  smooth loss = 0.6446
[2022-07-04 20:39:23,273 callbacks.py:105 INFO train-abinet] epoch 0 iter 35950: loss = 0.7187,  smooth loss = 0.6499
[2022-07-04 20:40:04,761 callbacks.py:105 INFO train-abinet] epoch 0 iter 36000: loss = 0.5355,  smooth loss = 0.6417
[2022-07-04 20:40:04,762 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8432s
█[2022-07-04 20:40:19,143 callbacks.py:123 INFO train-abinet] epoch 0 iter 36000: eval loss = 1.1726,  ccr = 0.9537,  cwr = 0.9077,  ted = 1494.0000,  ned = 300.3268,  ted/w = 0.2061, 
[2022-07-04 20:40:19,144 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_36000
[2022-07-04 20:41:02,287 callbacks.py:105 INFO train-abinet] epoch 0 iter 36050: loss = 0.4894,  smooth loss = 0.6337
[2022-07-04 20:41:44,962 callbacks.py:105 INFO train-abinet] epoch 0 iter 36100: loss = 0.6396,  smooth loss = 0.6296
[2022-07-04 20:42:26,515 callbacks.py:105 INFO train-abinet] epoch 0 iter 36150: loss = 0.6324,  smooth loss = 0.6559
[2022-07-04 20:43:08,662 callbacks.py:105 INFO train-abinet] epoch 0 iter 36200: loss = 0.6974,  smooth loss = 0.6617
[2022-07-04 20:43:50,772 callbacks.py:105 INFO train-abinet] epoch 0 iter 36250: loss = 0.5364,  smooth loss = 0.6354
[2022-07-04 20:44:33,346 callbacks.py:105 INFO train-abinet] epoch 0 iter 36300: loss = 0.6199,  smooth loss = 0.6318
[2022-07-04 20:45:16,033 callbacks.py:105 INFO train-abinet] epoch 0 iter 36350: loss = 0.6932,  smooth loss = 0.6423
[2022-07-04 20:45:58,017 callbacks.py:105 INFO train-abinet] epoch 0 iter 36400: loss = 0.6775,  smooth loss = 0.6468
[2022-07-04 20:46:39,568 callbacks.py:105 INFO train-abinet] epoch 0 iter 36450: loss = 0.5852,  smooth loss = 0.6606
[2022-07-04 20:47:20,454 callbacks.py:105 INFO train-abinet] epoch 0 iter 36500: loss = 0.6314,  smooth loss = 0.6523
[2022-07-04 20:48:02,786 callbacks.py:105 INFO train-abinet] epoch 0 iter 36550: loss = 0.8471,  smooth loss = 0.6509
[2022-07-04 20:48:45,371 callbacks.py:105 INFO train-abinet] epoch 0 iter 36600: loss = 0.7236,  smooth loss = 0.6315
[2022-07-04 20:49:27,151 callbacks.py:105 INFO train-abinet] epoch 0 iter 36650: loss = 0.6538,  smooth loss = 0.6553
[2022-07-04 20:50:08,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 36700: loss = 0.7627,  smooth loss = 0.6602
[2022-07-04 20:50:51,320 callbacks.py:105 INFO train-abinet] epoch 0 iter 36750: loss = 0.5931,  smooth loss = 0.6566
[2022-07-04 20:51:32,989 callbacks.py:105 INFO train-abinet] epoch 0 iter 36800: loss = 0.6318,  smooth loss = 0.6563
[2022-07-04 20:52:14,969 callbacks.py:105 INFO train-abinet] epoch 0 iter 36850: loss = 0.5588,  smooth loss = 0.6445
[2022-07-04 20:52:56,799 callbacks.py:105 INFO train-abinet] epoch 0 iter 36900: loss = 0.5496,  smooth loss = 0.6388
[2022-07-04 20:53:39,221 callbacks.py:105 INFO train-abinet] epoch 0 iter 36950: loss = 0.5672,  smooth loss = 0.6295
[2022-07-04 20:54:20,844 callbacks.py:105 INFO train-abinet] epoch 0 iter 37000: loss = 0.6338,  smooth loss = 0.6329
[2022-07-04 20:55:02,780 callbacks.py:105 INFO train-abinet] epoch 0 iter 37050: loss = 0.8770,  smooth loss = 0.6374
[2022-07-04 20:55:44,560 callbacks.py:105 INFO train-abinet] epoch 0 iter 37100: loss = 0.5845,  smooth loss = 0.6539
[2022-07-04 20:56:27,195 callbacks.py:105 INFO train-abinet] epoch 0 iter 37150: loss = 0.6973,  smooth loss = 0.6449
[2022-07-04 20:57:09,742 callbacks.py:105 INFO train-abinet] epoch 0 iter 37200: loss = 0.8135,  smooth loss = 0.6518
[2022-07-04 20:57:52,856 callbacks.py:105 INFO train-abinet] epoch 0 iter 37250: loss = 0.4834,  smooth loss = 0.6600
[2022-07-04 20:58:35,512 callbacks.py:105 INFO train-abinet] epoch 0 iter 37300: loss = 0.8065,  smooth loss = 0.6552
[2022-07-04 20:59:17,647 callbacks.py:105 INFO train-abinet] epoch 0 iter 37350: loss = 0.5052,  smooth loss = 0.6522
[2022-07-04 21:00:00,200 callbacks.py:105 INFO train-abinet] epoch 0 iter 37400: loss = 0.6667,  smooth loss = 0.6497
[2022-07-04 21:00:43,425 callbacks.py:105 INFO train-abinet] epoch 0 iter 37450: loss = 0.6502,  smooth loss = 0.6475
[2022-07-04 21:01:26,502 callbacks.py:105 INFO train-abinet] epoch 0 iter 37500: loss = 0.5047,  smooth loss = 0.6600
[2022-07-04 21:02:09,517 callbacks.py:105 INFO train-abinet] epoch 0 iter 37550: loss = 0.6867,  smooth loss = 0.6776
[2022-07-04 21:02:51,797 callbacks.py:105 INFO train-abinet] epoch 0 iter 37600: loss = 0.7485,  smooth loss = 0.6725
[2022-07-04 21:03:35,723 callbacks.py:105 INFO train-abinet] epoch 0 iter 37650: loss = 0.6551,  smooth loss = 0.6487
[2022-07-04 21:04:17,639 callbacks.py:105 INFO train-abinet] epoch 0 iter 37700: loss = 0.5874,  smooth loss = 0.6413
[2022-07-04 21:05:00,472 callbacks.py:105 INFO train-abinet] epoch 0 iter 37750: loss = 0.6086,  smooth loss = 0.6342
[2022-07-04 21:05:43,227 callbacks.py:105 INFO train-abinet] epoch 0 iter 37800: loss = 0.7239,  smooth loss = 0.6388
[2022-07-04 21:06:25,623 callbacks.py:105 INFO train-abinet] epoch 0 iter 37850: loss = 0.6106,  smooth loss = 0.6331
[2022-07-04 21:07:08,329 callbacks.py:105 INFO train-abinet] epoch 0 iter 37900: loss = 0.5637,  smooth loss = 0.6221
[2022-07-04 21:07:51,223 callbacks.py:105 INFO train-abinet] epoch 0 iter 37950: loss = 0.7230,  smooth loss = 0.6263
[2022-07-04 21:08:33,612 callbacks.py:105 INFO train-abinet] epoch 0 iter 38000: loss = 0.6701,  smooth loss = 0.6411
[2022-07-04 21:09:16,876 callbacks.py:105 INFO train-abinet] epoch 0 iter 38050: loss = 0.5482,  smooth loss = 0.6546
[2022-07-04 21:10:00,216 callbacks.py:105 INFO train-abinet] epoch 0 iter 38100: loss = 0.5563,  smooth loss = 0.6534
[2022-07-04 21:10:42,222 callbacks.py:105 INFO train-abinet] epoch 0 iter 38150: loss = 0.5609,  smooth loss = 0.6318
[2022-07-04 21:11:25,770 callbacks.py:105 INFO train-abinet] epoch 0 iter 38200: loss = 0.6946,  smooth loss = 0.6420
[2022-07-04 21:12:07,220 callbacks.py:105 INFO train-abinet] epoch 0 iter 38250: loss = 0.6449,  smooth loss = 0.6380
[2022-07-04 21:12:50,418 callbacks.py:105 INFO train-abinet] epoch 0 iter 38300: loss = 0.6624,  smooth loss = 0.6421
[2022-07-04 21:13:32,762 callbacks.py:105 INFO train-abinet] epoch 0 iter 38350: loss = 0.6287,  smooth loss = 0.6300
[2022-07-04 21:14:16,861 callbacks.py:105 INFO train-abinet] epoch 0 iter 38400: loss = 0.6937,  smooth loss = 0.6330
[2022-07-04 21:15:00,755 callbacks.py:105 INFO train-abinet] epoch 0 iter 38450: loss = 0.6293,  smooth loss = 0.6436
[2022-07-04 21:15:43,040 callbacks.py:105 INFO train-abinet] epoch 0 iter 38500: loss = 0.5907,  smooth loss = 0.6381
[2022-07-04 21:16:25,943 callbacks.py:105 INFO train-abinet] epoch 0 iter 38550: loss = 0.6901,  smooth loss = 0.6360
[2022-07-04 21:17:08,574 callbacks.py:105 INFO train-abinet] epoch 0 iter 38600: loss = 0.5433,  smooth loss = 0.6385
[2022-07-04 21:17:51,131 callbacks.py:105 INFO train-abinet] epoch 0 iter 38650: loss = 0.6592,  smooth loss = 0.6458
[2022-07-04 21:18:34,341 callbacks.py:105 INFO train-abinet] epoch 0 iter 38700: loss = 0.4808,  smooth loss = 0.6490
[2022-07-04 21:19:17,321 callbacks.py:105 INFO train-abinet] epoch 0 iter 38750: loss = 0.7596,  smooth loss = 0.6538
[2022-07-04 21:19:58,979 callbacks.py:105 INFO train-abinet] epoch 0 iter 38800: loss = 0.5835,  smooth loss = 0.6412
[2022-07-04 21:20:41,714 callbacks.py:105 INFO train-abinet] epoch 0 iter 38850: loss = 0.6611,  smooth loss = 0.6457
[2022-07-04 21:21:24,568 callbacks.py:105 INFO train-abinet] epoch 0 iter 38900: loss = 0.6844,  smooth loss = 0.6376
[2022-07-04 21:22:06,208 callbacks.py:105 INFO train-abinet] epoch 0 iter 38950: loss = 0.5479,  smooth loss = 0.6284
[2022-07-04 21:22:49,070 callbacks.py:105 INFO train-abinet] epoch 0 iter 39000: loss = 0.5477,  smooth loss = 0.6342
[2022-07-04 21:22:49,071 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8437s
█[2022-07-04 21:23:03,948 callbacks.py:123 INFO train-abinet] epoch 0 iter 39000: eval loss = 1.1708,  ccr = 0.9566,  cwr = 0.9140,  ted = 1431.0000,  ned = 279.1391,  ted/w = 0.1974, 
[2022-07-04 21:23:03,950 callbacks.py:130 INFO train-abinet] Better model found at epoch 0, iter 39000 with accuracy value: 0.9140.
[2022-07-04 21:23:05,195 callbacks.py:136 INFO train-abinet] Save model train-abinet_0_39000
[2022-07-04 21:23:48,713 callbacks.py:105 INFO train-abinet] epoch 0 iter 39050: loss = 0.5859,  smooth loss = 0.6304
[2022-07-04 21:24:31,389 callbacks.py:105 INFO train-abinet] epoch 0 iter 39100: loss = 0.5503,  smooth loss = 0.6355
[2022-07-04 21:25:13,853 callbacks.py:105 INFO train-abinet] epoch 0 iter 39150: loss = 0.7668,  smooth loss = 0.6323
[2022-07-04 21:25:56,577 callbacks.py:105 INFO train-abinet] epoch 0 iter 39200: loss = 0.5243,  smooth loss = 0.6386
[2022-07-04 21:26:38,622 callbacks.py:105 INFO train-abinet] epoch 0 iter 39250: loss = 0.7234,  smooth loss = 0.6233
[2022-07-04 21:27:20,764 callbacks.py:105 INFO train-abinet] epoch 0 iter 39300: loss = 0.5880,  smooth loss = 0.6299
[2022-07-04 21:28:02,933 callbacks.py:105 INFO train-abinet] epoch 0 iter 39350: loss = 0.6454,  smooth loss = 0.6352
[2022-07-04 21:28:45,086 callbacks.py:105 INFO train-abinet] epoch 0 iter 39400: loss = 0.5419,  smooth loss = 0.6394
[2022-07-04 21:29:27,440 callbacks.py:105 INFO train-abinet] epoch 0 iter 39450: loss = 0.6383,  smooth loss = 0.6519
[2022-07-04 21:30:11,396 callbacks.py:105 INFO train-abinet] epoch 0 iter 39500: loss = 0.7169,  smooth loss = 0.6546
[2022-07-04 21:30:54,383 callbacks.py:105 INFO train-abinet] epoch 0 iter 39550: loss = 0.6402,  smooth loss = 0.6496
[2022-07-04 21:31:36,983 callbacks.py:105 INFO train-abinet] epoch 0 iter 39600: loss = 0.5205,  smooth loss = 0.6386
[2022-07-04 21:32:19,919 callbacks.py:105 INFO train-abinet] epoch 0 iter 39650: loss = 0.6191,  smooth loss = 0.6514
[2022-07-04 21:33:03,837 callbacks.py:105 INFO train-abinet] epoch 0 iter 39700: loss = 0.5966,  smooth loss = 0.6426
[2022-07-04 21:33:47,467 callbacks.py:105 INFO train-abinet] epoch 0 iter 39750: loss = 0.5057,  smooth loss = 0.6511
[2022-07-04 21:34:31,189 callbacks.py:105 INFO train-abinet] epoch 0 iter 39800: loss = 0.6899,  smooth loss = 0.6491
[2022-07-04 21:35:14,001 callbacks.py:105 INFO train-abinet] epoch 0 iter 39850: loss = 0.7090,  smooth loss = 0.6373
[2022-07-04 21:35:58,551 callbacks.py:105 INFO train-abinet] epoch 0 iter 39900: loss = 0.7435,  smooth loss = 0.6329
[2022-07-04 21:36:41,811 callbacks.py:105 INFO train-abinet] epoch 0 iter 39950: loss = 0.5484,  smooth loss = 0.6336
[2022-07-04 21:37:24,536 callbacks.py:105 INFO train-abinet] epoch 0 iter 40000: loss = 0.8359,  smooth loss = 0.6314
[2022-07-04 21:38:08,266 callbacks.py:105 INFO train-abinet] epoch 0 iter 40050: loss = 0.5569,  smooth loss = 0.6438
[2022-07-04 21:38:51,411 callbacks.py:105 INFO train-abinet] epoch 0 iter 40100: loss = 0.6785,  smooth loss = 0.6448
[2022-07-04 21:39:34,732 callbacks.py:105 INFO train-abinet] epoch 0 iter 40150: loss = 0.6516,  smooth loss = 0.6336
[2022-07-04 21:40:17,847 callbacks.py:105 INFO train-abinet] epoch 0 iter 40200: loss = 0.5817,  smooth loss = 0.6399
[2022-07-04 21:41:01,531 callbacks.py:105 INFO train-abinet] epoch 0 iter 40250: loss = 0.5431,  smooth loss = 0.6360
[2022-07-04 21:41:44,354 callbacks.py:105 INFO train-abinet] epoch 0 iter 40300: loss = 0.7686,  smooth loss = 0.6482
[2022-07-04 21:42:28,345 callbacks.py:105 INFO train-abinet] epoch 0 iter 40350: loss = 0.5601,  smooth loss = 0.6491
[2022-07-04 21:43:10,942 callbacks.py:105 INFO train-abinet] epoch 0 iter 40400: loss = 0.6106,  smooth loss = 0.6396
[2022-07-04 21:43:54,460 callbacks.py:105 INFO train-abinet] epoch 0 iter 40450: loss = 0.5706,  smooth loss = 0.6452
[2022-07-04 21:44:39,135 callbacks.py:105 INFO train-abinet] epoch 0 iter 40500: loss = 0.6874,  smooth loss = 0.6416
[2022-07-04 21:45:21,769 callbacks.py:105 INFO train-abinet] epoch 0 iter 40550: loss = 0.6180,  smooth loss = 0.6223
[2022-07-04 21:46:04,881 callbacks.py:105 INFO train-abinet] epoch 0 iter 40600: loss = 0.4361,  smooth loss = 0.6425
[2022-07-04 21:46:48,343 callbacks.py:105 INFO train-abinet] epoch 0 iter 40650: loss = 0.5918,  smooth loss = 0.6354
[2022-07-04 21:47:30,814 callbacks.py:105 INFO train-abinet] epoch 0 iter 40700: loss = 0.7069,  smooth loss = 0.6240
[2022-07-04 21:48:14,716 callbacks.py:105 INFO train-abinet] epoch 0 iter 40750: loss = 0.6351,  smooth loss = 0.6403
[2022-07-04 21:48:58,813 callbacks.py:105 INFO train-abinet] epoch 0 iter 40800: loss = 0.8629,  smooth loss = 0.6291
[2022-07-04 21:49:42,018 callbacks.py:105 INFO train-abinet] epoch 0 iter 40850: loss = 0.4889,  smooth loss = 0.6305
[2022-07-04 21:50:26,529 callbacks.py:105 INFO train-abinet] epoch 0 iter 40900: loss = 0.6697,  smooth loss = 0.6268
[2022-07-04 21:51:09,452 callbacks.py:105 INFO train-abinet] epoch 0 iter 40950: loss = 0.6324,  smooth loss = 0.6270
[2022-07-04 21:51:55,368 callbacks.py:105 INFO train-abinet] epoch 0 iter 41000: loss = 0.6067,  smooth loss = 0.6259
[2022-07-04 21:52:39,239 callbacks.py:105 INFO train-abinet] epoch 0 iter 41050: loss = 0.5238,  smooth loss = 0.6247
[2022-07-04 21:53:23,186 callbacks.py:105 INFO train-abinet] epoch 0 iter 41100: loss = 0.5851,  smooth loss = 0.6403
[2022-07-04 21:54:07,884 callbacks.py:105 INFO train-abinet] epoch 0 iter 41150: loss = 0.6216,  smooth loss = 0.6277
[2022-07-04 21:54:51,521 callbacks.py:105 INFO train-abinet] epoch 0 iter 41200: loss = 0.7460,  smooth loss = 0.6369
[2022-07-04 21:55:34,383 callbacks.py:105 INFO train-abinet] epoch 0 iter 41250: loss = 0.7439,  smooth loss = 0.6323
[2022-07-04 21:56:17,886 callbacks.py:105 INFO train-abinet] epoch 0 iter 41300: loss = 0.5886,  smooth loss = 0.6317
[2022-07-04 21:57:02,090 callbacks.py:105 INFO train-abinet] epoch 0 iter 41350: loss = 0.7224,  smooth loss = 0.6307
█[2022-07-04 21:57:52,240 callbacks.py:105 INFO train-abinet] epoch 1 iter 41400: loss = 0.6311,  smooth loss = 0.6297
[2022-07-04 21:58:36,017 callbacks.py:105 INFO train-abinet] epoch 1 iter 41450: loss = 0.6511,  smooth loss = 0.6301
[2022-07-04 21:59:19,092 callbacks.py:105 INFO train-abinet] epoch 1 iter 41500: loss = 0.6540,  smooth loss = 0.6353
[2022-07-04 22:00:02,353 callbacks.py:105 INFO train-abinet] epoch 1 iter 41550: loss = 0.5377,  smooth loss = 0.6376
[2022-07-04 22:00:47,011 callbacks.py:105 INFO train-abinet] epoch 1 iter 41600: loss = 0.5474,  smooth loss = 0.6329
[2022-07-04 22:01:30,916 callbacks.py:105 INFO train-abinet] epoch 1 iter 41650: loss = 0.5556,  smooth loss = 0.6338
[2022-07-04 22:02:14,319 callbacks.py:105 INFO train-abinet] epoch 1 iter 41700: loss = 0.7641,  smooth loss = 0.6358
[2022-07-04 22:02:57,112 callbacks.py:105 INFO train-abinet] epoch 1 iter 41750: loss = 0.6400,  smooth loss = 0.6433
[2022-07-04 22:03:40,061 callbacks.py:105 INFO train-abinet] epoch 1 iter 41800: loss = 0.6332,  smooth loss = 0.6439
[2022-07-04 22:04:23,101 callbacks.py:105 INFO train-abinet] epoch 1 iter 41850: loss = 0.8058,  smooth loss = 0.6312
[2022-07-04 22:05:06,567 callbacks.py:105 INFO train-abinet] epoch 1 iter 41900: loss = 0.7742,  smooth loss = 0.6398
[2022-07-04 22:05:50,079 callbacks.py:105 INFO train-abinet] epoch 1 iter 41950: loss = 0.6803,  smooth loss = 0.6327
[2022-07-04 22:06:33,711 callbacks.py:105 INFO train-abinet] epoch 1 iter 42000: loss = 0.6821,  smooth loss = 0.6381
[2022-07-04 22:06:33,712 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8454s
█[2022-07-04 22:06:48,510 callbacks.py:123 INFO train-abinet] epoch 1 iter 42000: eval loss = 1.1789,  ccr = 0.9546,  cwr = 0.9128,  ted = 1466.0000,  ned = 280.4841,  ted/w = 0.2023, 
[2022-07-04 22:06:48,511 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_42000
[2022-07-04 22:07:33,501 callbacks.py:105 INFO train-abinet] epoch 1 iter 42050: loss = 0.7626,  smooth loss = 0.6272
[2022-07-04 22:08:16,261 callbacks.py:105 INFO train-abinet] epoch 1 iter 42100: loss = 0.6360,  smooth loss = 0.6315
[2022-07-04 22:09:00,591 callbacks.py:105 INFO train-abinet] epoch 1 iter 42150: loss = 0.7871,  smooth loss = 0.6244
[2022-07-04 22:09:43,888 callbacks.py:105 INFO train-abinet] epoch 1 iter 42200: loss = 0.6840,  smooth loss = 0.6214
[2022-07-04 22:10:28,088 callbacks.py:105 INFO train-abinet] epoch 1 iter 42250: loss = 0.6604,  smooth loss = 0.6417
[2022-07-04 22:11:13,824 callbacks.py:105 INFO train-abinet] epoch 1 iter 42300: loss = 0.5502,  smooth loss = 0.6466
[2022-07-04 22:11:57,089 callbacks.py:105 INFO train-abinet] epoch 1 iter 42350: loss = 0.5250,  smooth loss = 0.6399
[2022-07-04 22:12:41,402 callbacks.py:105 INFO train-abinet] epoch 1 iter 42400: loss = 0.6083,  smooth loss = 0.6327
[2022-07-04 22:13:24,391 callbacks.py:105 INFO train-abinet] epoch 1 iter 42450: loss = 0.6160,  smooth loss = 0.6476
[2022-07-04 22:14:08,304 callbacks.py:105 INFO train-abinet] epoch 1 iter 42500: loss = 0.6492,  smooth loss = 0.6481
[2022-07-04 22:14:52,784 callbacks.py:105 INFO train-abinet] epoch 1 iter 42550: loss = 0.5597,  smooth loss = 0.6385
[2022-07-04 22:15:35,228 callbacks.py:105 INFO train-abinet] epoch 1 iter 42600: loss = 0.5612,  smooth loss = 0.6178
[2022-07-04 22:16:18,499 callbacks.py:105 INFO train-abinet] epoch 1 iter 42650: loss = 0.5472,  smooth loss = 0.6376
[2022-07-04 22:17:02,239 callbacks.py:105 INFO train-abinet] epoch 1 iter 42700: loss = 0.6145,  smooth loss = 0.6313
[2022-07-04 22:17:47,543 callbacks.py:105 INFO train-abinet] epoch 1 iter 42750: loss = 0.7723,  smooth loss = 0.6232
[2022-07-04 22:18:32,435 callbacks.py:105 INFO train-abinet] epoch 1 iter 42800: loss = 0.5732,  smooth loss = 0.6344
[2022-07-04 22:19:16,244 callbacks.py:105 INFO train-abinet] epoch 1 iter 42850: loss = 0.6676,  smooth loss = 0.6227
[2022-07-04 22:20:01,112 callbacks.py:105 INFO train-abinet] epoch 1 iter 42900: loss = 0.7740,  smooth loss = 0.6442
[2022-07-04 22:20:44,973 callbacks.py:105 INFO train-abinet] epoch 1 iter 42950: loss = 0.6954,  smooth loss = 0.6403
[2022-07-04 22:21:30,896 callbacks.py:105 INFO train-abinet] epoch 1 iter 43000: loss = 0.6111,  smooth loss = 0.6206
[2022-07-04 22:22:16,548 callbacks.py:105 INFO train-abinet] epoch 1 iter 43050: loss = 0.8225,  smooth loss = 0.6363
[2022-07-04 22:23:02,673 callbacks.py:105 INFO train-abinet] epoch 1 iter 43100: loss = 0.6524,  smooth loss = 0.6342
[2022-07-04 22:23:49,669 callbacks.py:105 INFO train-abinet] epoch 1 iter 43150: loss = 0.4810,  smooth loss = 0.6294
[2022-07-04 22:24:35,955 callbacks.py:105 INFO train-abinet] epoch 1 iter 43200: loss = 0.6212,  smooth loss = 0.6437
[2022-07-04 22:25:21,288 callbacks.py:105 INFO train-abinet] epoch 1 iter 43250: loss = 0.5848,  smooth loss = 0.6355
[2022-07-04 22:26:07,797 callbacks.py:105 INFO train-abinet] epoch 1 iter 43300: loss = 0.6408,  smooth loss = 0.6471
[2022-07-04 22:26:55,177 callbacks.py:105 INFO train-abinet] epoch 1 iter 43350: loss = 0.6394,  smooth loss = 0.6289
[2022-07-04 22:27:40,929 callbacks.py:105 INFO train-abinet] epoch 1 iter 43400: loss = 0.5746,  smooth loss = 0.6255
[2022-07-04 22:28:27,180 callbacks.py:105 INFO train-abinet] epoch 1 iter 43450: loss = 0.5907,  smooth loss = 0.6322
[2022-07-04 22:29:12,990 callbacks.py:105 INFO train-abinet] epoch 1 iter 43500: loss = 0.5357,  smooth loss = 0.6206
[2022-07-04 22:30:00,610 callbacks.py:105 INFO train-abinet] epoch 1 iter 43550: loss = 0.4276,  smooth loss = 0.6293
[2022-07-04 22:30:46,686 callbacks.py:105 INFO train-abinet] epoch 1 iter 43600: loss = 0.6406,  smooth loss = 0.6292
[2022-07-04 22:31:34,161 callbacks.py:105 INFO train-abinet] epoch 1 iter 43650: loss = 0.6693,  smooth loss = 0.6196
[2022-07-04 22:32:19,390 callbacks.py:105 INFO train-abinet] epoch 1 iter 43700: loss = 0.6450,  smooth loss = 0.6276
[2022-07-04 22:33:05,308 callbacks.py:105 INFO train-abinet] epoch 1 iter 43750: loss = 0.5411,  smooth loss = 0.6211
[2022-07-04 22:33:50,925 callbacks.py:105 INFO train-abinet] epoch 1 iter 43800: loss = 0.7560,  smooth loss = 0.6224
[2022-07-04 22:34:36,619 callbacks.py:105 INFO train-abinet] epoch 1 iter 43850: loss = 0.6479,  smooth loss = 0.6335
[2022-07-04 22:35:21,916 callbacks.py:105 INFO train-abinet] epoch 1 iter 43900: loss = 0.5207,  smooth loss = 0.6327
[2022-07-04 22:36:07,173 callbacks.py:105 INFO train-abinet] epoch 1 iter 43950: loss = 0.7614,  smooth loss = 0.6433
[2022-07-04 22:36:52,942 callbacks.py:105 INFO train-abinet] epoch 1 iter 44000: loss = 0.6881,  smooth loss = 0.6379
[2022-07-04 22:37:37,656 callbacks.py:105 INFO train-abinet] epoch 1 iter 44050: loss = 0.6816,  smooth loss = 0.6300
[2022-07-04 22:38:22,115 callbacks.py:105 INFO train-abinet] epoch 1 iter 44100: loss = 0.6921,  smooth loss = 0.6326
[2022-07-04 22:39:08,028 callbacks.py:105 INFO train-abinet] epoch 1 iter 44150: loss = 0.6106,  smooth loss = 0.6386
[2022-07-04 22:39:54,529 callbacks.py:105 INFO train-abinet] epoch 1 iter 44200: loss = 0.6355,  smooth loss = 0.6395
[2022-07-04 22:40:41,638 callbacks.py:105 INFO train-abinet] epoch 1 iter 44250: loss = 0.5602,  smooth loss = 0.6330
[2022-07-04 22:41:26,912 callbacks.py:105 INFO train-abinet] epoch 1 iter 44300: loss = 0.7220,  smooth loss = 0.6296
[2022-07-04 22:42:11,982 callbacks.py:105 INFO train-abinet] epoch 1 iter 44350: loss = 0.8231,  smooth loss = 0.6302
[2022-07-04 22:42:57,714 callbacks.py:105 INFO train-abinet] epoch 1 iter 44400: loss = 0.5619,  smooth loss = 0.6290
[2022-07-04 22:43:44,951 callbacks.py:105 INFO train-abinet] epoch 1 iter 44450: loss = 0.6261,  smooth loss = 0.6341
[2022-07-04 22:44:31,108 callbacks.py:105 INFO train-abinet] epoch 1 iter 44500: loss = 0.6900,  smooth loss = 0.6365
[2022-07-04 22:45:19,094 callbacks.py:105 INFO train-abinet] epoch 1 iter 44550: loss = 0.5906,  smooth loss = 0.6439
[2022-07-04 22:46:05,655 callbacks.py:105 INFO train-abinet] epoch 1 iter 44600: loss = 0.6805,  smooth loss = 0.6243
[2022-07-04 22:46:52,892 callbacks.py:105 INFO train-abinet] epoch 1 iter 44650: loss = 0.5916,  smooth loss = 0.6203
[2022-07-04 22:47:39,084 callbacks.py:105 INFO train-abinet] epoch 1 iter 44700: loss = 0.7546,  smooth loss = 0.6252
[2022-07-04 22:48:25,138 callbacks.py:105 INFO train-abinet] epoch 1 iter 44750: loss = 0.7011,  smooth loss = 0.6184
[2022-07-04 22:49:11,013 callbacks.py:105 INFO train-abinet] epoch 1 iter 44800: loss = 0.7137,  smooth loss = 0.6232
[2022-07-04 22:49:58,017 callbacks.py:105 INFO train-abinet] epoch 1 iter 44850: loss = 0.5725,  smooth loss = 0.6300
[2022-07-04 22:50:44,704 callbacks.py:105 INFO train-abinet] epoch 1 iter 44900: loss = 0.7195,  smooth loss = 0.6278
[2022-07-04 22:51:32,068 callbacks.py:105 INFO train-abinet] epoch 1 iter 44950: loss = 0.6792,  smooth loss = 0.6423
[2022-07-04 22:52:19,805 callbacks.py:105 INFO train-abinet] epoch 1 iter 45000: loss = 0.6727,  smooth loss = 0.6275
[2022-07-04 22:52:19,805 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8497s
█[2022-07-04 22:52:35,904 callbacks.py:123 INFO train-abinet] epoch 1 iter 45000: eval loss = 1.1740,  ccr = 0.9553,  cwr = 0.9107,  ted = 1435.0000,  ned = 282.9510,  ted/w = 0.1980, 
[2022-07-04 22:52:35,905 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_45000
[2022-07-04 22:53:26,009 callbacks.py:105 INFO train-abinet] epoch 1 iter 45050: loss = 0.6867,  smooth loss = 0.6271
[2022-07-04 22:54:11,864 callbacks.py:105 INFO train-abinet] epoch 1 iter 45100: loss = 0.6741,  smooth loss = 0.6307
[2022-07-04 22:54:58,650 callbacks.py:105 INFO train-abinet] epoch 1 iter 45150: loss = 0.6463,  smooth loss = 0.6201
[2022-07-04 22:55:42,254 callbacks.py:105 INFO train-abinet] epoch 1 iter 45200: loss = 0.5927,  smooth loss = 0.6473
[2022-07-04 22:56:30,207 callbacks.py:105 INFO train-abinet] epoch 1 iter 45250: loss = 0.7965,  smooth loss = 0.6461
[2022-07-04 22:57:17,121 callbacks.py:105 INFO train-abinet] epoch 1 iter 45300: loss = 0.5440,  smooth loss = 0.6381
[2022-07-04 22:58:03,887 callbacks.py:105 INFO train-abinet] epoch 1 iter 45350: loss = 0.5460,  smooth loss = 0.6306
[2022-07-04 22:58:50,364 callbacks.py:105 INFO train-abinet] epoch 1 iter 45400: loss = 0.6266,  smooth loss = 0.6168
[2022-07-04 22:59:37,867 callbacks.py:105 INFO train-abinet] epoch 1 iter 45450: loss = 0.5452,  smooth loss = 0.6179
[2022-07-04 23:00:25,119 callbacks.py:105 INFO train-abinet] epoch 1 iter 45500: loss = 0.6271,  smooth loss = 0.6224
[2022-07-04 23:01:11,632 callbacks.py:105 INFO train-abinet] epoch 1 iter 45550: loss = 0.6129,  smooth loss = 0.6366
[2022-07-04 23:01:59,353 callbacks.py:105 INFO train-abinet] epoch 1 iter 45600: loss = 0.8142,  smooth loss = 0.6495
[2022-07-04 23:02:44,299 callbacks.py:105 INFO train-abinet] epoch 1 iter 45650: loss = 0.5658,  smooth loss = 0.6332
[2022-07-04 23:03:31,490 callbacks.py:105 INFO train-abinet] epoch 1 iter 45700: loss = 0.6953,  smooth loss = 0.6260
[2022-07-04 23:04:19,470 callbacks.py:105 INFO train-abinet] epoch 1 iter 45750: loss = 0.7135,  smooth loss = 0.6229
[2022-07-04 23:05:05,202 callbacks.py:105 INFO train-abinet] epoch 1 iter 45800: loss = 0.5877,  smooth loss = 0.6340
[2022-07-04 23:05:51,578 callbacks.py:105 INFO train-abinet] epoch 1 iter 45850: loss = 0.6775,  smooth loss = 0.6336
[2022-07-04 23:06:39,529 callbacks.py:105 INFO train-abinet] epoch 1 iter 45900: loss = 0.5499,  smooth loss = 0.6197
[2022-07-04 23:07:25,514 callbacks.py:105 INFO train-abinet] epoch 1 iter 45950: loss = 0.6377,  smooth loss = 0.6097
[2022-07-04 23:08:11,224 callbacks.py:105 INFO train-abinet] epoch 1 iter 46000: loss = 0.5943,  smooth loss = 0.6190
[2022-07-04 23:08:57,803 callbacks.py:105 INFO train-abinet] epoch 1 iter 46050: loss = 0.6488,  smooth loss = 0.6172
[2022-07-04 23:09:44,789 callbacks.py:105 INFO train-abinet] epoch 1 iter 46100: loss = 0.5814,  smooth loss = 0.6202
[2022-07-04 23:10:31,793 callbacks.py:105 INFO train-abinet] epoch 1 iter 46150: loss = 0.5172,  smooth loss = 0.6177
[2022-07-04 23:11:19,477 callbacks.py:105 INFO train-abinet] epoch 1 iter 46200: loss = 0.5203,  smooth loss = 0.6212
[2022-07-04 23:12:06,447 callbacks.py:105 INFO train-abinet] epoch 1 iter 46250: loss = 0.5425,  smooth loss = 0.6294
[2022-07-04 23:12:53,794 callbacks.py:105 INFO train-abinet] epoch 1 iter 46300: loss = 0.6674,  smooth loss = 0.6406
[2022-07-04 23:13:38,588 callbacks.py:105 INFO train-abinet] epoch 1 iter 46350: loss = 0.6205,  smooth loss = 0.6384
[2022-07-04 23:14:25,203 callbacks.py:105 INFO train-abinet] epoch 1 iter 46400: loss = 0.6141,  smooth loss = 0.6438
[2022-07-04 23:15:11,137 callbacks.py:105 INFO train-abinet] epoch 1 iter 46450: loss = 0.6215,  smooth loss = 0.6354
[2022-07-04 23:15:59,013 callbacks.py:105 INFO train-abinet] epoch 1 iter 46500: loss = 0.5253,  smooth loss = 0.6377
[2022-07-04 23:16:45,788 callbacks.py:105 INFO train-abinet] epoch 1 iter 46550: loss = 0.6357,  smooth loss = 0.6355
[2022-07-04 23:17:32,150 callbacks.py:105 INFO train-abinet] epoch 1 iter 46600: loss = 0.5489,  smooth loss = 0.6321
[2022-07-04 23:18:17,665 callbacks.py:105 INFO train-abinet] epoch 1 iter 46650: loss = 0.7927,  smooth loss = 0.6347
[2022-07-04 23:19:04,341 callbacks.py:105 INFO train-abinet] epoch 1 iter 46700: loss = 0.6214,  smooth loss = 0.6292
[2022-07-04 23:19:51,319 callbacks.py:105 INFO train-abinet] epoch 1 iter 46750: loss = 0.5478,  smooth loss = 0.6375
[2022-07-04 23:20:38,190 callbacks.py:105 INFO train-abinet] epoch 1 iter 46800: loss = 0.7023,  smooth loss = 0.6274
[2022-07-04 23:21:24,766 callbacks.py:105 INFO train-abinet] epoch 1 iter 46850: loss = 0.5595,  smooth loss = 0.6319
[2022-07-04 23:22:10,644 callbacks.py:105 INFO train-abinet] epoch 1 iter 46900: loss = 0.6619,  smooth loss = 0.6183
[2022-07-04 23:22:56,448 callbacks.py:105 INFO train-abinet] epoch 1 iter 46950: loss = 0.5615,  smooth loss = 0.6137
[2022-07-04 23:23:43,519 callbacks.py:105 INFO train-abinet] epoch 1 iter 47000: loss = 0.6591,  smooth loss = 0.6221
[2022-07-04 23:24:29,856 callbacks.py:105 INFO train-abinet] epoch 1 iter 47050: loss = 0.4795,  smooth loss = 0.6100
[2022-07-04 23:25:16,970 callbacks.py:105 INFO train-abinet] epoch 1 iter 47100: loss = 0.6477,  smooth loss = 0.6198
[2022-07-04 23:26:04,148 callbacks.py:105 INFO train-abinet] epoch 1 iter 47150: loss = 0.6246,  smooth loss = 0.6296
[2022-07-04 23:26:49,877 callbacks.py:105 INFO train-abinet] epoch 1 iter 47200: loss = 0.6795,  smooth loss = 0.6238
[2022-07-04 23:27:37,149 callbacks.py:105 INFO train-abinet] epoch 1 iter 47250: loss = 0.6375,  smooth loss = 0.6213
[2022-07-04 23:28:23,264 callbacks.py:105 INFO train-abinet] epoch 1 iter 47300: loss = 0.5848,  smooth loss = 0.6257
[2022-07-04 23:29:10,489 callbacks.py:105 INFO train-abinet] epoch 1 iter 47350: loss = 0.6529,  smooth loss = 0.6278
[2022-07-04 23:29:57,298 callbacks.py:105 INFO train-abinet] epoch 1 iter 47400: loss = 0.5624,  smooth loss = 0.6094
[2022-07-04 23:30:41,444 callbacks.py:105 INFO train-abinet] epoch 1 iter 47450: loss = 0.6197,  smooth loss = 0.6073
[2022-07-04 23:31:27,335 callbacks.py:105 INFO train-abinet] epoch 1 iter 47500: loss = 0.5615,  smooth loss = 0.6087
[2022-07-04 23:32:14,661 callbacks.py:105 INFO train-abinet] epoch 1 iter 47550: loss = 0.5223,  smooth loss = 0.6241
[2022-07-04 23:33:01,153 callbacks.py:105 INFO train-abinet] epoch 1 iter 47600: loss = 0.5090,  smooth loss = 0.6087
[2022-07-04 23:33:48,215 callbacks.py:105 INFO train-abinet] epoch 1 iter 47650: loss = 0.6403,  smooth loss = 0.6204
[2022-07-04 23:34:34,898 callbacks.py:105 INFO train-abinet] epoch 1 iter 47700: loss = 0.7882,  smooth loss = 0.6227
[2022-07-04 23:35:22,743 callbacks.py:105 INFO train-abinet] epoch 1 iter 47750: loss = 0.6833,  smooth loss = 0.6195
[2022-07-04 23:36:08,926 callbacks.py:105 INFO train-abinet] epoch 1 iter 47800: loss = 0.5056,  smooth loss = 0.6180
[2022-07-04 23:36:57,785 callbacks.py:105 INFO train-abinet] epoch 1 iter 47850: loss = 0.7399,  smooth loss = 0.6361
[2022-07-04 23:37:44,181 callbacks.py:105 INFO train-abinet] epoch 1 iter 47900: loss = 0.5729,  smooth loss = 0.6361
[2022-07-04 23:38:30,258 callbacks.py:105 INFO train-abinet] epoch 1 iter 47950: loss = 0.9506,  smooth loss = 0.6288
[2022-07-04 23:39:16,233 callbacks.py:105 INFO train-abinet] epoch 1 iter 48000: loss = 0.6408,  smooth loss = 0.6394
[2022-07-04 23:39:16,234 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8548s
█[2022-07-04 23:39:31,379 callbacks.py:123 INFO train-abinet] epoch 1 iter 48000: eval loss = 1.1405,  ccr = 0.9582,  cwr = 0.9121,  ted = 1384.0000,  ned = 269.8761,  ted/w = 0.1909, 
[2022-07-04 23:39:31,380 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_48000
[2022-07-04 23:40:17,889 callbacks.py:105 INFO train-abinet] epoch 1 iter 48050: loss = 0.7143,  smooth loss = 0.6293
[2022-07-04 23:41:05,250 callbacks.py:105 INFO train-abinet] epoch 1 iter 48100: loss = 0.5961,  smooth loss = 0.6316
[2022-07-04 23:41:52,026 callbacks.py:105 INFO train-abinet] epoch 1 iter 48150: loss = 0.6074,  smooth loss = 0.6261
[2022-07-04 23:42:38,645 callbacks.py:105 INFO train-abinet] epoch 1 iter 48200: loss = 0.7620,  smooth loss = 0.6260
[2022-07-04 23:43:25,043 callbacks.py:105 INFO train-abinet] epoch 1 iter 48250: loss = 0.7770,  smooth loss = 0.6313
[2022-07-04 23:44:13,041 callbacks.py:105 INFO train-abinet] epoch 1 iter 48300: loss = 0.5295,  smooth loss = 0.6271
[2022-07-04 23:45:01,020 callbacks.py:105 INFO train-abinet] epoch 1 iter 48350: loss = 0.6615,  smooth loss = 0.6231
[2022-07-04 23:45:48,440 callbacks.py:105 INFO train-abinet] epoch 1 iter 48400: loss = 0.6779,  smooth loss = 0.6208
[2022-07-04 23:46:35,180 callbacks.py:105 INFO train-abinet] epoch 1 iter 48450: loss = 0.6354,  smooth loss = 0.6382
[2022-07-04 23:47:22,758 callbacks.py:105 INFO train-abinet] epoch 1 iter 48500: loss = 0.5758,  smooth loss = 0.6338
[2022-07-04 23:48:09,332 callbacks.py:105 INFO train-abinet] epoch 1 iter 48550: loss = 0.5460,  smooth loss = 0.6244
[2022-07-04 23:48:53,415 callbacks.py:105 INFO train-abinet] epoch 1 iter 48600: loss = 0.5065,  smooth loss = 0.6301
[2022-07-04 23:49:40,774 callbacks.py:105 INFO train-abinet] epoch 1 iter 48650: loss = 0.6895,  smooth loss = 0.6447
[2022-07-04 23:50:26,387 callbacks.py:105 INFO train-abinet] epoch 1 iter 48700: loss = 0.5003,  smooth loss = 0.6410
[2022-07-04 23:51:13,401 callbacks.py:105 INFO train-abinet] epoch 1 iter 48750: loss = 0.6382,  smooth loss = 0.6281
[2022-07-04 23:52:01,930 callbacks.py:105 INFO train-abinet] epoch 1 iter 48800: loss = 0.7395,  smooth loss = 0.6296
[2022-07-04 23:52:49,286 callbacks.py:105 INFO train-abinet] epoch 1 iter 48850: loss = 0.4975,  smooth loss = 0.6402
[2022-07-04 23:53:37,738 callbacks.py:105 INFO train-abinet] epoch 1 iter 48900: loss = 0.7041,  smooth loss = 0.6389
[2022-07-04 23:54:25,487 callbacks.py:105 INFO train-abinet] epoch 1 iter 48950: loss = 0.5653,  smooth loss = 0.6136
[2022-07-04 23:55:13,672 callbacks.py:105 INFO train-abinet] epoch 1 iter 49000: loss = 1.0417,  smooth loss = 0.6329
[2022-07-04 23:56:01,003 callbacks.py:105 INFO train-abinet] epoch 1 iter 49050: loss = 0.6231,  smooth loss = 0.6231
[2022-07-04 23:56:49,504 callbacks.py:105 INFO train-abinet] epoch 1 iter 49100: loss = 0.5676,  smooth loss = 0.6344
[2022-07-04 23:57:36,201 callbacks.py:105 INFO train-abinet] epoch 1 iter 49150: loss = 0.5929,  smooth loss = 0.6365
[2022-07-04 23:58:23,693 callbacks.py:105 INFO train-abinet] epoch 1 iter 49200: loss = 0.7173,  smooth loss = 0.6382
[2022-07-04 23:59:11,328 callbacks.py:105 INFO train-abinet] epoch 1 iter 49250: loss = 0.6857,  smooth loss = 0.6353
[2022-07-04 23:59:58,138 callbacks.py:105 INFO train-abinet] epoch 1 iter 49300: loss = 0.5932,  smooth loss = 0.6378
[2022-07-05 00:00:45,138 callbacks.py:105 INFO train-abinet] epoch 1 iter 49350: loss = 0.8355,  smooth loss = 0.6382
[2022-07-05 00:01:32,470 callbacks.py:105 INFO train-abinet] epoch 1 iter 49400: loss = 0.6296,  smooth loss = 0.6204
[2022-07-05 00:02:18,566 callbacks.py:105 INFO train-abinet] epoch 1 iter 49450: loss = 0.5298,  smooth loss = 0.6233
[2022-07-05 00:03:05,516 callbacks.py:105 INFO train-abinet] epoch 1 iter 49500: loss = 0.6083,  smooth loss = 0.6227
[2022-07-05 00:03:52,085 callbacks.py:105 INFO train-abinet] epoch 1 iter 49550: loss = 0.6530,  smooth loss = 0.6131
[2022-07-05 00:04:39,186 callbacks.py:105 INFO train-abinet] epoch 1 iter 49600: loss = 0.4936,  smooth loss = 0.6270
[2022-07-05 00:05:26,081 callbacks.py:105 INFO train-abinet] epoch 1 iter 49650: loss = 0.8044,  smooth loss = 0.6347
[2022-07-05 00:06:10,232 callbacks.py:105 INFO train-abinet] epoch 1 iter 49700: loss = 0.5733,  smooth loss = 0.6159
[2022-07-05 00:06:57,446 callbacks.py:105 INFO train-abinet] epoch 1 iter 49750: loss = 0.6872,  smooth loss = 0.6214
[2022-07-05 00:07:44,093 callbacks.py:105 INFO train-abinet] epoch 1 iter 49800: loss = 0.6205,  smooth loss = 0.6346
[2022-07-05 00:08:29,977 callbacks.py:105 INFO train-abinet] epoch 1 iter 49850: loss = 0.7745,  smooth loss = 0.6370
[2022-07-05 00:09:16,031 callbacks.py:105 INFO train-abinet] epoch 1 iter 49900: loss = 0.6919,  smooth loss = 0.6314
[2022-07-05 00:10:02,480 callbacks.py:105 INFO train-abinet] epoch 1 iter 49950: loss = 0.5583,  smooth loss = 0.6147
[2022-07-05 00:10:49,000 callbacks.py:105 INFO train-abinet] epoch 1 iter 50000: loss = 0.4703,  smooth loss = 0.6180
[2022-07-05 00:11:36,722 callbacks.py:105 INFO train-abinet] epoch 1 iter 50050: loss = 0.6855,  smooth loss = 0.6275
[2022-07-05 00:12:25,101 callbacks.py:105 INFO train-abinet] epoch 1 iter 50100: loss = 0.5340,  smooth loss = 0.6233
[2022-07-05 00:13:11,982 callbacks.py:105 INFO train-abinet] epoch 1 iter 50150: loss = 0.6232,  smooth loss = 0.6338
[2022-07-05 00:13:58,474 callbacks.py:105 INFO train-abinet] epoch 1 iter 50200: loss = 0.6230,  smooth loss = 0.6474
[2022-07-05 00:14:46,654 callbacks.py:105 INFO train-abinet] epoch 1 iter 50250: loss = 0.7125,  smooth loss = 0.6261
[2022-07-05 00:15:33,869 callbacks.py:105 INFO train-abinet] epoch 1 iter 50300: loss = 0.5734,  smooth loss = 0.6135
[2022-07-05 00:16:21,334 callbacks.py:105 INFO train-abinet] epoch 1 iter 50350: loss = 0.4989,  smooth loss = 0.6198
[2022-07-05 00:17:08,408 callbacks.py:105 INFO train-abinet] epoch 1 iter 50400: loss = 0.6076,  smooth loss = 0.6247
[2022-07-05 00:17:56,168 callbacks.py:105 INFO train-abinet] epoch 1 iter 50450: loss = 0.7526,  smooth loss = 0.6350
[2022-07-05 00:18:44,054 callbacks.py:105 INFO train-abinet] epoch 1 iter 50500: loss = 0.7466,  smooth loss = 0.6403
[2022-07-05 00:19:31,121 callbacks.py:105 INFO train-abinet] epoch 1 iter 50550: loss = 0.6232,  smooth loss = 0.6265
[2022-07-05 00:20:18,254 callbacks.py:105 INFO train-abinet] epoch 1 iter 50600: loss = 0.7116,  smooth loss = 0.6173
[2022-07-05 00:21:05,370 callbacks.py:105 INFO train-abinet] epoch 1 iter 50650: loss = 0.5912,  smooth loss = 0.6211
[2022-07-05 00:21:52,549 callbacks.py:105 INFO train-abinet] epoch 1 iter 50700: loss = 0.7104,  smooth loss = 0.6361
[2022-07-05 00:22:40,839 callbacks.py:105 INFO train-abinet] epoch 1 iter 50750: loss = 0.6036,  smooth loss = 0.6151
[2022-07-05 00:23:28,539 callbacks.py:105 INFO train-abinet] epoch 1 iter 50800: loss = 0.7625,  smooth loss = 0.6102
[2022-07-05 00:24:12,510 callbacks.py:105 INFO train-abinet] epoch 1 iter 50850: loss = 0.5227,  smooth loss = 0.6207
[2022-07-05 00:24:59,344 callbacks.py:105 INFO train-abinet] epoch 1 iter 50900: loss = 0.8024,  smooth loss = 0.6288
[2022-07-05 00:25:46,920 callbacks.py:105 INFO train-abinet] epoch 1 iter 50950: loss = 0.6058,  smooth loss = 0.6448
[2022-07-05 00:26:33,938 callbacks.py:105 INFO train-abinet] epoch 1 iter 51000: loss = 0.5482,  smooth loss = 0.6347
[2022-07-05 00:26:33,939 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8598s
█[2022-07-05 00:26:50,357 callbacks.py:123 INFO train-abinet] epoch 1 iter 51000: eval loss = 1.2000,  ccr = 0.9539,  cwr = 0.9096,  ted = 1498.0000,  ned = 290.9468,  ted/w = 0.2067, 
[2022-07-05 00:26:50,358 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_51000
[2022-07-05 00:27:38,112 callbacks.py:105 INFO train-abinet] epoch 1 iter 51050: loss = 0.5355,  smooth loss = 0.6231
[2022-07-05 00:28:26,085 callbacks.py:105 INFO train-abinet] epoch 1 iter 51100: loss = 0.6461,  smooth loss = 0.6198
[2022-07-05 00:29:12,725 callbacks.py:105 INFO train-abinet] epoch 1 iter 51150: loss = 0.5426,  smooth loss = 0.6247
[2022-07-05 00:30:00,468 callbacks.py:105 INFO train-abinet] epoch 1 iter 51200: loss = 0.6468,  smooth loss = 0.6263
[2022-07-05 00:30:47,997 callbacks.py:105 INFO train-abinet] epoch 1 iter 51250: loss = 0.6873,  smooth loss = 0.6214
[2022-07-05 00:31:34,532 callbacks.py:105 INFO train-abinet] epoch 1 iter 51300: loss = 0.5058,  smooth loss = 0.6170
[2022-07-05 00:32:21,426 callbacks.py:105 INFO train-abinet] epoch 1 iter 51350: loss = 0.7310,  smooth loss = 0.6228
[2022-07-05 00:33:08,522 callbacks.py:105 INFO train-abinet] epoch 1 iter 51400: loss = 0.6559,  smooth loss = 0.6248
[2022-07-05 00:33:55,488 callbacks.py:105 INFO train-abinet] epoch 1 iter 51450: loss = 0.5497,  smooth loss = 0.6407
[2022-07-05 00:34:41,834 callbacks.py:105 INFO train-abinet] epoch 1 iter 51500: loss = 0.7277,  smooth loss = 0.6448
[2022-07-05 00:35:28,375 callbacks.py:105 INFO train-abinet] epoch 1 iter 51550: loss = 0.7457,  smooth loss = 0.6478
[2022-07-05 00:36:16,027 callbacks.py:105 INFO train-abinet] epoch 1 iter 51600: loss = 0.5811,  smooth loss = 0.6353
[2022-07-05 00:37:02,218 callbacks.py:105 INFO train-abinet] epoch 1 iter 51650: loss = 0.5356,  smooth loss = 0.6415
[2022-07-05 00:37:50,543 callbacks.py:105 INFO train-abinet] epoch 1 iter 51700: loss = 0.6089,  smooth loss = 0.6364
[2022-07-05 00:38:37,960 callbacks.py:105 INFO train-abinet] epoch 1 iter 51750: loss = 0.6339,  smooth loss = 0.6270
[2022-07-05 00:39:25,238 callbacks.py:105 INFO train-abinet] epoch 1 iter 51800: loss = 0.6905,  smooth loss = 0.6342
[2022-07-05 00:40:13,626 callbacks.py:105 INFO train-abinet] epoch 1 iter 51850: loss = 0.5567,  smooth loss = 0.6129
[2022-07-05 00:41:02,363 callbacks.py:105 INFO train-abinet] epoch 1 iter 51900: loss = 0.6182,  smooth loss = 0.6132
[2022-07-05 00:41:46,837 callbacks.py:105 INFO train-abinet] epoch 1 iter 51950: loss = 0.6068,  smooth loss = 0.6114
[2022-07-05 00:42:33,613 callbacks.py:105 INFO train-abinet] epoch 1 iter 52000: loss = 0.5988,  smooth loss = 0.6317
[2022-07-05 00:43:21,663 callbacks.py:105 INFO train-abinet] epoch 1 iter 52050: loss = 0.5949,  smooth loss = 0.6285
[2022-07-05 00:44:09,140 callbacks.py:105 INFO train-abinet] epoch 1 iter 52100: loss = 0.6839,  smooth loss = 0.6263
[2022-07-05 00:44:55,782 callbacks.py:105 INFO train-abinet] epoch 1 iter 52150: loss = 0.5872,  smooth loss = 0.6248
[2022-07-05 00:45:43,084 callbacks.py:105 INFO train-abinet] epoch 1 iter 52200: loss = 0.7456,  smooth loss = 0.6261
[2022-07-05 00:46:29,588 callbacks.py:105 INFO train-abinet] epoch 1 iter 52250: loss = 0.7582,  smooth loss = 0.6336
[2022-07-05 00:47:15,796 callbacks.py:105 INFO train-abinet] epoch 1 iter 52300: loss = 0.6793,  smooth loss = 0.6316
[2022-07-05 00:48:04,467 callbacks.py:105 INFO train-abinet] epoch 1 iter 52350: loss = 0.6038,  smooth loss = 0.6183
[2022-07-05 00:48:51,853 callbacks.py:105 INFO train-abinet] epoch 1 iter 52400: loss = 0.4992,  smooth loss = 0.6196
[2022-07-05 00:49:38,631 callbacks.py:105 INFO train-abinet] epoch 1 iter 52450: loss = 0.7540,  smooth loss = 0.6337
[2022-07-05 00:50:25,551 callbacks.py:105 INFO train-abinet] epoch 1 iter 52500: loss = 0.7628,  smooth loss = 0.6354
[2022-07-05 00:51:12,492 callbacks.py:105 INFO train-abinet] epoch 1 iter 52550: loss = 0.4967,  smooth loss = 0.6263
[2022-07-05 00:52:00,430 callbacks.py:105 INFO train-abinet] epoch 1 iter 52600: loss = 0.5116,  smooth loss = 0.6219
[2022-07-05 00:52:47,040 callbacks.py:105 INFO train-abinet] epoch 1 iter 52650: loss = 0.5532,  smooth loss = 0.6156
[2022-07-05 00:53:34,007 callbacks.py:105 INFO train-abinet] epoch 1 iter 52700: loss = 0.5881,  smooth loss = 0.6075
[2022-07-05 00:54:22,319 callbacks.py:105 INFO train-abinet] epoch 1 iter 52750: loss = 0.6884,  smooth loss = 0.6345
[2022-07-05 00:55:08,664 callbacks.py:105 INFO train-abinet] epoch 1 iter 52800: loss = 0.6640,  smooth loss = 0.6071
[2022-07-05 00:55:55,550 callbacks.py:105 INFO train-abinet] epoch 1 iter 52850: loss = 0.7496,  smooth loss = 0.6123
[2022-07-05 00:56:42,359 callbacks.py:105 INFO train-abinet] epoch 1 iter 52900: loss = 0.6045,  smooth loss = 0.6243
[2022-07-05 00:57:29,508 callbacks.py:105 INFO train-abinet] epoch 1 iter 52950: loss = 0.5094,  smooth loss = 0.6289
[2022-07-05 00:58:15,919 callbacks.py:105 INFO train-abinet] epoch 1 iter 53000: loss = 0.6926,  smooth loss = 0.6274
[2022-07-05 00:59:03,548 callbacks.py:105 INFO train-abinet] epoch 1 iter 53050: loss = 0.6353,  smooth loss = 0.6149
[2022-07-05 00:59:47,052 callbacks.py:105 INFO train-abinet] epoch 1 iter 53100: loss = 0.6354,  smooth loss = 0.6179
[2022-07-05 01:00:33,347 callbacks.py:105 INFO train-abinet] epoch 1 iter 53150: loss = 0.6678,  smooth loss = 0.6224
[2022-07-05 01:01:19,705 callbacks.py:105 INFO train-abinet] epoch 1 iter 53200: loss = 0.6781,  smooth loss = 0.6306
[2022-07-05 01:02:06,549 callbacks.py:105 INFO train-abinet] epoch 1 iter 53250: loss = 0.6417,  smooth loss = 0.6257
[2022-07-05 01:02:55,191 callbacks.py:105 INFO train-abinet] epoch 1 iter 53300: loss = 0.6365,  smooth loss = 0.6171
[2022-07-05 01:03:42,500 callbacks.py:105 INFO train-abinet] epoch 1 iter 53350: loss = 0.5367,  smooth loss = 0.6160
[2022-07-05 01:04:29,289 callbacks.py:105 INFO train-abinet] epoch 1 iter 53400: loss = 0.7129,  smooth loss = 0.6349
[2022-07-05 01:05:17,586 callbacks.py:105 INFO train-abinet] epoch 1 iter 53450: loss = 0.5429,  smooth loss = 0.6303
[2022-07-05 01:06:04,210 callbacks.py:105 INFO train-abinet] epoch 1 iter 53500: loss = 0.6716,  smooth loss = 0.6252
[2022-07-05 01:06:51,831 callbacks.py:105 INFO train-abinet] epoch 1 iter 53550: loss = 0.6154,  smooth loss = 0.6219
[2022-07-05 01:07:39,989 callbacks.py:105 INFO train-abinet] epoch 1 iter 53600: loss = 0.5130,  smooth loss = 0.6163
[2022-07-05 01:08:28,915 callbacks.py:105 INFO train-abinet] epoch 1 iter 53650: loss = 0.6502,  smooth loss = 0.6283
[2022-07-05 01:09:17,867 callbacks.py:105 INFO train-abinet] epoch 1 iter 53700: loss = 1.0041,  smooth loss = 0.6334
[2022-07-05 01:10:04,729 callbacks.py:105 INFO train-abinet] epoch 1 iter 53750: loss = 0.6053,  smooth loss = 0.6310
[2022-07-05 01:10:51,003 callbacks.py:105 INFO train-abinet] epoch 1 iter 53800: loss = 0.5563,  smooth loss = 0.6340
[2022-07-05 01:11:37,877 callbacks.py:105 INFO train-abinet] epoch 1 iter 53850: loss = 0.7399,  smooth loss = 0.6165
[2022-07-05 01:12:25,399 callbacks.py:105 INFO train-abinet] epoch 1 iter 53900: loss = 0.5843,  smooth loss = 0.6312
[2022-07-05 01:13:12,231 callbacks.py:105 INFO train-abinet] epoch 1 iter 53950: loss = 0.5953,  smooth loss = 0.6307
[2022-07-05 01:13:59,649 callbacks.py:105 INFO train-abinet] epoch 1 iter 54000: loss = 0.5615,  smooth loss = 0.6049
[2022-07-05 01:13:59,649 callbacks.py:114 INFO train-abinet] average data time = 0.0057s, average running time = 0.8643s
█[2022-07-05 01:14:14,939 callbacks.py:123 INFO train-abinet] epoch 1 iter 54000: eval loss = 1.1689,  ccr = 0.9569,  cwr = 0.9100,  ted = 1419.0000,  ned = 282.5606,  ted/w = 0.1958, 
[2022-07-05 01:14:14,940 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_54000
[2022-07-05 01:15:01,641 callbacks.py:105 INFO train-abinet] epoch 1 iter 54050: loss = 0.7085,  smooth loss = 0.6166
[2022-07-05 01:15:49,312 callbacks.py:105 INFO train-abinet] epoch 1 iter 54100: loss = 0.6932,  smooth loss = 0.6136
[2022-07-05 01:16:38,243 callbacks.py:105 INFO train-abinet] epoch 1 iter 54150: loss = 0.6877,  smooth loss = 0.6286
[2022-07-05 01:17:22,790 callbacks.py:105 INFO train-abinet] epoch 1 iter 54200: loss = 0.5757,  smooth loss = 0.6138
[2022-07-05 01:18:08,345 callbacks.py:105 INFO train-abinet] epoch 1 iter 54250: loss = 0.6991,  smooth loss = 0.6181
[2022-07-05 01:18:54,789 callbacks.py:105 INFO train-abinet] epoch 1 iter 54300: loss = 0.6867,  smooth loss = 0.6156
[2022-07-05 01:19:42,057 callbacks.py:105 INFO train-abinet] epoch 1 iter 54350: loss = 0.6532,  smooth loss = 0.6184
[2022-07-05 01:20:28,970 callbacks.py:105 INFO train-abinet] epoch 1 iter 54400: loss = 0.6754,  smooth loss = 0.6272
[2022-07-05 01:21:14,398 callbacks.py:105 INFO train-abinet] epoch 1 iter 54450: loss = 0.8598,  smooth loss = 0.6190
[2022-07-05 01:22:01,214 callbacks.py:105 INFO train-abinet] epoch 1 iter 54500: loss = 0.6952,  smooth loss = 0.6147
[2022-07-05 01:22:48,809 callbacks.py:105 INFO train-abinet] epoch 1 iter 54550: loss = 0.5588,  smooth loss = 0.6157
[2022-07-05 01:23:35,743 callbacks.py:105 INFO train-abinet] epoch 1 iter 54600: loss = 0.5344,  smooth loss = 0.6180
[2022-07-05 01:24:21,671 callbacks.py:105 INFO train-abinet] epoch 1 iter 54650: loss = 0.5601,  smooth loss = 0.6143
[2022-07-05 01:25:07,418 callbacks.py:105 INFO train-abinet] epoch 1 iter 54700: loss = 0.6464,  smooth loss = 0.6069
[2022-07-05 01:25:55,488 callbacks.py:105 INFO train-abinet] epoch 1 iter 54750: loss = 0.5386,  smooth loss = 0.6055
[2022-07-05 01:26:43,843 callbacks.py:105 INFO train-abinet] epoch 1 iter 54800: loss = 0.8313,  smooth loss = 0.6141
[2022-07-05 01:27:30,029 callbacks.py:105 INFO train-abinet] epoch 1 iter 54850: loss = 0.6017,  smooth loss = 0.6286
[2022-07-05 01:28:18,040 callbacks.py:105 INFO train-abinet] epoch 1 iter 54900: loss = 0.5460,  smooth loss = 0.6297
[2022-07-05 01:29:05,120 callbacks.py:105 INFO train-abinet] epoch 1 iter 54950: loss = 0.5360,  smooth loss = 0.6288
[2022-07-05 01:29:51,858 callbacks.py:105 INFO train-abinet] epoch 1 iter 55000: loss = 0.5996,  smooth loss = 0.6260
[2022-07-05 01:30:37,995 callbacks.py:105 INFO train-abinet] epoch 1 iter 55050: loss = 0.4175,  smooth loss = 0.6228
[2022-07-05 01:31:24,431 callbacks.py:105 INFO train-abinet] epoch 1 iter 55100: loss = 0.6431,  smooth loss = 0.6180
[2022-07-05 01:32:13,292 callbacks.py:105 INFO train-abinet] epoch 1 iter 55150: loss = 0.5909,  smooth loss = 0.6151
[2022-07-05 01:32:59,666 callbacks.py:105 INFO train-abinet] epoch 1 iter 55200: loss = 0.5872,  smooth loss = 0.6122
[2022-07-05 01:33:46,135 callbacks.py:105 INFO train-abinet] epoch 1 iter 55250: loss = 0.5234,  smooth loss = 0.6219
[2022-07-05 01:34:33,843 callbacks.py:105 INFO train-abinet] epoch 1 iter 55300: loss = 0.7032,  smooth loss = 0.6269
[2022-07-05 01:35:18,060 callbacks.py:105 INFO train-abinet] epoch 1 iter 55350: loss = 0.8214,  smooth loss = 0.6141
[2022-07-05 01:36:04,913 callbacks.py:105 INFO train-abinet] epoch 1 iter 55400: loss = 0.7848,  smooth loss = 0.6195
[2022-07-05 01:36:51,568 callbacks.py:105 INFO train-abinet] epoch 1 iter 55450: loss = 0.7030,  smooth loss = 0.6170
[2022-07-05 01:37:38,558 callbacks.py:105 INFO train-abinet] epoch 1 iter 55500: loss = 0.6475,  smooth loss = 0.6258
[2022-07-05 01:38:25,456 callbacks.py:105 INFO train-abinet] epoch 1 iter 55550: loss = 0.7363,  smooth loss = 0.6261
[2022-07-05 01:39:12,735 callbacks.py:105 INFO train-abinet] epoch 1 iter 55600: loss = 0.7784,  smooth loss = 0.6346
[2022-07-05 01:40:01,135 callbacks.py:105 INFO train-abinet] epoch 1 iter 55650: loss = 0.4541,  smooth loss = 0.6395
[2022-07-05 01:40:46,729 callbacks.py:105 INFO train-abinet] epoch 1 iter 55700: loss = 0.7039,  smooth loss = 0.6379
[2022-07-05 01:41:32,971 callbacks.py:105 INFO train-abinet] epoch 1 iter 55750: loss = 0.6295,  smooth loss = 0.6245
[2022-07-05 01:42:19,733 callbacks.py:105 INFO train-abinet] epoch 1 iter 55800: loss = 0.6729,  smooth loss = 0.6217
[2022-07-05 01:43:05,718 callbacks.py:105 INFO train-abinet] epoch 1 iter 55850: loss = 0.5905,  smooth loss = 0.6190
[2022-07-05 01:43:53,000 callbacks.py:105 INFO train-abinet] epoch 1 iter 55900: loss = 0.6022,  smooth loss = 0.6235
[2022-07-05 01:44:39,444 callbacks.py:105 INFO train-abinet] epoch 1 iter 55950: loss = 0.6331,  smooth loss = 0.6285
[2022-07-05 01:45:25,465 callbacks.py:105 INFO train-abinet] epoch 1 iter 56000: loss = 0.6310,  smooth loss = 0.6412
[2022-07-05 01:46:11,506 callbacks.py:105 INFO train-abinet] epoch 1 iter 56050: loss = 0.7581,  smooth loss = 0.6301
[2022-07-05 01:46:57,773 callbacks.py:105 INFO train-abinet] epoch 1 iter 56100: loss = 0.6089,  smooth loss = 0.6370
[2022-07-05 01:47:46,112 callbacks.py:105 INFO train-abinet] epoch 1 iter 56150: loss = 0.6303,  smooth loss = 0.6300
[2022-07-05 01:48:33,533 callbacks.py:105 INFO train-abinet] epoch 1 iter 56200: loss = 0.4796,  smooth loss = 0.6230
[2022-07-05 01:49:21,367 callbacks.py:105 INFO train-abinet] epoch 1 iter 56250: loss = 0.5135,  smooth loss = 0.6310
[2022-07-05 01:50:08,940 callbacks.py:105 INFO train-abinet] epoch 1 iter 56300: loss = 0.7291,  smooth loss = 0.6333
[2022-07-05 01:50:56,542 callbacks.py:105 INFO train-abinet] epoch 1 iter 56350: loss = 0.7983,  smooth loss = 0.6322
[2022-07-05 01:51:43,336 callbacks.py:105 INFO train-abinet] epoch 1 iter 56400: loss = 0.6495,  smooth loss = 0.6352
[2022-07-05 01:52:30,509 callbacks.py:105 INFO train-abinet] epoch 1 iter 56450: loss = 0.5611,  smooth loss = 0.6224
[2022-07-05 01:53:14,196 callbacks.py:105 INFO train-abinet] epoch 1 iter 56500: loss = 0.6233,  smooth loss = 0.6317
[2022-07-05 01:54:00,849 callbacks.py:105 INFO train-abinet] epoch 1 iter 56550: loss = 0.5645,  smooth loss = 0.6303
[2022-07-05 01:54:47,744 callbacks.py:105 INFO train-abinet] epoch 1 iter 56600: loss = 0.8171,  smooth loss = 0.6223
[2022-07-05 01:55:34,417 callbacks.py:105 INFO train-abinet] epoch 1 iter 56650: loss = 0.5472,  smooth loss = 0.6169
[2022-07-05 01:56:22,313 callbacks.py:105 INFO train-abinet] epoch 1 iter 56700: loss = 0.7079,  smooth loss = 0.6170
[2022-07-05 01:57:09,061 callbacks.py:105 INFO train-abinet] epoch 1 iter 56750: loss = 0.7729,  smooth loss = 0.6353
[2022-07-05 01:57:55,406 callbacks.py:105 INFO train-abinet] epoch 1 iter 56800: loss = 0.5147,  smooth loss = 0.6188
[2022-07-05 01:58:41,467 callbacks.py:105 INFO train-abinet] epoch 1 iter 56850: loss = 0.5040,  smooth loss = 0.6141
[2022-07-05 01:59:30,571 callbacks.py:105 INFO train-abinet] epoch 1 iter 56900: loss = 0.5804,  smooth loss = 0.6222
[2022-07-05 02:00:17,806 callbacks.py:105 INFO train-abinet] epoch 1 iter 56950: loss = 0.4282,  smooth loss = 0.6146
[2022-07-05 02:01:05,420 callbacks.py:105 INFO train-abinet] epoch 1 iter 57000: loss = 0.5833,  smooth loss = 0.6129
[2022-07-05 02:01:05,421 callbacks.py:114 INFO train-abinet] average data time = 0.0058s, average running time = 0.8681s
█[2022-07-05 02:01:22,707 callbacks.py:123 INFO train-abinet] epoch 1 iter 57000: eval loss = 1.1497,  ccr = 0.9564,  cwr = 0.9118,  ted = 1417.0000,  ned = 273.6160,  ted/w = 0.1955, 
[2022-07-05 02:01:22,708 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_57000
[2022-07-05 02:02:09,936 callbacks.py:105 INFO train-abinet] epoch 1 iter 57050: loss = 0.6667,  smooth loss = 0.6221
[2022-07-05 02:02:57,315 callbacks.py:105 INFO train-abinet] epoch 1 iter 57100: loss = 0.6526,  smooth loss = 0.6094
[2022-07-05 02:03:44,155 callbacks.py:105 INFO train-abinet] epoch 1 iter 57150: loss = 0.6112,  smooth loss = 0.6110
[2022-07-05 02:04:31,490 callbacks.py:105 INFO train-abinet] epoch 1 iter 57200: loss = 0.6863,  smooth loss = 0.6242
[2022-07-05 02:05:18,234 callbacks.py:105 INFO train-abinet] epoch 1 iter 57250: loss = 0.5982,  smooth loss = 0.6242
[2022-07-05 02:06:05,581 callbacks.py:105 INFO train-abinet] epoch 1 iter 57300: loss = 0.6594,  smooth loss = 0.6217
[2022-07-05 02:06:51,197 callbacks.py:105 INFO train-abinet] epoch 1 iter 57350: loss = 0.5717,  smooth loss = 0.6265
[2022-07-05 02:07:39,044 callbacks.py:105 INFO train-abinet] epoch 1 iter 57400: loss = 0.6172,  smooth loss = 0.6226
[2022-07-05 02:08:25,163 callbacks.py:105 INFO train-abinet] epoch 1 iter 57450: loss = 0.7957,  smooth loss = 0.6321
[2022-07-05 02:09:13,228 callbacks.py:105 INFO train-abinet] epoch 1 iter 57500: loss = 0.5097,  smooth loss = 0.6275
[2022-07-05 02:10:00,300 callbacks.py:105 INFO train-abinet] epoch 1 iter 57550: loss = 0.5765,  smooth loss = 0.6197
[2022-07-05 02:10:44,875 callbacks.py:105 INFO train-abinet] epoch 1 iter 57600: loss = 0.5213,  smooth loss = 0.6151
[2022-07-05 02:11:31,480 callbacks.py:105 INFO train-abinet] epoch 1 iter 57650: loss = 0.5645,  smooth loss = 0.6275
[2022-07-05 02:12:17,787 callbacks.py:105 INFO train-abinet] epoch 1 iter 57700: loss = 0.6801,  smooth loss = 0.6225
[2022-07-05 02:13:06,001 callbacks.py:105 INFO train-abinet] epoch 1 iter 57750: loss = 0.5948,  smooth loss = 0.6128
[2022-07-05 02:13:53,562 callbacks.py:105 INFO train-abinet] epoch 1 iter 57800: loss = 0.4168,  smooth loss = 0.6094
[2022-07-05 02:14:39,890 callbacks.py:105 INFO train-abinet] epoch 1 iter 57850: loss = 0.9556,  smooth loss = 0.6129
[2022-07-05 02:15:28,149 callbacks.py:105 INFO train-abinet] epoch 1 iter 57900: loss = 0.6538,  smooth loss = 0.6254
[2022-07-05 02:16:15,702 callbacks.py:105 INFO train-abinet] epoch 1 iter 57950: loss = 0.5511,  smooth loss = 0.6091
[2022-07-05 02:17:01,703 callbacks.py:105 INFO train-abinet] epoch 1 iter 58000: loss = 0.6919,  smooth loss = 0.6180
[2022-07-05 02:17:47,633 callbacks.py:105 INFO train-abinet] epoch 1 iter 58050: loss = 0.5063,  smooth loss = 0.6143
[2022-07-05 02:18:33,708 callbacks.py:105 INFO train-abinet] epoch 1 iter 58100: loss = 0.3943,  smooth loss = 0.6246
[2022-07-05 02:19:20,267 callbacks.py:105 INFO train-abinet] epoch 1 iter 58150: loss = 0.5573,  smooth loss = 0.6103
[2022-07-05 02:20:07,657 callbacks.py:105 INFO train-abinet] epoch 1 iter 58200: loss = 0.6518,  smooth loss = 0.6160
[2022-07-05 02:20:55,964 callbacks.py:105 INFO train-abinet] epoch 1 iter 58250: loss = 0.5975,  smooth loss = 0.6220
[2022-07-05 02:21:43,490 callbacks.py:105 INFO train-abinet] epoch 1 iter 58300: loss = 0.7143,  smooth loss = 0.6264
[2022-07-05 02:22:31,700 callbacks.py:105 INFO train-abinet] epoch 1 iter 58350: loss = 0.5604,  smooth loss = 0.6235
[2022-07-05 02:23:18,990 callbacks.py:105 INFO train-abinet] epoch 1 iter 58400: loss = 0.7103,  smooth loss = 0.6189
[2022-07-05 02:24:09,098 callbacks.py:105 INFO train-abinet] epoch 1 iter 58450: loss = 0.4504,  smooth loss = 0.6161
[2022-07-05 02:24:59,746 callbacks.py:105 INFO train-abinet] epoch 1 iter 58500: loss = 0.5299,  smooth loss = 0.6192
[2022-07-05 02:25:48,355 callbacks.py:105 INFO train-abinet] epoch 1 iter 58550: loss = 0.6539,  smooth loss = 0.6188
[2022-07-05 02:26:35,616 callbacks.py:105 INFO train-abinet] epoch 1 iter 58600: loss = 0.5210,  smooth loss = 0.6134
[2022-07-05 02:27:21,894 callbacks.py:105 INFO train-abinet] epoch 1 iter 58650: loss = 0.4007,  smooth loss = 0.6158
[2022-07-05 02:28:08,381 callbacks.py:105 INFO train-abinet] epoch 1 iter 58700: loss = 0.7288,  smooth loss = 0.6223
[2022-07-05 02:28:53,697 callbacks.py:105 INFO train-abinet] epoch 1 iter 58750: loss = 0.6165,  smooth loss = 0.6136
[2022-07-05 02:29:41,558 callbacks.py:105 INFO train-abinet] epoch 1 iter 58800: loss = 0.7057,  smooth loss = 0.6323
[2022-07-05 02:30:28,581 callbacks.py:105 INFO train-abinet] epoch 1 iter 58850: loss = 0.6374,  smooth loss = 0.6142
[2022-07-05 02:31:15,420 callbacks.py:105 INFO train-abinet] epoch 1 iter 58900: loss = 0.6673,  smooth loss = 0.6130
[2022-07-05 02:32:03,254 callbacks.py:105 INFO train-abinet] epoch 1 iter 58950: loss = 0.4142,  smooth loss = 0.6180
[2022-07-05 02:32:50,380 callbacks.py:105 INFO train-abinet] epoch 1 iter 59000: loss = 0.6289,  smooth loss = 0.6245
[2022-07-05 02:33:38,699 callbacks.py:105 INFO train-abinet] epoch 1 iter 59050: loss = 0.5330,  smooth loss = 0.6138
[2022-07-05 02:34:28,397 callbacks.py:105 INFO train-abinet] epoch 1 iter 59100: loss = 0.6735,  smooth loss = 0.6139
[2022-07-05 02:35:17,303 callbacks.py:105 INFO train-abinet] epoch 1 iter 59150: loss = 0.5850,  smooth loss = 0.6128
[2022-07-05 02:36:07,049 callbacks.py:105 INFO train-abinet] epoch 1 iter 59200: loss = 0.5589,  smooth loss = 0.6035
[2022-07-05 02:36:56,528 callbacks.py:105 INFO train-abinet] epoch 1 iter 59250: loss = 0.7480,  smooth loss = 0.6233
[2022-07-05 02:37:48,041 callbacks.py:105 INFO train-abinet] epoch 1 iter 59300: loss = 0.6533,  smooth loss = 0.6121
[2022-07-05 02:38:38,929 callbacks.py:105 INFO train-abinet] epoch 1 iter 59350: loss = 0.6402,  smooth loss = 0.6182
[2022-07-05 02:39:26,654 callbacks.py:105 INFO train-abinet] epoch 1 iter 59400: loss = 0.7003,  smooth loss = 0.6205
[2022-07-05 02:40:16,189 callbacks.py:105 INFO train-abinet] epoch 1 iter 59450: loss = 0.5982,  smooth loss = 0.6070
[2022-07-05 02:41:04,873 callbacks.py:105 INFO train-abinet] epoch 1 iter 59500: loss = 0.5850,  smooth loss = 0.6012
[2022-07-05 02:41:53,038 callbacks.py:105 INFO train-abinet] epoch 1 iter 59550: loss = 0.7391,  smooth loss = 0.6087
[2022-07-05 02:42:42,490 callbacks.py:105 INFO train-abinet] epoch 1 iter 59600: loss = 0.5875,  smooth loss = 0.6052
[2022-07-05 02:43:30,080 callbacks.py:105 INFO train-abinet] epoch 1 iter 59650: loss = 0.6406,  smooth loss = 0.6266
[2022-07-05 02:44:19,361 callbacks.py:105 INFO train-abinet] epoch 1 iter 59700: loss = 0.6192,  smooth loss = 0.6109
[2022-07-05 02:45:08,543 callbacks.py:105 INFO train-abinet] epoch 1 iter 59750: loss = 0.5413,  smooth loss = 0.6075
[2022-07-05 02:45:56,913 callbacks.py:105 INFO train-abinet] epoch 1 iter 59800: loss = 0.5729,  smooth loss = 0.6197
[2022-07-05 02:46:43,033 callbacks.py:105 INFO train-abinet] epoch 1 iter 59850: loss = 0.4579,  smooth loss = 0.6194
[2022-07-05 02:47:31,543 callbacks.py:105 INFO train-abinet] epoch 1 iter 59900: loss = 0.7558,  smooth loss = 0.6155
[2022-07-05 02:48:19,540 callbacks.py:105 INFO train-abinet] epoch 1 iter 59950: loss = 0.7118,  smooth loss = 0.6127
[2022-07-05 02:49:07,246 callbacks.py:105 INFO train-abinet] epoch 1 iter 60000: loss = 0.5298,  smooth loss = 0.6200
[2022-07-05 02:49:07,247 callbacks.py:114 INFO train-abinet] average data time = 0.0058s, average running time = 0.8723s
█[2022-07-05 02:49:23,895 callbacks.py:123 INFO train-abinet] epoch 1 iter 60000: eval loss = 1.1514,  ccr = 0.9580,  cwr = 0.9095,  ted = 1443.0000,  ned = 282.5714,  ted/w = 0.1991, 
[2022-07-05 02:49:23,896 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_60000
[2022-07-05 02:50:12,894 callbacks.py:105 INFO train-abinet] epoch 1 iter 60050: loss = 0.6900,  smooth loss = 0.6243
[2022-07-05 02:51:00,354 callbacks.py:105 INFO train-abinet] epoch 1 iter 60100: loss = 0.5229,  smooth loss = 0.6307
[2022-07-05 02:51:46,952 callbacks.py:105 INFO train-abinet] epoch 1 iter 60150: loss = 0.6647,  smooth loss = 0.6362
[2022-07-05 02:52:36,089 callbacks.py:105 INFO train-abinet] epoch 1 iter 60200: loss = 0.5950,  smooth loss = 0.6234
[2022-07-05 02:53:25,922 callbacks.py:105 INFO train-abinet] epoch 1 iter 60250: loss = 0.5814,  smooth loss = 0.6330
[2022-07-05 02:54:13,370 callbacks.py:105 INFO train-abinet] epoch 1 iter 60300: loss = 0.6715,  smooth loss = 0.6349
[2022-07-05 02:55:01,779 callbacks.py:105 INFO train-abinet] epoch 1 iter 60350: loss = 0.5647,  smooth loss = 0.6248
[2022-07-05 02:55:48,228 callbacks.py:105 INFO train-abinet] epoch 1 iter 60400: loss = 0.6205,  smooth loss = 0.6292
[2022-07-05 02:56:37,132 callbacks.py:105 INFO train-abinet] epoch 1 iter 60450: loss = 0.6303,  smooth loss = 0.6097
[2022-07-05 02:57:24,786 callbacks.py:105 INFO train-abinet] epoch 1 iter 60500: loss = 0.5908,  smooth loss = 0.6174
[2022-07-05 02:58:12,548 callbacks.py:105 INFO train-abinet] epoch 1 iter 60550: loss = 0.6495,  smooth loss = 0.6136
[2022-07-05 02:59:01,125 callbacks.py:105 INFO train-abinet] epoch 1 iter 60600: loss = 0.5342,  smooth loss = 0.6372
[2022-07-05 02:59:48,684 callbacks.py:105 INFO train-abinet] epoch 1 iter 60650: loss = 0.6109,  smooth loss = 0.6414
[2022-07-05 03:00:37,867 callbacks.py:105 INFO train-abinet] epoch 1 iter 60700: loss = 0.5316,  smooth loss = 0.6192
[2022-07-05 03:01:25,977 callbacks.py:105 INFO train-abinet] epoch 1 iter 60750: loss = 0.4781,  smooth loss = 0.6162
[2022-07-05 03:02:14,699 callbacks.py:105 INFO train-abinet] epoch 1 iter 60800: loss = 0.6566,  smooth loss = 0.6168
[2022-07-05 03:03:03,931 callbacks.py:105 INFO train-abinet] epoch 1 iter 60850: loss = 0.6267,  smooth loss = 0.6043
[2022-07-05 03:03:52,909 callbacks.py:105 INFO train-abinet] epoch 1 iter 60900: loss = 0.5420,  smooth loss = 0.6154
[2022-07-05 03:04:40,605 callbacks.py:105 INFO train-abinet] epoch 1 iter 60950: loss = 0.6859,  smooth loss = 0.6254
[2022-07-05 03:05:26,368 callbacks.py:105 INFO train-abinet] epoch 1 iter 61000: loss = 0.6416,  smooth loss = 0.6081
[2022-07-05 03:06:15,343 callbacks.py:105 INFO train-abinet] epoch 1 iter 61050: loss = 0.6136,  smooth loss = 0.6197
[2022-07-05 03:07:06,607 callbacks.py:105 INFO train-abinet] epoch 1 iter 61100: loss = 0.5123,  smooth loss = 0.6098
[2022-07-05 03:07:57,193 callbacks.py:105 INFO train-abinet] epoch 1 iter 61150: loss = 0.5488,  smooth loss = 0.6073
[2022-07-05 03:08:48,364 callbacks.py:105 INFO train-abinet] epoch 1 iter 61200: loss = 0.6501,  smooth loss = 0.6142
[2022-07-05 03:09:34,252 callbacks.py:105 INFO train-abinet] epoch 1 iter 61250: loss = 0.7109,  smooth loss = 0.6100
[2022-07-05 03:10:23,324 callbacks.py:105 INFO train-abinet] epoch 1 iter 61300: loss = 0.6390,  smooth loss = 0.6144
[2022-07-05 03:11:10,620 callbacks.py:105 INFO train-abinet] epoch 1 iter 61350: loss = 0.8421,  smooth loss = 0.6249
[2022-07-05 03:11:58,130 callbacks.py:105 INFO train-abinet] epoch 1 iter 61400: loss = 0.6618,  smooth loss = 0.6130
[2022-07-05 03:12:46,704 callbacks.py:105 INFO train-abinet] epoch 1 iter 61450: loss = 0.7009,  smooth loss = 0.6051
[2022-07-05 03:13:35,791 callbacks.py:105 INFO train-abinet] epoch 1 iter 61500: loss = 0.6007,  smooth loss = 0.6206
[2022-07-05 03:14:23,135 callbacks.py:105 INFO train-abinet] epoch 1 iter 61550: loss = 0.5771,  smooth loss = 0.6106
[2022-07-05 03:15:10,576 callbacks.py:105 INFO train-abinet] epoch 1 iter 61600: loss = 0.6556,  smooth loss = 0.6203
[2022-07-05 03:15:58,735 callbacks.py:105 INFO train-abinet] epoch 1 iter 61650: loss = 0.6220,  smooth loss = 0.6041
[2022-07-05 03:16:45,918 callbacks.py:105 INFO train-abinet] epoch 1 iter 61700: loss = 0.6168,  smooth loss = 0.6043
[2022-07-05 03:17:34,522 callbacks.py:105 INFO train-abinet] epoch 1 iter 61750: loss = 0.6219,  smooth loss = 0.6330
[2022-07-05 03:18:22,041 callbacks.py:105 INFO train-abinet] epoch 1 iter 61800: loss = 0.6924,  smooth loss = 0.6213
[2022-07-05 03:19:09,998 callbacks.py:105 INFO train-abinet] epoch 1 iter 61850: loss = 0.5966,  smooth loss = 0.6264
[2022-07-05 03:19:59,779 callbacks.py:105 INFO train-abinet] epoch 1 iter 61900: loss = 0.5907,  smooth loss = 0.6226
[2022-07-05 03:20:47,736 callbacks.py:105 INFO train-abinet] epoch 1 iter 61950: loss = 0.6201,  smooth loss = 0.6117
[2022-07-05 03:21:36,201 callbacks.py:105 INFO train-abinet] epoch 1 iter 62000: loss = 0.5719,  smooth loss = 0.6157
[2022-07-05 03:22:22,705 callbacks.py:105 INFO train-abinet] epoch 1 iter 62050: loss = 0.5532,  smooth loss = 0.6009
[2022-07-05 03:23:07,990 callbacks.py:105 INFO train-abinet] epoch 1 iter 62100: loss = 0.4605,  smooth loss = 0.6104
[2022-07-05 03:23:58,899 callbacks.py:105 INFO train-abinet] epoch 1 iter 62150: loss = 0.6152,  smooth loss = 0.6155
[2022-07-05 03:24:49,905 callbacks.py:105 INFO train-abinet] epoch 1 iter 62200: loss = 0.6742,  smooth loss = 0.6148
[2022-07-05 03:25:37,482 callbacks.py:105 INFO train-abinet] epoch 1 iter 62250: loss = 0.6273,  smooth loss = 0.6092
[2022-07-05 03:26:31,896 callbacks.py:105 INFO train-abinet] epoch 1 iter 62300: loss = 0.6422,  smooth loss = 0.6149
[2022-07-05 03:27:24,260 callbacks.py:105 INFO train-abinet] epoch 1 iter 62350: loss = 0.6143,  smooth loss = 0.6290
[2022-07-05 03:28:16,219 callbacks.py:105 INFO train-abinet] epoch 1 iter 62400: loss = 0.6362,  smooth loss = 0.6023
[2022-07-05 03:29:13,964 callbacks.py:105 INFO train-abinet] epoch 1 iter 62450: loss = 0.6686,  smooth loss = 0.6060
[2022-07-05 03:30:07,714 callbacks.py:105 INFO train-abinet] epoch 1 iter 62500: loss = 0.5336,  smooth loss = 0.6092
[2022-07-05 03:31:02,675 callbacks.py:105 INFO train-abinet] epoch 1 iter 62550: loss = 0.5313,  smooth loss = 0.6122
[2022-07-05 03:31:59,585 callbacks.py:105 INFO train-abinet] epoch 1 iter 62600: loss = 0.4732,  smooth loss = 0.6136
[2022-07-05 03:32:53,808 callbacks.py:105 INFO train-abinet] epoch 1 iter 62650: loss = 0.5058,  smooth loss = 0.6027
[2022-07-05 03:33:52,230 callbacks.py:105 INFO train-abinet] epoch 1 iter 62700: loss = 0.5579,  smooth loss = 0.6058
[2022-07-05 03:34:46,783 callbacks.py:105 INFO train-abinet] epoch 1 iter 62750: loss = 0.5724,  smooth loss = 0.6061
[2022-07-05 03:35:36,029 callbacks.py:105 INFO train-abinet] epoch 1 iter 62800: loss = 0.5810,  smooth loss = 0.5993
[2022-07-05 03:36:33,330 callbacks.py:105 INFO train-abinet] epoch 1 iter 62850: loss = 0.7261,  smooth loss = 0.6019
[2022-07-05 03:37:37,111 callbacks.py:105 INFO train-abinet] epoch 1 iter 62900: loss = 0.5650,  smooth loss = 0.5956
[2022-07-05 03:38:33,916 callbacks.py:105 INFO train-abinet] epoch 1 iter 62950: loss = 0.5859,  smooth loss = 0.5977
[2022-07-05 03:39:17,820 callbacks.py:105 INFO train-abinet] epoch 1 iter 63000: loss = 0.5516,  smooth loss = 0.6114
[2022-07-05 03:39:17,821 callbacks.py:114 INFO train-abinet] average data time = 0.0059s, average running time = 0.8782s
█[2022-07-05 03:39:34,961 callbacks.py:123 INFO train-abinet] epoch 1 iter 63000: eval loss = 1.1388,  ccr = 0.9578,  cwr = 0.9121,  ted = 1449.0000,  ned = 285.7200,  ted/w = 0.1999, 
[2022-07-05 03:39:34,963 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_63000
[2022-07-05 03:40:40,817 callbacks.py:105 INFO train-abinet] epoch 1 iter 63050: loss = 0.5939,  smooth loss = 0.6207
[2022-07-05 03:41:57,698 callbacks.py:105 INFO train-abinet] epoch 1 iter 63100: loss = 0.5620,  smooth loss = 0.6259
[2022-07-05 03:43:04,512 callbacks.py:105 INFO train-abinet] epoch 1 iter 63150: loss = 0.6464,  smooth loss = 0.6289
[2022-07-05 03:44:03,318 callbacks.py:105 INFO train-abinet] epoch 1 iter 63200: loss = 0.5612,  smooth loss = 0.6189
[2022-07-05 03:45:01,200 callbacks.py:105 INFO train-abinet] epoch 1 iter 63250: loss = 0.6943,  smooth loss = 0.6177
[2022-07-05 03:45:56,550 callbacks.py:105 INFO train-abinet] epoch 1 iter 63300: loss = 0.6851,  smooth loss = 0.6191
[2022-07-05 03:46:56,790 callbacks.py:105 INFO train-abinet] epoch 1 iter 63350: loss = 0.5725,  smooth loss = 0.6237
[2022-07-05 03:47:54,874 callbacks.py:105 INFO train-abinet] epoch 1 iter 63400: loss = 0.6306,  smooth loss = 0.6291
[2022-07-05 03:48:53,916 callbacks.py:105 INFO train-abinet] epoch 1 iter 63450: loss = 0.5263,  smooth loss = 0.6228
[2022-07-05 03:49:50,612 callbacks.py:105 INFO train-abinet] epoch 1 iter 63500: loss = 0.5337,  smooth loss = 0.6227
[2022-07-05 03:50:46,354 callbacks.py:105 INFO train-abinet] epoch 1 iter 63550: loss = 0.6374,  smooth loss = 0.6252
[2022-07-05 03:51:43,592 callbacks.py:105 INFO train-abinet] epoch 1 iter 63600: loss = 0.5487,  smooth loss = 0.6219
[2022-07-05 03:52:42,443 callbacks.py:105 INFO train-abinet] epoch 1 iter 63650: loss = 0.5838,  smooth loss = 0.6112
[2022-07-05 03:53:37,880 callbacks.py:105 INFO train-abinet] epoch 1 iter 63700: loss = 0.7370,  smooth loss = 0.6143
[2022-07-05 03:54:34,999 callbacks.py:105 INFO train-abinet] epoch 1 iter 63750: loss = 0.5182,  smooth loss = 0.6181
[2022-07-05 03:55:30,067 callbacks.py:105 INFO train-abinet] epoch 1 iter 63800: loss = 0.5124,  smooth loss = 0.6127
[2022-07-05 03:56:18,160 callbacks.py:105 INFO train-abinet] epoch 1 iter 63850: loss = 0.5769,  smooth loss = 0.6165
[2022-07-05 03:57:04,992 callbacks.py:105 INFO train-abinet] epoch 1 iter 63900: loss = 0.6661,  smooth loss = 0.6230
[2022-07-05 03:57:49,781 callbacks.py:105 INFO train-abinet] epoch 1 iter 63950: loss = 0.5211,  smooth loss = 0.6077
[2022-07-05 03:58:37,023 callbacks.py:105 INFO train-abinet] epoch 1 iter 64000: loss = 0.8484,  smooth loss = 0.6279
[2022-07-05 03:59:30,358 callbacks.py:105 INFO train-abinet] epoch 1 iter 64050: loss = 0.5145,  smooth loss = 0.6197
[2022-07-05 04:00:27,379 callbacks.py:105 INFO train-abinet] epoch 1 iter 64100: loss = 0.5659,  smooth loss = 0.6198
[2022-07-05 04:01:19,199 callbacks.py:105 INFO train-abinet] epoch 1 iter 64150: loss = 0.6288,  smooth loss = 0.6259
[2022-07-05 04:02:14,859 callbacks.py:105 INFO train-abinet] epoch 1 iter 64200: loss = 0.6012,  smooth loss = 0.6266
[2022-07-05 04:03:04,539 callbacks.py:105 INFO train-abinet] epoch 1 iter 64250: loss = 0.6177,  smooth loss = 0.6051
[2022-07-05 04:03:58,440 callbacks.py:105 INFO train-abinet] epoch 1 iter 64300: loss = 0.6442,  smooth loss = 0.6135
[2022-07-05 04:04:52,587 callbacks.py:105 INFO train-abinet] epoch 1 iter 64350: loss = 0.5172,  smooth loss = 0.6157
[2022-07-05 04:05:41,159 callbacks.py:105 INFO train-abinet] epoch 1 iter 64400: loss = 0.4897,  smooth loss = 0.6003
[2022-07-05 04:06:35,472 callbacks.py:105 INFO train-abinet] epoch 1 iter 64450: loss = 0.5168,  smooth loss = 0.6092
[2022-07-05 04:07:33,409 callbacks.py:105 INFO train-abinet] epoch 1 iter 64500: loss = 0.6304,  smooth loss = 0.6116
[2022-07-05 04:08:34,928 callbacks.py:105 INFO train-abinet] epoch 1 iter 64550: loss = 0.4958,  smooth loss = 0.5965
[2022-07-05 04:09:33,912 callbacks.py:105 INFO train-abinet] epoch 1 iter 64600: loss = 0.5536,  smooth loss = 0.6078
[2022-07-05 04:10:33,588 callbacks.py:105 INFO train-abinet] epoch 1 iter 64650: loss = 0.5371,  smooth loss = 0.5987
[2022-07-05 04:11:31,592 callbacks.py:105 INFO train-abinet] epoch 1 iter 64700: loss = 0.7299,  smooth loss = 0.6241
[2022-07-05 04:12:34,566 callbacks.py:105 INFO train-abinet] epoch 1 iter 64750: loss = 0.4834,  smooth loss = 0.6227
[2022-07-05 04:13:31,192 callbacks.py:105 INFO train-abinet] epoch 1 iter 64800: loss = 0.6755,  smooth loss = 0.6232
[2022-07-05 04:14:22,556 callbacks.py:105 INFO train-abinet] epoch 1 iter 64850: loss = 0.4876,  smooth loss = 0.6070
[2022-07-05 04:15:10,180 callbacks.py:105 INFO train-abinet] epoch 1 iter 64900: loss = 0.6827,  smooth loss = 0.6182
[2022-07-05 04:15:59,085 callbacks.py:105 INFO train-abinet] epoch 1 iter 64950: loss = 0.6195,  smooth loss = 0.6123
[2022-07-05 04:16:54,238 callbacks.py:105 INFO train-abinet] epoch 1 iter 65000: loss = 0.5722,  smooth loss = 0.6146
[2022-07-05 04:17:50,683 callbacks.py:105 INFO train-abinet] epoch 1 iter 65050: loss = 0.6000,  smooth loss = 0.6156
[2022-07-05 04:18:51,038 callbacks.py:105 INFO train-abinet] epoch 1 iter 65100: loss = 0.6586,  smooth loss = 0.6051
[2022-07-05 04:19:47,502 callbacks.py:105 INFO train-abinet] epoch 1 iter 65150: loss = 0.4382,  smooth loss = 0.5967
[2022-07-05 04:20:47,230 callbacks.py:105 INFO train-abinet] epoch 1 iter 65200: loss = 0.6895,  smooth loss = 0.6120
[2022-07-05 04:21:45,564 callbacks.py:105 INFO train-abinet] epoch 1 iter 65250: loss = 0.5726,  smooth loss = 0.6205
[2022-07-05 04:22:45,820 callbacks.py:105 INFO train-abinet] epoch 1 iter 65300: loss = 0.7084,  smooth loss = 0.6128
[2022-07-05 04:23:44,881 callbacks.py:105 INFO train-abinet] epoch 1 iter 65350: loss = 0.6693,  smooth loss = 0.6043
[2022-07-05 04:24:39,947 callbacks.py:105 INFO train-abinet] epoch 1 iter 65400: loss = 0.5980,  smooth loss = 0.5936
[2022-07-05 04:25:40,687 callbacks.py:105 INFO train-abinet] epoch 1 iter 65450: loss = 0.6210,  smooth loss = 0.5952
[2022-07-05 04:26:40,182 callbacks.py:105 INFO train-abinet] epoch 1 iter 65500: loss = 0.6513,  smooth loss = 0.6130
[2022-07-05 04:27:38,052 callbacks.py:105 INFO train-abinet] epoch 1 iter 65550: loss = 0.6087,  smooth loss = 0.6097
[2022-07-05 04:28:36,482 callbacks.py:105 INFO train-abinet] epoch 1 iter 65600: loss = 0.6672,  smooth loss = 0.6121
[2022-07-05 04:29:30,774 callbacks.py:105 INFO train-abinet] epoch 1 iter 65650: loss = 0.7191,  smooth loss = 0.6105
[2022-07-05 04:30:23,266 callbacks.py:105 INFO train-abinet] epoch 1 iter 65700: loss = 0.6049,  smooth loss = 0.6086
[2022-07-05 04:31:14,008 callbacks.py:105 INFO train-abinet] epoch 1 iter 65750: loss = 0.4694,  smooth loss = 0.6067
[2022-07-05 04:32:03,706 callbacks.py:105 INFO train-abinet] epoch 1 iter 65800: loss = 0.5976,  smooth loss = 0.6047
[2022-07-05 04:32:48,319 callbacks.py:105 INFO train-abinet] epoch 1 iter 65850: loss = 0.6861,  smooth loss = 0.6110
[2022-07-05 04:33:30,873 callbacks.py:105 INFO train-abinet] epoch 1 iter 65900: loss = 0.6372,  smooth loss = 0.6087
[2022-07-05 04:34:13,157 callbacks.py:105 INFO train-abinet] epoch 1 iter 65950: loss = 0.3802,  smooth loss = 0.6221
[2022-07-05 04:35:02,659 callbacks.py:105 INFO train-abinet] epoch 1 iter 66000: loss = 0.8570,  smooth loss = 0.6238
[2022-07-05 04:35:02,661 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8885s
█[2022-07-05 04:35:17,188 callbacks.py:123 INFO train-abinet] epoch 1 iter 66000: eval loss = 1.1445,  ccr = 0.9577,  cwr = 0.9149,  ted = 1402.0000,  ned = 267.9291,  ted/w = 0.1934, 
[2022-07-05 04:35:17,189 callbacks.py:130 INFO train-abinet] Better model found at epoch 1, iter 66000 with accuracy value: 0.9149.
[2022-07-05 04:35:18,346 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_66000
[2022-07-05 04:36:13,313 callbacks.py:105 INFO train-abinet] epoch 1 iter 66050: loss = 0.5353,  smooth loss = 0.6298
[2022-07-05 04:37:01,744 callbacks.py:105 INFO train-abinet] epoch 1 iter 66100: loss = 0.5265,  smooth loss = 0.6125
[2022-07-05 04:37:43,772 callbacks.py:105 INFO train-abinet] epoch 1 iter 66150: loss = 0.5629,  smooth loss = 0.6136
[2022-07-05 04:38:28,238 callbacks.py:105 INFO train-abinet] epoch 1 iter 66200: loss = 0.5465,  smooth loss = 0.6120
[2022-07-05 04:39:17,100 callbacks.py:105 INFO train-abinet] epoch 1 iter 66250: loss = 0.7444,  smooth loss = 0.6074
[2022-07-05 04:40:00,574 callbacks.py:105 INFO train-abinet] epoch 1 iter 66300: loss = 0.5105,  smooth loss = 0.6166
[2022-07-05 04:40:44,841 callbacks.py:105 INFO train-abinet] epoch 1 iter 66350: loss = 0.5323,  smooth loss = 0.6124
[2022-07-05 04:41:28,106 callbacks.py:105 INFO train-abinet] epoch 1 iter 66400: loss = 0.6449,  smooth loss = 0.6119
[2022-07-05 04:42:11,797 callbacks.py:105 INFO train-abinet] epoch 1 iter 66450: loss = 0.6669,  smooth loss = 0.6137
[2022-07-05 04:42:54,123 callbacks.py:105 INFO train-abinet] epoch 1 iter 66500: loss = 0.5530,  smooth loss = 0.5994
[2022-07-05 04:43:37,737 callbacks.py:105 INFO train-abinet] epoch 1 iter 66550: loss = 0.5822,  smooth loss = 0.6011
[2022-07-05 04:44:21,020 callbacks.py:105 INFO train-abinet] epoch 1 iter 66600: loss = 0.6980,  smooth loss = 0.5906
[2022-07-05 04:45:05,340 callbacks.py:105 INFO train-abinet] epoch 1 iter 66650: loss = 0.7759,  smooth loss = 0.5996
[2022-07-05 04:45:49,148 callbacks.py:105 INFO train-abinet] epoch 1 iter 66700: loss = 0.5096,  smooth loss = 0.6109
[2022-07-05 04:46:33,195 callbacks.py:105 INFO train-abinet] epoch 1 iter 66750: loss = 0.6740,  smooth loss = 0.6195
[2022-07-05 04:47:17,399 callbacks.py:105 INFO train-abinet] epoch 1 iter 66800: loss = 0.6823,  smooth loss = 0.6117
[2022-07-05 04:48:01,887 callbacks.py:105 INFO train-abinet] epoch 1 iter 66850: loss = 0.5259,  smooth loss = 0.6050
[2022-07-05 04:48:46,879 callbacks.py:105 INFO train-abinet] epoch 1 iter 66900: loss = 0.6433,  smooth loss = 0.6139
[2022-07-05 04:49:32,132 callbacks.py:105 INFO train-abinet] epoch 1 iter 66950: loss = 0.5617,  smooth loss = 0.6278
[2022-07-05 04:50:15,858 callbacks.py:105 INFO train-abinet] epoch 1 iter 67000: loss = 0.7853,  smooth loss = 0.6173
[2022-07-05 04:50:59,726 callbacks.py:105 INFO train-abinet] epoch 1 iter 67050: loss = 0.5349,  smooth loss = 0.6174
[2022-07-05 04:51:43,533 callbacks.py:105 INFO train-abinet] epoch 1 iter 67100: loss = 0.4710,  smooth loss = 0.6170
[2022-07-05 04:52:27,695 callbacks.py:105 INFO train-abinet] epoch 1 iter 67150: loss = 0.5818,  smooth loss = 0.6212
[2022-07-05 04:53:10,862 callbacks.py:105 INFO train-abinet] epoch 1 iter 67200: loss = 0.7022,  smooth loss = 0.6152
[2022-07-05 04:53:56,024 callbacks.py:105 INFO train-abinet] epoch 1 iter 67250: loss = 0.6795,  smooth loss = 0.6111
[2022-07-05 04:54:40,307 callbacks.py:105 INFO train-abinet] epoch 1 iter 67300: loss = 0.5203,  smooth loss = 0.6065
[2022-07-05 04:55:24,255 callbacks.py:105 INFO train-abinet] epoch 1 iter 67350: loss = 0.6172,  smooth loss = 0.5972
[2022-07-05 04:56:07,469 callbacks.py:105 INFO train-abinet] epoch 1 iter 67400: loss = 0.7953,  smooth loss = 0.6172
[2022-07-05 04:56:50,764 callbacks.py:105 INFO train-abinet] epoch 1 iter 67450: loss = 0.5555,  smooth loss = 0.6078
[2022-07-05 04:57:33,894 callbacks.py:105 INFO train-abinet] epoch 1 iter 67500: loss = 0.5941,  smooth loss = 0.6009
[2022-07-05 04:58:17,600 callbacks.py:105 INFO train-abinet] epoch 1 iter 67550: loss = 0.6881,  smooth loss = 0.5997
[2022-07-05 04:59:01,512 callbacks.py:105 INFO train-abinet] epoch 1 iter 67600: loss = 0.7114,  smooth loss = 0.6148
[2022-07-05 04:59:44,798 callbacks.py:105 INFO train-abinet] epoch 1 iter 67650: loss = 0.5721,  smooth loss = 0.6069
[2022-07-05 05:00:27,566 callbacks.py:105 INFO train-abinet] epoch 1 iter 67700: loss = 0.6628,  smooth loss = 0.6196
[2022-07-05 05:01:11,124 callbacks.py:105 INFO train-abinet] epoch 1 iter 67750: loss = 0.4527,  smooth loss = 0.6118
[2022-07-05 05:01:54,579 callbacks.py:105 INFO train-abinet] epoch 1 iter 67800: loss = 0.5974,  smooth loss = 0.6266
[2022-07-05 05:02:39,113 callbacks.py:105 INFO train-abinet] epoch 1 iter 67850: loss = 0.5893,  smooth loss = 0.6176
[2022-07-05 05:03:23,413 callbacks.py:105 INFO train-abinet] epoch 1 iter 67900: loss = 0.6731,  smooth loss = 0.6012
[2022-07-05 05:04:07,548 callbacks.py:105 INFO train-abinet] epoch 1 iter 67950: loss = 0.5062,  smooth loss = 0.6059
[2022-07-05 05:04:51,230 callbacks.py:105 INFO train-abinet] epoch 1 iter 68000: loss = 0.5431,  smooth loss = 0.6044
[2022-07-05 05:05:34,474 callbacks.py:105 INFO train-abinet] epoch 1 iter 68050: loss = 0.6803,  smooth loss = 0.6247
[2022-07-05 05:06:18,341 callbacks.py:105 INFO train-abinet] epoch 1 iter 68100: loss = 0.6994,  smooth loss = 0.6075
[2022-07-05 05:07:02,383 callbacks.py:105 INFO train-abinet] epoch 1 iter 68150: loss = 0.6218,  smooth loss = 0.6245
[2022-07-05 05:07:45,572 callbacks.py:105 INFO train-abinet] epoch 1 iter 68200: loss = 0.6259,  smooth loss = 0.6196
[2022-07-05 05:08:27,727 callbacks.py:105 INFO train-abinet] epoch 1 iter 68250: loss = 0.5453,  smooth loss = 0.6149
[2022-07-05 05:09:12,137 callbacks.py:105 INFO train-abinet] epoch 1 iter 68300: loss = 0.5458,  smooth loss = 0.6139
[2022-07-05 05:09:55,076 callbacks.py:105 INFO train-abinet] epoch 1 iter 68350: loss = 0.7631,  smooth loss = 0.6107
[2022-07-05 05:10:37,076 callbacks.py:105 INFO train-abinet] epoch 1 iter 68400: loss = 0.6190,  smooth loss = 0.6114
[2022-07-05 05:11:20,346 callbacks.py:105 INFO train-abinet] epoch 1 iter 68450: loss = 0.5732,  smooth loss = 0.6130
[2022-07-05 05:12:03,775 callbacks.py:105 INFO train-abinet] epoch 1 iter 68500: loss = 0.6324,  smooth loss = 0.6069
[2022-07-05 05:12:47,717 callbacks.py:105 INFO train-abinet] epoch 1 iter 68550: loss = 0.5428,  smooth loss = 0.5958
[2022-07-05 05:13:31,840 callbacks.py:105 INFO train-abinet] epoch 1 iter 68600: loss = 0.6930,  smooth loss = 0.6038
[2022-07-05 05:14:15,499 callbacks.py:105 INFO train-abinet] epoch 1 iter 68650: loss = 0.6137,  smooth loss = 0.6221
[2022-07-05 05:14:59,329 callbacks.py:105 INFO train-abinet] epoch 1 iter 68700: loss = 0.5020,  smooth loss = 0.6126
[2022-07-05 05:15:42,859 callbacks.py:105 INFO train-abinet] epoch 1 iter 68750: loss = 0.5735,  smooth loss = 0.6130
[2022-07-05 05:16:26,799 callbacks.py:105 INFO train-abinet] epoch 1 iter 68800: loss = 0.6036,  smooth loss = 0.6157
[2022-07-05 05:17:09,037 callbacks.py:105 INFO train-abinet] epoch 1 iter 68850: loss = 0.6172,  smooth loss = 0.6180
[2022-07-05 05:17:52,331 callbacks.py:105 INFO train-abinet] epoch 1 iter 68900: loss = 0.7079,  smooth loss = 0.6150
[2022-07-05 05:18:36,330 callbacks.py:105 INFO train-abinet] epoch 1 iter 68950: loss = 0.5432,  smooth loss = 0.6244
[2022-07-05 05:19:20,661 callbacks.py:105 INFO train-abinet] epoch 1 iter 69000: loss = 0.7497,  smooth loss = 0.6236
[2022-07-05 05:19:20,662 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8882s
█[2022-07-05 05:19:35,720 callbacks.py:123 INFO train-abinet] epoch 1 iter 69000: eval loss = 1.1513,  ccr = 0.9555,  cwr = 0.9131,  ted = 1410.0000,  ned = 273.0408,  ted/w = 0.1945, 
[2022-07-05 05:19:35,721 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_69000
[2022-07-05 05:20:20,250 callbacks.py:105 INFO train-abinet] epoch 1 iter 69050: loss = 0.7195,  smooth loss = 0.6211
[2022-07-05 05:21:04,197 callbacks.py:105 INFO train-abinet] epoch 1 iter 69100: loss = 0.5022,  smooth loss = 0.6025
[2022-07-05 05:21:48,766 callbacks.py:105 INFO train-abinet] epoch 1 iter 69150: loss = 0.6918,  smooth loss = 0.6066
[2022-07-05 05:22:32,661 callbacks.py:105 INFO train-abinet] epoch 1 iter 69200: loss = 0.6372,  smooth loss = 0.6131
[2022-07-05 05:23:17,894 callbacks.py:105 INFO train-abinet] epoch 1 iter 69250: loss = 0.6079,  smooth loss = 0.6198
[2022-07-05 05:24:01,742 callbacks.py:105 INFO train-abinet] epoch 1 iter 69300: loss = 0.6699,  smooth loss = 0.6168
[2022-07-05 05:24:45,653 callbacks.py:105 INFO train-abinet] epoch 1 iter 69350: loss = 0.6532,  smooth loss = 0.6062
[2022-07-05 05:25:29,789 callbacks.py:105 INFO train-abinet] epoch 1 iter 69400: loss = 0.7498,  smooth loss = 0.6226
[2022-07-05 05:26:12,875 callbacks.py:105 INFO train-abinet] epoch 1 iter 69450: loss = 0.7438,  smooth loss = 0.6165
[2022-07-05 05:26:56,130 callbacks.py:105 INFO train-abinet] epoch 1 iter 69500: loss = 0.6526,  smooth loss = 0.6260
[2022-07-05 05:27:40,235 callbacks.py:105 INFO train-abinet] epoch 1 iter 69550: loss = 0.6914,  smooth loss = 0.6377
[2022-07-05 05:28:24,223 callbacks.py:105 INFO train-abinet] epoch 1 iter 69600: loss = 0.4507,  smooth loss = 0.6417
[2022-07-05 05:29:07,521 callbacks.py:105 INFO train-abinet] epoch 1 iter 69650: loss = 0.6214,  smooth loss = 0.6273
[2022-07-05 05:29:50,355 callbacks.py:105 INFO train-abinet] epoch 1 iter 69700: loss = 0.5688,  smooth loss = 0.6301
[2022-07-05 05:30:35,273 callbacks.py:105 INFO train-abinet] epoch 1 iter 69750: loss = 0.5474,  smooth loss = 0.6174
[2022-07-05 05:31:20,781 callbacks.py:105 INFO train-abinet] epoch 1 iter 69800: loss = 0.6825,  smooth loss = 0.6200
[2022-07-05 05:32:05,774 callbacks.py:105 INFO train-abinet] epoch 1 iter 69850: loss = 0.4060,  smooth loss = 0.6085
[2022-07-05 05:32:57,864 callbacks.py:105 INFO train-abinet] epoch 1 iter 69900: loss = 0.4876,  smooth loss = 0.5989
[2022-07-05 05:33:41,358 callbacks.py:105 INFO train-abinet] epoch 1 iter 69950: loss = 0.6450,  smooth loss = 0.6009
[2022-07-05 05:34:25,670 callbacks.py:105 INFO train-abinet] epoch 1 iter 70000: loss = 0.6516,  smooth loss = 0.5988
[2022-07-05 05:35:10,214 callbacks.py:105 INFO train-abinet] epoch 1 iter 70050: loss = 0.7056,  smooth loss = 0.6070
[2022-07-05 05:35:53,524 callbacks.py:105 INFO train-abinet] epoch 1 iter 70100: loss = 0.6631,  smooth loss = 0.6102
[2022-07-05 05:36:36,720 callbacks.py:105 INFO train-abinet] epoch 1 iter 70150: loss = 0.6937,  smooth loss = 0.6138
[2022-07-05 05:37:20,281 callbacks.py:105 INFO train-abinet] epoch 1 iter 70200: loss = 0.5719,  smooth loss = 0.6203
[2022-07-05 05:38:04,868 callbacks.py:105 INFO train-abinet] epoch 1 iter 70250: loss = 0.4511,  smooth loss = 0.6149
[2022-07-05 05:38:48,523 callbacks.py:105 INFO train-abinet] epoch 1 iter 70300: loss = 0.5012,  smooth loss = 0.6058
[2022-07-05 05:39:31,854 callbacks.py:105 INFO train-abinet] epoch 1 iter 70350: loss = 0.4778,  smooth loss = 0.5954
[2022-07-05 05:40:15,427 callbacks.py:105 INFO train-abinet] epoch 1 iter 70400: loss = 0.6974,  smooth loss = 0.6058
[2022-07-05 05:40:59,093 callbacks.py:105 INFO train-abinet] epoch 1 iter 70450: loss = 0.4988,  smooth loss = 0.6161
[2022-07-05 05:41:43,098 callbacks.py:105 INFO train-abinet] epoch 1 iter 70500: loss = 0.4548,  smooth loss = 0.6125
[2022-07-05 05:42:26,091 callbacks.py:105 INFO train-abinet] epoch 1 iter 70550: loss = 0.5333,  smooth loss = 0.6158
[2022-07-05 05:43:09,452 callbacks.py:105 INFO train-abinet] epoch 1 iter 70600: loss = 0.7365,  smooth loss = 0.6070
[2022-07-05 05:43:53,871 callbacks.py:105 INFO train-abinet] epoch 1 iter 70650: loss = 0.7803,  smooth loss = 0.6298
[2022-07-05 05:44:36,923 callbacks.py:105 INFO train-abinet] epoch 1 iter 70700: loss = 0.5186,  smooth loss = 0.6236
[2022-07-05 05:45:20,062 callbacks.py:105 INFO train-abinet] epoch 1 iter 70750: loss = 0.6225,  smooth loss = 0.6225
[2022-07-05 05:46:06,658 callbacks.py:105 INFO train-abinet] epoch 1 iter 70800: loss = 0.6084,  smooth loss = 0.6062
[2022-07-05 05:46:56,936 callbacks.py:105 INFO train-abinet] epoch 1 iter 70850: loss = 0.6435,  smooth loss = 0.6149
[2022-07-05 05:47:40,675 callbacks.py:105 INFO train-abinet] epoch 1 iter 70900: loss = 0.5059,  smooth loss = 0.6185
[2022-07-05 05:48:24,984 callbacks.py:105 INFO train-abinet] epoch 1 iter 70950: loss = 0.7570,  smooth loss = 0.6201
[2022-07-05 05:49:09,304 callbacks.py:105 INFO train-abinet] epoch 1 iter 71000: loss = 0.5465,  smooth loss = 0.6123
[2022-07-05 05:49:53,814 callbacks.py:105 INFO train-abinet] epoch 1 iter 71050: loss = 0.5256,  smooth loss = 0.5947
[2022-07-05 05:50:38,559 callbacks.py:105 INFO train-abinet] epoch 1 iter 71100: loss = 0.5417,  smooth loss = 0.5987
[2022-07-05 05:51:21,601 callbacks.py:105 INFO train-abinet] epoch 1 iter 71150: loss = 0.5152,  smooth loss = 0.5854
[2022-07-05 05:52:07,066 callbacks.py:105 INFO train-abinet] epoch 1 iter 71200: loss = 0.5969,  smooth loss = 0.6063
[2022-07-05 05:52:51,254 callbacks.py:105 INFO train-abinet] epoch 1 iter 71250: loss = 0.5710,  smooth loss = 0.5990
[2022-07-05 05:53:36,285 callbacks.py:105 INFO train-abinet] epoch 1 iter 71300: loss = 0.5558,  smooth loss = 0.5979
[2022-07-05 05:54:20,259 callbacks.py:105 INFO train-abinet] epoch 1 iter 71350: loss = 0.6628,  smooth loss = 0.6098
[2022-07-05 05:55:03,245 callbacks.py:105 INFO train-abinet] epoch 1 iter 71400: loss = 0.5731,  smooth loss = 0.6081
[2022-07-05 05:55:47,627 callbacks.py:105 INFO train-abinet] epoch 1 iter 71450: loss = 0.4817,  smooth loss = 0.6040
[2022-07-05 05:56:30,672 callbacks.py:105 INFO train-abinet] epoch 1 iter 71500: loss = 0.6103,  smooth loss = 0.5985
[2022-07-05 05:57:14,678 callbacks.py:105 INFO train-abinet] epoch 1 iter 71550: loss = 0.5574,  smooth loss = 0.6022
[2022-07-05 05:57:57,982 callbacks.py:105 INFO train-abinet] epoch 1 iter 71600: loss = 0.4899,  smooth loss = 0.5928
[2022-07-05 05:58:43,010 callbacks.py:105 INFO train-abinet] epoch 1 iter 71650: loss = 0.6436,  smooth loss = 0.5921
[2022-07-05 05:59:27,034 callbacks.py:105 INFO train-abinet] epoch 1 iter 71700: loss = 0.5461,  smooth loss = 0.6120
[2022-07-05 06:00:10,283 callbacks.py:105 INFO train-abinet] epoch 1 iter 71750: loss = 0.7000,  smooth loss = 0.6208
[2022-07-05 06:00:54,216 callbacks.py:105 INFO train-abinet] epoch 1 iter 71800: loss = 0.6799,  smooth loss = 0.6150
[2022-07-05 06:01:38,751 callbacks.py:105 INFO train-abinet] epoch 1 iter 71850: loss = 0.6652,  smooth loss = 0.6234
[2022-07-05 06:02:22,551 callbacks.py:105 INFO train-abinet] epoch 1 iter 71900: loss = 0.6941,  smooth loss = 0.6256
[2022-07-05 06:03:05,852 callbacks.py:105 INFO train-abinet] epoch 1 iter 71950: loss = 0.7069,  smooth loss = 0.6275
[2022-07-05 06:03:50,206 callbacks.py:105 INFO train-abinet] epoch 1 iter 72000: loss = 0.5409,  smooth loss = 0.6063
[2022-07-05 06:03:50,207 callbacks.py:114 INFO train-abinet] average data time = 0.0060s, average running time = 0.8880s
█[2022-07-05 06:04:05,604 callbacks.py:123 INFO train-abinet] epoch 1 iter 72000: eval loss = 1.1703,  ccr = 0.9587,  cwr = 0.9153,  ted = 1372.0000,  ned = 276.6590,  ted/w = 0.1893, 
[2022-07-05 06:04:05,605 callbacks.py:130 INFO train-abinet] Better model found at epoch 1, iter 72000 with accuracy value: 0.9153.
[2022-07-05 06:04:06,850 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_72000
[2022-07-05 06:04:50,859 callbacks.py:105 INFO train-abinet] epoch 1 iter 72050: loss = 0.5116,  smooth loss = 0.6292
[2022-07-05 06:05:34,245 callbacks.py:105 INFO train-abinet] epoch 1 iter 72100: loss = 0.4242,  smooth loss = 0.6280
[2022-07-05 06:06:18,405 callbacks.py:105 INFO train-abinet] epoch 1 iter 72150: loss = 0.7151,  smooth loss = 0.6092
[2022-07-05 06:07:02,986 callbacks.py:105 INFO train-abinet] epoch 1 iter 72200: loss = 0.4532,  smooth loss = 0.6073
[2022-07-05 06:07:46,756 callbacks.py:105 INFO train-abinet] epoch 1 iter 72250: loss = 0.4603,  smooth loss = 0.6261
[2022-07-05 06:08:29,879 callbacks.py:105 INFO train-abinet] epoch 1 iter 72300: loss = 0.4673,  smooth loss = 0.6169
[2022-07-05 06:09:13,825 callbacks.py:105 INFO train-abinet] epoch 1 iter 72350: loss = 0.6084,  smooth loss = 0.6041
[2022-07-05 06:09:57,089 callbacks.py:105 INFO train-abinet] epoch 1 iter 72400: loss = 0.5579,  smooth loss = 0.6159
[2022-07-05 06:10:39,868 callbacks.py:105 INFO train-abinet] epoch 1 iter 72450: loss = 0.4836,  smooth loss = 0.6105
[2022-07-05 06:11:23,317 callbacks.py:105 INFO train-abinet] epoch 1 iter 72500: loss = 0.5076,  smooth loss = 0.6057
[2022-07-05 06:12:06,535 callbacks.py:105 INFO train-abinet] epoch 1 iter 72550: loss = 0.7630,  smooth loss = 0.6059
[2022-07-05 06:12:50,054 callbacks.py:105 INFO train-abinet] epoch 1 iter 72600: loss = 0.6381,  smooth loss = 0.6163
[2022-07-05 06:13:33,827 callbacks.py:105 INFO train-abinet] epoch 1 iter 72650: loss = 0.6992,  smooth loss = 0.6009
[2022-07-05 06:14:18,577 callbacks.py:105 INFO train-abinet] epoch 1 iter 72700: loss = 0.6024,  smooth loss = 0.6001
[2022-07-05 06:15:01,345 callbacks.py:105 INFO train-abinet] epoch 1 iter 72750: loss = 0.5794,  smooth loss = 0.6099
[2022-07-05 06:15:46,203 callbacks.py:105 INFO train-abinet] epoch 1 iter 72800: loss = 0.5902,  smooth loss = 0.6086
[2022-07-05 06:16:31,380 callbacks.py:105 INFO train-abinet] epoch 1 iter 72850: loss = 0.5459,  smooth loss = 0.5959
[2022-07-05 06:17:15,142 callbacks.py:105 INFO train-abinet] epoch 1 iter 72900: loss = 0.6095,  smooth loss = 0.5977
[2022-07-05 06:18:00,577 callbacks.py:105 INFO train-abinet] epoch 1 iter 72950: loss = 0.6027,  smooth loss = 0.6078
[2022-07-05 06:18:50,707 callbacks.py:105 INFO train-abinet] epoch 1 iter 73000: loss = 0.6888,  smooth loss = 0.6037
[2022-07-05 06:19:34,998 callbacks.py:105 INFO train-abinet] epoch 1 iter 73050: loss = 0.8185,  smooth loss = 0.6223
[2022-07-05 06:20:19,711 callbacks.py:105 INFO train-abinet] epoch 1 iter 73100: loss = 0.7704,  smooth loss = 0.6260
[2022-07-05 06:21:02,999 callbacks.py:105 INFO train-abinet] epoch 1 iter 73150: loss = 0.6403,  smooth loss = 0.6214
[2022-07-05 06:21:46,989 callbacks.py:105 INFO train-abinet] epoch 1 iter 73200: loss = 0.5879,  smooth loss = 0.6228
[2022-07-05 06:22:30,413 callbacks.py:105 INFO train-abinet] epoch 1 iter 73250: loss = 0.5788,  smooth loss = 0.6085
[2022-07-05 06:23:14,305 callbacks.py:105 INFO train-abinet] epoch 1 iter 73300: loss = 0.5959,  smooth loss = 0.5969
[2022-07-05 06:23:58,975 callbacks.py:105 INFO train-abinet] epoch 1 iter 73350: loss = 0.6725,  smooth loss = 0.6127
[2022-07-05 06:24:42,840 callbacks.py:105 INFO train-abinet] epoch 1 iter 73400: loss = 0.7216,  smooth loss = 0.6204
[2022-07-05 06:25:25,841 callbacks.py:105 INFO train-abinet] epoch 1 iter 73450: loss = 0.7385,  smooth loss = 0.6189
[2022-07-05 06:26:08,883 callbacks.py:105 INFO train-abinet] epoch 1 iter 73500: loss = 0.5468,  smooth loss = 0.6103
[2022-07-05 06:26:53,766 callbacks.py:105 INFO train-abinet] epoch 1 iter 73550: loss = 0.5134,  smooth loss = 0.6124
[2022-07-05 06:27:38,431 callbacks.py:105 INFO train-abinet] epoch 1 iter 73600: loss = 0.6783,  smooth loss = 0.6215
[2022-07-05 06:28:21,724 callbacks.py:105 INFO train-abinet] epoch 1 iter 73650: loss = 0.6623,  smooth loss = 0.6234
[2022-07-05 06:29:05,101 callbacks.py:105 INFO train-abinet] epoch 1 iter 73700: loss = 0.7143,  smooth loss = 0.6162
[2022-07-05 06:29:48,854 callbacks.py:105 INFO train-abinet] epoch 1 iter 73750: loss = 0.6301,  smooth loss = 0.6067
[2022-07-05 06:30:32,944 callbacks.py:105 INFO train-abinet] epoch 1 iter 73800: loss = 0.5654,  smooth loss = 0.6028
[2022-07-05 06:31:16,908 callbacks.py:105 INFO train-abinet] epoch 1 iter 73850: loss = 0.7234,  smooth loss = 0.5966
[2022-07-05 06:32:01,128 callbacks.py:105 INFO train-abinet] epoch 1 iter 73900: loss = 0.6931,  smooth loss = 0.6060
[2022-07-05 06:32:45,100 callbacks.py:105 INFO train-abinet] epoch 1 iter 73950: loss = 0.5138,  smooth loss = 0.6128
[2022-07-05 06:33:29,246 callbacks.py:105 INFO train-abinet] epoch 1 iter 74000: loss = 0.6450,  smooth loss = 0.6295
[2022-07-05 06:34:12,747 callbacks.py:105 INFO train-abinet] epoch 1 iter 74050: loss = 0.6196,  smooth loss = 0.6181
[2022-07-05 06:34:56,355 callbacks.py:105 INFO train-abinet] epoch 1 iter 74100: loss = 0.5415,  smooth loss = 0.6183
[2022-07-05 06:35:41,301 callbacks.py:105 INFO train-abinet] epoch 1 iter 74150: loss = 0.5303,  smooth loss = 0.6134
[2022-07-05 06:36:24,439 callbacks.py:105 INFO train-abinet] epoch 1 iter 74200: loss = 0.5233,  smooth loss = 0.6062
[2022-07-05 06:37:05,226 callbacks.py:105 INFO train-abinet] epoch 1 iter 74250: loss = 0.7687,  smooth loss = 0.6017
[2022-07-05 06:37:46,120 callbacks.py:105 INFO train-abinet] epoch 1 iter 74300: loss = 0.6235,  smooth loss = 0.6021
[2022-07-05 06:38:26,533 callbacks.py:105 INFO train-abinet] epoch 1 iter 74350: loss = 0.4995,  smooth loss = 0.6062
[2022-07-05 06:39:06,956 callbacks.py:105 INFO train-abinet] epoch 1 iter 74400: loss = 0.5325,  smooth loss = 0.5995
[2022-07-05 06:39:48,032 callbacks.py:105 INFO train-abinet] epoch 1 iter 74450: loss = 0.5468,  smooth loss = 0.6067
[2022-07-05 06:40:28,517 callbacks.py:105 INFO train-abinet] epoch 1 iter 74500: loss = 0.6523,  smooth loss = 0.6161
[2022-07-05 06:41:09,605 callbacks.py:105 INFO train-abinet] epoch 1 iter 74550: loss = 0.6125,  smooth loss = 0.6248
[2022-07-05 06:41:50,158 callbacks.py:105 INFO train-abinet] epoch 1 iter 74600: loss = 0.6786,  smooth loss = 0.6316
[2022-07-05 06:42:30,685 callbacks.py:105 INFO train-abinet] epoch 1 iter 74650: loss = 0.6453,  smooth loss = 0.6105
[2022-07-05 06:43:11,000 callbacks.py:105 INFO train-abinet] epoch 1 iter 74700: loss = 0.6241,  smooth loss = 0.6054
[2022-07-05 06:43:51,600 callbacks.py:105 INFO train-abinet] epoch 1 iter 74750: loss = 0.6600,  smooth loss = 0.6108
[2022-07-05 06:44:32,084 callbacks.py:105 INFO train-abinet] epoch 1 iter 74800: loss = 0.5951,  smooth loss = 0.5894
[2022-07-05 06:45:13,189 callbacks.py:105 INFO train-abinet] epoch 1 iter 74850: loss = 0.5647,  smooth loss = 0.6003
[2022-07-05 06:45:54,730 callbacks.py:105 INFO train-abinet] epoch 1 iter 74900: loss = 0.6399,  smooth loss = 0.6048
[2022-07-05 06:46:35,296 callbacks.py:105 INFO train-abinet] epoch 1 iter 74950: loss = 0.6536,  smooth loss = 0.6045
[2022-07-05 06:47:15,971 callbacks.py:105 INFO train-abinet] epoch 1 iter 75000: loss = 0.6541,  smooth loss = 0.6124
[2022-07-05 06:47:15,971 callbacks.py:114 INFO train-abinet] average data time = 0.0060s, average running time = 0.8871s
█[2022-07-05 06:47:30,527 callbacks.py:123 INFO train-abinet] epoch 1 iter 75000: eval loss = 1.1608,  ccr = 0.9590,  cwr = 0.9135,  ted = 1387.0000,  ned = 277.9514,  ted/w = 0.1914, 
[2022-07-05 06:47:30,528 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_75000
[2022-07-05 06:48:12,707 callbacks.py:105 INFO train-abinet] epoch 1 iter 75050: loss = 0.7448,  smooth loss = 0.6199
[2022-07-05 06:48:53,790 callbacks.py:105 INFO train-abinet] epoch 1 iter 75100: loss = 0.6767,  smooth loss = 0.6241
[2022-07-05 06:49:34,872 callbacks.py:105 INFO train-abinet] epoch 1 iter 75150: loss = 0.6324,  smooth loss = 0.6218
[2022-07-05 06:50:15,873 callbacks.py:105 INFO train-abinet] epoch 1 iter 75200: loss = 0.6777,  smooth loss = 0.6242
[2022-07-05 06:50:56,845 callbacks.py:105 INFO train-abinet] epoch 1 iter 75250: loss = 0.6176,  smooth loss = 0.6120
[2022-07-05 06:51:37,879 callbacks.py:105 INFO train-abinet] epoch 1 iter 75300: loss = 0.7008,  smooth loss = 0.6311
[2022-07-05 06:52:18,671 callbacks.py:105 INFO train-abinet] epoch 1 iter 75350: loss = 0.4880,  smooth loss = 0.6267
[2022-07-05 06:52:59,810 callbacks.py:105 INFO train-abinet] epoch 1 iter 75400: loss = 0.4691,  smooth loss = 0.6113
[2022-07-05 06:53:43,614 callbacks.py:105 INFO train-abinet] epoch 1 iter 75450: loss = 0.6094,  smooth loss = 0.6051
[2022-07-05 06:54:24,684 callbacks.py:105 INFO train-abinet] epoch 1 iter 75500: loss = 0.6052,  smooth loss = 0.6170
[2022-07-05 06:55:05,182 callbacks.py:105 INFO train-abinet] epoch 1 iter 75550: loss = 0.6392,  smooth loss = 0.6116
[2022-07-05 06:55:45,631 callbacks.py:105 INFO train-abinet] epoch 1 iter 75600: loss = 0.6192,  smooth loss = 0.6036
[2022-07-05 06:56:26,921 callbacks.py:105 INFO train-abinet] epoch 1 iter 75650: loss = 0.5794,  smooth loss = 0.6087
[2022-07-05 06:57:08,507 callbacks.py:105 INFO train-abinet] epoch 1 iter 75700: loss = 0.5788,  smooth loss = 0.6137
[2022-07-05 06:57:49,557 callbacks.py:105 INFO train-abinet] epoch 1 iter 75750: loss = 0.5883,  smooth loss = 0.6104
[2022-07-05 06:58:30,455 callbacks.py:105 INFO train-abinet] epoch 1 iter 75800: loss = 0.7296,  smooth loss = 0.6079
[2022-07-05 06:59:11,245 callbacks.py:105 INFO train-abinet] epoch 1 iter 75850: loss = 0.4967,  smooth loss = 0.5974
[2022-07-05 06:59:53,308 callbacks.py:105 INFO train-abinet] epoch 1 iter 75900: loss = 0.5026,  smooth loss = 0.5943
[2022-07-05 07:00:34,590 callbacks.py:105 INFO train-abinet] epoch 1 iter 75950: loss = 0.6081,  smooth loss = 0.5796
[2022-07-05 07:01:16,191 callbacks.py:105 INFO train-abinet] epoch 1 iter 76000: loss = 0.5954,  smooth loss = 0.5972
[2022-07-05 07:01:57,882 callbacks.py:105 INFO train-abinet] epoch 1 iter 76050: loss = 0.6173,  smooth loss = 0.6060
[2022-07-05 07:02:38,995 callbacks.py:105 INFO train-abinet] epoch 1 iter 76100: loss = 0.4518,  smooth loss = 0.6019
[2022-07-05 07:03:20,447 callbacks.py:105 INFO train-abinet] epoch 1 iter 76150: loss = 0.5235,  smooth loss = 0.6026
[2022-07-05 07:04:02,050 callbacks.py:105 INFO train-abinet] epoch 1 iter 76200: loss = 0.6357,  smooth loss = 0.6064
[2022-07-05 07:04:42,878 callbacks.py:105 INFO train-abinet] epoch 1 iter 76250: loss = 0.6533,  smooth loss = 0.6215
[2022-07-05 07:05:25,034 callbacks.py:105 INFO train-abinet] epoch 1 iter 76300: loss = 0.7292,  smooth loss = 0.6163
[2022-07-05 07:06:07,462 callbacks.py:105 INFO train-abinet] epoch 1 iter 76350: loss = 0.6047,  smooth loss = 0.5987
[2022-07-05 07:06:49,507 callbacks.py:105 INFO train-abinet] epoch 1 iter 76400: loss = 0.5225,  smooth loss = 0.6054
[2022-07-05 07:07:31,946 callbacks.py:105 INFO train-abinet] epoch 1 iter 76450: loss = 0.6819,  smooth loss = 0.6086
[2022-07-05 07:08:13,870 callbacks.py:105 INFO train-abinet] epoch 1 iter 76500: loss = 0.4682,  smooth loss = 0.5970
[2022-07-05 07:08:55,606 callbacks.py:105 INFO train-abinet] epoch 1 iter 76550: loss = 0.5845,  smooth loss = 0.6107
[2022-07-05 07:09:37,174 callbacks.py:105 INFO train-abinet] epoch 1 iter 76600: loss = 0.5860,  smooth loss = 0.6040
[2022-07-05 07:10:20,793 callbacks.py:105 INFO train-abinet] epoch 1 iter 76650: loss = 0.7267,  smooth loss = 0.6035
[2022-07-05 07:11:03,509 callbacks.py:105 INFO train-abinet] epoch 1 iter 76700: loss = 0.5686,  smooth loss = 0.5971
[2022-07-05 07:11:45,393 callbacks.py:105 INFO train-abinet] epoch 1 iter 76750: loss = 0.5384,  smooth loss = 0.6004
[2022-07-05 07:12:28,145 callbacks.py:105 INFO train-abinet] epoch 1 iter 76800: loss = 0.6054,  smooth loss = 0.6086
[2022-07-05 07:13:10,327 callbacks.py:105 INFO train-abinet] epoch 1 iter 76850: loss = 0.6792,  smooth loss = 0.6234
[2022-07-05 07:13:52,836 callbacks.py:105 INFO train-abinet] epoch 1 iter 76900: loss = 0.5428,  smooth loss = 0.6203
[2022-07-05 07:14:34,688 callbacks.py:105 INFO train-abinet] epoch 1 iter 76950: loss = 0.5236,  smooth loss = 0.5994
[2022-07-05 07:15:17,261 callbacks.py:105 INFO train-abinet] epoch 1 iter 77000: loss = 0.5365,  smooth loss = 0.5981
[2022-07-05 07:16:00,690 callbacks.py:105 INFO train-abinet] epoch 1 iter 77050: loss = 0.7486,  smooth loss = 0.6047
[2022-07-05 07:16:50,963 callbacks.py:105 INFO train-abinet] epoch 1 iter 77100: loss = 0.7327,  smooth loss = 0.6196
[2022-07-05 07:17:43,977 callbacks.py:105 INFO train-abinet] epoch 1 iter 77150: loss = 0.6532,  smooth loss = 0.6057
[2022-07-05 07:18:36,522 callbacks.py:105 INFO train-abinet] epoch 1 iter 77200: loss = 0.6991,  smooth loss = 0.6048
[2022-07-05 07:19:27,644 callbacks.py:105 INFO train-abinet] epoch 1 iter 77250: loss = 0.6018,  smooth loss = 0.6029
[2022-07-05 07:20:20,350 callbacks.py:105 INFO train-abinet] epoch 1 iter 77300: loss = 0.6657,  smooth loss = 0.6165
[2022-07-05 07:21:16,250 callbacks.py:105 INFO train-abinet] epoch 1 iter 77350: loss = 0.6322,  smooth loss = 0.6233
[2022-07-05 07:22:09,641 callbacks.py:105 INFO train-abinet] epoch 1 iter 77400: loss = 0.6659,  smooth loss = 0.6016
[2022-07-05 07:22:54,954 callbacks.py:105 INFO train-abinet] epoch 1 iter 77450: loss = 0.6781,  smooth loss = 0.6117
[2022-07-05 07:23:40,435 callbacks.py:105 INFO train-abinet] epoch 1 iter 77500: loss = 0.5803,  smooth loss = 0.6093
[2022-07-05 07:24:30,591 callbacks.py:105 INFO train-abinet] epoch 1 iter 77550: loss = 0.5441,  smooth loss = 0.6059
[2022-07-05 07:25:28,073 callbacks.py:105 INFO train-abinet] epoch 1 iter 77600: loss = 0.6546,  smooth loss = 0.6052
[2022-07-05 07:26:21,313 callbacks.py:105 INFO train-abinet] epoch 1 iter 77650: loss = 0.7515,  smooth loss = 0.6071
[2022-07-05 07:27:05,277 callbacks.py:105 INFO train-abinet] epoch 1 iter 77700: loss = 0.5601,  smooth loss = 0.6081
[2022-07-05 07:27:54,558 callbacks.py:105 INFO train-abinet] epoch 1 iter 77750: loss = 0.6236,  smooth loss = 0.6166
[2022-07-05 07:28:50,628 callbacks.py:105 INFO train-abinet] epoch 1 iter 77800: loss = 0.7069,  smooth loss = 0.6230
[2022-07-05 07:29:41,549 callbacks.py:105 INFO train-abinet] epoch 1 iter 77850: loss = 0.5504,  smooth loss = 0.6193
[2022-07-05 07:30:35,372 callbacks.py:105 INFO train-abinet] epoch 1 iter 77900: loss = 0.6726,  smooth loss = 0.6150
[2022-07-05 07:31:26,529 callbacks.py:105 INFO train-abinet] epoch 1 iter 77950: loss = 0.6528,  smooth loss = 0.6101
[2022-07-05 07:32:19,856 callbacks.py:105 INFO train-abinet] epoch 1 iter 78000: loss = 0.5483,  smooth loss = 0.6022
[2022-07-05 07:32:19,856 callbacks.py:114 INFO train-abinet] average data time = 0.0059s, average running time = 0.8874s
█[2022-07-05 07:32:38,404 callbacks.py:123 INFO train-abinet] epoch 1 iter 78000: eval loss = 1.1655,  ccr = 0.9585,  cwr = 0.9117,  ted = 1402.0000,  ned = 283.9957,  ted/w = 0.1934, 
[2022-07-05 07:32:38,406 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_78000
[2022-07-05 07:33:32,113 callbacks.py:105 INFO train-abinet] epoch 1 iter 78050: loss = 0.5312,  smooth loss = 0.6022
[2022-07-05 07:34:25,848 callbacks.py:105 INFO train-abinet] epoch 1 iter 78100: loss = 0.6192,  smooth loss = 0.6242
[2022-07-05 07:35:17,995 callbacks.py:105 INFO train-abinet] epoch 1 iter 78150: loss = 0.6114,  smooth loss = 0.6139
[2022-07-05 07:36:05,907 callbacks.py:105 INFO train-abinet] epoch 1 iter 78200: loss = 0.5572,  smooth loss = 0.6057
[2022-07-05 07:36:59,683 callbacks.py:105 INFO train-abinet] epoch 1 iter 78250: loss = 0.7466,  smooth loss = 0.6189
[2022-07-05 07:37:53,900 callbacks.py:105 INFO train-abinet] epoch 1 iter 78300: loss = 0.7383,  smooth loss = 0.6166
[2022-07-05 07:38:47,988 callbacks.py:105 INFO train-abinet] epoch 1 iter 78350: loss = 0.5683,  smooth loss = 0.6173
[2022-07-05 07:39:42,679 callbacks.py:105 INFO train-abinet] epoch 1 iter 78400: loss = 0.7136,  smooth loss = 0.6070
[2022-07-05 07:40:34,657 callbacks.py:105 INFO train-abinet] epoch 1 iter 78450: loss = 0.4536,  smooth loss = 0.5965
[2022-07-05 07:41:27,165 callbacks.py:105 INFO train-abinet] epoch 1 iter 78500: loss = 0.6199,  smooth loss = 0.5905
[2022-07-05 07:42:20,239 callbacks.py:105 INFO train-abinet] epoch 1 iter 78550: loss = 0.4953,  smooth loss = 0.5944
[2022-07-05 07:43:13,638 callbacks.py:105 INFO train-abinet] epoch 1 iter 78600: loss = 0.4896,  smooth loss = 0.5971
[2022-07-05 07:43:59,029 callbacks.py:105 INFO train-abinet] epoch 1 iter 78650: loss = 0.8228,  smooth loss = 0.5901
[2022-07-05 07:44:42,479 callbacks.py:105 INFO train-abinet] epoch 1 iter 78700: loss = 0.5242,  smooth loss = 0.5910
[2022-07-05 07:45:25,844 callbacks.py:105 INFO train-abinet] epoch 1 iter 78750: loss = 0.5359,  smooth loss = 0.6000
[2022-07-05 07:46:09,913 callbacks.py:105 INFO train-abinet] epoch 1 iter 78800: loss = 0.5241,  smooth loss = 0.6075
[2022-07-05 07:46:56,761 callbacks.py:105 INFO train-abinet] epoch 1 iter 78850: loss = 0.7462,  smooth loss = 0.6231
[2022-07-05 07:47:47,881 callbacks.py:105 INFO train-abinet] epoch 1 iter 78900: loss = 0.6490,  smooth loss = 0.6137
[2022-07-05 07:48:40,419 callbacks.py:105 INFO train-abinet] epoch 1 iter 78950: loss = 0.4845,  smooth loss = 0.6055
[2022-07-05 07:49:31,880 callbacks.py:105 INFO train-abinet] epoch 1 iter 79000: loss = 0.4842,  smooth loss = 0.6141
[2022-07-05 07:50:23,962 callbacks.py:105 INFO train-abinet] epoch 1 iter 79050: loss = 0.4757,  smooth loss = 0.5985
[2022-07-05 07:51:15,668 callbacks.py:105 INFO train-abinet] epoch 1 iter 79100: loss = 0.6490,  smooth loss = 0.5979
[2022-07-05 07:52:09,292 callbacks.py:105 INFO train-abinet] epoch 1 iter 79150: loss = 0.5069,  smooth loss = 0.6050
[2022-07-05 07:52:55,317 callbacks.py:105 INFO train-abinet] epoch 1 iter 79200: loss = 0.5412,  smooth loss = 0.5931
[2022-07-05 07:53:38,059 callbacks.py:105 INFO train-abinet] epoch 1 iter 79250: loss = 0.5958,  smooth loss = 0.6066
[2022-07-05 07:54:27,755 callbacks.py:105 INFO train-abinet] epoch 1 iter 79300: loss = 0.5841,  smooth loss = 0.6003
[2022-07-05 07:55:19,845 callbacks.py:105 INFO train-abinet] epoch 1 iter 79350: loss = 0.5336,  smooth loss = 0.6070
[2022-07-05 07:56:06,450 callbacks.py:105 INFO train-abinet] epoch 1 iter 79400: loss = 0.7050,  smooth loss = 0.6170
[2022-07-05 07:56:58,861 callbacks.py:105 INFO train-abinet] epoch 1 iter 79450: loss = 0.6237,  smooth loss = 0.6047
[2022-07-05 07:57:53,160 callbacks.py:105 INFO train-abinet] epoch 1 iter 79500: loss = 0.5686,  smooth loss = 0.5986
[2022-07-05 07:58:46,725 callbacks.py:105 INFO train-abinet] epoch 1 iter 79550: loss = 0.5499,  smooth loss = 0.5994
[2022-07-05 07:59:40,337 callbacks.py:105 INFO train-abinet] epoch 1 iter 79600: loss = 0.5075,  smooth loss = 0.6032
[2022-07-05 08:00:35,622 callbacks.py:105 INFO train-abinet] epoch 1 iter 79650: loss = 0.6347,  smooth loss = 0.6168
[2022-07-05 08:01:24,952 callbacks.py:105 INFO train-abinet] epoch 1 iter 79700: loss = 0.4007,  smooth loss = 0.6070
[2022-07-05 08:02:11,509 callbacks.py:105 INFO train-abinet] epoch 1 iter 79750: loss = 0.5745,  smooth loss = 0.6011
[2022-07-05 08:02:55,721 callbacks.py:105 INFO train-abinet] epoch 1 iter 79800: loss = 0.4592,  smooth loss = 0.6038
[2022-07-05 08:03:39,514 callbacks.py:105 INFO train-abinet] epoch 1 iter 79850: loss = 0.6595,  smooth loss = 0.6085
[2022-07-05 08:04:25,824 callbacks.py:105 INFO train-abinet] epoch 1 iter 79900: loss = 0.6217,  smooth loss = 0.6112
[2022-07-05 08:05:18,337 callbacks.py:105 INFO train-abinet] epoch 1 iter 79950: loss = 0.5623,  smooth loss = 0.6136
[2022-07-05 08:06:09,282 callbacks.py:105 INFO train-abinet] epoch 1 iter 80000: loss = 0.5388,  smooth loss = 0.6017
[2022-07-05 08:07:03,367 callbacks.py:105 INFO train-abinet] epoch 1 iter 80050: loss = 0.5339,  smooth loss = 0.5982
[2022-07-05 08:08:01,427 callbacks.py:105 INFO train-abinet] epoch 1 iter 80100: loss = 0.4935,  smooth loss = 0.6027
[2022-07-05 08:08:54,707 callbacks.py:105 INFO train-abinet] epoch 1 iter 80150: loss = 0.5934,  smooth loss = 0.5924
[2022-07-05 08:09:46,985 callbacks.py:105 INFO train-abinet] epoch 1 iter 80200: loss = 0.6549,  smooth loss = 0.6045
[2022-07-05 08:10:39,165 callbacks.py:105 INFO train-abinet] epoch 1 iter 80250: loss = 0.5715,  smooth loss = 0.5965
[2022-07-05 08:11:29,443 callbacks.py:105 INFO train-abinet] epoch 1 iter 80300: loss = 0.6952,  smooth loss = 0.5985
[2022-07-05 08:12:22,486 callbacks.py:105 INFO train-abinet] epoch 1 iter 80350: loss = 0.6120,  smooth loss = 0.6115
[2022-07-05 08:13:13,677 callbacks.py:105 INFO train-abinet] epoch 1 iter 80400: loss = 0.5617,  smooth loss = 0.6086
[2022-07-05 08:14:07,991 callbacks.py:105 INFO train-abinet] epoch 1 iter 80450: loss = 0.4669,  smooth loss = 0.5892
[2022-07-05 08:15:05,084 callbacks.py:105 INFO train-abinet] epoch 1 iter 80500: loss = 0.5581,  smooth loss = 0.6010
[2022-07-05 08:16:04,464 callbacks.py:105 INFO train-abinet] epoch 1 iter 80550: loss = 0.6182,  smooth loss = 0.5834
[2022-07-05 08:16:50,979 callbacks.py:105 INFO train-abinet] epoch 1 iter 80600: loss = 0.4770,  smooth loss = 0.5993
[2022-07-05 08:17:44,926 callbacks.py:105 INFO train-abinet] epoch 1 iter 80650: loss = 0.6982,  smooth loss = 0.6009
[2022-07-05 08:18:34,551 callbacks.py:105 INFO train-abinet] epoch 1 iter 80700: loss = 0.5930,  smooth loss = 0.5991
[2022-07-05 08:19:22,359 callbacks.py:105 INFO train-abinet] epoch 1 iter 80750: loss = 0.5418,  smooth loss = 0.6073
[2022-07-05 08:20:10,239 callbacks.py:105 INFO train-abinet] epoch 1 iter 80800: loss = 0.5522,  smooth loss = 0.5931
[2022-07-05 08:20:53,780 callbacks.py:105 INFO train-abinet] epoch 1 iter 80850: loss = 0.6222,  smooth loss = 0.6028
[2022-07-05 08:21:37,000 callbacks.py:105 INFO train-abinet] epoch 1 iter 80900: loss = 0.5239,  smooth loss = 0.5973
[2022-07-05 08:22:23,428 callbacks.py:105 INFO train-abinet] epoch 1 iter 80950: loss = 0.6500,  smooth loss = 0.6103
[2022-07-05 08:23:11,337 callbacks.py:105 INFO train-abinet] epoch 1 iter 81000: loss = 0.4680,  smooth loss = 0.6008
[2022-07-05 08:23:11,337 callbacks.py:114 INFO train-abinet] average data time = 0.0060s, average running time = 0.8919s
█[2022-07-05 08:23:28,875 callbacks.py:123 INFO train-abinet] epoch 1 iter 81000: eval loss = 1.1496,  ccr = 0.9585,  cwr = 0.9139,  ted = 1367.0000,  ned = 275.2768,  ted/w = 0.1886, 
[2022-07-05 08:23:28,877 callbacks.py:136 INFO train-abinet] Save model train-abinet_1_81000
[2022-07-05 08:24:26,905 callbacks.py:105 INFO train-abinet] epoch 1 iter 81050: loss = 0.6209,  smooth loss = 0.5990
[2022-07-05 08:25:13,898 callbacks.py:105 INFO train-abinet] epoch 1 iter 81100: loss = 0.6146,  smooth loss = 0.5868
[2022-07-05 08:25:58,237 callbacks.py:105 INFO train-abinet] epoch 1 iter 81150: loss = 0.6650,  smooth loss = 0.6129
[2022-07-05 08:26:42,838 callbacks.py:105 INFO train-abinet] epoch 1 iter 81200: loss = 0.5514,  smooth loss = 0.6180
[2022-07-05 08:27:27,706 callbacks.py:105 INFO train-abinet] epoch 1 iter 81250: loss = 0.5691,  smooth loss = 0.6065
[2022-07-05 08:28:13,177 callbacks.py:105 INFO train-abinet] epoch 1 iter 81300: loss = 0.5167,  smooth loss = 0.6116
[2022-07-05 08:28:57,824 callbacks.py:105 INFO train-abinet] epoch 1 iter 81350: loss = 0.5397,  smooth loss = 0.5998
[2022-07-05 08:29:43,026 callbacks.py:105 INFO train-abinet] epoch 1 iter 81400: loss = 0.5494,  smooth loss = 0.6151
[2022-07-05 08:30:29,639 callbacks.py:105 INFO train-abinet] epoch 1 iter 81450: loss = 0.8364,  smooth loss = 0.6087
[2022-07-05 08:31:16,058 callbacks.py:105 INFO train-abinet] epoch 1 iter 81500: loss = 0.5340,  smooth loss = 0.6047
[2022-07-05 08:32:00,986 callbacks.py:105 INFO train-abinet] epoch 1 iter 81550: loss = 0.5528,  smooth loss = 0.6013
[2022-07-05 08:32:48,384 callbacks.py:105 INFO train-abinet] epoch 1 iter 81600: loss = 0.6237,  smooth loss = 0.5920
[2022-07-05 08:33:35,111 callbacks.py:105 INFO train-abinet] epoch 1 iter 81650: loss = 0.5048,  smooth loss = 0.5964
[2022-07-05 08:34:20,717 callbacks.py:105 INFO train-abinet] epoch 1 iter 81700: loss = 0.7228,  smooth loss = 0.5978
[2022-07-05 08:35:05,642 callbacks.py:105 INFO train-abinet] epoch 1 iter 81750: loss = 0.6526,  smooth loss = 0.6012
[2022-07-05 08:35:52,505 callbacks.py:105 INFO train-abinet] epoch 1 iter 81800: loss = 0.6196,  smooth loss = 0.6062
[2022-07-05 08:36:42,279 callbacks.py:105 INFO train-abinet] epoch 1 iter 81850: loss = 0.5936,  smooth loss = 0.6067
[2022-07-05 08:37:30,896 callbacks.py:105 INFO train-abinet] epoch 1 iter 81900: loss = 0.6904,  smooth loss = 0.6112
[2022-07-05 08:38:17,467 callbacks.py:105 INFO train-abinet] epoch 1 iter 81950: loss = 0.6933,  smooth loss = 0.6146
[2022-07-05 08:39:06,648 callbacks.py:105 INFO train-abinet] epoch 1 iter 82000: loss = 0.5157,  smooth loss = 0.6150
[2022-07-05 08:39:53,651 callbacks.py:105 INFO train-abinet] epoch 1 iter 82050: loss = 0.7053,  smooth loss = 0.6068
[2022-07-05 08:40:39,710 callbacks.py:105 INFO train-abinet] epoch 1 iter 82100: loss = 0.5799,  smooth loss = 0.6069
[2022-07-05 08:41:25,191 callbacks.py:105 INFO train-abinet] epoch 1 iter 82150: loss = 0.5917,  smooth loss = 0.6093
[2022-07-05 08:42:10,579 callbacks.py:105 INFO train-abinet] epoch 1 iter 82200: loss = 0.5610,  smooth loss = 0.5942
[2022-07-05 08:42:55,159 callbacks.py:105 INFO train-abinet] epoch 1 iter 82250: loss = 0.5607,  smooth loss = 0.5831
[2022-07-05 08:43:39,673 callbacks.py:105 INFO train-abinet] epoch 1 iter 82300: loss = 0.4709,  smooth loss = 0.5893
[2022-07-05 08:44:23,394 callbacks.py:105 INFO train-abinet] epoch 1 iter 82350: loss = 0.6063,  smooth loss = 0.5969
[2022-07-05 08:45:07,828 callbacks.py:105 INFO train-abinet] epoch 1 iter 82400: loss = 0.4389,  smooth loss = 0.5864
[2022-07-05 08:45:51,624 callbacks.py:105 INFO train-abinet] epoch 1 iter 82450: loss = 0.4574,  smooth loss = 0.6027
[2022-07-05 08:46:35,601 callbacks.py:105 INFO train-abinet] epoch 1 iter 82500: loss = 0.5905,  smooth loss = 0.5941
[2022-07-05 08:47:18,939 callbacks.py:105 INFO train-abinet] epoch 1 iter 82550: loss = 0.5901,  smooth loss = 0.5991
[2022-07-05 08:48:03,267 callbacks.py:105 INFO train-abinet] epoch 1 iter 82600: loss = 0.4795,  smooth loss = 0.6074
[2022-07-05 08:48:47,951 callbacks.py:105 INFO train-abinet] epoch 1 iter 82650: loss = 0.5059,  smooth loss = 0.6065
[2022-07-05 08:49:31,764 callbacks.py:105 INFO train-abinet] epoch 1 iter 82700: loss = 0.6368,  smooth loss = 0.5990
[2022-07-05 08:50:15,733 callbacks.py:105 INFO train-abinet] epoch 1 iter 82750: loss = 0.5294,  smooth loss = 0.6034
█[2022-07-05 08:51:06,534 callbacks.py:105 INFO train-abinet] epoch 2 iter 82800: loss = 0.5555,  smooth loss = 0.6043
[2022-07-05 08:51:50,738 callbacks.py:105 INFO train-abinet] epoch 2 iter 82850: loss = 0.7416,  smooth loss = 0.6024
[2022-07-05 08:52:33,886 callbacks.py:105 INFO train-abinet] epoch 2 iter 82900: loss = 0.7677,  smooth loss = 0.6119
[2022-07-05 08:53:17,339 callbacks.py:105 INFO train-abinet] epoch 2 iter 82950: loss = 0.5204,  smooth loss = 0.5966
[2022-07-05 08:54:01,911 callbacks.py:105 INFO train-abinet] epoch 2 iter 83000: loss = 0.5107,  smooth loss = 0.6056
[2022-07-05 08:54:46,845 callbacks.py:105 INFO train-abinet] epoch 2 iter 83050: loss = 0.6359,  smooth loss = 0.5943
[2022-07-05 08:55:31,132 callbacks.py:105 INFO train-abinet] epoch 2 iter 83100: loss = 0.8580,  smooth loss = 0.6052
[2022-07-05 08:56:14,569 callbacks.py:105 INFO train-abinet] epoch 2 iter 83150: loss = 0.4382,  smooth loss = 0.5965
[2022-07-05 08:56:57,961 callbacks.py:105 INFO train-abinet] epoch 2 iter 83200: loss = 0.5933,  smooth loss = 0.6052
[2022-07-05 08:57:42,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 83250: loss = 0.5937,  smooth loss = 0.5931
[2022-07-05 08:58:25,942 callbacks.py:105 INFO train-abinet] epoch 2 iter 83300: loss = 0.5355,  smooth loss = 0.5891
[2022-07-05 08:59:09,849 callbacks.py:105 INFO train-abinet] epoch 2 iter 83350: loss = 0.7983,  smooth loss = 0.6022
[2022-07-05 08:59:53,866 callbacks.py:105 INFO train-abinet] epoch 2 iter 83400: loss = 0.6542,  smooth loss = 0.5985
[2022-07-05 09:00:38,560 callbacks.py:105 INFO train-abinet] epoch 2 iter 83450: loss = 0.5412,  smooth loss = 0.5856
[2022-07-05 09:01:22,609 callbacks.py:105 INFO train-abinet] epoch 2 iter 83500: loss = 0.5719,  smooth loss = 0.6020
[2022-07-05 09:02:07,279 callbacks.py:105 INFO train-abinet] epoch 2 iter 83550: loss = 0.5301,  smooth loss = 0.5961
[2022-07-05 09:02:51,380 callbacks.py:105 INFO train-abinet] epoch 2 iter 83600: loss = 0.5287,  smooth loss = 0.5933
[2022-07-05 09:03:35,690 callbacks.py:105 INFO train-abinet] epoch 2 iter 83650: loss = 0.4906,  smooth loss = 0.6048
[2022-07-05 09:04:18,797 callbacks.py:105 INFO train-abinet] epoch 2 iter 83700: loss = 0.6712,  smooth loss = 0.6174
[2022-07-05 09:05:02,765 callbacks.py:105 INFO train-abinet] epoch 2 iter 83750: loss = 0.5829,  smooth loss = 0.5980
[2022-07-05 09:05:46,841 callbacks.py:105 INFO train-abinet] epoch 2 iter 83800: loss = 0.5698,  smooth loss = 0.5997
[2022-07-05 09:06:30,355 callbacks.py:105 INFO train-abinet] epoch 2 iter 83850: loss = 0.4551,  smooth loss = 0.6009
[2022-07-05 09:07:19,188 callbacks.py:105 INFO train-abinet] epoch 2 iter 83900: loss = 0.5920,  smooth loss = 0.5931
[2022-07-05 09:08:09,172 callbacks.py:105 INFO train-abinet] epoch 2 iter 83950: loss = 0.5577,  smooth loss = 0.5917
[2022-07-05 09:08:56,030 callbacks.py:105 INFO train-abinet] epoch 2 iter 84000: loss = 0.5702,  smooth loss = 0.5995
[2022-07-05 09:08:56,033 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8925s
█[2022-07-05 09:09:10,118 callbacks.py:123 INFO train-abinet] epoch 2 iter 84000: eval loss = 1.1700,  ccr = 0.9583,  cwr = 0.9136,  ted = 1380.0000,  ned = 265.1322,  ted/w = 0.1904, 
[2022-07-05 09:09:10,119 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_84000
[2022-07-05 09:09:56,352 callbacks.py:105 INFO train-abinet] epoch 2 iter 84050: loss = 0.4507,  smooth loss = 0.5707
[2022-07-05 09:10:43,920 callbacks.py:105 INFO train-abinet] epoch 2 iter 84100: loss = 0.7380,  smooth loss = 0.5848
[2022-07-05 09:11:29,067 callbacks.py:105 INFO train-abinet] epoch 2 iter 84150: loss = 0.7198,  smooth loss = 0.5972
[2022-07-05 09:12:16,482 callbacks.py:105 INFO train-abinet] epoch 2 iter 84200: loss = 0.7275,  smooth loss = 0.5913
[2022-07-05 09:13:05,109 callbacks.py:105 INFO train-abinet] epoch 2 iter 84250: loss = 0.7226,  smooth loss = 0.5964
[2022-07-05 09:13:54,101 callbacks.py:105 INFO train-abinet] epoch 2 iter 84300: loss = 0.4636,  smooth loss = 0.5911
[2022-07-05 09:14:42,775 callbacks.py:105 INFO train-abinet] epoch 2 iter 84350: loss = 0.4588,  smooth loss = 0.5998
[2022-07-05 09:15:32,085 callbacks.py:105 INFO train-abinet] epoch 2 iter 84400: loss = 0.5361,  smooth loss = 0.5847
[2022-07-05 09:16:20,831 callbacks.py:105 INFO train-abinet] epoch 2 iter 84450: loss = 0.4262,  smooth loss = 0.5726
[2022-07-05 09:17:07,629 callbacks.py:105 INFO train-abinet] epoch 2 iter 84500: loss = 0.5955,  smooth loss = 0.6016
[2022-07-05 09:17:55,845 callbacks.py:105 INFO train-abinet] epoch 2 iter 84550: loss = 0.4570,  smooth loss = 0.5996
[2022-07-05 09:18:44,182 callbacks.py:105 INFO train-abinet] epoch 2 iter 84600: loss = 0.5987,  smooth loss = 0.5952
[2022-07-05 09:19:34,460 callbacks.py:105 INFO train-abinet] epoch 2 iter 84650: loss = 0.6547,  smooth loss = 0.5910
[2022-07-05 09:20:22,827 callbacks.py:105 INFO train-abinet] epoch 2 iter 84700: loss = 0.5570,  smooth loss = 0.5915
[2022-07-05 09:21:12,336 callbacks.py:105 INFO train-abinet] epoch 2 iter 84750: loss = 0.5434,  smooth loss = 0.5849
[2022-07-05 09:22:01,579 callbacks.py:105 INFO train-abinet] epoch 2 iter 84800: loss = 0.6525,  smooth loss = 0.5898
[2022-07-05 09:22:49,335 callbacks.py:105 INFO train-abinet] epoch 2 iter 84850: loss = 0.6384,  smooth loss = 0.6031
[2022-07-05 09:23:35,898 callbacks.py:105 INFO train-abinet] epoch 2 iter 84900: loss = 0.5374,  smooth loss = 0.5955
[2022-07-05 09:24:18,963 callbacks.py:105 INFO train-abinet] epoch 2 iter 84950: loss = 0.5267,  smooth loss = 0.6013
[2022-07-05 09:25:08,245 callbacks.py:105 INFO train-abinet] epoch 2 iter 85000: loss = 0.6557,  smooth loss = 0.6032
[2022-07-05 09:25:57,452 callbacks.py:105 INFO train-abinet] epoch 2 iter 85050: loss = 0.5381,  smooth loss = 0.6050
[2022-07-05 09:26:47,292 callbacks.py:105 INFO train-abinet] epoch 2 iter 85100: loss = 0.5639,  smooth loss = 0.5964
[2022-07-05 09:27:32,229 callbacks.py:105 INFO train-abinet] epoch 2 iter 85150: loss = 0.6453,  smooth loss = 0.5998
[2022-07-05 09:28:23,372 callbacks.py:105 INFO train-abinet] epoch 2 iter 85200: loss = 0.5929,  smooth loss = 0.6070
[2022-07-05 09:29:13,774 callbacks.py:105 INFO train-abinet] epoch 2 iter 85250: loss = 0.5418,  smooth loss = 0.6087
[2022-07-05 09:30:04,531 callbacks.py:105 INFO train-abinet] epoch 2 iter 85300: loss = 0.6758,  smooth loss = 0.6011
[2022-07-05 09:30:53,777 callbacks.py:105 INFO train-abinet] epoch 2 iter 85350: loss = 0.6397,  smooth loss = 0.5842
[2022-07-05 09:31:42,606 callbacks.py:105 INFO train-abinet] epoch 2 iter 85400: loss = 0.5949,  smooth loss = 0.5829
[2022-07-05 09:32:31,958 callbacks.py:105 INFO train-abinet] epoch 2 iter 85450: loss = 0.5527,  smooth loss = 0.5693
[2022-07-05 09:33:20,739 callbacks.py:105 INFO train-abinet] epoch 2 iter 85500: loss = 0.5284,  smooth loss = 0.5771
[2022-07-05 09:34:09,265 callbacks.py:105 INFO train-abinet] epoch 2 iter 85550: loss = 0.6149,  smooth loss = 0.5797
[2022-07-05 09:34:59,918 callbacks.py:105 INFO train-abinet] epoch 2 iter 85600: loss = 0.5895,  smooth loss = 0.5896
[2022-07-05 09:35:48,942 callbacks.py:105 INFO train-abinet] epoch 2 iter 85650: loss = 0.7270,  smooth loss = 0.5862
[2022-07-05 09:36:39,176 callbacks.py:105 INFO train-abinet] epoch 2 iter 85700: loss = 0.6077,  smooth loss = 0.5885
[2022-07-05 09:37:28,288 callbacks.py:105 INFO train-abinet] epoch 2 iter 85750: loss = 0.6300,  smooth loss = 0.5910
[2022-07-05 09:38:18,135 callbacks.py:105 INFO train-abinet] epoch 2 iter 85800: loss = 0.5980,  smooth loss = 0.5886
[2022-07-05 09:39:06,255 callbacks.py:105 INFO train-abinet] epoch 2 iter 85850: loss = 0.4977,  smooth loss = 0.5885
[2022-07-05 09:39:56,404 callbacks.py:105 INFO train-abinet] epoch 2 iter 85900: loss = 0.5904,  smooth loss = 0.5967
[2022-07-05 09:40:41,720 callbacks.py:105 INFO train-abinet] epoch 2 iter 85950: loss = 0.6324,  smooth loss = 0.5824
[2022-07-05 09:41:27,892 callbacks.py:105 INFO train-abinet] epoch 2 iter 86000: loss = 0.5323,  smooth loss = 0.5842
[2022-07-05 09:42:12,269 callbacks.py:105 INFO train-abinet] epoch 2 iter 86050: loss = 0.5826,  smooth loss = 0.6028
[2022-07-05 09:42:57,560 callbacks.py:105 INFO train-abinet] epoch 2 iter 86100: loss = 0.6422,  smooth loss = 0.5982
[2022-07-05 09:43:42,024 callbacks.py:105 INFO train-abinet] epoch 2 iter 86150: loss = 0.6264,  smooth loss = 0.5950
[2022-07-05 09:44:26,673 callbacks.py:105 INFO train-abinet] epoch 2 iter 86200: loss = 0.4984,  smooth loss = 0.5958
[2022-07-05 09:45:11,721 callbacks.py:105 INFO train-abinet] epoch 2 iter 86250: loss = 0.4827,  smooth loss = 0.5981
[2022-07-05 09:45:54,955 callbacks.py:105 INFO train-abinet] epoch 2 iter 86300: loss = 0.5436,  smooth loss = 0.5812
[2022-07-05 09:46:38,662 callbacks.py:105 INFO train-abinet] epoch 2 iter 86350: loss = 0.6135,  smooth loss = 0.5909
[2022-07-05 09:47:22,615 callbacks.py:105 INFO train-abinet] epoch 2 iter 86400: loss = 0.6827,  smooth loss = 0.5862
[2022-07-05 09:48:06,642 callbacks.py:105 INFO train-abinet] epoch 2 iter 86450: loss = 0.5360,  smooth loss = 0.5844
[2022-07-05 09:48:51,161 callbacks.py:105 INFO train-abinet] epoch 2 iter 86500: loss = 0.5314,  smooth loss = 0.5909
[2022-07-05 09:49:36,176 callbacks.py:105 INFO train-abinet] epoch 2 iter 86550: loss = 0.5092,  smooth loss = 0.5974
[2022-07-05 09:50:20,439 callbacks.py:105 INFO train-abinet] epoch 2 iter 86600: loss = 0.6203,  smooth loss = 0.5867
[2022-07-05 09:51:03,990 callbacks.py:105 INFO train-abinet] epoch 2 iter 86650: loss = 0.5552,  smooth loss = 0.5852
[2022-07-05 09:51:47,381 callbacks.py:105 INFO train-abinet] epoch 2 iter 86700: loss = 0.6448,  smooth loss = 0.5875
[2022-07-05 09:52:31,107 callbacks.py:105 INFO train-abinet] epoch 2 iter 86750: loss = 0.6244,  smooth loss = 0.5927
[2022-07-05 09:53:13,479 callbacks.py:105 INFO train-abinet] epoch 2 iter 86800: loss = 0.7284,  smooth loss = 0.6062
[2022-07-05 09:53:57,846 callbacks.py:105 INFO train-abinet] epoch 2 iter 86850: loss = 0.6345,  smooth loss = 0.6025
[2022-07-05 09:54:42,238 callbacks.py:105 INFO train-abinet] epoch 2 iter 86900: loss = 0.7731,  smooth loss = 0.6012
[2022-07-05 09:55:26,117 callbacks.py:105 INFO train-abinet] epoch 2 iter 86950: loss = 0.5877,  smooth loss = 0.6023
[2022-07-05 09:56:09,331 callbacks.py:105 INFO train-abinet] epoch 2 iter 87000: loss = 0.5481,  smooth loss = 0.5953
[2022-07-05 09:56:09,331 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8940s
█[2022-07-05 09:56:24,785 callbacks.py:123 INFO train-abinet] epoch 2 iter 87000: eval loss = 1.1950,  ccr = 0.9555,  cwr = 0.9103,  ted = 1418.0000,  ned = 279.4453,  ted/w = 0.1956, 
[2022-07-05 09:56:24,788 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_87000
[2022-07-05 09:57:10,561 callbacks.py:105 INFO train-abinet] epoch 2 iter 87050: loss = 0.6032,  smooth loss = 0.5920
[2022-07-05 09:57:55,320 callbacks.py:105 INFO train-abinet] epoch 2 iter 87100: loss = 0.5325,  smooth loss = 0.6057
[2022-07-05 09:58:40,458 callbacks.py:105 INFO train-abinet] epoch 2 iter 87150: loss = 0.4452,  smooth loss = 0.5978
[2022-07-05 09:59:24,493 callbacks.py:105 INFO train-abinet] epoch 2 iter 87200: loss = 0.6339,  smooth loss = 0.5955
[2022-07-05 10:00:09,250 callbacks.py:105 INFO train-abinet] epoch 2 iter 87250: loss = 0.6432,  smooth loss = 0.5946
[2022-07-05 10:00:52,711 callbacks.py:105 INFO train-abinet] epoch 2 iter 87300: loss = 0.5799,  smooth loss = 0.5981
[2022-07-05 10:01:37,110 callbacks.py:105 INFO train-abinet] epoch 2 iter 87350: loss = 0.6088,  smooth loss = 0.6039
[2022-07-05 10:02:21,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 87400: loss = 0.5997,  smooth loss = 0.5998
[2022-07-05 10:03:03,574 callbacks.py:105 INFO train-abinet] epoch 2 iter 87450: loss = 0.4731,  smooth loss = 0.6154
[2022-07-05 10:03:47,404 callbacks.py:105 INFO train-abinet] epoch 2 iter 87500: loss = 0.6198,  smooth loss = 0.6057
[2022-07-05 10:04:32,317 callbacks.py:105 INFO train-abinet] epoch 2 iter 87550: loss = 0.6751,  smooth loss = 0.6020
[2022-07-05 10:05:16,131 callbacks.py:105 INFO train-abinet] epoch 2 iter 87600: loss = 0.5723,  smooth loss = 0.6052
[2022-07-05 10:06:00,110 callbacks.py:105 INFO train-abinet] epoch 2 iter 87650: loss = 0.5415,  smooth loss = 0.5803
[2022-07-05 10:06:43,962 callbacks.py:105 INFO train-abinet] epoch 2 iter 87700: loss = 0.5824,  smooth loss = 0.5880
[2022-07-05 10:07:29,110 callbacks.py:105 INFO train-abinet] epoch 2 iter 87750: loss = 0.5943,  smooth loss = 0.5958
[2022-07-05 10:08:13,985 callbacks.py:105 INFO train-abinet] epoch 2 iter 87800: loss = 0.5606,  smooth loss = 0.5964
[2022-07-05 10:09:00,160 callbacks.py:105 INFO train-abinet] epoch 2 iter 87850: loss = 0.5802,  smooth loss = 0.6075
[2022-07-05 10:09:46,349 callbacks.py:105 INFO train-abinet] epoch 2 iter 87900: loss = 0.4586,  smooth loss = 0.5933
[2022-07-05 10:10:30,519 callbacks.py:105 INFO train-abinet] epoch 2 iter 87950: loss = 0.5692,  smooth loss = 0.5971
[2022-07-05 10:11:14,510 callbacks.py:105 INFO train-abinet] epoch 2 iter 88000: loss = 0.4735,  smooth loss = 0.6054
[2022-07-05 10:11:57,498 callbacks.py:105 INFO train-abinet] epoch 2 iter 88050: loss = 0.7205,  smooth loss = 0.5846
[2022-07-05 10:12:41,853 callbacks.py:105 INFO train-abinet] epoch 2 iter 88100: loss = 0.6232,  smooth loss = 0.5772
[2022-07-05 10:13:25,647 callbacks.py:105 INFO train-abinet] epoch 2 iter 88150: loss = 0.6020,  smooth loss = 0.5807
[2022-07-05 10:14:10,703 callbacks.py:105 INFO train-abinet] epoch 2 iter 88200: loss = 0.4922,  smooth loss = 0.5892
[2022-07-05 10:14:54,694 callbacks.py:105 INFO train-abinet] epoch 2 iter 88250: loss = 0.6208,  smooth loss = 0.5779
[2022-07-05 10:15:38,416 callbacks.py:105 INFO train-abinet] epoch 2 iter 88300: loss = 0.5120,  smooth loss = 0.5829
[2022-07-05 10:16:23,706 callbacks.py:105 INFO train-abinet] epoch 2 iter 88350: loss = 0.6104,  smooth loss = 0.5899
[2022-07-05 10:17:08,002 callbacks.py:105 INFO train-abinet] epoch 2 iter 88400: loss = 0.6751,  smooth loss = 0.5952
[2022-07-05 10:17:52,114 callbacks.py:105 INFO train-abinet] epoch 2 iter 88450: loss = 0.5874,  smooth loss = 0.5953
[2022-07-05 10:18:36,232 callbacks.py:105 INFO train-abinet] epoch 2 iter 88500: loss = 0.6652,  smooth loss = 0.6063
[2022-07-05 10:19:20,615 callbacks.py:105 INFO train-abinet] epoch 2 iter 88550: loss = 0.5661,  smooth loss = 0.6130
[2022-07-05 10:20:02,806 callbacks.py:105 INFO train-abinet] epoch 2 iter 88600: loss = 0.6982,  smooth loss = 0.5934
[2022-07-05 10:20:46,879 callbacks.py:105 INFO train-abinet] epoch 2 iter 88650: loss = 0.7138,  smooth loss = 0.5945
[2022-07-05 10:21:30,877 callbacks.py:105 INFO train-abinet] epoch 2 iter 88700: loss = 0.5839,  smooth loss = 0.5865
[2022-07-05 10:22:14,667 callbacks.py:105 INFO train-abinet] epoch 2 iter 88750: loss = 0.7912,  smooth loss = 0.5982
[2022-07-05 10:22:58,333 callbacks.py:105 INFO train-abinet] epoch 2 iter 88800: loss = 0.5916,  smooth loss = 0.6146
[2022-07-05 10:23:42,487 callbacks.py:105 INFO train-abinet] epoch 2 iter 88850: loss = 0.6909,  smooth loss = 0.5952
[2022-07-05 10:24:26,413 callbacks.py:105 INFO train-abinet] epoch 2 iter 88900: loss = 0.6678,  smooth loss = 0.5995
[2022-07-05 10:25:11,106 callbacks.py:105 INFO train-abinet] epoch 2 iter 88950: loss = 0.4597,  smooth loss = 0.5900
[2022-07-05 10:25:55,427 callbacks.py:105 INFO train-abinet] epoch 2 iter 89000: loss = 0.6795,  smooth loss = 0.5824
[2022-07-05 10:26:39,493 callbacks.py:105 INFO train-abinet] epoch 2 iter 89050: loss = 0.6043,  smooth loss = 0.5955
[2022-07-05 10:27:23,340 callbacks.py:105 INFO train-abinet] epoch 2 iter 89100: loss = 0.5284,  smooth loss = 0.5888
[2022-07-05 10:28:08,587 callbacks.py:105 INFO train-abinet] epoch 2 iter 89150: loss = 0.5668,  smooth loss = 0.6057
[2022-07-05 10:28:52,226 callbacks.py:105 INFO train-abinet] epoch 2 iter 89200: loss = 0.6570,  smooth loss = 0.5962
[2022-07-05 10:29:36,483 callbacks.py:105 INFO train-abinet] epoch 2 iter 89250: loss = 0.5151,  smooth loss = 0.6036
[2022-07-05 10:30:21,270 callbacks.py:105 INFO train-abinet] epoch 2 iter 89300: loss = 0.6289,  smooth loss = 0.5951
[2022-07-05 10:31:05,295 callbacks.py:105 INFO train-abinet] epoch 2 iter 89350: loss = 0.7193,  smooth loss = 0.5849
[2022-07-05 10:31:49,376 callbacks.py:105 INFO train-abinet] epoch 2 iter 89400: loss = 0.6173,  smooth loss = 0.5873
[2022-07-05 10:32:33,610 callbacks.py:105 INFO train-abinet] epoch 2 iter 89450: loss = 0.6628,  smooth loss = 0.5982
[2022-07-05 10:33:16,799 callbacks.py:105 INFO train-abinet] epoch 2 iter 89500: loss = 0.5883,  smooth loss = 0.6002
[2022-07-05 10:34:00,856 callbacks.py:105 INFO train-abinet] epoch 2 iter 89550: loss = 0.5959,  smooth loss = 0.5932
[2022-07-05 10:34:44,588 callbacks.py:105 INFO train-abinet] epoch 2 iter 89600: loss = 0.6978,  smooth loss = 0.6001
[2022-07-05 10:35:28,894 callbacks.py:105 INFO train-abinet] epoch 2 iter 89650: loss = 0.6011,  smooth loss = 0.5899
[2022-07-05 10:36:13,295 callbacks.py:105 INFO train-abinet] epoch 2 iter 89700: loss = 0.5038,  smooth loss = 0.5909
[2022-07-05 10:36:55,725 callbacks.py:105 INFO train-abinet] epoch 2 iter 89750: loss = 0.6222,  smooth loss = 0.6021
[2022-07-05 10:37:40,069 callbacks.py:105 INFO train-abinet] epoch 2 iter 89800: loss = 0.5108,  smooth loss = 0.5932
[2022-07-05 10:38:24,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 89850: loss = 0.5683,  smooth loss = 0.5960
[2022-07-05 10:39:07,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 89900: loss = 0.7466,  smooth loss = 0.6012
[2022-07-05 10:39:50,104 callbacks.py:105 INFO train-abinet] epoch 2 iter 89950: loss = 0.5931,  smooth loss = 0.5908
[2022-07-05 10:40:34,188 callbacks.py:105 INFO train-abinet] epoch 2 iter 90000: loss = 0.4844,  smooth loss = 0.5938
[2022-07-05 10:40:34,194 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8936s
█[2022-07-05 10:40:49,101 callbacks.py:123 INFO train-abinet] epoch 2 iter 90000: eval loss = 1.1832,  ccr = 0.9571,  cwr = 0.9117,  ted = 1428.0000,  ned = 289.8877,  ted/w = 0.1970, 
[2022-07-05 10:40:49,102 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_90000
[2022-07-05 10:41:34,754 callbacks.py:105 INFO train-abinet] epoch 2 iter 90050: loss = 0.6505,  smooth loss = 0.5913
[2022-07-05 10:42:18,591 callbacks.py:105 INFO train-abinet] epoch 2 iter 90100: loss = 0.6080,  smooth loss = 0.5946
[2022-07-05 10:43:02,960 callbacks.py:105 INFO train-abinet] epoch 2 iter 90150: loss = 0.4236,  smooth loss = 0.5882
[2022-07-05 10:43:47,809 callbacks.py:105 INFO train-abinet] epoch 2 iter 90200: loss = 0.4582,  smooth loss = 0.5813
[2022-07-05 10:44:32,775 callbacks.py:105 INFO train-abinet] epoch 2 iter 90250: loss = 0.6604,  smooth loss = 0.5839
[2022-07-05 10:45:16,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 90300: loss = 0.5925,  smooth loss = 0.5854
[2022-07-05 10:45:59,246 callbacks.py:105 INFO train-abinet] epoch 2 iter 90350: loss = 0.5109,  smooth loss = 0.5888
[2022-07-05 10:46:44,512 callbacks.py:105 INFO train-abinet] epoch 2 iter 90400: loss = 0.6284,  smooth loss = 0.5840
[2022-07-05 10:47:28,829 callbacks.py:105 INFO train-abinet] epoch 2 iter 90450: loss = 0.6905,  smooth loss = 0.6010
[2022-07-05 10:48:13,008 callbacks.py:105 INFO train-abinet] epoch 2 iter 90500: loss = 0.5809,  smooth loss = 0.6000
[2022-07-05 10:48:56,834 callbacks.py:105 INFO train-abinet] epoch 2 iter 90550: loss = 0.3628,  smooth loss = 0.5904
[2022-07-05 10:49:40,648 callbacks.py:105 INFO train-abinet] epoch 2 iter 90600: loss = 0.5429,  smooth loss = 0.5826
[2022-07-05 10:50:24,414 callbacks.py:105 INFO train-abinet] epoch 2 iter 90650: loss = 0.5126,  smooth loss = 0.5728
[2022-07-05 10:51:08,364 callbacks.py:105 INFO train-abinet] epoch 2 iter 90700: loss = 0.4616,  smooth loss = 0.5764
[2022-07-05 10:51:51,639 callbacks.py:105 INFO train-abinet] epoch 2 iter 90750: loss = 0.5013,  smooth loss = 0.5920
[2022-07-05 10:52:35,766 callbacks.py:105 INFO train-abinet] epoch 2 iter 90800: loss = 0.5378,  smooth loss = 0.6020
[2022-07-05 10:53:19,806 callbacks.py:105 INFO train-abinet] epoch 2 iter 90850: loss = 0.5014,  smooth loss = 0.5905
[2022-07-05 10:54:02,586 callbacks.py:105 INFO train-abinet] epoch 2 iter 90900: loss = 0.8338,  smooth loss = 0.5878
[2022-07-05 10:54:46,916 callbacks.py:105 INFO train-abinet] epoch 2 iter 90950: loss = 0.6221,  smooth loss = 0.5777
[2022-07-05 10:55:31,065 callbacks.py:105 INFO train-abinet] epoch 2 iter 91000: loss = 0.5852,  smooth loss = 0.5811
[2022-07-05 10:56:14,980 callbacks.py:105 INFO train-abinet] epoch 2 iter 91050: loss = 0.5683,  smooth loss = 0.5757
[2022-07-05 10:56:59,728 callbacks.py:105 INFO train-abinet] epoch 2 iter 91100: loss = 0.5640,  smooth loss = 0.5979
[2022-07-05 10:57:42,959 callbacks.py:105 INFO train-abinet] epoch 2 iter 91150: loss = 0.6011,  smooth loss = 0.6007
[2022-07-05 10:58:25,907 callbacks.py:105 INFO train-abinet] epoch 2 iter 91200: loss = 0.6072,  smooth loss = 0.6060
[2022-07-05 10:59:09,885 callbacks.py:105 INFO train-abinet] epoch 2 iter 91250: loss = 0.6214,  smooth loss = 0.5908
[2022-07-05 10:59:53,072 callbacks.py:105 INFO train-abinet] epoch 2 iter 91300: loss = 0.5387,  smooth loss = 0.5802
[2022-07-05 11:00:36,955 callbacks.py:105 INFO train-abinet] epoch 2 iter 91350: loss = 0.5280,  smooth loss = 0.5811
[2022-07-05 11:01:21,632 callbacks.py:105 INFO train-abinet] epoch 2 iter 91400: loss = 0.6650,  smooth loss = 0.6015
[2022-07-05 11:02:05,661 callbacks.py:105 INFO train-abinet] epoch 2 iter 91450: loss = 0.7423,  smooth loss = 0.6021
[2022-07-05 11:02:50,320 callbacks.py:105 INFO train-abinet] epoch 2 iter 91500: loss = 0.4663,  smooth loss = 0.5844
[2022-07-05 11:03:34,933 callbacks.py:105 INFO train-abinet] epoch 2 iter 91550: loss = 0.5560,  smooth loss = 0.5962
[2022-07-05 11:04:18,360 callbacks.py:105 INFO train-abinet] epoch 2 iter 91600: loss = 0.7047,  smooth loss = 0.6009
[2022-07-05 11:05:03,159 callbacks.py:105 INFO train-abinet] epoch 2 iter 91650: loss = 0.6240,  smooth loss = 0.5959
[2022-07-05 11:05:47,486 callbacks.py:105 INFO train-abinet] epoch 2 iter 91700: loss = 0.5915,  smooth loss = 0.6113
[2022-07-05 11:06:30,828 callbacks.py:105 INFO train-abinet] epoch 2 iter 91750: loss = 0.5208,  smooth loss = 0.6005
[2022-07-05 11:07:14,651 callbacks.py:105 INFO train-abinet] epoch 2 iter 91800: loss = 0.6325,  smooth loss = 0.5955
[2022-07-05 11:07:58,536 callbacks.py:105 INFO train-abinet] epoch 2 iter 91850: loss = 0.4938,  smooth loss = 0.5985
[2022-07-05 11:08:43,414 callbacks.py:105 INFO train-abinet] epoch 2 iter 91900: loss = 0.7107,  smooth loss = 0.5799
[2022-07-05 11:09:27,498 callbacks.py:105 INFO train-abinet] epoch 2 iter 91950: loss = 0.6287,  smooth loss = 0.5820
[2022-07-05 11:10:10,913 callbacks.py:105 INFO train-abinet] epoch 2 iter 92000: loss = 0.5184,  smooth loss = 0.5824
[2022-07-05 11:10:53,103 callbacks.py:105 INFO train-abinet] epoch 2 iter 92050: loss = 0.5116,  smooth loss = 0.5955
[2022-07-05 11:11:37,587 callbacks.py:105 INFO train-abinet] epoch 2 iter 92100: loss = 0.6714,  smooth loss = 0.5876
[2022-07-05 11:12:22,373 callbacks.py:105 INFO train-abinet] epoch 2 iter 92150: loss = 0.5494,  smooth loss = 0.6093
[2022-07-05 11:13:06,015 callbacks.py:105 INFO train-abinet] epoch 2 iter 92200: loss = 0.5648,  smooth loss = 0.5947
[2022-07-05 11:13:50,347 callbacks.py:105 INFO train-abinet] epoch 2 iter 92250: loss = 0.6309,  smooth loss = 0.6006
[2022-07-05 11:14:34,197 callbacks.py:105 INFO train-abinet] epoch 2 iter 92300: loss = 0.5386,  smooth loss = 0.5943
[2022-07-05 11:15:17,533 callbacks.py:105 INFO train-abinet] epoch 2 iter 92350: loss = 0.5447,  smooth loss = 0.6066
[2022-07-05 11:16:02,219 callbacks.py:105 INFO train-abinet] epoch 2 iter 92400: loss = 0.6905,  smooth loss = 0.6005
[2022-07-05 11:16:46,180 callbacks.py:105 INFO train-abinet] epoch 2 iter 92450: loss = 0.5925,  smooth loss = 0.6120
[2022-07-05 11:17:30,435 callbacks.py:105 INFO train-abinet] epoch 2 iter 92500: loss = 0.5678,  smooth loss = 0.6091
[2022-07-05 11:18:14,101 callbacks.py:105 INFO train-abinet] epoch 2 iter 92550: loss = 0.5618,  smooth loss = 0.5921
[2022-07-05 11:18:58,234 callbacks.py:105 INFO train-abinet] epoch 2 iter 92600: loss = 0.5434,  smooth loss = 0.5816
[2022-07-05 11:19:42,350 callbacks.py:105 INFO train-abinet] epoch 2 iter 92650: loss = 0.5640,  smooth loss = 0.5834
[2022-07-05 11:20:25,953 callbacks.py:105 INFO train-abinet] epoch 2 iter 92700: loss = 0.5805,  smooth loss = 0.5857
[2022-07-05 11:21:09,001 callbacks.py:105 INFO train-abinet] epoch 2 iter 92750: loss = 0.5625,  smooth loss = 0.5981
[2022-07-05 11:21:52,358 callbacks.py:105 INFO train-abinet] epoch 2 iter 92800: loss = 0.6868,  smooth loss = 0.6077
[2022-07-05 11:22:37,191 callbacks.py:105 INFO train-abinet] epoch 2 iter 92850: loss = 0.6257,  smooth loss = 0.6077
[2022-07-05 11:23:20,894 callbacks.py:105 INFO train-abinet] epoch 2 iter 92900: loss = 0.5581,  smooth loss = 0.5907
[2022-07-05 11:24:04,475 callbacks.py:105 INFO train-abinet] epoch 2 iter 92950: loss = 0.5954,  smooth loss = 0.5931
[2022-07-05 11:24:48,262 callbacks.py:105 INFO train-abinet] epoch 2 iter 93000: loss = 0.7948,  smooth loss = 0.6003
[2022-07-05 11:24:48,263 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8932s
█[2022-07-05 11:25:04,060 callbacks.py:123 INFO train-abinet] epoch 2 iter 93000: eval loss = 1.1656,  ccr = 0.9591,  cwr = 0.9147,  ted = 1384.0000,  ned = 279.4078,  ted/w = 0.1909, 
[2022-07-05 11:25:04,061 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_93000
[2022-07-05 11:25:49,804 callbacks.py:105 INFO train-abinet] epoch 2 iter 93050: loss = 0.5025,  smooth loss = 0.5814
[2022-07-05 11:26:34,337 callbacks.py:105 INFO train-abinet] epoch 2 iter 93100: loss = 0.4633,  smooth loss = 0.6050
[2022-07-05 11:27:19,062 callbacks.py:105 INFO train-abinet] epoch 2 iter 93150: loss = 0.5493,  smooth loss = 0.5848
[2022-07-05 11:28:02,050 callbacks.py:105 INFO train-abinet] epoch 2 iter 93200: loss = 0.6500,  smooth loss = 0.5907
[2022-07-05 11:28:46,729 callbacks.py:105 INFO train-abinet] epoch 2 iter 93250: loss = 0.6003,  smooth loss = 0.5919
[2022-07-05 11:29:31,919 callbacks.py:105 INFO train-abinet] epoch 2 iter 93300: loss = 0.4490,  smooth loss = 0.5908
[2022-07-05 11:30:16,088 callbacks.py:105 INFO train-abinet] epoch 2 iter 93350: loss = 0.5383,  smooth loss = 0.5856
[2022-07-05 11:31:00,201 callbacks.py:105 INFO train-abinet] epoch 2 iter 93400: loss = 0.6636,  smooth loss = 0.5838
[2022-07-05 11:31:44,682 callbacks.py:105 INFO train-abinet] epoch 2 iter 93450: loss = 0.6501,  smooth loss = 0.5997
[2022-07-05 11:32:29,233 callbacks.py:105 INFO train-abinet] epoch 2 iter 93500: loss = 0.5219,  smooth loss = 0.5981
[2022-07-05 11:33:13,159 callbacks.py:105 INFO train-abinet] epoch 2 iter 93550: loss = 0.7431,  smooth loss = 0.5897
[2022-07-05 11:33:57,413 callbacks.py:105 INFO train-abinet] epoch 2 iter 93600: loss = 0.6695,  smooth loss = 0.6036
[2022-07-05 11:34:40,570 callbacks.py:105 INFO train-abinet] epoch 2 iter 93650: loss = 0.6412,  smooth loss = 0.5962
[2022-07-05 11:35:25,343 callbacks.py:105 INFO train-abinet] epoch 2 iter 93700: loss = 0.5814,  smooth loss = 0.5764
[2022-07-05 11:36:09,883 callbacks.py:105 INFO train-abinet] epoch 2 iter 93750: loss = 0.5923,  smooth loss = 0.5816
[2022-07-05 11:36:54,331 callbacks.py:105 INFO train-abinet] epoch 2 iter 93800: loss = 0.5730,  smooth loss = 0.5869
[2022-07-05 11:37:38,876 callbacks.py:105 INFO train-abinet] epoch 2 iter 93850: loss = 0.5905,  smooth loss = 0.5849
[2022-07-05 11:38:23,632 callbacks.py:105 INFO train-abinet] epoch 2 iter 93900: loss = 0.6637,  smooth loss = 0.6085
[2022-07-05 11:39:07,686 callbacks.py:105 INFO train-abinet] epoch 2 iter 93950: loss = 0.6287,  smooth loss = 0.5846
[2022-07-05 11:39:52,386 callbacks.py:105 INFO train-abinet] epoch 2 iter 94000: loss = 0.5673,  smooth loss = 0.5896
[2022-07-05 11:40:37,759 callbacks.py:105 INFO train-abinet] epoch 2 iter 94050: loss = 0.6098,  smooth loss = 0.6012
[2022-07-05 11:41:21,713 callbacks.py:105 INFO train-abinet] epoch 2 iter 94100: loss = 0.5787,  smooth loss = 0.6041
[2022-07-05 11:42:05,822 callbacks.py:105 INFO train-abinet] epoch 2 iter 94150: loss = 0.4951,  smooth loss = 0.5904
[2022-07-05 11:42:50,358 callbacks.py:105 INFO train-abinet] epoch 2 iter 94200: loss = 0.6906,  smooth loss = 0.5897
[2022-07-05 11:43:34,323 callbacks.py:105 INFO train-abinet] epoch 2 iter 94250: loss = 0.4540,  smooth loss = 0.5847
[2022-07-05 11:44:19,724 callbacks.py:105 INFO train-abinet] epoch 2 iter 94300: loss = 0.5256,  smooth loss = 0.5778
[2022-07-05 11:45:02,995 callbacks.py:105 INFO train-abinet] epoch 2 iter 94350: loss = 0.5203,  smooth loss = 0.5893
[2022-07-05 11:45:47,775 callbacks.py:105 INFO train-abinet] epoch 2 iter 94400: loss = 0.6175,  smooth loss = 0.6018
[2022-07-05 11:46:32,275 callbacks.py:105 INFO train-abinet] epoch 2 iter 94450: loss = 0.5477,  smooth loss = 0.5939
[2022-07-05 11:47:16,036 callbacks.py:105 INFO train-abinet] epoch 2 iter 94500: loss = 0.6175,  smooth loss = 0.5918
[2022-07-05 11:48:00,099 callbacks.py:105 INFO train-abinet] epoch 2 iter 94550: loss = 0.5593,  smooth loss = 0.5862
[2022-07-05 11:48:44,262 callbacks.py:105 INFO train-abinet] epoch 2 iter 94600: loss = 0.5471,  smooth loss = 0.5871
[2022-07-05 11:49:28,331 callbacks.py:105 INFO train-abinet] epoch 2 iter 94650: loss = 0.6179,  smooth loss = 0.5979
[2022-07-05 11:50:11,527 callbacks.py:105 INFO train-abinet] epoch 2 iter 94700: loss = 0.5775,  smooth loss = 0.5980
[2022-07-05 11:50:54,842 callbacks.py:105 INFO train-abinet] epoch 2 iter 94750: loss = 0.5715,  smooth loss = 0.5997
[2022-07-05 11:51:38,782 callbacks.py:105 INFO train-abinet] epoch 2 iter 94800: loss = 0.6152,  smooth loss = 0.5927
[2022-07-05 11:52:22,518 callbacks.py:105 INFO train-abinet] epoch 2 iter 94850: loss = 0.6976,  smooth loss = 0.5836
[2022-07-05 11:53:08,076 callbacks.py:105 INFO train-abinet] epoch 2 iter 94900: loss = 0.8728,  smooth loss = 0.5895
[2022-07-05 11:53:52,790 callbacks.py:105 INFO train-abinet] epoch 2 iter 94950: loss = 0.6849,  smooth loss = 0.5939
[2022-07-05 11:54:37,100 callbacks.py:105 INFO train-abinet] epoch 2 iter 95000: loss = 0.7231,  smooth loss = 0.5847
[2022-07-05 11:55:21,512 callbacks.py:105 INFO train-abinet] epoch 2 iter 95050: loss = 0.3701,  smooth loss = 0.5776
[2022-07-05 11:56:05,588 callbacks.py:105 INFO train-abinet] epoch 2 iter 95100: loss = 0.6210,  smooth loss = 0.5917
[2022-07-05 11:56:50,420 callbacks.py:105 INFO train-abinet] epoch 2 iter 95150: loss = 0.5544,  smooth loss = 0.5843
[2022-07-05 11:57:33,948 callbacks.py:105 INFO train-abinet] epoch 2 iter 95200: loss = 0.5624,  smooth loss = 0.5924
[2022-07-05 11:58:17,874 callbacks.py:105 INFO train-abinet] epoch 2 iter 95250: loss = 0.4345,  smooth loss = 0.5828
[2022-07-05 11:59:01,891 callbacks.py:105 INFO train-abinet] epoch 2 iter 95300: loss = 0.5697,  smooth loss = 0.5811
[2022-07-05 11:59:45,871 callbacks.py:105 INFO train-abinet] epoch 2 iter 95350: loss = 0.5610,  smooth loss = 0.5823
[2022-07-05 12:00:29,632 callbacks.py:105 INFO train-abinet] epoch 2 iter 95400: loss = 0.6802,  smooth loss = 0.5809
[2022-07-05 12:01:13,809 callbacks.py:105 INFO train-abinet] epoch 2 iter 95450: loss = 0.5870,  smooth loss = 0.5890
[2022-07-05 12:01:57,825 callbacks.py:105 INFO train-abinet] epoch 2 iter 95500: loss = 0.5302,  smooth loss = 0.5824
[2022-07-05 12:02:40,728 callbacks.py:105 INFO train-abinet] epoch 2 iter 95550: loss = 0.6582,  smooth loss = 0.5969
[2022-07-05 12:03:24,230 callbacks.py:105 INFO train-abinet] epoch 2 iter 95600: loss = 0.5607,  smooth loss = 0.5935
[2022-07-05 12:04:08,297 callbacks.py:105 INFO train-abinet] epoch 2 iter 95650: loss = 0.5533,  smooth loss = 0.5841
[2022-07-05 12:04:52,279 callbacks.py:105 INFO train-abinet] epoch 2 iter 95700: loss = 0.5793,  smooth loss = 0.6036
[2022-07-05 12:05:37,352 callbacks.py:105 INFO train-abinet] epoch 2 iter 95750: loss = 0.5161,  smooth loss = 0.5928
[2022-07-05 12:06:21,440 callbacks.py:105 INFO train-abinet] epoch 2 iter 95800: loss = 0.4940,  smooth loss = 0.5899
[2022-07-05 12:07:06,587 callbacks.py:105 INFO train-abinet] epoch 2 iter 95850: loss = 0.5804,  smooth loss = 0.5804
[2022-07-05 12:07:50,404 callbacks.py:105 INFO train-abinet] epoch 2 iter 95900: loss = 0.5194,  smooth loss = 0.5830
[2022-07-05 12:08:34,063 callbacks.py:105 INFO train-abinet] epoch 2 iter 95950: loss = 0.5678,  smooth loss = 0.6042
[2022-07-05 12:09:18,566 callbacks.py:105 INFO train-abinet] epoch 2 iter 96000: loss = 0.5906,  smooth loss = 0.6001
[2022-07-05 12:09:18,566 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8929s
█[2022-07-05 12:09:33,750 callbacks.py:123 INFO train-abinet] epoch 2 iter 96000: eval loss = 1.1827,  ccr = 0.9581,  cwr = 0.9146,  ted = 1365.0000,  ned = 269.4653,  ted/w = 0.1883, 
[2022-07-05 12:09:33,752 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_96000
[2022-07-05 12:10:19,442 callbacks.py:105 INFO train-abinet] epoch 2 iter 96050: loss = 0.7448,  smooth loss = 0.6050
[2022-07-05 12:11:03,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 96100: loss = 0.6325,  smooth loss = 0.5981
[2022-07-05 12:11:47,483 callbacks.py:105 INFO train-abinet] epoch 2 iter 96150: loss = 0.5589,  smooth loss = 0.5924
[2022-07-05 12:12:31,646 callbacks.py:105 INFO train-abinet] epoch 2 iter 96200: loss = 0.5339,  smooth loss = 0.5820
[2022-07-05 12:13:16,195 callbacks.py:105 INFO train-abinet] epoch 2 iter 96250: loss = 0.5362,  smooth loss = 0.5854
[2022-07-05 12:14:01,058 callbacks.py:105 INFO train-abinet] epoch 2 iter 96300: loss = 0.6707,  smooth loss = 0.5855
[2022-07-05 12:14:46,541 callbacks.py:105 INFO train-abinet] epoch 2 iter 96350: loss = 0.8163,  smooth loss = 0.6011
[2022-07-05 12:15:30,490 callbacks.py:105 INFO train-abinet] epoch 2 iter 96400: loss = 0.5110,  smooth loss = 0.5933
[2022-07-05 12:16:16,820 callbacks.py:105 INFO train-abinet] epoch 2 iter 96450: loss = 0.6195,  smooth loss = 0.5927
[2022-07-05 12:17:00,958 callbacks.py:105 INFO train-abinet] epoch 2 iter 96500: loss = 0.5571,  smooth loss = 0.5815
[2022-07-05 12:17:45,095 callbacks.py:105 INFO train-abinet] epoch 2 iter 96550: loss = 0.4499,  smooth loss = 0.5698
[2022-07-05 12:18:28,596 callbacks.py:105 INFO train-abinet] epoch 2 iter 96600: loss = 0.7730,  smooth loss = 0.5847
[2022-07-05 12:19:11,609 callbacks.py:105 INFO train-abinet] epoch 2 iter 96650: loss = 0.4636,  smooth loss = 0.5842
[2022-07-05 12:19:55,757 callbacks.py:105 INFO train-abinet] epoch 2 iter 96700: loss = 0.6285,  smooth loss = 0.5942
[2022-07-05 12:20:39,714 callbacks.py:105 INFO train-abinet] epoch 2 iter 96750: loss = 0.5132,  smooth loss = 0.5984
[2022-07-05 12:21:23,949 callbacks.py:105 INFO train-abinet] epoch 2 iter 96800: loss = 0.5292,  smooth loss = 0.5770
[2022-07-05 12:22:08,105 callbacks.py:105 INFO train-abinet] epoch 2 iter 96850: loss = 0.5538,  smooth loss = 0.5868
[2022-07-05 12:22:51,887 callbacks.py:105 INFO train-abinet] epoch 2 iter 96900: loss = 0.6678,  smooth loss = 0.6013
[2022-07-05 12:23:35,703 callbacks.py:105 INFO train-abinet] epoch 2 iter 96950: loss = 0.6827,  smooth loss = 0.6018
[2022-07-05 12:24:19,555 callbacks.py:105 INFO train-abinet] epoch 2 iter 97000: loss = 0.4215,  smooth loss = 0.5888
[2022-07-05 12:25:03,375 callbacks.py:105 INFO train-abinet] epoch 2 iter 97050: loss = 0.6087,  smooth loss = 0.5925
[2022-07-05 12:25:47,875 callbacks.py:105 INFO train-abinet] epoch 2 iter 97100: loss = 0.5906,  smooth loss = 0.6008
[2022-07-05 12:26:30,863 callbacks.py:105 INFO train-abinet] epoch 2 iter 97150: loss = 0.5082,  smooth loss = 0.6016
[2022-07-05 12:27:15,900 callbacks.py:105 INFO train-abinet] epoch 2 iter 97200: loss = 0.6092,  smooth loss = 0.6023
[2022-07-05 12:28:02,825 callbacks.py:105 INFO train-abinet] epoch 2 iter 97250: loss = 0.4961,  smooth loss = 0.5969
[2022-07-05 12:28:47,584 callbacks.py:105 INFO train-abinet] epoch 2 iter 97300: loss = 0.6144,  smooth loss = 0.5854
[2022-07-05 12:29:31,279 callbacks.py:105 INFO train-abinet] epoch 2 iter 97350: loss = 0.6161,  smooth loss = 0.5954
[2022-07-05 12:30:20,173 callbacks.py:105 INFO train-abinet] epoch 2 iter 97400: loss = 0.5704,  smooth loss = 0.6012
[2022-07-05 12:31:10,544 callbacks.py:105 INFO train-abinet] epoch 2 iter 97450: loss = 0.6896,  smooth loss = 0.5994
[2022-07-05 12:32:00,556 callbacks.py:105 INFO train-abinet] epoch 2 iter 97500: loss = 0.6870,  smooth loss = 0.5915
[2022-07-05 12:32:53,098 callbacks.py:105 INFO train-abinet] epoch 2 iter 97550: loss = 0.5572,  smooth loss = 0.5950
[2022-07-05 12:33:43,300 callbacks.py:105 INFO train-abinet] epoch 2 iter 97600: loss = 0.6897,  smooth loss = 0.5883
[2022-07-05 12:34:26,467 callbacks.py:105 INFO train-abinet] epoch 2 iter 97650: loss = 0.7563,  smooth loss = 0.5855
[2022-07-05 12:35:15,422 callbacks.py:105 INFO train-abinet] epoch 2 iter 97700: loss = 0.5356,  smooth loss = 0.5916
[2022-07-05 12:36:05,878 callbacks.py:105 INFO train-abinet] epoch 2 iter 97750: loss = 0.5652,  smooth loss = 0.5908
[2022-07-05 12:36:50,427 callbacks.py:105 INFO train-abinet] epoch 2 iter 97800: loss = 0.5799,  smooth loss = 0.5964
[2022-07-05 12:37:32,685 callbacks.py:105 INFO train-abinet] epoch 2 iter 97850: loss = 0.5536,  smooth loss = 0.5918
[2022-07-05 12:38:16,145 callbacks.py:105 INFO train-abinet] epoch 2 iter 97900: loss = 0.6025,  smooth loss = 0.5961
[2022-07-05 12:38:59,744 callbacks.py:105 INFO train-abinet] epoch 2 iter 97950: loss = 0.5479,  smooth loss = 0.5843
[2022-07-05 12:39:43,506 callbacks.py:105 INFO train-abinet] epoch 2 iter 98000: loss = 0.8458,  smooth loss = 0.5977
[2022-07-05 12:40:26,564 callbacks.py:105 INFO train-abinet] epoch 2 iter 98050: loss = 0.6063,  smooth loss = 0.5855
[2022-07-05 12:41:10,909 callbacks.py:105 INFO train-abinet] epoch 2 iter 98100: loss = 0.7094,  smooth loss = 0.5904
[2022-07-05 12:41:54,027 callbacks.py:105 INFO train-abinet] epoch 2 iter 98150: loss = 0.5493,  smooth loss = 0.5943
[2022-07-05 12:42:38,163 callbacks.py:105 INFO train-abinet] epoch 2 iter 98200: loss = 0.6521,  smooth loss = 0.5953
[2022-07-05 12:43:21,987 callbacks.py:105 INFO train-abinet] epoch 2 iter 98250: loss = 0.5192,  smooth loss = 0.5887
[2022-07-05 12:44:06,385 callbacks.py:105 INFO train-abinet] epoch 2 iter 98300: loss = 0.5893,  smooth loss = 0.5870
[2022-07-05 12:44:50,815 callbacks.py:105 INFO train-abinet] epoch 2 iter 98350: loss = 0.6188,  smooth loss = 0.5792
[2022-07-05 12:45:33,737 callbacks.py:105 INFO train-abinet] epoch 2 iter 98400: loss = 0.5612,  smooth loss = 0.5796
[2022-07-05 12:46:16,936 callbacks.py:105 INFO train-abinet] epoch 2 iter 98450: loss = 0.5480,  smooth loss = 0.5805
[2022-07-05 12:47:00,397 callbacks.py:105 INFO train-abinet] epoch 2 iter 98500: loss = 0.6055,  smooth loss = 0.5763
[2022-07-05 12:47:43,961 callbacks.py:105 INFO train-abinet] epoch 2 iter 98550: loss = 0.5332,  smooth loss = 0.5877
[2022-07-05 12:48:27,775 callbacks.py:105 INFO train-abinet] epoch 2 iter 98600: loss = 0.6440,  smooth loss = 0.5905
[2022-07-05 12:49:10,936 callbacks.py:105 INFO train-abinet] epoch 2 iter 98650: loss = 0.3580,  smooth loss = 0.5858
[2022-07-05 12:49:54,506 callbacks.py:105 INFO train-abinet] epoch 2 iter 98700: loss = 0.4747,  smooth loss = 0.5759
[2022-07-05 12:50:38,052 callbacks.py:105 INFO train-abinet] epoch 2 iter 98750: loss = 0.5869,  smooth loss = 0.5759
[2022-07-05 12:51:22,088 callbacks.py:105 INFO train-abinet] epoch 2 iter 98800: loss = 0.6263,  smooth loss = 0.5860
[2022-07-05 12:52:05,839 callbacks.py:105 INFO train-abinet] epoch 2 iter 98850: loss = 0.7102,  smooth loss = 0.5918
[2022-07-05 12:52:50,366 callbacks.py:105 INFO train-abinet] epoch 2 iter 98900: loss = 0.5120,  smooth loss = 0.6019
[2022-07-05 12:53:35,200 callbacks.py:105 INFO train-abinet] epoch 2 iter 98950: loss = 0.5575,  smooth loss = 0.5803
[2022-07-05 12:54:20,939 callbacks.py:105 INFO train-abinet] epoch 2 iter 99000: loss = 0.7227,  smooth loss = 0.5841
[2022-07-05 12:54:20,940 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8930s
█[2022-07-05 12:54:37,909 callbacks.py:123 INFO train-abinet] epoch 2 iter 99000: eval loss = 1.1942,  ccr = 0.9585,  cwr = 0.9146,  ted = 1368.0000,  ned = 272.4678,  ted/w = 0.1887, 
[2022-07-05 12:54:37,912 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_99000
[2022-07-05 12:55:29,897 callbacks.py:105 INFO train-abinet] epoch 2 iter 99050: loss = 0.5588,  smooth loss = 0.5824
[2022-07-05 12:56:14,484 callbacks.py:105 INFO train-abinet] epoch 2 iter 99100: loss = 0.6953,  smooth loss = 0.5826
[2022-07-05 12:56:59,007 callbacks.py:105 INFO train-abinet] epoch 2 iter 99150: loss = 0.6766,  smooth loss = 0.5826
[2022-07-05 12:57:42,073 callbacks.py:105 INFO train-abinet] epoch 2 iter 99200: loss = 0.6825,  smooth loss = 0.5992
[2022-07-05 12:58:26,176 callbacks.py:105 INFO train-abinet] epoch 2 iter 99250: loss = 0.6932,  smooth loss = 0.5973
[2022-07-05 12:59:08,617 callbacks.py:105 INFO train-abinet] epoch 2 iter 99300: loss = 0.5368,  smooth loss = 0.6050
[2022-07-05 12:59:52,739 callbacks.py:105 INFO train-abinet] epoch 2 iter 99350: loss = 0.5430,  smooth loss = 0.6118
[2022-07-05 13:00:36,253 callbacks.py:105 INFO train-abinet] epoch 2 iter 99400: loss = 0.5874,  smooth loss = 0.6026
[2022-07-05 13:01:20,284 callbacks.py:105 INFO train-abinet] epoch 2 iter 99450: loss = 0.5901,  smooth loss = 0.5816
[2022-07-05 13:02:05,096 callbacks.py:105 INFO train-abinet] epoch 2 iter 99500: loss = 0.6120,  smooth loss = 0.5848
[2022-07-05 13:02:50,560 callbacks.py:105 INFO train-abinet] epoch 2 iter 99550: loss = 0.6780,  smooth loss = 0.5943
[2022-07-05 13:03:38,692 callbacks.py:105 INFO train-abinet] epoch 2 iter 99600: loss = 0.5401,  smooth loss = 0.5874
[2022-07-05 13:04:23,819 callbacks.py:105 INFO train-abinet] epoch 2 iter 99650: loss = 0.5625,  smooth loss = 0.5869
[2022-07-05 13:05:17,076 callbacks.py:105 INFO train-abinet] epoch 2 iter 99700: loss = 0.6131,  smooth loss = 0.5733
[2022-07-05 13:06:15,140 callbacks.py:105 INFO train-abinet] epoch 2 iter 99750: loss = 0.4990,  smooth loss = 0.5841
[2022-07-05 13:07:10,031 callbacks.py:105 INFO train-abinet] epoch 2 iter 99800: loss = 0.5227,  smooth loss = 0.5765
[2022-07-05 13:08:04,495 callbacks.py:105 INFO train-abinet] epoch 2 iter 99850: loss = 0.6988,  smooth loss = 0.5839
[2022-07-05 13:09:00,108 callbacks.py:105 INFO train-abinet] epoch 2 iter 99900: loss = 0.4956,  smooth loss = 0.5759
[2022-07-05 13:09:56,532 callbacks.py:105 INFO train-abinet] epoch 2 iter 99950: loss = 0.7551,  smooth loss = 0.5938
[2022-07-05 13:10:48,203 callbacks.py:105 INFO train-abinet] epoch 2 iter 100000: loss = 0.5513,  smooth loss = 0.5959
[2022-07-05 13:11:36,167 callbacks.py:105 INFO train-abinet] epoch 2 iter 100050: loss = 0.6763,  smooth loss = 0.6006
[2022-07-05 13:12:18,576 callbacks.py:105 INFO train-abinet] epoch 2 iter 100100: loss = 0.6040,  smooth loss = 0.5939
[2022-07-05 13:13:02,872 callbacks.py:105 INFO train-abinet] epoch 2 iter 100150: loss = 0.5098,  smooth loss = 0.6043
[2022-07-05 13:13:57,291 callbacks.py:105 INFO train-abinet] epoch 2 iter 100200: loss = 0.7090,  smooth loss = 0.6047
[2022-07-05 13:14:50,662 callbacks.py:105 INFO train-abinet] epoch 2 iter 100250: loss = 0.5786,  smooth loss = 0.5952
[2022-07-05 13:15:39,221 callbacks.py:105 INFO train-abinet] epoch 2 iter 100300: loss = 0.6256,  smooth loss = 0.6061
[2022-07-05 13:16:24,256 callbacks.py:105 INFO train-abinet] epoch 2 iter 100350: loss = 0.5638,  smooth loss = 0.5934
[2022-07-05 13:17:13,240 callbacks.py:105 INFO train-abinet] epoch 2 iter 100400: loss = 0.5362,  smooth loss = 0.5790
[2022-07-05 13:18:04,780 callbacks.py:105 INFO train-abinet] epoch 2 iter 100450: loss = 0.6152,  smooth loss = 0.5806
[2022-07-05 13:18:59,161 callbacks.py:105 INFO train-abinet] epoch 2 iter 100500: loss = 0.8110,  smooth loss = 0.5911
[2022-07-05 13:19:54,395 callbacks.py:105 INFO train-abinet] epoch 2 iter 100550: loss = 0.6014,  smooth loss = 0.5925
[2022-07-05 13:20:50,937 callbacks.py:105 INFO train-abinet] epoch 2 iter 100600: loss = 0.6331,  smooth loss = 0.5909
[2022-07-05 13:21:45,413 callbacks.py:105 INFO train-abinet] epoch 2 iter 100650: loss = 0.5362,  smooth loss = 0.5979
[2022-07-05 13:22:40,479 callbacks.py:105 INFO train-abinet] epoch 2 iter 100700: loss = 0.7313,  smooth loss = 0.5969
[2022-07-05 13:23:33,764 callbacks.py:105 INFO train-abinet] epoch 2 iter 100750: loss = 0.4830,  smooth loss = 0.5977
[2022-07-05 13:24:28,225 callbacks.py:105 INFO train-abinet] epoch 2 iter 100800: loss = 0.5147,  smooth loss = 0.5830
[2022-07-05 13:25:22,436 callbacks.py:105 INFO train-abinet] epoch 2 iter 100850: loss = 0.5211,  smooth loss = 0.5958
[2022-07-05 13:26:16,847 callbacks.py:105 INFO train-abinet] epoch 2 iter 100900: loss = 0.6832,  smooth loss = 0.5767
[2022-07-05 13:27:12,674 callbacks.py:105 INFO train-abinet] epoch 2 iter 100950: loss = 0.6154,  smooth loss = 0.5880
[2022-07-05 13:28:06,938 callbacks.py:105 INFO train-abinet] epoch 2 iter 101000: loss = 0.6437,  smooth loss = 0.6062
[2022-07-05 13:29:00,737 callbacks.py:105 INFO train-abinet] epoch 2 iter 101050: loss = 0.6478,  smooth loss = 0.6000
[2022-07-05 13:29:56,682 callbacks.py:105 INFO train-abinet] epoch 2 iter 101100: loss = 0.6982,  smooth loss = 0.6027
[2022-07-05 13:30:49,994 callbacks.py:105 INFO train-abinet] epoch 2 iter 101150: loss = 0.6661,  smooth loss = 0.5890
[2022-07-05 13:31:40,052 callbacks.py:105 INFO train-abinet] epoch 2 iter 101200: loss = 0.5856,  smooth loss = 0.6024
[2022-07-05 13:32:28,865 callbacks.py:105 INFO train-abinet] epoch 2 iter 101250: loss = 0.5649,  smooth loss = 0.5891
[2022-07-05 13:33:13,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 101300: loss = 0.5054,  smooth loss = 0.5899
[2022-07-05 13:33:56,130 callbacks.py:105 INFO train-abinet] epoch 2 iter 101350: loss = 0.5293,  smooth loss = 0.5841
[2022-07-05 13:34:39,277 callbacks.py:105 INFO train-abinet] epoch 2 iter 101400: loss = 0.8502,  smooth loss = 0.5967
[2022-07-05 13:35:23,814 callbacks.py:105 INFO train-abinet] epoch 2 iter 101450: loss = 0.6071,  smooth loss = 0.5877
[2022-07-05 13:36:15,204 callbacks.py:105 INFO train-abinet] epoch 2 iter 101500: loss = 0.5514,  smooth loss = 0.5884
[2022-07-05 13:37:08,058 callbacks.py:105 INFO train-abinet] epoch 2 iter 101550: loss = 0.6778,  smooth loss = 0.5988
[2022-07-05 13:38:01,116 callbacks.py:105 INFO train-abinet] epoch 2 iter 101600: loss = 0.4734,  smooth loss = 0.5832
[2022-07-05 13:38:54,502 callbacks.py:105 INFO train-abinet] epoch 2 iter 101650: loss = 0.5046,  smooth loss = 0.5995
[2022-07-05 13:39:51,105 callbacks.py:105 INFO train-abinet] epoch 2 iter 101700: loss = 0.6101,  smooth loss = 0.5911
[2022-07-05 13:40:47,229 callbacks.py:105 INFO train-abinet] epoch 2 iter 101750: loss = 0.5986,  smooth loss = 0.5824
[2022-07-05 13:41:38,284 callbacks.py:105 INFO train-abinet] epoch 2 iter 101800: loss = 0.5560,  smooth loss = 0.5706
[2022-07-05 13:42:20,803 callbacks.py:105 INFO train-abinet] epoch 2 iter 101850: loss = 0.5408,  smooth loss = 0.5813
[2022-07-05 13:43:10,200 callbacks.py:105 INFO train-abinet] epoch 2 iter 101900: loss = 0.5419,  smooth loss = 0.5782
[2022-07-05 13:44:06,131 callbacks.py:105 INFO train-abinet] epoch 2 iter 101950: loss = 0.5781,  smooth loss = 0.5811
[2022-07-05 13:44:59,067 callbacks.py:105 INFO train-abinet] epoch 2 iter 102000: loss = 0.6501,  smooth loss = 0.5946
[2022-07-05 13:44:59,067 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8963s
█[2022-07-05 13:45:18,336 callbacks.py:123 INFO train-abinet] epoch 2 iter 102000: eval loss = 1.2265,  ccr = 0.9539,  cwr = 0.9135,  ted = 1469.0000,  ned = 279.0220,  ted/w = 0.2027, 
[2022-07-05 13:45:18,337 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_102000
[2022-07-05 13:46:14,285 callbacks.py:105 INFO train-abinet] epoch 2 iter 102050: loss = 0.5820,  smooth loss = 0.5976
[2022-07-05 13:47:09,643 callbacks.py:105 INFO train-abinet] epoch 2 iter 102100: loss = 0.7334,  smooth loss = 0.5873
[2022-07-05 13:48:04,384 callbacks.py:105 INFO train-abinet] epoch 2 iter 102150: loss = 0.6099,  smooth loss = 0.5908
[2022-07-05 13:48:59,364 callbacks.py:105 INFO train-abinet] epoch 2 iter 102200: loss = 0.5552,  smooth loss = 0.5976
[2022-07-05 13:49:54,561 callbacks.py:105 INFO train-abinet] epoch 2 iter 102250: loss = 0.7425,  smooth loss = 0.6103
[2022-07-05 13:50:41,675 callbacks.py:105 INFO train-abinet] epoch 2 iter 102300: loss = 0.6031,  smooth loss = 0.5785
[2022-07-05 13:51:25,805 callbacks.py:105 INFO train-abinet] epoch 2 iter 102350: loss = 0.4604,  smooth loss = 0.5766
[2022-07-05 13:52:10,936 callbacks.py:105 INFO train-abinet] epoch 2 iter 102400: loss = 0.6015,  smooth loss = 0.6039
[2022-07-05 13:52:54,527 callbacks.py:105 INFO train-abinet] epoch 2 iter 102450: loss = 0.4799,  smooth loss = 0.5953
[2022-07-05 13:53:45,754 callbacks.py:105 INFO train-abinet] epoch 2 iter 102500: loss = 0.6295,  smooth loss = 0.5991
[2022-07-05 13:54:41,681 callbacks.py:105 INFO train-abinet] epoch 2 iter 102550: loss = 0.5454,  smooth loss = 0.5959
[2022-07-05 13:55:36,626 callbacks.py:105 INFO train-abinet] epoch 2 iter 102600: loss = 0.5103,  smooth loss = 0.5859
[2022-07-05 13:56:33,748 callbacks.py:105 INFO train-abinet] epoch 2 iter 102650: loss = 0.4821,  smooth loss = 0.5786
[2022-07-05 13:57:29,483 callbacks.py:105 INFO train-abinet] epoch 2 iter 102700: loss = 0.5307,  smooth loss = 0.5847
[2022-07-05 13:58:25,143 callbacks.py:105 INFO train-abinet] epoch 2 iter 102750: loss = 0.6472,  smooth loss = 0.5966
[2022-07-05 13:59:20,822 callbacks.py:105 INFO train-abinet] epoch 2 iter 102800: loss = 0.7789,  smooth loss = 0.5876
[2022-07-05 14:00:15,216 callbacks.py:105 INFO train-abinet] epoch 2 iter 102850: loss = 0.5580,  smooth loss = 0.5915
[2022-07-05 14:01:09,612 callbacks.py:105 INFO train-abinet] epoch 2 iter 102900: loss = 0.6894,  smooth loss = 0.5896
[2022-07-05 14:02:02,746 callbacks.py:105 INFO train-abinet] epoch 2 iter 102950: loss = 0.5694,  smooth loss = 0.5860
[2022-07-05 14:02:57,504 callbacks.py:105 INFO train-abinet] epoch 2 iter 103000: loss = 0.6155,  smooth loss = 0.5710
[2022-07-05 14:03:53,259 callbacks.py:105 INFO train-abinet] epoch 2 iter 103050: loss = 0.5405,  smooth loss = 0.5707
[2022-07-05 14:04:46,909 callbacks.py:105 INFO train-abinet] epoch 2 iter 103100: loss = 0.5801,  smooth loss = 0.5847
[2022-07-05 14:05:41,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 103150: loss = 0.5257,  smooth loss = 0.5855
[2022-07-05 14:06:37,213 callbacks.py:105 INFO train-abinet] epoch 2 iter 103200: loss = 0.7098,  smooth loss = 0.5965
[2022-07-05 14:07:27,191 callbacks.py:105 INFO train-abinet] epoch 2 iter 103250: loss = 0.7302,  smooth loss = 0.5800
[2022-07-05 14:08:11,747 callbacks.py:105 INFO train-abinet] epoch 2 iter 103300: loss = 0.5606,  smooth loss = 0.5939
[2022-07-05 14:08:59,061 callbacks.py:105 INFO train-abinet] epoch 2 iter 103350: loss = 0.4564,  smooth loss = 0.5836
[2022-07-05 14:09:42,173 callbacks.py:105 INFO train-abinet] epoch 2 iter 103400: loss = 0.6271,  smooth loss = 0.5849
[2022-07-05 14:10:29,934 callbacks.py:105 INFO train-abinet] epoch 2 iter 103450: loss = 0.6159,  smooth loss = 0.5882
[2022-07-05 14:11:16,563 callbacks.py:105 INFO train-abinet] epoch 2 iter 103500: loss = 0.5881,  smooth loss = 0.5841
[2022-07-05 14:12:05,904 callbacks.py:105 INFO train-abinet] epoch 2 iter 103550: loss = 0.4834,  smooth loss = 0.5875
[2022-07-05 14:12:54,403 callbacks.py:105 INFO train-abinet] epoch 2 iter 103600: loss = 0.7109,  smooth loss = 0.5981
[2022-07-05 14:13:45,104 callbacks.py:105 INFO train-abinet] epoch 2 iter 103650: loss = 0.6807,  smooth loss = 0.5909
[2022-07-05 14:14:27,681 callbacks.py:105 INFO train-abinet] epoch 2 iter 103700: loss = 0.6238,  smooth loss = 0.5828
[2022-07-05 14:15:11,035 callbacks.py:105 INFO train-abinet] epoch 2 iter 103750: loss = 0.5816,  smooth loss = 0.5886
[2022-07-05 14:15:57,459 callbacks.py:105 INFO train-abinet] epoch 2 iter 103800: loss = 0.4598,  smooth loss = 0.5661
[2022-07-05 14:16:42,326 callbacks.py:105 INFO train-abinet] epoch 2 iter 103850: loss = 0.6312,  smooth loss = 0.5875
[2022-07-05 14:17:26,240 callbacks.py:105 INFO train-abinet] epoch 2 iter 103900: loss = 0.6870,  smooth loss = 0.5788
[2022-07-05 14:18:08,628 callbacks.py:105 INFO train-abinet] epoch 2 iter 103950: loss = 0.6175,  smooth loss = 0.5723
[2022-07-05 14:18:51,745 callbacks.py:105 INFO train-abinet] epoch 2 iter 104000: loss = 0.5868,  smooth loss = 0.5763
[2022-07-05 14:19:34,780 callbacks.py:105 INFO train-abinet] epoch 2 iter 104050: loss = 0.6580,  smooth loss = 0.5716
[2022-07-05 14:20:17,208 callbacks.py:105 INFO train-abinet] epoch 2 iter 104100: loss = 0.6485,  smooth loss = 0.5784
[2022-07-05 14:20:59,272 callbacks.py:105 INFO train-abinet] epoch 2 iter 104150: loss = 0.6640,  smooth loss = 0.5717
[2022-07-05 14:21:41,958 callbacks.py:105 INFO train-abinet] epoch 2 iter 104200: loss = 0.6144,  smooth loss = 0.5833
[2022-07-05 14:22:24,988 callbacks.py:105 INFO train-abinet] epoch 2 iter 104250: loss = 0.7381,  smooth loss = 0.5954
[2022-07-05 14:23:08,616 callbacks.py:105 INFO train-abinet] epoch 2 iter 104300: loss = 0.7591,  smooth loss = 0.5970
[2022-07-05 14:23:51,269 callbacks.py:105 INFO train-abinet] epoch 2 iter 104350: loss = 0.6158,  smooth loss = 0.5826
[2022-07-05 14:24:34,227 callbacks.py:105 INFO train-abinet] epoch 2 iter 104400: loss = 0.4369,  smooth loss = 0.5881
[2022-07-05 14:25:17,558 callbacks.py:105 INFO train-abinet] epoch 2 iter 104450: loss = 0.6042,  smooth loss = 0.5816
[2022-07-05 14:26:01,079 callbacks.py:105 INFO train-abinet] epoch 2 iter 104500: loss = 0.4993,  smooth loss = 0.5900
[2022-07-05 14:26:45,765 callbacks.py:105 INFO train-abinet] epoch 2 iter 104550: loss = 0.5352,  smooth loss = 0.5986
[2022-07-05 14:27:27,388 callbacks.py:105 INFO train-abinet] epoch 2 iter 104600: loss = 0.6114,  smooth loss = 0.5977
[2022-07-05 14:28:10,411 callbacks.py:105 INFO train-abinet] epoch 2 iter 104650: loss = 0.5349,  smooth loss = 0.5806
[2022-07-05 14:28:52,601 callbacks.py:105 INFO train-abinet] epoch 2 iter 104700: loss = 0.5733,  smooth loss = 0.5858
[2022-07-05 14:29:34,840 callbacks.py:105 INFO train-abinet] epoch 2 iter 104750: loss = 0.7508,  smooth loss = 0.5864
[2022-07-05 14:30:17,496 callbacks.py:105 INFO train-abinet] epoch 2 iter 104800: loss = 0.6263,  smooth loss = 0.5872
[2022-07-05 14:31:01,279 callbacks.py:105 INFO train-abinet] epoch 2 iter 104850: loss = 0.5744,  smooth loss = 0.5894
[2022-07-05 14:31:43,252 callbacks.py:105 INFO train-abinet] epoch 2 iter 104900: loss = 0.5317,  smooth loss = 0.5979
[2022-07-05 14:32:26,437 callbacks.py:105 INFO train-abinet] epoch 2 iter 104950: loss = 0.6777,  smooth loss = 0.5949
[2022-07-05 14:33:10,530 callbacks.py:105 INFO train-abinet] epoch 2 iter 105000: loss = 0.6215,  smooth loss = 0.5842
[2022-07-05 14:33:10,530 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8980s
█[2022-07-05 14:33:25,462 callbacks.py:123 INFO train-abinet] epoch 2 iter 105000: eval loss = 1.1963,  ccr = 0.9578,  cwr = 0.9167,  ted = 1370.0000,  ned = 267.2817,  ted/w = 0.1890, 
[2022-07-05 14:33:25,463 callbacks.py:130 INFO train-abinet] Better model found at epoch 2, iter 105000 with accuracy value: 0.9167.
[2022-07-05 14:33:26,635 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_105000
[2022-07-05 14:34:09,571 callbacks.py:105 INFO train-abinet] epoch 2 iter 105050: loss = 0.5973,  smooth loss = 0.5900
[2022-07-05 14:34:52,400 callbacks.py:105 INFO train-abinet] epoch 2 iter 105100: loss = 0.5954,  smooth loss = 0.5845
[2022-07-05 14:35:35,261 callbacks.py:105 INFO train-abinet] epoch 2 iter 105150: loss = 0.7345,  smooth loss = 0.5886
[2022-07-05 14:36:17,828 callbacks.py:105 INFO train-abinet] epoch 2 iter 105200: loss = 0.6145,  smooth loss = 0.5812
[2022-07-05 14:37:01,787 callbacks.py:105 INFO train-abinet] epoch 2 iter 105250: loss = 0.4621,  smooth loss = 0.5842
[2022-07-05 14:37:44,195 callbacks.py:105 INFO train-abinet] epoch 2 iter 105300: loss = 0.6494,  smooth loss = 0.5939
[2022-07-05 14:38:26,793 callbacks.py:105 INFO train-abinet] epoch 2 iter 105350: loss = 0.5475,  smooth loss = 0.5928
[2022-07-05 14:39:10,297 callbacks.py:105 INFO train-abinet] epoch 2 iter 105400: loss = 0.4921,  smooth loss = 0.5956
[2022-07-05 14:39:52,754 callbacks.py:105 INFO train-abinet] epoch 2 iter 105450: loss = 0.6632,  smooth loss = 0.5890
[2022-07-05 14:40:35,352 callbacks.py:105 INFO train-abinet] epoch 2 iter 105500: loss = 0.5851,  smooth loss = 0.6032
[2022-07-05 14:41:18,034 callbacks.py:105 INFO train-abinet] epoch 2 iter 105550: loss = 0.4359,  smooth loss = 0.5848
[2022-07-05 14:42:01,231 callbacks.py:105 INFO train-abinet] epoch 2 iter 105600: loss = 0.6646,  smooth loss = 0.5731
[2022-07-05 14:42:44,657 callbacks.py:105 INFO train-abinet] epoch 2 iter 105650: loss = 0.5549,  smooth loss = 0.5833
[2022-07-05 14:43:27,658 callbacks.py:105 INFO train-abinet] epoch 2 iter 105700: loss = 0.7007,  smooth loss = 0.5909
[2022-07-05 14:44:09,467 callbacks.py:105 INFO train-abinet] epoch 2 iter 105750: loss = 0.6312,  smooth loss = 0.5803
[2022-07-05 14:44:52,361 callbacks.py:105 INFO train-abinet] epoch 2 iter 105800: loss = 0.5697,  smooth loss = 0.5789
[2022-07-05 14:45:35,571 callbacks.py:105 INFO train-abinet] epoch 2 iter 105850: loss = 0.6469,  smooth loss = 0.5886
[2022-07-05 14:46:19,755 callbacks.py:105 INFO train-abinet] epoch 2 iter 105900: loss = 0.7372,  smooth loss = 0.5885
[2022-07-05 14:47:02,526 callbacks.py:105 INFO train-abinet] epoch 2 iter 105950: loss = 0.4454,  smooth loss = 0.5825
[2022-07-05 14:47:45,530 callbacks.py:105 INFO train-abinet] epoch 2 iter 106000: loss = 0.7245,  smooth loss = 0.5828
[2022-07-05 14:48:28,685 callbacks.py:105 INFO train-abinet] epoch 2 iter 106050: loss = 0.6061,  smooth loss = 0.5816
[2022-07-05 14:49:12,098 callbacks.py:105 INFO train-abinet] epoch 2 iter 106100: loss = 0.5798,  smooth loss = 0.5846
[2022-07-05 14:49:55,350 callbacks.py:105 INFO train-abinet] epoch 2 iter 106150: loss = 0.7994,  smooth loss = 0.5827
[2022-07-05 14:50:37,564 callbacks.py:105 INFO train-abinet] epoch 2 iter 106200: loss = 0.4928,  smooth loss = 0.5834
[2022-07-05 14:51:20,500 callbacks.py:105 INFO train-abinet] epoch 2 iter 106250: loss = 0.7266,  smooth loss = 0.5823
[2022-07-05 14:52:04,291 callbacks.py:105 INFO train-abinet] epoch 2 iter 106300: loss = 0.5876,  smooth loss = 0.6026
[2022-07-05 14:52:46,179 callbacks.py:105 INFO train-abinet] epoch 2 iter 106350: loss = 0.8407,  smooth loss = 0.6033
[2022-07-05 14:53:27,992 callbacks.py:105 INFO train-abinet] epoch 2 iter 106400: loss = 0.5457,  smooth loss = 0.6103
[2022-07-05 14:54:07,976 callbacks.py:105 INFO train-abinet] epoch 2 iter 106450: loss = 0.5593,  smooth loss = 0.5895
[2022-07-05 14:54:48,414 callbacks.py:105 INFO train-abinet] epoch 2 iter 106500: loss = 0.6151,  smooth loss = 0.5950
[2022-07-05 14:55:28,936 callbacks.py:105 INFO train-abinet] epoch 2 iter 106550: loss = 0.5859,  smooth loss = 0.5956
[2022-07-05 14:56:09,492 callbacks.py:105 INFO train-abinet] epoch 2 iter 106600: loss = 0.5063,  smooth loss = 0.5875
[2022-07-05 14:56:50,937 callbacks.py:105 INFO train-abinet] epoch 2 iter 106650: loss = 0.5059,  smooth loss = 0.5786
[2022-07-05 14:57:31,950 callbacks.py:105 INFO train-abinet] epoch 2 iter 106700: loss = 0.6247,  smooth loss = 0.5908
[2022-07-05 14:58:12,643 callbacks.py:105 INFO train-abinet] epoch 2 iter 106750: loss = 0.6689,  smooth loss = 0.5854
[2022-07-05 14:58:53,257 callbacks.py:105 INFO train-abinet] epoch 2 iter 106800: loss = 0.6380,  smooth loss = 0.5977
[2022-07-05 14:59:33,555 callbacks.py:105 INFO train-abinet] epoch 2 iter 106850: loss = 0.5733,  smooth loss = 0.5842
[2022-07-05 15:00:14,908 callbacks.py:105 INFO train-abinet] epoch 2 iter 106900: loss = 0.6645,  smooth loss = 0.5780
[2022-07-05 15:00:56,306 callbacks.py:105 INFO train-abinet] epoch 2 iter 106950: loss = 0.6128,  smooth loss = 0.5985
[2022-07-05 15:01:36,813 callbacks.py:105 INFO train-abinet] epoch 2 iter 107000: loss = 0.7097,  smooth loss = 0.5844
[2022-07-05 15:02:17,694 callbacks.py:105 INFO train-abinet] epoch 2 iter 107050: loss = 0.8375,  smooth loss = 0.5992
[2022-07-05 15:02:58,678 callbacks.py:105 INFO train-abinet] epoch 2 iter 107100: loss = 0.5571,  smooth loss = 0.5929
[2022-07-05 15:03:39,609 callbacks.py:105 INFO train-abinet] epoch 2 iter 107150: loss = 0.5640,  smooth loss = 0.5832
[2022-07-05 15:04:20,654 callbacks.py:105 INFO train-abinet] epoch 2 iter 107200: loss = 0.5449,  smooth loss = 0.5799
[2022-07-05 15:05:01,776 callbacks.py:105 INFO train-abinet] epoch 2 iter 107250: loss = 0.7086,  smooth loss = 0.5865
[2022-07-05 15:05:42,801 callbacks.py:105 INFO train-abinet] epoch 2 iter 107300: loss = 0.6438,  smooth loss = 0.5862
[2022-07-05 15:06:23,531 callbacks.py:105 INFO train-abinet] epoch 2 iter 107350: loss = 0.6850,  smooth loss = 0.5890
[2022-07-05 15:07:04,503 callbacks.py:105 INFO train-abinet] epoch 2 iter 107400: loss = 0.5436,  smooth loss = 0.5839
[2022-07-05 15:07:46,150 callbacks.py:105 INFO train-abinet] epoch 2 iter 107450: loss = 0.6019,  smooth loss = 0.5746
[2022-07-05 15:08:26,925 callbacks.py:105 INFO train-abinet] epoch 2 iter 107500: loss = 0.5727,  smooth loss = 0.5867
[2022-07-05 15:09:07,313 callbacks.py:105 INFO train-abinet] epoch 2 iter 107550: loss = 0.4258,  smooth loss = 0.5959
[2022-07-05 15:09:48,224 callbacks.py:105 INFO train-abinet] epoch 2 iter 107600: loss = 0.5216,  smooth loss = 0.5945
[2022-07-05 15:10:28,570 callbacks.py:105 INFO train-abinet] epoch 2 iter 107650: loss = 0.4701,  smooth loss = 0.5859
[2022-07-05 15:11:09,785 callbacks.py:105 INFO train-abinet] epoch 2 iter 107700: loss = 0.5178,  smooth loss = 0.5882
[2022-07-05 15:11:51,126 callbacks.py:105 INFO train-abinet] epoch 2 iter 107750: loss = 0.5404,  smooth loss = 0.5834
[2022-07-05 15:12:32,256 callbacks.py:105 INFO train-abinet] epoch 2 iter 107800: loss = 0.5784,  smooth loss = 0.5861
[2022-07-05 15:13:13,198 callbacks.py:105 INFO train-abinet] epoch 2 iter 107850: loss = 0.5242,  smooth loss = 0.5984
[2022-07-05 15:13:54,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 107900: loss = 0.6696,  smooth loss = 0.5990
[2022-07-05 15:14:35,117 callbacks.py:105 INFO train-abinet] epoch 2 iter 107950: loss = 0.5149,  smooth loss = 0.5944
[2022-07-05 15:15:15,504 callbacks.py:105 INFO train-abinet] epoch 2 iter 108000: loss = 0.5085,  smooth loss = 0.5840
[2022-07-05 15:15:15,504 callbacks.py:114 INFO train-abinet] average data time = 0.0061s, average running time = 0.8963s
█[2022-07-05 15:15:30,203 callbacks.py:123 INFO train-abinet] epoch 2 iter 108000: eval loss = 1.1603,  ccr = 0.9560,  cwr = 0.9143,  ted = 1420.0000,  ned = 275.7538,  ted/w = 0.1959, 
[2022-07-05 15:15:30,204 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_108000
[2022-07-05 15:16:13,030 callbacks.py:105 INFO train-abinet] epoch 2 iter 108050: loss = 0.6476,  smooth loss = 0.6019
[2022-07-05 15:16:55,086 callbacks.py:105 INFO train-abinet] epoch 2 iter 108100: loss = 0.6270,  smooth loss = 0.5936
[2022-07-05 15:17:36,364 callbacks.py:105 INFO train-abinet] epoch 2 iter 108150: loss = 0.5193,  smooth loss = 0.5866
[2022-07-05 15:18:17,530 callbacks.py:105 INFO train-abinet] epoch 2 iter 108200: loss = 0.5380,  smooth loss = 0.5692
[2022-07-05 15:18:58,698 callbacks.py:105 INFO train-abinet] epoch 2 iter 108250: loss = 0.4161,  smooth loss = 0.5811
[2022-07-05 15:19:39,545 callbacks.py:105 INFO train-abinet] epoch 2 iter 108300: loss = 0.6543,  smooth loss = 0.5743
[2022-07-05 15:20:20,512 callbacks.py:105 INFO train-abinet] epoch 2 iter 108350: loss = 0.5926,  smooth loss = 0.5821
[2022-07-05 15:21:01,484 callbacks.py:105 INFO train-abinet] epoch 2 iter 108400: loss = 0.4721,  smooth loss = 0.5830
[2022-07-05 15:21:42,013 callbacks.py:105 INFO train-abinet] epoch 2 iter 108450: loss = 0.5022,  smooth loss = 0.5845
[2022-07-05 15:22:23,341 callbacks.py:105 INFO train-abinet] epoch 2 iter 108500: loss = 0.4913,  smooth loss = 0.5857
[2022-07-05 15:23:03,628 callbacks.py:105 INFO train-abinet] epoch 2 iter 108550: loss = 0.6149,  smooth loss = 0.5901
[2022-07-05 15:23:45,161 callbacks.py:105 INFO train-abinet] epoch 2 iter 108600: loss = 0.4977,  smooth loss = 0.5796
[2022-07-05 15:24:25,703 callbacks.py:105 INFO train-abinet] epoch 2 iter 108650: loss = 0.4814,  smooth loss = 0.5762
[2022-07-05 15:25:06,049 callbacks.py:105 INFO train-abinet] epoch 2 iter 108700: loss = 0.5392,  smooth loss = 0.5941
[2022-07-05 15:25:46,814 callbacks.py:105 INFO train-abinet] epoch 2 iter 108750: loss = 0.6295,  smooth loss = 0.5879
[2022-07-05 15:26:27,634 callbacks.py:105 INFO train-abinet] epoch 2 iter 108800: loss = 0.5131,  smooth loss = 0.5825
[2022-07-05 15:27:09,074 callbacks.py:105 INFO train-abinet] epoch 2 iter 108850: loss = 0.6883,  smooth loss = 0.5891
[2022-07-05 15:27:49,645 callbacks.py:105 INFO train-abinet] epoch 2 iter 108900: loss = 0.6205,  smooth loss = 0.5854
[2022-07-05 15:28:30,130 callbacks.py:105 INFO train-abinet] epoch 2 iter 108950: loss = 0.6980,  smooth loss = 0.5813
[2022-07-05 15:29:11,259 callbacks.py:105 INFO train-abinet] epoch 2 iter 109000: loss = 0.6133,  smooth loss = 0.5700
[2022-07-05 15:29:51,543 callbacks.py:105 INFO train-abinet] epoch 2 iter 109050: loss = 0.6498,  smooth loss = 0.5744
[2022-07-05 15:30:32,536 callbacks.py:105 INFO train-abinet] epoch 2 iter 109100: loss = 0.5229,  smooth loss = 0.5847
[2022-07-05 15:31:13,181 callbacks.py:105 INFO train-abinet] epoch 2 iter 109150: loss = 0.5189,  smooth loss = 0.5850
[2022-07-05 15:31:54,013 callbacks.py:105 INFO train-abinet] epoch 2 iter 109200: loss = 0.6971,  smooth loss = 0.5833
[2022-07-05 15:32:34,886 callbacks.py:105 INFO train-abinet] epoch 2 iter 109250: loss = 0.6603,  smooth loss = 0.5851
[2022-07-05 15:33:14,861 callbacks.py:105 INFO train-abinet] epoch 2 iter 109300: loss = 0.4716,  smooth loss = 0.5769
[2022-07-05 15:33:55,396 callbacks.py:105 INFO train-abinet] epoch 2 iter 109350: loss = 0.6457,  smooth loss = 0.5899
[2022-07-05 15:34:36,295 callbacks.py:105 INFO train-abinet] epoch 2 iter 109400: loss = 0.6420,  smooth loss = 0.5864
[2022-07-05 15:35:17,373 callbacks.py:105 INFO train-abinet] epoch 2 iter 109450: loss = 0.5663,  smooth loss = 0.5871
[2022-07-05 15:35:58,147 callbacks.py:105 INFO train-abinet] epoch 2 iter 109500: loss = 0.5947,  smooth loss = 0.5941
[2022-07-05 15:36:39,030 callbacks.py:105 INFO train-abinet] epoch 2 iter 109550: loss = 0.5071,  smooth loss = 0.6028
[2022-07-05 15:37:19,683 callbacks.py:105 INFO train-abinet] epoch 2 iter 109600: loss = 0.6306,  smooth loss = 0.5935
[2022-07-05 15:38:00,071 callbacks.py:105 INFO train-abinet] epoch 2 iter 109650: loss = 0.4896,  smooth loss = 0.5907
[2022-07-05 15:38:40,618 callbacks.py:105 INFO train-abinet] epoch 2 iter 109700: loss = 0.7178,  smooth loss = 0.5812
[2022-07-05 15:39:22,025 callbacks.py:105 INFO train-abinet] epoch 2 iter 109750: loss = 0.6060,  smooth loss = 0.5742
[2022-07-05 15:40:02,218 callbacks.py:105 INFO train-abinet] epoch 2 iter 109800: loss = 0.4995,  smooth loss = 0.5714
[2022-07-05 15:40:42,713 callbacks.py:105 INFO train-abinet] epoch 2 iter 109850: loss = 0.5132,  smooth loss = 0.5786
[2022-07-05 15:41:23,092 callbacks.py:105 INFO train-abinet] epoch 2 iter 109900: loss = 0.4477,  smooth loss = 0.5902
[2022-07-05 15:42:03,931 callbacks.py:105 INFO train-abinet] epoch 2 iter 109950: loss = 0.4621,  smooth loss = 0.5731
[2022-07-05 15:42:44,786 callbacks.py:105 INFO train-abinet] epoch 2 iter 110000: loss = 0.4918,  smooth loss = 0.5738
[2022-07-05 15:43:25,058 callbacks.py:105 INFO train-abinet] epoch 2 iter 110050: loss = 0.5101,  smooth loss = 0.5655
[2022-07-05 15:44:05,952 callbacks.py:105 INFO train-abinet] epoch 2 iter 110100: loss = 0.5784,  smooth loss = 0.5715
[2022-07-05 15:44:46,224 callbacks.py:105 INFO train-abinet] epoch 2 iter 110150: loss = 0.7441,  smooth loss = 0.5932
[2022-07-05 15:45:26,795 callbacks.py:105 INFO train-abinet] epoch 2 iter 110200: loss = 0.5830,  smooth loss = 0.5852
[2022-07-05 15:46:06,800 callbacks.py:105 INFO train-abinet] epoch 2 iter 110250: loss = 0.4575,  smooth loss = 0.5811
[2022-07-05 15:46:47,598 callbacks.py:105 INFO train-abinet] epoch 2 iter 110300: loss = 0.7543,  smooth loss = 0.5838
[2022-07-05 15:47:28,252 callbacks.py:105 INFO train-abinet] epoch 2 iter 110350: loss = 0.6155,  smooth loss = 0.5771
[2022-07-05 15:48:08,804 callbacks.py:105 INFO train-abinet] epoch 2 iter 110400: loss = 0.5720,  smooth loss = 0.5766
[2022-07-05 15:48:49,719 callbacks.py:105 INFO train-abinet] epoch 2 iter 110450: loss = 0.5533,  smooth loss = 0.5764
[2022-07-05 15:49:30,597 callbacks.py:105 INFO train-abinet] epoch 2 iter 110500: loss = 0.6939,  smooth loss = 0.5849
[2022-07-05 15:50:10,843 callbacks.py:105 INFO train-abinet] epoch 2 iter 110550: loss = 0.6609,  smooth loss = 0.5885
[2022-07-05 15:50:51,283 callbacks.py:105 INFO train-abinet] epoch 2 iter 110600: loss = 0.4935,  smooth loss = 0.5788
[2022-07-05 15:51:32,018 callbacks.py:105 INFO train-abinet] epoch 2 iter 110650: loss = 0.6026,  smooth loss = 0.5872
[2022-07-05 15:52:12,856 callbacks.py:105 INFO train-abinet] epoch 2 iter 110700: loss = 0.5010,  smooth loss = 0.5843
[2022-07-05 15:52:53,190 callbacks.py:105 INFO train-abinet] epoch 2 iter 110750: loss = 0.5930,  smooth loss = 0.5872
[2022-07-05 15:53:34,180 callbacks.py:105 INFO train-abinet] epoch 2 iter 110800: loss = 0.7249,  smooth loss = 0.5984
[2022-07-05 15:54:14,854 callbacks.py:105 INFO train-abinet] epoch 2 iter 110850: loss = 0.4697,  smooth loss = 0.5800
[2022-07-05 15:54:55,092 callbacks.py:105 INFO train-abinet] epoch 2 iter 110900: loss = 0.6313,  smooth loss = 0.5767
[2022-07-05 15:55:35,725 callbacks.py:105 INFO train-abinet] epoch 2 iter 110950: loss = 0.5342,  smooth loss = 0.5800
[2022-07-05 15:56:15,933 callbacks.py:105 INFO train-abinet] epoch 2 iter 111000: loss = 0.7823,  smooth loss = 0.5916
[2022-07-05 15:56:15,933 callbacks.py:114 INFO train-abinet] average data time = 0.0060s, average running time = 0.8942s
█[2022-07-05 15:56:29,983 callbacks.py:123 INFO train-abinet] epoch 2 iter 111000: eval loss = 1.2108,  ccr = 0.9555,  cwr = 0.9138,  ted = 1427.0000,  ned = 275.0559,  ted/w = 0.1969, 
[2022-07-05 15:56:29,984 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_111000
[2022-07-05 15:57:11,922 callbacks.py:105 INFO train-abinet] epoch 2 iter 111050: loss = 0.5931,  smooth loss = 0.5789
[2022-07-05 15:57:53,162 callbacks.py:105 INFO train-abinet] epoch 2 iter 111100: loss = 0.5224,  smooth loss = 0.5813
[2022-07-05 15:58:33,558 callbacks.py:105 INFO train-abinet] epoch 2 iter 111150: loss = 0.4937,  smooth loss = 0.5812
[2022-07-05 15:59:14,094 callbacks.py:105 INFO train-abinet] epoch 2 iter 111200: loss = 0.6633,  smooth loss = 0.5859
[2022-07-05 15:59:55,614 callbacks.py:105 INFO train-abinet] epoch 2 iter 111250: loss = 0.6480,  smooth loss = 0.5971
[2022-07-05 16:00:36,327 callbacks.py:105 INFO train-abinet] epoch 2 iter 111300: loss = 0.4689,  smooth loss = 0.5847
[2022-07-05 16:01:16,918 callbacks.py:105 INFO train-abinet] epoch 2 iter 111350: loss = 0.5212,  smooth loss = 0.5926
[2022-07-05 16:01:57,897 callbacks.py:105 INFO train-abinet] epoch 2 iter 111400: loss = 0.6757,  smooth loss = 0.5883
[2022-07-05 16:02:38,753 callbacks.py:105 INFO train-abinet] epoch 2 iter 111450: loss = 0.5284,  smooth loss = 0.5898
[2022-07-05 16:03:19,313 callbacks.py:105 INFO train-abinet] epoch 2 iter 111500: loss = 0.5348,  smooth loss = 0.5874
[2022-07-05 16:04:00,257 callbacks.py:105 INFO train-abinet] epoch 2 iter 111550: loss = 0.5887,  smooth loss = 0.5841
[2022-07-05 16:04:41,869 callbacks.py:105 INFO train-abinet] epoch 2 iter 111600: loss = 0.6279,  smooth loss = 0.5776
[2022-07-05 16:05:23,090 callbacks.py:105 INFO train-abinet] epoch 2 iter 111650: loss = 0.4620,  smooth loss = 0.5852
[2022-07-05 16:06:03,756 callbacks.py:105 INFO train-abinet] epoch 2 iter 111700: loss = 0.5690,  smooth loss = 0.5826
[2022-07-05 16:06:44,277 callbacks.py:105 INFO train-abinet] epoch 2 iter 111750: loss = 0.7653,  smooth loss = 0.5754
[2022-07-05 16:07:25,351 callbacks.py:105 INFO train-abinet] epoch 2 iter 111800: loss = 0.5937,  smooth loss = 0.5839
[2022-07-05 16:08:07,009 callbacks.py:105 INFO train-abinet] epoch 2 iter 111850: loss = 0.5425,  smooth loss = 0.5826
[2022-07-05 16:08:47,528 callbacks.py:105 INFO train-abinet] epoch 2 iter 111900: loss = 0.6188,  smooth loss = 0.5813
[2022-07-05 16:09:27,554 callbacks.py:105 INFO train-abinet] epoch 2 iter 111950: loss = 0.5776,  smooth loss = 0.5972
[2022-07-05 16:10:07,904 callbacks.py:105 INFO train-abinet] epoch 2 iter 112000: loss = 0.6550,  smooth loss = 0.5819
[2022-07-05 16:10:48,930 callbacks.py:105 INFO train-abinet] epoch 2 iter 112050: loss = 0.5926,  smooth loss = 0.5860
[2022-07-05 16:11:29,732 callbacks.py:105 INFO train-abinet] epoch 2 iter 112100: loss = 0.5707,  smooth loss = 0.5936
[2022-07-05 16:12:10,460 callbacks.py:105 INFO train-abinet] epoch 2 iter 112150: loss = 0.5259,  smooth loss = 0.5820
[2022-07-05 16:12:51,156 callbacks.py:105 INFO train-abinet] epoch 2 iter 112200: loss = 0.4090,  smooth loss = 0.5829
[2022-07-05 16:13:32,036 callbacks.py:105 INFO train-abinet] epoch 2 iter 112250: loss = 0.4764,  smooth loss = 0.5763
[2022-07-05 16:14:12,267 callbacks.py:105 INFO train-abinet] epoch 2 iter 112300: loss = 0.5251,  smooth loss = 0.5733
[2022-07-05 16:14:53,187 callbacks.py:105 INFO train-abinet] epoch 2 iter 112350: loss = 0.7909,  smooth loss = 0.5871
[2022-07-05 16:15:33,720 callbacks.py:105 INFO train-abinet] epoch 2 iter 112400: loss = 0.5337,  smooth loss = 0.5953
[2022-07-05 16:16:14,201 callbacks.py:105 INFO train-abinet] epoch 2 iter 112450: loss = 0.6760,  smooth loss = 0.5918
[2022-07-05 16:16:55,260 callbacks.py:105 INFO train-abinet] epoch 2 iter 112500: loss = 0.4874,  smooth loss = 0.5884
[2022-07-05 16:17:35,755 callbacks.py:105 INFO train-abinet] epoch 2 iter 112550: loss = 0.5637,  smooth loss = 0.5868
[2022-07-05 16:18:16,311 callbacks.py:105 INFO train-abinet] epoch 2 iter 112600: loss = 0.4881,  smooth loss = 0.5656
[2022-07-05 16:18:57,844 callbacks.py:105 INFO train-abinet] epoch 2 iter 112650: loss = 0.6089,  smooth loss = 0.5746
[2022-07-05 16:19:38,093 callbacks.py:105 INFO train-abinet] epoch 2 iter 112700: loss = 0.6882,  smooth loss = 0.5811
[2022-07-05 16:20:18,968 callbacks.py:105 INFO train-abinet] epoch 2 iter 112750: loss = 0.8524,  smooth loss = 0.5740
[2022-07-05 16:21:00,117 callbacks.py:105 INFO train-abinet] epoch 2 iter 112800: loss = 0.6229,  smooth loss = 0.5827
[2022-07-05 16:21:40,762 callbacks.py:105 INFO train-abinet] epoch 2 iter 112850: loss = 0.6154,  smooth loss = 0.5877
[2022-07-05 16:22:21,915 callbacks.py:105 INFO train-abinet] epoch 2 iter 112900: loss = 0.6550,  smooth loss = 0.5925
[2022-07-05 16:23:03,016 callbacks.py:105 INFO train-abinet] epoch 2 iter 112950: loss = 0.5961,  smooth loss = 0.5835
[2022-07-05 16:23:44,337 callbacks.py:105 INFO train-abinet] epoch 2 iter 113000: loss = 0.6307,  smooth loss = 0.5928
[2022-07-05 16:24:24,857 callbacks.py:105 INFO train-abinet] epoch 2 iter 113050: loss = 0.4948,  smooth loss = 0.6052
[2022-07-05 16:25:05,590 callbacks.py:105 INFO train-abinet] epoch 2 iter 113100: loss = 0.6382,  smooth loss = 0.5931
[2022-07-05 16:25:46,620 callbacks.py:105 INFO train-abinet] epoch 2 iter 113150: loss = 0.7058,  smooth loss = 0.5774
[2022-07-05 16:26:27,851 callbacks.py:105 INFO train-abinet] epoch 2 iter 113200: loss = 0.5401,  smooth loss = 0.5833
[2022-07-05 16:27:08,452 callbacks.py:105 INFO train-abinet] epoch 2 iter 113250: loss = 0.5415,  smooth loss = 0.5857
[2022-07-05 16:27:49,306 callbacks.py:105 INFO train-abinet] epoch 2 iter 113300: loss = 0.6288,  smooth loss = 0.5937
[2022-07-05 16:28:30,677 callbacks.py:105 INFO train-abinet] epoch 2 iter 113350: loss = 0.6254,  smooth loss = 0.5765
[2022-07-05 16:29:11,620 callbacks.py:105 INFO train-abinet] epoch 2 iter 113400: loss = 0.5748,  smooth loss = 0.5633
[2022-07-05 16:29:52,289 callbacks.py:105 INFO train-abinet] epoch 2 iter 113450: loss = 0.6406,  smooth loss = 0.5820
[2022-07-05 16:30:33,692 callbacks.py:105 INFO train-abinet] epoch 2 iter 113500: loss = 0.7390,  smooth loss = 0.5928
[2022-07-05 16:31:14,513 callbacks.py:105 INFO train-abinet] epoch 2 iter 113550: loss = 0.5828,  smooth loss = 0.5781
[2022-07-05 16:31:55,690 callbacks.py:105 INFO train-abinet] epoch 2 iter 113600: loss = 0.5454,  smooth loss = 0.5815
[2022-07-05 16:32:37,062 callbacks.py:105 INFO train-abinet] epoch 2 iter 113650: loss = 0.5986,  smooth loss = 0.5784
[2022-07-05 16:33:18,090 callbacks.py:105 INFO train-abinet] epoch 2 iter 113700: loss = 0.8050,  smooth loss = 0.5802
[2022-07-05 16:33:59,405 callbacks.py:105 INFO train-abinet] epoch 2 iter 113750: loss = 0.5660,  smooth loss = 0.5962
[2022-07-05 16:34:40,143 callbacks.py:105 INFO train-abinet] epoch 2 iter 113800: loss = 0.6358,  smooth loss = 0.6029
[2022-07-05 16:35:20,186 callbacks.py:105 INFO train-abinet] epoch 2 iter 113850: loss = 0.5150,  smooth loss = 0.6012
[2022-07-05 16:36:00,743 callbacks.py:105 INFO train-abinet] epoch 2 iter 113900: loss = 0.5564,  smooth loss = 0.6030
[2022-07-05 16:36:41,221 callbacks.py:105 INFO train-abinet] epoch 2 iter 113950: loss = 0.6728,  smooth loss = 0.5997
[2022-07-05 16:37:21,792 callbacks.py:105 INFO train-abinet] epoch 2 iter 114000: loss = 0.4021,  smooth loss = 0.5966
[2022-07-05 16:37:21,793 callbacks.py:114 INFO train-abinet] average data time = 0.0059s, average running time = 0.8922s
█[2022-07-05 16:37:36,222 callbacks.py:123 INFO train-abinet] epoch 2 iter 114000: eval loss = 1.1986,  ccr = 0.9574,  cwr = 0.9157,  ted = 1403.0000,  ned = 276.7602,  ted/w = 0.1936, 
[2022-07-05 16:37:36,222 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_114000
[2022-07-05 16:38:17,670 callbacks.py:105 INFO train-abinet] epoch 2 iter 114050: loss = 0.6296,  smooth loss = 0.5784
[2022-07-05 16:38:58,610 callbacks.py:105 INFO train-abinet] epoch 2 iter 114100: loss = 0.4296,  smooth loss = 0.5741
[2022-07-05 16:39:38,672 callbacks.py:105 INFO train-abinet] epoch 2 iter 114150: loss = 0.6679,  smooth loss = 0.5879
[2022-07-05 16:40:19,345 callbacks.py:105 INFO train-abinet] epoch 2 iter 114200: loss = 0.6653,  smooth loss = 0.5939
[2022-07-05 16:40:59,976 callbacks.py:105 INFO train-abinet] epoch 2 iter 114250: loss = 0.5313,  smooth loss = 0.6043
[2022-07-05 16:41:41,085 callbacks.py:105 INFO train-abinet] epoch 2 iter 114300: loss = 0.6547,  smooth loss = 0.5989
[2022-07-05 16:42:21,640 callbacks.py:105 INFO train-abinet] epoch 2 iter 114350: loss = 0.5650,  smooth loss = 0.5815
[2022-07-05 16:43:01,991 callbacks.py:105 INFO train-abinet] epoch 2 iter 114400: loss = 0.4846,  smooth loss = 0.5797
[2022-07-05 16:43:43,082 callbacks.py:105 INFO train-abinet] epoch 2 iter 114450: loss = 0.7539,  smooth loss = 0.5811
[2022-07-05 16:44:23,999 callbacks.py:105 INFO train-abinet] epoch 2 iter 114500: loss = 0.6285,  smooth loss = 0.5854
[2022-07-05 16:45:04,937 callbacks.py:105 INFO train-abinet] epoch 2 iter 114550: loss = 0.6077,  smooth loss = 0.5899
[2022-07-05 16:45:46,144 callbacks.py:105 INFO train-abinet] epoch 2 iter 114600: loss = 0.6620,  smooth loss = 0.5919
[2022-07-05 16:46:26,555 callbacks.py:105 INFO train-abinet] epoch 2 iter 114650: loss = 0.4656,  smooth loss = 0.5841
[2022-07-05 16:47:07,359 callbacks.py:105 INFO train-abinet] epoch 2 iter 114700: loss = 0.5768,  smooth loss = 0.5713
[2022-07-05 16:47:48,562 callbacks.py:105 INFO train-abinet] epoch 2 iter 114750: loss = 0.5363,  smooth loss = 0.5761
[2022-07-05 16:48:29,135 callbacks.py:105 INFO train-abinet] epoch 2 iter 114800: loss = 0.6976,  smooth loss = 0.5731
[2022-07-05 16:49:10,118 callbacks.py:105 INFO train-abinet] epoch 2 iter 114850: loss = 0.5945,  smooth loss = 0.5758
[2022-07-05 16:49:50,599 callbacks.py:105 INFO train-abinet] epoch 2 iter 114900: loss = 0.5344,  smooth loss = 0.5895
[2022-07-05 16:50:31,455 callbacks.py:105 INFO train-abinet] epoch 2 iter 114950: loss = 0.5139,  smooth loss = 0.5836
[2022-07-05 16:51:11,852 callbacks.py:105 INFO train-abinet] epoch 2 iter 115000: loss = 0.5248,  smooth loss = 0.5830
[2022-07-05 16:51:52,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 115050: loss = 0.5493,  smooth loss = 0.6107
[2022-07-05 16:52:33,105 callbacks.py:105 INFO train-abinet] epoch 2 iter 115100: loss = 0.6298,  smooth loss = 0.5980
[2022-07-05 16:53:13,966 callbacks.py:105 INFO train-abinet] epoch 2 iter 115150: loss = 0.5923,  smooth loss = 0.5873
[2022-07-05 16:53:54,588 callbacks.py:105 INFO train-abinet] epoch 2 iter 115200: loss = 0.4747,  smooth loss = 0.5770
[2022-07-05 16:54:36,120 callbacks.py:105 INFO train-abinet] epoch 2 iter 115250: loss = 0.4822,  smooth loss = 0.5747
[2022-07-05 16:55:17,083 callbacks.py:105 INFO train-abinet] epoch 2 iter 115300: loss = 0.5724,  smooth loss = 0.5739
[2022-07-05 16:55:58,276 callbacks.py:105 INFO train-abinet] epoch 2 iter 115350: loss = 0.5019,  smooth loss = 0.5808
[2022-07-05 16:56:38,793 callbacks.py:105 INFO train-abinet] epoch 2 iter 115400: loss = 0.6067,  smooth loss = 0.5905
[2022-07-05 16:57:19,983 callbacks.py:105 INFO train-abinet] epoch 2 iter 115450: loss = 0.4650,  smooth loss = 0.5852
[2022-07-05 16:58:00,387 callbacks.py:105 INFO train-abinet] epoch 2 iter 115500: loss = 0.5816,  smooth loss = 0.5985
[2022-07-05 16:58:42,023 callbacks.py:105 INFO train-abinet] epoch 2 iter 115550: loss = 0.5300,  smooth loss = 0.5976
[2022-07-05 16:59:22,731 callbacks.py:105 INFO train-abinet] epoch 2 iter 115600: loss = 0.5760,  smooth loss = 0.6024
[2022-07-05 17:00:04,114 callbacks.py:105 INFO train-abinet] epoch 2 iter 115650: loss = 0.6332,  smooth loss = 0.5956
[2022-07-05 17:00:45,505 callbacks.py:105 INFO train-abinet] epoch 2 iter 115700: loss = 0.4283,  smooth loss = 0.5875
[2022-07-05 17:01:26,953 callbacks.py:105 INFO train-abinet] epoch 2 iter 115750: loss = 0.7244,  smooth loss = 0.5883
[2022-07-05 17:02:08,001 callbacks.py:105 INFO train-abinet] epoch 2 iter 115800: loss = 0.6441,  smooth loss = 0.5847
[2022-07-05 17:02:48,624 callbacks.py:105 INFO train-abinet] epoch 2 iter 115850: loss = 0.5044,  smooth loss = 0.5813
[2022-07-05 17:03:29,419 callbacks.py:105 INFO train-abinet] epoch 2 iter 115900: loss = 0.6465,  smooth loss = 0.5855
[2022-07-05 17:04:10,449 callbacks.py:105 INFO train-abinet] epoch 2 iter 115950: loss = 0.5109,  smooth loss = 0.5914
[2022-07-05 17:04:50,336 callbacks.py:105 INFO train-abinet] epoch 2 iter 116000: loss = 0.4392,  smooth loss = 0.5764
[2022-07-05 17:05:31,009 callbacks.py:105 INFO train-abinet] epoch 2 iter 116050: loss = 0.4905,  smooth loss = 0.5930
[2022-07-05 17:06:11,774 callbacks.py:105 INFO train-abinet] epoch 2 iter 116100: loss = 0.5537,  smooth loss = 0.5823
[2022-07-05 17:06:52,557 callbacks.py:105 INFO train-abinet] epoch 2 iter 116150: loss = 0.4301,  smooth loss = 0.5807
[2022-07-05 17:07:33,898 callbacks.py:105 INFO train-abinet] epoch 2 iter 116200: loss = 0.5891,  smooth loss = 0.5829
[2022-07-05 17:08:14,608 callbacks.py:105 INFO train-abinet] epoch 2 iter 116250: loss = 0.6556,  smooth loss = 0.5762
[2022-07-05 17:08:55,710 callbacks.py:105 INFO train-abinet] epoch 2 iter 116300: loss = 0.5032,  smooth loss = 0.5762
[2022-07-05 17:09:36,739 callbacks.py:105 INFO train-abinet] epoch 2 iter 116350: loss = 0.5080,  smooth loss = 0.5846
[2022-07-05 17:10:18,198 callbacks.py:105 INFO train-abinet] epoch 2 iter 116400: loss = 0.4152,  smooth loss = 0.5894
[2022-07-05 17:10:59,240 callbacks.py:105 INFO train-abinet] epoch 2 iter 116450: loss = 0.4552,  smooth loss = 0.5748
[2022-07-05 17:11:40,072 callbacks.py:105 INFO train-abinet] epoch 2 iter 116500: loss = 0.6297,  smooth loss = 0.5934
[2022-07-05 17:12:21,667 callbacks.py:105 INFO train-abinet] epoch 2 iter 116550: loss = 0.6452,  smooth loss = 0.5836
[2022-07-05 17:13:02,327 callbacks.py:105 INFO train-abinet] epoch 2 iter 116600: loss = 0.5452,  smooth loss = 0.5783
[2022-07-05 17:13:43,981 callbacks.py:105 INFO train-abinet] epoch 2 iter 116650: loss = 0.6449,  smooth loss = 0.5857
[2022-07-05 17:14:24,900 callbacks.py:105 INFO train-abinet] epoch 2 iter 116700: loss = 0.5585,  smooth loss = 0.5946
[2022-07-05 17:15:06,174 callbacks.py:105 INFO train-abinet] epoch 2 iter 116750: loss = 0.5863,  smooth loss = 0.5785
[2022-07-05 17:15:47,509 callbacks.py:105 INFO train-abinet] epoch 2 iter 116800: loss = 0.6253,  smooth loss = 0.5739
[2022-07-05 17:16:28,682 callbacks.py:105 INFO train-abinet] epoch 2 iter 116850: loss = 0.5045,  smooth loss = 0.5877
[2022-07-05 17:17:09,233 callbacks.py:105 INFO train-abinet] epoch 2 iter 116900: loss = 0.6456,  smooth loss = 0.5782
[2022-07-05 17:17:50,294 callbacks.py:105 INFO train-abinet] epoch 2 iter 116950: loss = 0.4656,  smooth loss = 0.5825
[2022-07-05 17:18:31,192 callbacks.py:105 INFO train-abinet] epoch 2 iter 117000: loss = 0.5545,  smooth loss = 0.5942
[2022-07-05 17:18:31,193 callbacks.py:114 INFO train-abinet] average data time = 0.0059s, average running time = 0.8903s
█[2022-07-05 17:18:46,012 callbacks.py:123 INFO train-abinet] epoch 2 iter 117000: eval loss = 1.2160,  ccr = 0.9532,  cwr = 0.9129,  ted = 1463.0000,  ned = 282.0335,  ted/w = 0.2018, 
[2022-07-05 17:18:46,013 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_117000
[2022-07-05 17:19:28,336 callbacks.py:105 INFO train-abinet] epoch 2 iter 117050: loss = 0.5927,  smooth loss = 0.5840
[2022-07-05 17:20:09,516 callbacks.py:105 INFO train-abinet] epoch 2 iter 117100: loss = 0.5731,  smooth loss = 0.5765
[2022-07-05 17:20:50,818 callbacks.py:105 INFO train-abinet] epoch 2 iter 117150: loss = 0.4621,  smooth loss = 0.5684
[2022-07-05 17:21:31,719 callbacks.py:105 INFO train-abinet] epoch 2 iter 117200: loss = 0.4695,  smooth loss = 0.5670
[2022-07-05 17:22:12,659 callbacks.py:105 INFO train-abinet] epoch 2 iter 117250: loss = 0.6351,  smooth loss = 0.5716
[2022-07-05 17:22:53,940 callbacks.py:105 INFO train-abinet] epoch 2 iter 117300: loss = 0.6445,  smooth loss = 0.5816
[2022-07-05 17:23:35,612 callbacks.py:105 INFO train-abinet] epoch 2 iter 117350: loss = 0.4683,  smooth loss = 0.5874
[2022-07-05 17:24:16,055 callbacks.py:105 INFO train-abinet] epoch 2 iter 117400: loss = 0.5374,  smooth loss = 0.5819
[2022-07-05 17:24:56,949 callbacks.py:105 INFO train-abinet] epoch 2 iter 117450: loss = 0.6607,  smooth loss = 0.5886
[2022-07-05 17:25:37,860 callbacks.py:105 INFO train-abinet] epoch 2 iter 117500: loss = 0.4783,  smooth loss = 0.5735
[2022-07-05 17:26:18,891 callbacks.py:105 INFO train-abinet] epoch 2 iter 117550: loss = 0.6485,  smooth loss = 0.5787
[2022-07-05 17:26:59,549 callbacks.py:105 INFO train-abinet] epoch 2 iter 117600: loss = 0.6912,  smooth loss = 0.5720
[2022-07-05 17:27:40,255 callbacks.py:105 INFO train-abinet] epoch 2 iter 117650: loss = 0.6137,  smooth loss = 0.5746
[2022-07-05 17:28:21,017 callbacks.py:105 INFO train-abinet] epoch 2 iter 117700: loss = 0.5617,  smooth loss = 0.5926
[2022-07-05 17:29:02,495 callbacks.py:105 INFO train-abinet] epoch 2 iter 117750: loss = 0.6743,  smooth loss = 0.5899
[2022-07-05 17:29:42,957 callbacks.py:105 INFO train-abinet] epoch 2 iter 117800: loss = 0.5183,  smooth loss = 0.5786
[2022-07-05 17:30:24,283 callbacks.py:105 INFO train-abinet] epoch 2 iter 117850: loss = 0.5491,  smooth loss = 0.5759
[2022-07-05 17:31:05,124 callbacks.py:105 INFO train-abinet] epoch 2 iter 117900: loss = 0.4611,  smooth loss = 0.5794
[2022-07-05 17:31:46,067 callbacks.py:105 INFO train-abinet] epoch 2 iter 117950: loss = 0.5394,  smooth loss = 0.5670
[2022-07-05 17:32:26,980 callbacks.py:105 INFO train-abinet] epoch 2 iter 118000: loss = 0.5200,  smooth loss = 0.5826
[2022-07-05 17:33:08,205 callbacks.py:105 INFO train-abinet] epoch 2 iter 118050: loss = 0.6199,  smooth loss = 0.5943
[2022-07-05 17:33:49,273 callbacks.py:105 INFO train-abinet] epoch 2 iter 118100: loss = 0.6020,  smooth loss = 0.5837
[2022-07-05 17:34:30,480 callbacks.py:105 INFO train-abinet] epoch 2 iter 118150: loss = 0.5147,  smooth loss = 0.5826
[2022-07-05 17:35:11,613 callbacks.py:105 INFO train-abinet] epoch 2 iter 118200: loss = 0.6286,  smooth loss = 0.5795
[2022-07-05 17:35:53,041 callbacks.py:105 INFO train-abinet] epoch 2 iter 118250: loss = 0.5162,  smooth loss = 0.5777
[2022-07-05 17:36:34,164 callbacks.py:105 INFO train-abinet] epoch 2 iter 118300: loss = 0.5433,  smooth loss = 0.5749
[2022-07-05 17:37:15,456 callbacks.py:105 INFO train-abinet] epoch 2 iter 118350: loss = 0.5262,  smooth loss = 0.5812
[2022-07-05 17:37:56,089 callbacks.py:105 INFO train-abinet] epoch 2 iter 118400: loss = 0.7248,  smooth loss = 0.5875
[2022-07-05 17:38:37,605 callbacks.py:105 INFO train-abinet] epoch 2 iter 118450: loss = 0.6231,  smooth loss = 0.5728
[2022-07-05 17:39:19,047 callbacks.py:105 INFO train-abinet] epoch 2 iter 118500: loss = 0.4486,  smooth loss = 0.5622
[2022-07-05 17:39:59,605 callbacks.py:105 INFO train-abinet] epoch 2 iter 118550: loss = 0.4860,  smooth loss = 0.5851
[2022-07-05 17:40:41,086 callbacks.py:105 INFO train-abinet] epoch 2 iter 118600: loss = 0.5506,  smooth loss = 0.5984
[2022-07-05 17:41:22,423 callbacks.py:105 INFO train-abinet] epoch 2 iter 118650: loss = 0.7338,  smooth loss = 0.5850
[2022-07-05 17:42:03,761 callbacks.py:105 INFO train-abinet] epoch 2 iter 118700: loss = 0.7311,  smooth loss = 0.5984
[2022-07-05 17:42:44,934 callbacks.py:105 INFO train-abinet] epoch 2 iter 118750: loss = 0.6821,  smooth loss = 0.5998
[2022-07-05 17:43:25,675 callbacks.py:105 INFO train-abinet] epoch 2 iter 118800: loss = 0.5895,  smooth loss = 0.6098
[2022-07-05 17:44:07,093 callbacks.py:105 INFO train-abinet] epoch 2 iter 118850: loss = 0.6951,  smooth loss = 0.5842
[2022-07-05 17:44:48,357 callbacks.py:105 INFO train-abinet] epoch 2 iter 118900: loss = 0.5971,  smooth loss = 0.5819
[2022-07-05 17:45:29,413 callbacks.py:105 INFO train-abinet] epoch 2 iter 118950: loss = 0.5945,  smooth loss = 0.5708
[2022-07-05 17:46:10,228 callbacks.py:105 INFO train-abinet] epoch 2 iter 119000: loss = 0.5334,  smooth loss = 0.5909
[2022-07-05 17:46:52,257 callbacks.py:105 INFO train-abinet] epoch 2 iter 119050: loss = 0.5212,  smooth loss = 0.5817
[2022-07-05 17:47:33,459 callbacks.py:105 INFO train-abinet] epoch 2 iter 119100: loss = 0.6112,  smooth loss = 0.5785
[2022-07-05 17:48:15,143 callbacks.py:105 INFO train-abinet] epoch 2 iter 119150: loss = 0.5698,  smooth loss = 0.5712
[2022-07-05 17:48:56,220 callbacks.py:105 INFO train-abinet] epoch 2 iter 119200: loss = 0.5932,  smooth loss = 0.5712
[2022-07-05 17:49:37,790 callbacks.py:105 INFO train-abinet] epoch 2 iter 119250: loss = 0.4481,  smooth loss = 0.5795
[2022-07-05 17:50:19,545 callbacks.py:105 INFO train-abinet] epoch 2 iter 119300: loss = 0.5662,  smooth loss = 0.5725
[2022-07-05 17:51:00,992 callbacks.py:105 INFO train-abinet] epoch 2 iter 119350: loss = 0.6644,  smooth loss = 0.5781
[2022-07-05 17:51:42,169 callbacks.py:105 INFO train-abinet] epoch 2 iter 119400: loss = 0.6069,  smooth loss = 0.5873
[2022-07-05 17:52:23,810 callbacks.py:105 INFO train-abinet] epoch 2 iter 119450: loss = 0.5850,  smooth loss = 0.5887
[2022-07-05 17:53:04,970 callbacks.py:105 INFO train-abinet] epoch 2 iter 119500: loss = 0.5797,  smooth loss = 0.5819
[2022-07-05 17:53:46,427 callbacks.py:105 INFO train-abinet] epoch 2 iter 119550: loss = 0.5349,  smooth loss = 0.5763
[2022-07-05 17:54:28,352 callbacks.py:105 INFO train-abinet] epoch 2 iter 119600: loss = 0.5491,  smooth loss = 0.5721
[2022-07-05 17:55:10,031 callbacks.py:105 INFO train-abinet] epoch 2 iter 119650: loss = 0.5788,  smooth loss = 0.5806
[2022-07-05 17:55:51,554 callbacks.py:105 INFO train-abinet] epoch 2 iter 119700: loss = 0.5521,  smooth loss = 0.5763
[2022-07-05 17:56:33,049 callbacks.py:105 INFO train-abinet] epoch 2 iter 119750: loss = 0.5609,  smooth loss = 0.5745
[2022-07-05 17:57:14,732 callbacks.py:105 INFO train-abinet] epoch 2 iter 119800: loss = 0.5602,  smooth loss = 0.5956
[2022-07-05 17:57:56,287 callbacks.py:105 INFO train-abinet] epoch 2 iter 119850: loss = 0.4396,  smooth loss = 0.5790
[2022-07-05 17:58:38,510 callbacks.py:105 INFO train-abinet] epoch 2 iter 119900: loss = 0.5702,  smooth loss = 0.5600
[2022-07-05 17:59:19,789 callbacks.py:105 INFO train-abinet] epoch 2 iter 119950: loss = 0.4795,  smooth loss = 0.5647
[2022-07-05 18:00:02,344 callbacks.py:105 INFO train-abinet] epoch 2 iter 120000: loss = 0.5537,  smooth loss = 0.5701
[2022-07-05 18:00:02,345 callbacks.py:114 INFO train-abinet] average data time = 0.0058s, average running time = 0.8887s
█[2022-07-05 18:00:17,101 callbacks.py:123 INFO train-abinet] epoch 2 iter 120000: eval loss = 1.2150,  ccr = 0.9561,  cwr = 0.9128,  ted = 1382.0000,  ned = 270.5645,  ted/w = 0.1907, 
[2022-07-05 18:00:17,102 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_120000
[2022-07-05 18:00:59,818 callbacks.py:105 INFO train-abinet] epoch 2 iter 120050: loss = 0.5834,  smooth loss = 0.5776
[2022-07-05 18:01:41,219 callbacks.py:105 INFO train-abinet] epoch 2 iter 120100: loss = 0.4908,  smooth loss = 0.5941
[2022-07-05 18:02:23,114 callbacks.py:105 INFO train-abinet] epoch 2 iter 120150: loss = 0.6182,  smooth loss = 0.5900
[2022-07-05 18:03:05,293 callbacks.py:105 INFO train-abinet] epoch 2 iter 120200: loss = 0.6605,  smooth loss = 0.5839
[2022-07-05 18:03:48,133 callbacks.py:105 INFO train-abinet] epoch 2 iter 120250: loss = 0.6191,  smooth loss = 0.5876
[2022-07-05 18:04:29,601 callbacks.py:105 INFO train-abinet] epoch 2 iter 120300: loss = 0.5179,  smooth loss = 0.5967
[2022-07-05 18:05:11,301 callbacks.py:105 INFO train-abinet] epoch 2 iter 120350: loss = 0.6709,  smooth loss = 0.5798
[2022-07-05 18:05:53,401 callbacks.py:105 INFO train-abinet] epoch 2 iter 120400: loss = 0.5618,  smooth loss = 0.5963
[2022-07-05 18:06:35,579 callbacks.py:105 INFO train-abinet] epoch 2 iter 120450: loss = 0.3895,  smooth loss = 0.5748
[2022-07-05 18:07:17,283 callbacks.py:105 INFO train-abinet] epoch 2 iter 120500: loss = 0.5632,  smooth loss = 0.5791
[2022-07-05 18:07:59,707 callbacks.py:105 INFO train-abinet] epoch 2 iter 120550: loss = 0.6170,  smooth loss = 0.5817
[2022-07-05 18:08:41,961 callbacks.py:105 INFO train-abinet] epoch 2 iter 120600: loss = 0.7581,  smooth loss = 0.5916
[2022-07-05 18:09:24,243 callbacks.py:105 INFO train-abinet] epoch 2 iter 120650: loss = 0.5919,  smooth loss = 0.5885
[2022-07-05 18:10:05,759 callbacks.py:105 INFO train-abinet] epoch 2 iter 120700: loss = 0.4964,  smooth loss = 0.6014
[2022-07-05 18:10:47,206 callbacks.py:105 INFO train-abinet] epoch 2 iter 120750: loss = 0.6827,  smooth loss = 0.6040
[2022-07-05 18:11:29,391 callbacks.py:105 INFO train-abinet] epoch 2 iter 120800: loss = 0.4830,  smooth loss = 0.5835
[2022-07-05 18:12:11,513 callbacks.py:105 INFO train-abinet] epoch 2 iter 120850: loss = 0.6652,  smooth loss = 0.5932
[2022-07-05 18:12:53,653 callbacks.py:105 INFO train-abinet] epoch 2 iter 120900: loss = 0.5342,  smooth loss = 0.5789
[2022-07-05 18:13:35,004 callbacks.py:105 INFO train-abinet] epoch 2 iter 120950: loss = 0.4901,  smooth loss = 0.5734
[2022-07-05 18:14:17,076 callbacks.py:105 INFO train-abinet] epoch 2 iter 121000: loss = 0.6570,  smooth loss = 0.5735
[2022-07-05 18:14:58,341 callbacks.py:105 INFO train-abinet] epoch 2 iter 121050: loss = 0.5710,  smooth loss = 0.5633
[2022-07-05 18:15:39,953 callbacks.py:105 INFO train-abinet] epoch 2 iter 121100: loss = 0.7132,  smooth loss = 0.5723
[2022-07-05 18:16:22,698 callbacks.py:105 INFO train-abinet] epoch 2 iter 121150: loss = 0.4884,  smooth loss = 0.5674
[2022-07-05 18:17:04,462 callbacks.py:105 INFO train-abinet] epoch 2 iter 121200: loss = 0.5255,  smooth loss = 0.5808
[2022-07-05 18:17:46,144 callbacks.py:105 INFO train-abinet] epoch 2 iter 121250: loss = 0.4674,  smooth loss = 0.5730
[2022-07-05 18:18:28,693 callbacks.py:105 INFO train-abinet] epoch 2 iter 121300: loss = 0.6754,  smooth loss = 0.5754
[2022-07-05 18:19:10,426 callbacks.py:105 INFO train-abinet] epoch 2 iter 121350: loss = 0.7382,  smooth loss = 0.5755
[2022-07-05 18:19:51,725 callbacks.py:105 INFO train-abinet] epoch 2 iter 121400: loss = 0.6599,  smooth loss = 0.5836
[2022-07-05 18:20:34,047 callbacks.py:105 INFO train-abinet] epoch 2 iter 121450: loss = 0.5141,  smooth loss = 0.5855
[2022-07-05 18:21:15,281 callbacks.py:105 INFO train-abinet] epoch 2 iter 121500: loss = 0.5765,  smooth loss = 0.5826
[2022-07-05 18:21:57,116 callbacks.py:105 INFO train-abinet] epoch 2 iter 121550: loss = 0.6368,  smooth loss = 0.5871
[2022-07-05 18:22:39,193 callbacks.py:105 INFO train-abinet] epoch 2 iter 121600: loss = 0.4843,  smooth loss = 0.5765
[2022-07-05 18:23:20,586 callbacks.py:105 INFO train-abinet] epoch 2 iter 121650: loss = 0.7349,  smooth loss = 0.5764
[2022-07-05 18:24:03,465 callbacks.py:105 INFO train-abinet] epoch 2 iter 121700: loss = 0.7486,  smooth loss = 0.5882
[2022-07-05 18:24:45,463 callbacks.py:105 INFO train-abinet] epoch 2 iter 121750: loss = 0.7342,  smooth loss = 0.5892
[2022-07-05 18:25:27,360 callbacks.py:105 INFO train-abinet] epoch 2 iter 121800: loss = 0.5185,  smooth loss = 0.5833
[2022-07-05 18:26:08,794 callbacks.py:105 INFO train-abinet] epoch 2 iter 121850: loss = 0.5984,  smooth loss = 0.5895
[2022-07-05 18:26:50,720 callbacks.py:105 INFO train-abinet] epoch 2 iter 121900: loss = 0.5409,  smooth loss = 0.5871
[2022-07-05 18:27:33,393 callbacks.py:105 INFO train-abinet] epoch 2 iter 121950: loss = 0.5632,  smooth loss = 0.5791
[2022-07-05 18:28:15,386 callbacks.py:105 INFO train-abinet] epoch 2 iter 122000: loss = 0.4123,  smooth loss = 0.5648
[2022-07-05 18:28:57,601 callbacks.py:105 INFO train-abinet] epoch 2 iter 122050: loss = 0.4951,  smooth loss = 0.5854
[2022-07-05 18:29:39,842 callbacks.py:105 INFO train-abinet] epoch 2 iter 122100: loss = 0.4665,  smooth loss = 0.5852
[2022-07-05 18:30:22,128 callbacks.py:105 INFO train-abinet] epoch 2 iter 122150: loss = 0.5609,  smooth loss = 0.5849
[2022-07-05 18:31:04,125 callbacks.py:105 INFO train-abinet] epoch 2 iter 122200: loss = 0.6865,  smooth loss = 0.5787
[2022-07-05 18:31:46,195 callbacks.py:105 INFO train-abinet] epoch 2 iter 122250: loss = 0.4809,  smooth loss = 0.5846
[2022-07-05 18:32:28,572 callbacks.py:105 INFO train-abinet] epoch 2 iter 122300: loss = 0.5998,  smooth loss = 0.5856
[2022-07-05 18:33:10,314 callbacks.py:105 INFO train-abinet] epoch 2 iter 122350: loss = 0.7273,  smooth loss = 0.5949
[2022-07-05 18:33:52,713 callbacks.py:105 INFO train-abinet] epoch 2 iter 122400: loss = 0.6379,  smooth loss = 0.5760
[2022-07-05 18:34:34,890 callbacks.py:105 INFO train-abinet] epoch 2 iter 122450: loss = 0.4642,  smooth loss = 0.5734
[2022-07-05 18:35:16,253 callbacks.py:105 INFO train-abinet] epoch 2 iter 122500: loss = 0.5294,  smooth loss = 0.5856
[2022-07-05 18:35:58,210 callbacks.py:105 INFO train-abinet] epoch 2 iter 122550: loss = 0.6047,  smooth loss = 0.5733
[2022-07-05 18:36:40,098 callbacks.py:105 INFO train-abinet] epoch 2 iter 122600: loss = 0.4483,  smooth loss = 0.5761
[2022-07-05 18:37:22,504 callbacks.py:105 INFO train-abinet] epoch 2 iter 122650: loss = 0.6377,  smooth loss = 0.5768
[2022-07-05 18:38:03,947 callbacks.py:105 INFO train-abinet] epoch 2 iter 122700: loss = 0.6269,  smooth loss = 0.5798
[2022-07-05 18:38:45,919 callbacks.py:105 INFO train-abinet] epoch 2 iter 122750: loss = 0.6554,  smooth loss = 0.5934
[2022-07-05 18:39:28,150 callbacks.py:105 INFO train-abinet] epoch 2 iter 122800: loss = 0.5679,  smooth loss = 0.5795
[2022-07-05 18:40:10,125 callbacks.py:105 INFO train-abinet] epoch 2 iter 122850: loss = 0.5084,  smooth loss = 0.5837
[2022-07-05 18:40:51,986 callbacks.py:105 INFO train-abinet] epoch 2 iter 122900: loss = 0.8276,  smooth loss = 0.5857
[2022-07-05 18:41:34,163 callbacks.py:105 INFO train-abinet] epoch 2 iter 122950: loss = 0.4484,  smooth loss = 0.5682
[2022-07-05 18:42:16,024 callbacks.py:105 INFO train-abinet] epoch 2 iter 123000: loss = 0.7775,  smooth loss = 0.5795
[2022-07-05 18:42:16,025 callbacks.py:114 INFO train-abinet] average data time = 0.0058s, average running time = 0.8876s
█[2022-07-05 18:42:30,553 callbacks.py:123 INFO train-abinet] epoch 2 iter 123000: eval loss = 1.2043,  ccr = 0.9561,  cwr = 0.9150,  ted = 1375.0000,  ned = 266.2775,  ted/w = 0.1897, 
[2022-07-05 18:42:30,555 callbacks.py:136 INFO train-abinet] Save model train-abinet_2_123000
[2022-07-05 18:43:14,089 callbacks.py:105 INFO train-abinet] epoch 2 iter 123050: loss = 0.5092,  smooth loss = 0.5646
[2022-07-05 18:43:56,659 callbacks.py:105 INFO train-abinet] epoch 2 iter 123100: loss = 0.4592,  smooth loss = 0.5621
[2022-07-05 18:44:39,725 callbacks.py:105 INFO train-abinet] epoch 2 iter 123150: loss = 0.5207,  smooth loss = 0.5672
[2022-07-05 18:45:21,384 callbacks.py:105 INFO train-abinet] epoch 2 iter 123200: loss = 0.6476,  smooth loss = 0.5633
[2022-07-05 18:46:03,215 callbacks.py:105 INFO train-abinet] epoch 2 iter 123250: loss = 0.7027,  smooth loss = 0.5738
[2022-07-05 18:46:45,360 callbacks.py:105 INFO train-abinet] epoch 2 iter 123300: loss = 0.5009,  smooth loss = 0.5943
[2022-07-05 18:47:27,294 callbacks.py:105 INFO train-abinet] epoch 2 iter 123350: loss = 0.6853,  smooth loss = 0.5825
[2022-07-05 18:48:09,372 callbacks.py:105 INFO train-abinet] epoch 2 iter 123400: loss = 0.6526,  smooth loss = 0.5823
[2022-07-05 18:48:50,540 callbacks.py:105 INFO train-abinet] epoch 2 iter 123450: loss = 0.6602,  smooth loss = 0.5844
[2022-07-05 18:49:33,181 callbacks.py:105 INFO train-abinet] epoch 2 iter 123500: loss = 0.5545,  smooth loss = 0.5693
[2022-07-05 18:50:14,642 callbacks.py:105 INFO train-abinet] epoch 2 iter 123550: loss = 0.4548,  smooth loss = 0.5608
[2022-07-05 18:50:57,200 callbacks.py:105 INFO train-abinet] epoch 2 iter 123600: loss = 0.5340,  smooth loss = 0.5679
[2022-07-05 18:51:38,692 callbacks.py:105 INFO train-abinet] epoch 2 iter 123650: loss = 0.5242,  smooth loss = 0.5794
[2022-07-05 18:52:21,277 callbacks.py:105 INFO train-abinet] epoch 2 iter 123700: loss = 0.5701,  smooth loss = 0.5760
[2022-07-05 18:53:03,817 callbacks.py:105 INFO train-abinet] epoch 2 iter 123750: loss = 0.5856,  smooth loss = 0.5669
[2022-07-05 18:53:46,130 callbacks.py:105 INFO train-abinet] epoch 2 iter 123800: loss = 0.4873,  smooth loss = 0.5791
[2022-07-05 18:54:27,719 callbacks.py:105 INFO train-abinet] epoch 2 iter 123850: loss = 0.6725,  smooth loss = 0.5868
[2022-07-05 18:55:09,554 callbacks.py:105 INFO train-abinet] epoch 2 iter 123900: loss = 0.5262,  smooth loss = 0.5751
[2022-07-05 18:55:51,002 callbacks.py:105 INFO train-abinet] epoch 2 iter 123950: loss = 0.4994,  smooth loss = 0.5700
[2022-07-05 18:56:32,518 callbacks.py:105 INFO train-abinet] epoch 2 iter 124000: loss = 0.6464,  smooth loss = 0.5636
[2022-07-05 18:57:14,134 callbacks.py:105 INFO train-abinet] epoch 2 iter 124050: loss = 0.6208,  smooth loss = 0.5852
[2022-07-05 18:57:57,243 callbacks.py:105 INFO train-abinet] epoch 2 iter 124100: loss = 0.6022,  smooth loss = 0.5907
[2022-07-05 18:58:38,926 callbacks.py:105 INFO train-abinet] epoch 2 iter 124150: loss = 0.5207,  smooth loss = 0.5833
█[2022-07-05 18:59:27,236 callbacks.py:105 INFO train-abinet] epoch 3 iter 124200: loss = 0.5828,  smooth loss = 0.5918
[2022-07-05 19:00:08,909 callbacks.py:105 INFO train-abinet] epoch 3 iter 124250: loss = 0.6343,  smooth loss = 0.5766
[2022-07-05 19:00:51,987 callbacks.py:105 INFO train-abinet] epoch 3 iter 124300: loss = 0.6449,  smooth loss = 0.5692
[2022-07-05 19:01:33,636 callbacks.py:105 INFO train-abinet] epoch 3 iter 124350: loss = 0.4908,  smooth loss = 0.5639
[2022-07-05 19:02:15,819 callbacks.py:105 INFO train-abinet] epoch 3 iter 124400: loss = 0.5550,  smooth loss = 0.5729
[2022-07-05 19:02:58,082 callbacks.py:105 INFO train-abinet] epoch 3 iter 124450: loss = 0.5928,  smooth loss = 0.5655
[2022-07-05 19:03:40,437 callbacks.py:105 INFO train-abinet] epoch 3 iter 124500: loss = 0.6426,  smooth loss = 0.5712
[2022-07-05 19:04:22,475 callbacks.py:105 INFO train-abinet] epoch 3 iter 124550: loss = 0.6376,  smooth loss = 0.5694
[2022-07-05 19:05:03,905 callbacks.py:105 INFO train-abinet] epoch 3 iter 124600: loss = 0.5202,  smooth loss = 0.5787
[2022-07-05 19:05:46,189 callbacks.py:105 INFO train-abinet] epoch 3 iter 124650: loss = 0.6521,  smooth loss = 0.5716
[2022-07-05 19:06:27,765 callbacks.py:105 INFO train-abinet] epoch 3 iter 124700: loss = 0.6856,  smooth loss = 0.5761
[2022-07-05 19:07:09,586 callbacks.py:105 INFO train-abinet] epoch 3 iter 124750: loss = 0.5888,  smooth loss = 0.5789
[2022-07-05 19:07:52,369 callbacks.py:105 INFO train-abinet] epoch 3 iter 124800: loss = 0.5897,  smooth loss = 0.5707
[2022-07-05 19:08:34,544 callbacks.py:105 INFO train-abinet] epoch 3 iter 124850: loss = 0.5422,  smooth loss = 0.5781
[2022-07-05 19:09:17,681 callbacks.py:105 INFO train-abinet] epoch 3 iter 124900: loss = 0.5803,  smooth loss = 0.5814
[2022-07-05 19:10:00,271 callbacks.py:105 INFO train-abinet] epoch 3 iter 124950: loss = 0.6604,  smooth loss = 0.5828
[2022-07-05 19:10:42,805 callbacks.py:105 INFO train-abinet] epoch 3 iter 125000: loss = 0.6982,  smooth loss = 0.5825
[2022-07-05 19:11:25,903 callbacks.py:105 INFO train-abinet] epoch 3 iter 125050: loss = 0.5582,  smooth loss = 0.5639
[2022-07-05 19:12:08,555 callbacks.py:105 INFO train-abinet] epoch 3 iter 125100: loss = 0.5897,  smooth loss = 0.5733
[2022-07-05 19:12:50,563 callbacks.py:105 INFO train-abinet] epoch 3 iter 125150: loss = 0.5440,  smooth loss = 0.5713
[2022-07-05 19:13:32,748 callbacks.py:105 INFO train-abinet] epoch 3 iter 125200: loss = 0.4236,  smooth loss = 0.5726
[2022-07-05 19:14:15,059 callbacks.py:105 INFO train-abinet] epoch 3 iter 125250: loss = 0.4657,  smooth loss = 0.5542
[2022-07-05 19:14:57,373 callbacks.py:105 INFO train-abinet] epoch 3 iter 125300: loss = 0.6251,  smooth loss = 0.5666
[2022-07-05 19:15:40,554 callbacks.py:105 INFO train-abinet] epoch 3 iter 125350: loss = 0.6636,  smooth loss = 0.5750
[2022-07-05 19:16:23,300 callbacks.py:105 INFO train-abinet] epoch 3 iter 125400: loss = 0.5977,  smooth loss = 0.5737
[2022-07-05 19:17:05,775 callbacks.py:105 INFO train-abinet] epoch 3 iter 125450: loss = 0.4268,  smooth loss = 0.5754
[2022-07-05 19:17:48,046 callbacks.py:105 INFO train-abinet] epoch 3 iter 125500: loss = 0.6393,  smooth loss = 0.5529
[2022-07-05 19:18:30,231 callbacks.py:105 INFO train-abinet] epoch 3 iter 125550: loss = 0.4617,  smooth loss = 0.5621
[2022-07-05 19:19:12,905 callbacks.py:105 INFO train-abinet] epoch 3 iter 125600: loss = 0.6212,  smooth loss = 0.5740
[2022-07-05 19:19:55,646 callbacks.py:105 INFO train-abinet] epoch 3 iter 125650: loss = 0.6197,  smooth loss = 0.5743
[2022-07-05 19:20:38,756 callbacks.py:105 INFO train-abinet] epoch 3 iter 125700: loss = 0.4770,  smooth loss = 0.5813
[2022-07-05 19:21:21,596 callbacks.py:105 INFO train-abinet] epoch 3 iter 125750: loss = 0.5370,  smooth loss = 0.5747
[2022-07-05 19:22:04,627 callbacks.py:105 INFO train-abinet] epoch 3 iter 125800: loss = 0.5416,  smooth loss = 0.5768
[2022-07-05 19:22:47,177 callbacks.py:105 INFO train-abinet] epoch 3 iter 125850: loss = 0.5936,  smooth loss = 0.5757
[2022-07-05 19:23:29,075 callbacks.py:105 INFO train-abinet] epoch 3 iter 125900: loss = 0.6872,  smooth loss = 0.5737
[2022-07-05 19:24:10,929 callbacks.py:105 INFO train-abinet] epoch 3 iter 125950: loss = 0.6687,  smooth loss = 0.5609
[2022-07-05 19:24:53,004 callbacks.py:105 INFO train-abinet] epoch 3 iter 126000: loss = 0.5490,  smooth loss = 0.5809
[2022-07-05 19:24:53,005 callbacks.py:114 INFO train-abinet] average data time = 0.0058s, average running time = 0.8866s
█[2022-07-05 19:25:07,308 callbacks.py:123 INFO train-abinet] epoch 3 iter 126000: eval loss = 1.1760,  ccr = 0.9570,  cwr = 0.9136,  ted = 1406.0000,  ned = 278.1185,  ted/w = 0.1940, 
[2022-07-05 19:25:07,309 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_126000
[2022-07-05 19:25:50,367 callbacks.py:105 INFO train-abinet] epoch 3 iter 126050: loss = 0.4576,  smooth loss = 0.5779
[2022-07-05 19:26:32,848 callbacks.py:105 INFO train-abinet] epoch 3 iter 126100: loss = 0.7371,  smooth loss = 0.5918
[2022-07-05 19:27:13,862 callbacks.py:105 INFO train-abinet] epoch 3 iter 126150: loss = 0.5551,  smooth loss = 0.5827
[2022-07-05 19:27:56,528 callbacks.py:105 INFO train-abinet] epoch 3 iter 126200: loss = 0.5558,  smooth loss = 0.5716
[2022-07-05 19:28:38,024 callbacks.py:105 INFO train-abinet] epoch 3 iter 126250: loss = 0.7059,  smooth loss = 0.5756
[2022-07-05 19:29:18,771 callbacks.py:105 INFO train-abinet] epoch 3 iter 126300: loss = 0.6278,  smooth loss = 0.5695
[2022-07-05 19:30:00,651 callbacks.py:105 INFO train-abinet] epoch 3 iter 126350: loss = 0.5745,  smooth loss = 0.5617
[2022-07-05 19:30:42,373 callbacks.py:105 INFO train-abinet] epoch 3 iter 126400: loss = 0.6007,  smooth loss = 0.5708
[2022-07-05 19:31:24,619 callbacks.py:105 INFO train-abinet] epoch 3 iter 126450: loss = 0.7123,  smooth loss = 0.5805
[2022-07-05 19:32:06,584 callbacks.py:105 INFO train-abinet] epoch 3 iter 126500: loss = 0.6376,  smooth loss = 0.5728
[2022-07-05 19:32:48,797 callbacks.py:105 INFO train-abinet] epoch 3 iter 126550: loss = 0.7429,  smooth loss = 0.5614
[2022-07-05 19:33:31,214 callbacks.py:105 INFO train-abinet] epoch 3 iter 126600: loss = 0.5731,  smooth loss = 0.5649
[2022-07-05 19:34:13,156 callbacks.py:105 INFO train-abinet] epoch 3 iter 126650: loss = 0.6509,  smooth loss = 0.5718
[2022-07-05 19:34:54,655 callbacks.py:105 INFO train-abinet] epoch 3 iter 126700: loss = 0.3561,  smooth loss = 0.5619
[2022-07-05 19:35:35,859 callbacks.py:105 INFO train-abinet] epoch 3 iter 126750: loss = 0.4357,  smooth loss = 0.5675
[2022-07-05 19:36:17,417 callbacks.py:105 INFO train-abinet] epoch 3 iter 126800: loss = 0.5748,  smooth loss = 0.5733
[2022-07-05 19:36:59,355 callbacks.py:105 INFO train-abinet] epoch 3 iter 126850: loss = 0.7280,  smooth loss = 0.5737
[2022-07-05 19:37:40,631 callbacks.py:105 INFO train-abinet] epoch 3 iter 126900: loss = 0.4953,  smooth loss = 0.5665
[2022-07-05 19:38:22,324 callbacks.py:105 INFO train-abinet] epoch 3 iter 126950: loss = 0.4464,  smooth loss = 0.5661
[2022-07-05 19:39:03,899 callbacks.py:105 INFO train-abinet] epoch 3 iter 127000: loss = 0.5755,  smooth loss = 0.5739
[2022-07-05 19:39:45,222 callbacks.py:105 INFO train-abinet] epoch 3 iter 127050: loss = 0.5806,  smooth loss = 0.5670
[2022-07-05 19:40:26,662 callbacks.py:105 INFO train-abinet] epoch 3 iter 127100: loss = 0.6328,  smooth loss = 0.5848
[2022-07-05 19:41:07,817 callbacks.py:105 INFO train-abinet] epoch 3 iter 127150: loss = 0.7059,  smooth loss = 0.5875
[2022-07-05 19:41:49,384 callbacks.py:105 INFO train-abinet] epoch 3 iter 127200: loss = 0.6338,  smooth loss = 0.5692
[2022-07-05 19:42:31,276 callbacks.py:105 INFO train-abinet] epoch 3 iter 127250: loss = 0.5667,  smooth loss = 0.5713
[2022-07-05 19:43:13,344 callbacks.py:105 INFO train-abinet] epoch 3 iter 127300: loss = 0.5700,  smooth loss = 0.5560
[2022-07-05 19:43:55,301 callbacks.py:105 INFO train-abinet] epoch 3 iter 127350: loss = 0.4606,  smooth loss = 0.5582
[2022-07-05 19:44:36,827 callbacks.py:105 INFO train-abinet] epoch 3 iter 127400: loss = 0.3954,  smooth loss = 0.5578
[2022-07-05 19:45:18,122 callbacks.py:105 INFO train-abinet] epoch 3 iter 127450: loss = 0.5180,  smooth loss = 0.5630
[2022-07-05 19:45:59,310 callbacks.py:105 INFO train-abinet] epoch 3 iter 127500: loss = 0.6453,  smooth loss = 0.5655
[2022-07-05 19:46:40,155 callbacks.py:105 INFO train-abinet] epoch 3 iter 127550: loss = 0.5299,  smooth loss = 0.5641
[2022-07-05 19:47:22,136 callbacks.py:105 INFO train-abinet] epoch 3 iter 127600: loss = 0.5167,  smooth loss = 0.5764
[2022-07-05 19:48:03,210 callbacks.py:105 INFO train-abinet] epoch 3 iter 127650: loss = 0.7166,  smooth loss = 0.5821
[2022-07-05 19:48:44,510 callbacks.py:105 INFO train-abinet] epoch 3 iter 127700: loss = 0.7204,  smooth loss = 0.5780
[2022-07-05 19:49:26,193 callbacks.py:105 INFO train-abinet] epoch 3 iter 127750: loss = 0.6913,  smooth loss = 0.5780
[2022-07-05 19:50:07,913 callbacks.py:105 INFO train-abinet] epoch 3 iter 127800: loss = 0.6255,  smooth loss = 0.5852
[2022-07-05 19:50:48,948 callbacks.py:105 INFO train-abinet] epoch 3 iter 127850: loss = 0.4989,  smooth loss = 0.5648
[2022-07-05 19:51:30,665 callbacks.py:105 INFO train-abinet] epoch 3 iter 127900: loss = 0.5539,  smooth loss = 0.5755
[2022-07-05 19:52:11,900 callbacks.py:105 INFO train-abinet] epoch 3 iter 127950: loss = 0.5667,  smooth loss = 0.5688
[2022-07-05 19:52:53,405 callbacks.py:105 INFO train-abinet] epoch 3 iter 128000: loss = 0.4883,  smooth loss = 0.5760
[2022-07-05 19:53:35,188 callbacks.py:105 INFO train-abinet] epoch 3 iter 128050: loss = 0.5446,  smooth loss = 0.5765
[2022-07-05 19:54:16,880 callbacks.py:105 INFO train-abinet] epoch 3 iter 128100: loss = 0.5580,  smooth loss = 0.5803
[2022-07-05 19:54:58,358 callbacks.py:105 INFO train-abinet] epoch 3 iter 128150: loss = 0.5507,  smooth loss = 0.5705
[2022-07-05 19:55:39,387 callbacks.py:105 INFO train-abinet] epoch 3 iter 128200: loss = 0.5216,  smooth loss = 0.5635
[2022-07-05 19:56:21,123 callbacks.py:105 INFO train-abinet] epoch 3 iter 128250: loss = 0.7112,  smooth loss = 0.5745
[2022-07-05 19:57:03,098 callbacks.py:105 INFO train-abinet] epoch 3 iter 128300: loss = 0.4375,  smooth loss = 0.5530
[2022-07-05 19:57:44,362 callbacks.py:105 INFO train-abinet] epoch 3 iter 128350: loss = 0.6887,  smooth loss = 0.5806
[2022-07-05 19:58:26,752 callbacks.py:105 INFO train-abinet] epoch 3 iter 128400: loss = 0.4592,  smooth loss = 0.5816
[2022-07-05 19:59:07,762 callbacks.py:105 INFO train-abinet] epoch 3 iter 128450: loss = 0.4156,  smooth loss = 0.5715
[2022-07-05 19:59:49,368 callbacks.py:105 INFO train-abinet] epoch 3 iter 128500: loss = 0.5475,  smooth loss = 0.5716
[2022-07-05 20:00:30,735 callbacks.py:105 INFO train-abinet] epoch 3 iter 128550: loss = 0.5811,  smooth loss = 0.5707
[2022-07-05 20:01:12,116 callbacks.py:105 INFO train-abinet] epoch 3 iter 128600: loss = 0.5272,  smooth loss = 0.5651
[2022-07-05 20:01:52,567 callbacks.py:105 INFO train-abinet] epoch 3 iter 128650: loss = 0.5222,  smooth loss = 0.5733
[2022-07-05 20:02:33,737 callbacks.py:105 INFO train-abinet] epoch 3 iter 128700: loss = 0.4980,  smooth loss = 0.5724
[2022-07-05 20:03:15,065 callbacks.py:105 INFO train-abinet] epoch 3 iter 128750: loss = 0.7458,  smooth loss = 0.5745
[2022-07-05 20:03:57,064 callbacks.py:105 INFO train-abinet] epoch 3 iter 128800: loss = 0.5258,  smooth loss = 0.5696
[2022-07-05 20:04:38,127 callbacks.py:105 INFO train-abinet] epoch 3 iter 128850: loss = 0.4495,  smooth loss = 0.5824
[2022-07-05 20:05:19,718 callbacks.py:105 INFO train-abinet] epoch 3 iter 128900: loss = 0.4897,  smooth loss = 0.5662
[2022-07-05 20:06:01,843 callbacks.py:105 INFO train-abinet] epoch 3 iter 128950: loss = 0.5723,  smooth loss = 0.5611
[2022-07-05 20:06:43,260 callbacks.py:105 INFO train-abinet] epoch 3 iter 129000: loss = 0.6525,  smooth loss = 0.5715
[2022-07-05 20:06:43,261 callbacks.py:114 INFO train-abinet] average data time = 0.0057s, average running time = 0.8853s
█[2022-07-05 20:06:57,568 callbacks.py:123 INFO train-abinet] epoch 3 iter 129000: eval loss = 1.1992,  ccr = 0.9574,  cwr = 0.9138,  ted = 1411.0000,  ned = 281.1868,  ted/w = 0.1947, 
[2022-07-05 20:06:57,568 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_129000
[2022-07-05 20:07:39,893 callbacks.py:105 INFO train-abinet] epoch 3 iter 129050: loss = 0.5869,  smooth loss = 0.5755
[2022-07-05 20:08:22,206 callbacks.py:105 INFO train-abinet] epoch 3 iter 129100: loss = 0.6062,  smooth loss = 0.5623
[2022-07-05 20:09:03,060 callbacks.py:105 INFO train-abinet] epoch 3 iter 129150: loss = 0.6481,  smooth loss = 0.5728
[2022-07-05 20:09:44,539 callbacks.py:105 INFO train-abinet] epoch 3 iter 129200: loss = 0.3950,  smooth loss = 0.5616
[2022-07-05 20:10:25,602 callbacks.py:105 INFO train-abinet] epoch 3 iter 129250: loss = 0.4444,  smooth loss = 0.5639
[2022-07-05 20:11:06,885 callbacks.py:105 INFO train-abinet] epoch 3 iter 129300: loss = 0.4947,  smooth loss = 0.5693
[2022-07-05 20:11:48,998 callbacks.py:105 INFO train-abinet] epoch 3 iter 129350: loss = 0.5707,  smooth loss = 0.5678
[2022-07-05 20:12:30,027 callbacks.py:105 INFO train-abinet] epoch 3 iter 129400: loss = 0.6885,  smooth loss = 0.5714
[2022-07-05 20:13:11,232 callbacks.py:105 INFO train-abinet] epoch 3 iter 129450: loss = 0.3840,  smooth loss = 0.5684
[2022-07-05 20:13:53,358 callbacks.py:105 INFO train-abinet] epoch 3 iter 129500: loss = 0.6575,  smooth loss = 0.5675
[2022-07-05 20:14:35,084 callbacks.py:105 INFO train-abinet] epoch 3 iter 129550: loss = 0.5294,  smooth loss = 0.5623
[2022-07-05 20:15:15,882 callbacks.py:105 INFO train-abinet] epoch 3 iter 129600: loss = 0.5712,  smooth loss = 0.5704
[2022-07-05 20:15:57,049 callbacks.py:105 INFO train-abinet] epoch 3 iter 129650: loss = 0.5185,  smooth loss = 0.5724
[2022-07-05 20:16:38,186 callbacks.py:105 INFO train-abinet] epoch 3 iter 129700: loss = 0.5417,  smooth loss = 0.5783
[2022-07-05 20:17:19,262 callbacks.py:105 INFO train-abinet] epoch 3 iter 129750: loss = 0.5714,  smooth loss = 0.5855
[2022-07-05 20:18:00,802 callbacks.py:105 INFO train-abinet] epoch 3 iter 129800: loss = 0.4775,  smooth loss = 0.5754
[2022-07-05 20:18:42,068 callbacks.py:105 INFO train-abinet] epoch 3 iter 129850: loss = 0.7046,  smooth loss = 0.5835
[2022-07-05 20:19:23,832 callbacks.py:105 INFO train-abinet] epoch 3 iter 129900: loss = 0.5653,  smooth loss = 0.5707
[2022-07-05 20:20:05,623 callbacks.py:105 INFO train-abinet] epoch 3 iter 129950: loss = 0.6587,  smooth loss = 0.5748
[2022-07-05 20:20:46,995 callbacks.py:105 INFO train-abinet] epoch 3 iter 130000: loss = 0.4608,  smooth loss = 0.5832
[2022-07-05 20:21:28,239 callbacks.py:105 INFO train-abinet] epoch 3 iter 130050: loss = 0.5676,  smooth loss = 0.5831
[2022-07-05 20:22:09,723 callbacks.py:105 INFO train-abinet] epoch 3 iter 130100: loss = 0.5572,  smooth loss = 0.5702
[2022-07-05 20:22:51,301 callbacks.py:105 INFO train-abinet] epoch 3 iter 130150: loss = 0.6102,  smooth loss = 0.5710
[2022-07-05 20:23:32,796 callbacks.py:105 INFO train-abinet] epoch 3 iter 130200: loss = 0.4224,  smooth loss = 0.5688
[2022-07-05 20:24:13,915 callbacks.py:105 INFO train-abinet] epoch 3 iter 130250: loss = 0.6178,  smooth loss = 0.5775
[2022-07-05 20:24:55,685 callbacks.py:105 INFO train-abinet] epoch 3 iter 130300: loss = 0.5434,  smooth loss = 0.5710
[2022-07-05 20:25:37,029 callbacks.py:105 INFO train-abinet] epoch 3 iter 130350: loss = 0.4338,  smooth loss = 0.5679
[2022-07-05 20:26:18,531 callbacks.py:105 INFO train-abinet] epoch 3 iter 130400: loss = 0.5748,  smooth loss = 0.5730
[2022-07-05 20:26:59,794 callbacks.py:105 INFO train-abinet] epoch 3 iter 130450: loss = 0.8166,  smooth loss = 0.5857
[2022-07-05 20:27:41,742 callbacks.py:105 INFO train-abinet] epoch 3 iter 130500: loss = 0.6992,  smooth loss = 0.5824
[2022-07-05 20:28:22,961 callbacks.py:105 INFO train-abinet] epoch 3 iter 130550: loss = 0.6400,  smooth loss = 0.5838
[2022-07-05 20:29:04,602 callbacks.py:105 INFO train-abinet] epoch 3 iter 130600: loss = 0.5099,  smooth loss = 0.5668
[2022-07-05 20:29:45,526 callbacks.py:105 INFO train-abinet] epoch 3 iter 130650: loss = 0.6317,  smooth loss = 0.5633
[2022-07-05 20:30:27,144 callbacks.py:105 INFO train-abinet] epoch 3 iter 130700: loss = 0.6575,  smooth loss = 0.5721
[2022-07-05 20:31:08,084 callbacks.py:105 INFO train-abinet] epoch 3 iter 130750: loss = 0.6295,  smooth loss = 0.5782
[2022-07-05 20:31:49,983 callbacks.py:105 INFO train-abinet] epoch 3 iter 130800: loss = 0.5390,  smooth loss = 0.5691
[2022-07-05 20:32:32,233 callbacks.py:105 INFO train-abinet] epoch 3 iter 130850: loss = 0.6191,  smooth loss = 0.5758
[2022-07-05 20:33:14,123 callbacks.py:105 INFO train-abinet] epoch 3 iter 130900: loss = 0.6015,  smooth loss = 0.5676
[2022-07-05 20:33:55,388 callbacks.py:105 INFO train-abinet] epoch 3 iter 130950: loss = 0.5412,  smooth loss = 0.5665
[2022-07-05 20:34:36,350 callbacks.py:105 INFO train-abinet] epoch 3 iter 131000: loss = 0.4912,  smooth loss = 0.5634
[2022-07-05 20:35:17,649 callbacks.py:105 INFO train-abinet] epoch 3 iter 131050: loss = 0.7021,  smooth loss = 0.5664
[2022-07-05 20:35:59,194 callbacks.py:105 INFO train-abinet] epoch 3 iter 131100: loss = 0.5313,  smooth loss = 0.5853
[2022-07-05 20:36:40,789 callbacks.py:105 INFO train-abinet] epoch 3 iter 131150: loss = 0.5742,  smooth loss = 0.5799
[2022-07-05 20:37:22,068 callbacks.py:105 INFO train-abinet] epoch 3 iter 131200: loss = 0.5035,  smooth loss = 0.5618
[2022-07-05 20:38:03,456 callbacks.py:105 INFO train-abinet] epoch 3 iter 131250: loss = 0.6016,  smooth loss = 0.5710
[2022-07-05 20:38:45,178 callbacks.py:105 INFO train-abinet] epoch 3 iter 131300: loss = 0.6599,  smooth loss = 0.5799
[2022-07-05 20:39:26,641 callbacks.py:105 INFO train-abinet] epoch 3 iter 131350: loss = 0.6837,  smooth loss = 0.5699
[2022-07-05 20:40:08,074 callbacks.py:105 INFO train-abinet] epoch 3 iter 131400: loss = 0.7683,  smooth loss = 0.5787
[2022-07-05 20:40:49,455 callbacks.py:105 INFO train-abinet] epoch 3 iter 131450: loss = 0.5359,  smooth loss = 0.5735
[2022-07-05 20:41:31,524 callbacks.py:105 INFO train-abinet] epoch 3 iter 131500: loss = 0.6458,  smooth loss = 0.5823
[2022-07-05 20:42:13,115 callbacks.py:105 INFO train-abinet] epoch 3 iter 131550: loss = 0.6556,  smooth loss = 0.5736
[2022-07-05 20:42:55,050 callbacks.py:105 INFO train-abinet] epoch 3 iter 131600: loss = 0.6074,  smooth loss = 0.5815
[2022-07-05 20:43:36,948 callbacks.py:105 INFO train-abinet] epoch 3 iter 131650: loss = 0.7758,  smooth loss = 0.5918
[2022-07-05 20:44:19,258 callbacks.py:105 INFO train-abinet] epoch 3 iter 131700: loss = 0.5575,  smooth loss = 0.5782
[2022-07-05 20:45:00,888 callbacks.py:105 INFO train-abinet] epoch 3 iter 131750: loss = 0.4147,  smooth loss = 0.5688
[2022-07-05 20:45:42,486 callbacks.py:105 INFO train-abinet] epoch 3 iter 131800: loss = 0.5964,  smooth loss = 0.5820
[2022-07-05 20:46:23,235 callbacks.py:105 INFO train-abinet] epoch 3 iter 131850: loss = 0.5400,  smooth loss = 0.5913
[2022-07-05 20:47:05,274 callbacks.py:105 INFO train-abinet] epoch 3 iter 131900: loss = 0.5887,  smooth loss = 0.5665
[2022-07-05 20:47:46,696 callbacks.py:105 INFO train-abinet] epoch 3 iter 131950: loss = 0.5935,  smooth loss = 0.5767
[2022-07-05 20:48:28,500 callbacks.py:105 INFO train-abinet] epoch 3 iter 132000: loss = 0.5839,  smooth loss = 0.5648
[2022-07-05 20:48:28,500 callbacks.py:114 INFO train-abinet] average data time = 0.0057s, average running time = 0.8841s
█[2022-07-05 20:48:43,217 callbacks.py:123 INFO train-abinet] epoch 3 iter 132000: eval loss = 1.1812,  ccr = 0.9550,  cwr = 0.9096,  ted = 1453.0000,  ned = 281.0834,  ted/w = 0.2005, 
[2022-07-05 20:48:43,218 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_132000
[2022-07-05 20:49:26,040 callbacks.py:105 INFO train-abinet] epoch 3 iter 132050: loss = 0.6324,  smooth loss = 0.5785
[2022-07-05 20:50:07,604 callbacks.py:105 INFO train-abinet] epoch 3 iter 132100: loss = 0.5637,  smooth loss = 0.5641
[2022-07-05 20:50:49,638 callbacks.py:105 INFO train-abinet] epoch 3 iter 132150: loss = 0.5436,  smooth loss = 0.5650
[2022-07-05 20:51:30,866 callbacks.py:105 INFO train-abinet] epoch 3 iter 132200: loss = 0.6263,  smooth loss = 0.5714
[2022-07-05 20:52:12,055 callbacks.py:105 INFO train-abinet] epoch 3 iter 132250: loss = 0.6119,  smooth loss = 0.5736
[2022-07-05 20:52:53,516 callbacks.py:105 INFO train-abinet] epoch 3 iter 132300: loss = 0.5044,  smooth loss = 0.5721
[2022-07-05 20:53:35,088 callbacks.py:105 INFO train-abinet] epoch 3 iter 132350: loss = 0.6122,  smooth loss = 0.5669
[2022-07-05 20:54:16,395 callbacks.py:105 INFO train-abinet] epoch 3 iter 132400: loss = 0.4278,  smooth loss = 0.5730
[2022-07-05 20:54:58,305 callbacks.py:105 INFO train-abinet] epoch 3 iter 132450: loss = 0.7006,  smooth loss = 0.5688
[2022-07-05 20:55:39,601 callbacks.py:105 INFO train-abinet] epoch 3 iter 132500: loss = 0.4701,  smooth loss = 0.5726
[2022-07-05 20:56:21,988 callbacks.py:105 INFO train-abinet] epoch 3 iter 132550: loss = 0.6280,  smooth loss = 0.5736
[2022-07-05 20:57:03,457 callbacks.py:105 INFO train-abinet] epoch 3 iter 132600: loss = 0.4466,  smooth loss = 0.5664
[2022-07-05 20:57:45,156 callbacks.py:105 INFO train-abinet] epoch 3 iter 132650: loss = 0.5748,  smooth loss = 0.5751
[2022-07-05 20:58:26,472 callbacks.py:105 INFO train-abinet] epoch 3 iter 132700: loss = 0.5824,  smooth loss = 0.5723
[2022-07-05 20:59:07,952 callbacks.py:105 INFO train-abinet] epoch 3 iter 132750: loss = 0.5215,  smooth loss = 0.5731
[2022-07-05 20:59:49,415 callbacks.py:105 INFO train-abinet] epoch 3 iter 132800: loss = 0.5218,  smooth loss = 0.5682
[2022-07-05 21:00:31,369 callbacks.py:105 INFO train-abinet] epoch 3 iter 132850: loss = 0.5169,  smooth loss = 0.5690
[2022-07-05 21:01:13,147 callbacks.py:105 INFO train-abinet] epoch 3 iter 132900: loss = 0.4852,  smooth loss = 0.5749
[2022-07-05 21:01:54,964 callbacks.py:105 INFO train-abinet] epoch 3 iter 132950: loss = 0.6580,  smooth loss = 0.5733
[2022-07-05 21:02:36,985 callbacks.py:105 INFO train-abinet] epoch 3 iter 133000: loss = 0.5870,  smooth loss = 0.5763
[2022-07-05 21:03:18,290 callbacks.py:105 INFO train-abinet] epoch 3 iter 133050: loss = 0.5008,  smooth loss = 0.5507
[2022-07-05 21:04:00,396 callbacks.py:105 INFO train-abinet] epoch 3 iter 133100: loss = 0.6233,  smooth loss = 0.5553
[2022-07-05 21:04:41,914 callbacks.py:105 INFO train-abinet] epoch 3 iter 133150: loss = 0.6209,  smooth loss = 0.5678
[2022-07-05 21:05:23,534 callbacks.py:105 INFO train-abinet] epoch 3 iter 133200: loss = 0.5450,  smooth loss = 0.5643
[2022-07-05 21:06:05,075 callbacks.py:105 INFO train-abinet] epoch 3 iter 133250: loss = 0.6584,  smooth loss = 0.5824
[2022-07-05 21:06:46,401 callbacks.py:105 INFO train-abinet] epoch 3 iter 133300: loss = 0.4644,  smooth loss = 0.5731
[2022-07-05 21:07:27,789 callbacks.py:105 INFO train-abinet] epoch 3 iter 133350: loss = 0.5810,  smooth loss = 0.5754
[2022-07-05 21:08:09,300 callbacks.py:105 INFO train-abinet] epoch 3 iter 133400: loss = 0.7075,  smooth loss = 0.5773
[2022-07-05 21:08:50,713 callbacks.py:105 INFO train-abinet] epoch 3 iter 133450: loss = 0.6732,  smooth loss = 0.5846
[2022-07-05 21:09:32,431 callbacks.py:105 INFO train-abinet] epoch 3 iter 133500: loss = 0.7626,  smooth loss = 0.5825
[2022-07-05 21:10:14,277 callbacks.py:105 INFO train-abinet] epoch 3 iter 133550: loss = 0.6669,  smooth loss = 0.5897
[2022-07-05 21:10:55,480 callbacks.py:105 INFO train-abinet] epoch 3 iter 133600: loss = 0.8263,  smooth loss = 0.5998
[2022-07-05 21:11:37,396 callbacks.py:105 INFO train-abinet] epoch 3 iter 133650: loss = 0.6190,  smooth loss = 0.5737
[2022-07-05 21:12:19,156 callbacks.py:105 INFO train-abinet] epoch 3 iter 133700: loss = 0.5083,  smooth loss = 0.5843
[2022-07-05 21:13:01,604 callbacks.py:105 INFO train-abinet] epoch 3 iter 133750: loss = 0.6460,  smooth loss = 0.5856
[2022-07-05 21:13:42,667 callbacks.py:105 INFO train-abinet] epoch 3 iter 133800: loss = 0.5501,  smooth loss = 0.5806
[2022-07-05 21:14:24,275 callbacks.py:105 INFO train-abinet] epoch 3 iter 133850: loss = 0.7508,  smooth loss = 0.5918
[2022-07-05 21:15:06,113 callbacks.py:105 INFO train-abinet] epoch 3 iter 133900: loss = 0.6424,  smooth loss = 0.5946
[2022-07-05 21:15:48,168 callbacks.py:105 INFO train-abinet] epoch 3 iter 133950: loss = 0.6578,  smooth loss = 0.5831
[2022-07-05 21:16:30,196 callbacks.py:105 INFO train-abinet] epoch 3 iter 134000: loss = 0.6213,  smooth loss = 0.5772
[2022-07-05 21:17:11,800 callbacks.py:105 INFO train-abinet] epoch 3 iter 134050: loss = 0.4425,  smooth loss = 0.5679
[2022-07-05 21:17:53,626 callbacks.py:105 INFO train-abinet] epoch 3 iter 134100: loss = 0.3757,  smooth loss = 0.5668
[2022-07-05 21:18:36,430 callbacks.py:105 INFO train-abinet] epoch 3 iter 134150: loss = 0.8549,  smooth loss = 0.5713
[2022-07-05 21:19:18,504 callbacks.py:105 INFO train-abinet] epoch 3 iter 134200: loss = 0.6062,  smooth loss = 0.5714
[2022-07-05 21:20:00,633 callbacks.py:105 INFO train-abinet] epoch 3 iter 134250: loss = 0.5785,  smooth loss = 0.5676
[2022-07-05 21:20:43,133 callbacks.py:105 INFO train-abinet] epoch 3 iter 134300: loss = 0.7011,  smooth loss = 0.5651
[2022-07-05 21:21:25,166 callbacks.py:105 INFO train-abinet] epoch 3 iter 134350: loss = 0.4976,  smooth loss = 0.5458
[2022-07-05 21:22:06,661 callbacks.py:105 INFO train-abinet] epoch 3 iter 134400: loss = 0.6198,  smooth loss = 0.5682
[2022-07-05 21:22:48,746 callbacks.py:105 INFO train-abinet] epoch 3 iter 134450: loss = 0.5321,  smooth loss = 0.5783
[2022-07-05 21:23:30,653 callbacks.py:105 INFO train-abinet] epoch 3 iter 134500: loss = 0.5926,  smooth loss = 0.5753
[2022-07-05 21:24:12,115 callbacks.py:105 INFO train-abinet] epoch 3 iter 134550: loss = 0.6656,  smooth loss = 0.5757
[2022-07-05 21:24:53,378 callbacks.py:105 INFO train-abinet] epoch 3 iter 134600: loss = 0.6482,  smooth loss = 0.5873
[2022-07-05 21:25:34,917 callbacks.py:105 INFO train-abinet] epoch 3 iter 134650: loss = 0.6208,  smooth loss = 0.5735
[2022-07-05 21:26:16,331 callbacks.py:105 INFO train-abinet] epoch 3 iter 134700: loss = 0.6128,  smooth loss = 0.5684
[2022-07-05 21:26:58,009 callbacks.py:105 INFO train-abinet] epoch 3 iter 134750: loss = 0.4769,  smooth loss = 0.5664
[2022-07-05 21:27:39,584 callbacks.py:105 INFO train-abinet] epoch 3 iter 134800: loss = 0.5929,  smooth loss = 0.5724
[2022-07-05 21:28:20,975 callbacks.py:105 INFO train-abinet] epoch 3 iter 134850: loss = 0.5975,  smooth loss = 0.5835
[2022-07-05 21:29:02,795 callbacks.py:105 INFO train-abinet] epoch 3 iter 134900: loss = 0.5378,  smooth loss = 0.5796
[2022-07-05 21:29:44,026 callbacks.py:105 INFO train-abinet] epoch 3 iter 134950: loss = 0.3093,  smooth loss = 0.5637
[2022-07-05 21:30:26,036 callbacks.py:105 INFO train-abinet] epoch 3 iter 135000: loss = 0.5388,  smooth loss = 0.5619
[2022-07-05 21:30:26,036 callbacks.py:114 INFO train-abinet] average data time = 0.0057s, average running time = 0.8830s
█[2022-07-05 21:30:40,510 callbacks.py:123 INFO train-abinet] epoch 3 iter 135000: eval loss = 1.1404,  ccr = 0.9586,  cwr = 0.9187,  ted = 1327.0000,  ned = 261.5715,  ted/w = 0.1831, 
[2022-07-05 21:30:40,512 callbacks.py:130 INFO train-abinet] Better model found at epoch 3, iter 135000 with accuracy value: 0.9187.
[2022-07-05 21:30:41,778 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_135000
[2022-07-05 21:31:24,847 callbacks.py:105 INFO train-abinet] epoch 3 iter 135050: loss = 0.5599,  smooth loss = 0.5620
[2022-07-05 21:32:06,810 callbacks.py:105 INFO train-abinet] epoch 3 iter 135100: loss = 0.5549,  smooth loss = 0.5481
[2022-07-05 21:32:49,298 callbacks.py:105 INFO train-abinet] epoch 3 iter 135150: loss = 0.5747,  smooth loss = 0.5756
[2022-07-05 21:33:30,614 callbacks.py:105 INFO train-abinet] epoch 3 iter 135200: loss = 0.6143,  smooth loss = 0.5699
[2022-07-05 21:34:13,311 callbacks.py:105 INFO train-abinet] epoch 3 iter 135250: loss = 0.5229,  smooth loss = 0.5792
[2022-07-05 21:34:55,020 callbacks.py:105 INFO train-abinet] epoch 3 iter 135300: loss = 0.6120,  smooth loss = 0.5797
[2022-07-05 21:35:36,254 callbacks.py:105 INFO train-abinet] epoch 3 iter 135350: loss = 0.5101,  smooth loss = 0.5674
[2022-07-05 21:36:17,724 callbacks.py:105 INFO train-abinet] epoch 3 iter 135400: loss = 0.6248,  smooth loss = 0.5760
[2022-07-05 21:36:59,507 callbacks.py:105 INFO train-abinet] epoch 3 iter 135450: loss = 0.5160,  smooth loss = 0.5814
[2022-07-05 21:37:41,336 callbacks.py:105 INFO train-abinet] epoch 3 iter 135500: loss = 0.5849,  smooth loss = 0.5567
[2022-07-05 21:38:23,809 callbacks.py:105 INFO train-abinet] epoch 3 iter 135550: loss = 0.6223,  smooth loss = 0.5599
[2022-07-05 21:39:05,527 callbacks.py:105 INFO train-abinet] epoch 3 iter 135600: loss = 0.6403,  smooth loss = 0.5621
[2022-07-05 21:39:48,186 callbacks.py:105 INFO train-abinet] epoch 3 iter 135650: loss = 0.6095,  smooth loss = 0.5787
[2022-07-05 21:40:30,182 callbacks.py:105 INFO train-abinet] epoch 3 iter 135700: loss = 0.5660,  smooth loss = 0.5732
[2022-07-05 21:41:11,806 callbacks.py:105 INFO train-abinet] epoch 3 iter 135750: loss = 0.5035,  smooth loss = 0.5835
[2022-07-05 21:41:53,071 callbacks.py:105 INFO train-abinet] epoch 3 iter 135800: loss = 0.5367,  smooth loss = 0.5802
[2022-07-05 21:42:34,410 callbacks.py:105 INFO train-abinet] epoch 3 iter 135850: loss = 0.6086,  smooth loss = 0.5769
[2022-07-05 21:43:16,286 callbacks.py:105 INFO train-abinet] epoch 3 iter 135900: loss = 0.6107,  smooth loss = 0.5870
[2022-07-05 21:43:57,357 callbacks.py:105 INFO train-abinet] epoch 3 iter 135950: loss = 0.6031,  smooth loss = 0.5717
[2022-07-05 21:44:38,372 callbacks.py:105 INFO train-abinet] epoch 3 iter 136000: loss = 0.6300,  smooth loss = 0.5769
[2022-07-05 21:45:19,883 callbacks.py:105 INFO train-abinet] epoch 3 iter 136050: loss = 0.4591,  smooth loss = 0.5534
[2022-07-05 21:46:01,561 callbacks.py:105 INFO train-abinet] epoch 3 iter 136100: loss = 0.5200,  smooth loss = 0.5623
[2022-07-05 21:46:43,208 callbacks.py:105 INFO train-abinet] epoch 3 iter 136150: loss = 0.5016,  smooth loss = 0.5711
[2022-07-05 21:47:24,887 callbacks.py:105 INFO train-abinet] epoch 3 iter 136200: loss = 0.5971,  smooth loss = 0.5542
[2022-07-05 21:48:06,259 callbacks.py:105 INFO train-abinet] epoch 3 iter 136250: loss = 0.5011,  smooth loss = 0.5613
[2022-07-05 21:48:47,848 callbacks.py:105 INFO train-abinet] epoch 3 iter 136300: loss = 0.6234,  smooth loss = 0.5705
[2022-07-05 21:49:30,078 callbacks.py:105 INFO train-abinet] epoch 3 iter 136350: loss = 0.5680,  smooth loss = 0.5702
[2022-07-05 21:50:11,391 callbacks.py:105 INFO train-abinet] epoch 3 iter 136400: loss = 0.4397,  smooth loss = 0.5762
[2022-07-05 21:50:52,824 callbacks.py:105 INFO train-abinet] epoch 3 iter 136450: loss = 0.4950,  smooth loss = 0.5702
[2022-07-05 21:51:34,526 callbacks.py:105 INFO train-abinet] epoch 3 iter 136500: loss = 0.6764,  smooth loss = 0.5750
[2022-07-05 21:52:15,909 callbacks.py:105 INFO train-abinet] epoch 3 iter 136550: loss = 0.5231,  smooth loss = 0.5813
[2022-07-05 21:52:57,584 callbacks.py:105 INFO train-abinet] epoch 3 iter 136600: loss = 0.5489,  smooth loss = 0.5788
[2022-07-05 21:53:39,399 callbacks.py:105 INFO train-abinet] epoch 3 iter 136650: loss = 0.4805,  smooth loss = 0.5802
[2022-07-05 21:54:20,783 callbacks.py:105 INFO train-abinet] epoch 3 iter 136700: loss = 0.5171,  smooth loss = 0.5837
[2022-07-05 21:55:02,033 callbacks.py:105 INFO train-abinet] epoch 3 iter 136750: loss = 0.6806,  smooth loss = 0.5778
[2022-07-05 21:55:42,708 callbacks.py:105 INFO train-abinet] epoch 3 iter 136800: loss = 0.5140,  smooth loss = 0.5868
[2022-07-05 21:56:24,112 callbacks.py:105 INFO train-abinet] epoch 3 iter 136850: loss = 0.6029,  smooth loss = 0.5781
[2022-07-05 21:57:05,276 callbacks.py:105 INFO train-abinet] epoch 3 iter 136900: loss = 0.4417,  smooth loss = 0.5664
[2022-07-05 21:57:46,949 callbacks.py:105 INFO train-abinet] epoch 3 iter 136950: loss = 0.7012,  smooth loss = 0.5748
[2022-07-05 21:58:27,718 callbacks.py:105 INFO train-abinet] epoch 3 iter 137000: loss = 0.4917,  smooth loss = 0.5695
[2022-07-05 21:59:08,947 callbacks.py:105 INFO train-abinet] epoch 3 iter 137050: loss = 0.5915,  smooth loss = 0.5777
[2022-07-05 21:59:51,129 callbacks.py:105 INFO train-abinet] epoch 3 iter 137100: loss = 0.3958,  smooth loss = 0.5692
[2022-07-05 22:00:33,316 callbacks.py:105 INFO train-abinet] epoch 3 iter 137150: loss = 0.5126,  smooth loss = 0.5667
[2022-07-05 22:01:15,083 callbacks.py:105 INFO train-abinet] epoch 3 iter 137200: loss = 0.4742,  smooth loss = 0.5618
[2022-07-05 22:01:57,129 callbacks.py:105 INFO train-abinet] epoch 3 iter 137250: loss = 0.5496,  smooth loss = 0.5632
[2022-07-05 22:02:38,974 callbacks.py:105 INFO train-abinet] epoch 3 iter 137300: loss = 0.5792,  smooth loss = 0.5663
[2022-07-05 22:03:20,395 callbacks.py:105 INFO train-abinet] epoch 3 iter 137350: loss = 0.6014,  smooth loss = 0.5672
[2022-07-05 22:04:02,103 callbacks.py:105 INFO train-abinet] epoch 3 iter 137400: loss = 0.5989,  smooth loss = 0.5790
[2022-07-05 22:04:43,809 callbacks.py:105 INFO train-abinet] epoch 3 iter 137450: loss = 0.7025,  smooth loss = 0.5664
[2022-07-05 22:05:26,004 callbacks.py:105 INFO train-abinet] epoch 3 iter 137500: loss = 0.5128,  smooth loss = 0.5566
[2022-07-05 22:06:07,535 callbacks.py:105 INFO train-abinet] epoch 3 iter 137550: loss = 0.5854,  smooth loss = 0.5824
[2022-07-05 22:06:48,801 callbacks.py:105 INFO train-abinet] epoch 3 iter 137600: loss = 0.7407,  smooth loss = 0.5755
[2022-07-05 22:07:30,696 callbacks.py:105 INFO train-abinet] epoch 3 iter 137650: loss = 0.5109,  smooth loss = 0.5797
[2022-07-05 22:08:12,922 callbacks.py:105 INFO train-abinet] epoch 3 iter 137700: loss = 0.6742,  smooth loss = 0.5834
[2022-07-05 22:08:54,769 callbacks.py:105 INFO train-abinet] epoch 3 iter 137750: loss = 0.6387,  smooth loss = 0.5763
[2022-07-05 22:09:35,776 callbacks.py:105 INFO train-abinet] epoch 3 iter 137800: loss = 0.5741,  smooth loss = 0.6011
[2022-07-05 22:10:16,708 callbacks.py:105 INFO train-abinet] epoch 3 iter 137850: loss = 0.6997,  smooth loss = 0.5952
[2022-07-05 22:10:57,864 callbacks.py:105 INFO train-abinet] epoch 3 iter 137900: loss = 0.6085,  smooth loss = 0.5909
[2022-07-05 22:11:39,172 callbacks.py:105 INFO train-abinet] epoch 3 iter 137950: loss = 0.6045,  smooth loss = 0.5742
[2022-07-05 22:12:20,852 callbacks.py:105 INFO train-abinet] epoch 3 iter 138000: loss = 0.6074,  smooth loss = 0.5791
[2022-07-05 22:12:20,852 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8819s
█[2022-07-05 22:12:35,363 callbacks.py:123 INFO train-abinet] epoch 3 iter 138000: eval loss = 1.1653,  ccr = 0.9563,  cwr = 0.9135,  ted = 1425.0000,  ned = 280.2935,  ted/w = 0.1966, 
[2022-07-05 22:12:35,364 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_138000
[2022-07-05 22:13:18,140 callbacks.py:105 INFO train-abinet] epoch 3 iter 138050: loss = 0.6204,  smooth loss = 0.5672
[2022-07-05 22:13:59,568 callbacks.py:105 INFO train-abinet] epoch 3 iter 138100: loss = 0.5727,  smooth loss = 0.5647
[2022-07-05 22:14:42,620 callbacks.py:105 INFO train-abinet] epoch 3 iter 138150: loss = 0.5110,  smooth loss = 0.5650
[2022-07-05 22:15:24,032 callbacks.py:105 INFO train-abinet] epoch 3 iter 138200: loss = 0.6604,  smooth loss = 0.5589
[2022-07-05 22:16:05,839 callbacks.py:105 INFO train-abinet] epoch 3 iter 138250: loss = 0.5363,  smooth loss = 0.5610
[2022-07-05 22:16:47,779 callbacks.py:105 INFO train-abinet] epoch 3 iter 138300: loss = 0.5732,  smooth loss = 0.5737
[2022-07-05 22:17:29,508 callbacks.py:105 INFO train-abinet] epoch 3 iter 138350: loss = 0.4370,  smooth loss = 0.5763
[2022-07-05 22:18:11,335 callbacks.py:105 INFO train-abinet] epoch 3 iter 138400: loss = 0.5493,  smooth loss = 0.5618
[2022-07-05 22:18:52,248 callbacks.py:105 INFO train-abinet] epoch 3 iter 138450: loss = 0.7038,  smooth loss = 0.5742
[2022-07-05 22:19:34,793 callbacks.py:105 INFO train-abinet] epoch 3 iter 138500: loss = 0.6824,  smooth loss = 0.5779
[2022-07-05 22:20:16,866 callbacks.py:105 INFO train-abinet] epoch 3 iter 138550: loss = 0.7222,  smooth loss = 0.5689
[2022-07-05 22:20:58,704 callbacks.py:105 INFO train-abinet] epoch 3 iter 138600: loss = 0.4987,  smooth loss = 0.5577
[2022-07-05 22:21:40,319 callbacks.py:105 INFO train-abinet] epoch 3 iter 138650: loss = 0.6528,  smooth loss = 0.5855
[2022-07-05 22:22:21,513 callbacks.py:105 INFO train-abinet] epoch 3 iter 138700: loss = 0.5843,  smooth loss = 0.5749
[2022-07-05 22:23:02,519 callbacks.py:105 INFO train-abinet] epoch 3 iter 138750: loss = 0.6196,  smooth loss = 0.5750
[2022-07-05 22:23:44,033 callbacks.py:105 INFO train-abinet] epoch 3 iter 138800: loss = 0.5676,  smooth loss = 0.5738
[2022-07-05 22:24:26,149 callbacks.py:105 INFO train-abinet] epoch 3 iter 138850: loss = 0.5394,  smooth loss = 0.5660
[2022-07-05 22:25:07,390 callbacks.py:105 INFO train-abinet] epoch 3 iter 138900: loss = 0.6973,  smooth loss = 0.5618
[2022-07-05 22:25:48,684 callbacks.py:105 INFO train-abinet] epoch 3 iter 138950: loss = 0.6284,  smooth loss = 0.5606
[2022-07-05 22:26:30,351 callbacks.py:105 INFO train-abinet] epoch 3 iter 139000: loss = 0.4991,  smooth loss = 0.5668
[2022-07-05 22:27:11,941 callbacks.py:105 INFO train-abinet] epoch 3 iter 139050: loss = 0.6106,  smooth loss = 0.5605
[2022-07-05 22:27:53,342 callbacks.py:105 INFO train-abinet] epoch 3 iter 139100: loss = 0.4459,  smooth loss = 0.5769
[2022-07-05 22:28:34,678 callbacks.py:105 INFO train-abinet] epoch 3 iter 139150: loss = 0.4426,  smooth loss = 0.5846
[2022-07-05 22:29:16,038 callbacks.py:105 INFO train-abinet] epoch 3 iter 139200: loss = 0.5897,  smooth loss = 0.5723
[2022-07-05 22:29:57,574 callbacks.py:105 INFO train-abinet] epoch 3 iter 139250: loss = 0.5727,  smooth loss = 0.5727
[2022-07-05 22:30:38,181 callbacks.py:105 INFO train-abinet] epoch 3 iter 139300: loss = 0.7065,  smooth loss = 0.5683
[2022-07-05 22:31:19,619 callbacks.py:105 INFO train-abinet] epoch 3 iter 139350: loss = 0.6261,  smooth loss = 0.5702
[2022-07-05 22:32:01,004 callbacks.py:105 INFO train-abinet] epoch 3 iter 139400: loss = 0.5342,  smooth loss = 0.5689
[2022-07-05 22:32:42,748 callbacks.py:105 INFO train-abinet] epoch 3 iter 139450: loss = 0.5123,  smooth loss = 0.5560
[2022-07-05 22:33:24,298 callbacks.py:105 INFO train-abinet] epoch 3 iter 139500: loss = 0.5100,  smooth loss = 0.5549
[2022-07-05 22:34:06,258 callbacks.py:105 INFO train-abinet] epoch 3 iter 139550: loss = 0.4268,  smooth loss = 0.5678
[2022-07-05 22:34:47,388 callbacks.py:105 INFO train-abinet] epoch 3 iter 139600: loss = 0.7513,  smooth loss = 0.5693
[2022-07-05 22:35:29,268 callbacks.py:105 INFO train-abinet] epoch 3 iter 139650: loss = 0.6499,  smooth loss = 0.5720
[2022-07-05 22:36:10,532 callbacks.py:105 INFO train-abinet] epoch 3 iter 139700: loss = 0.6312,  smooth loss = 0.5683
[2022-07-05 22:36:51,677 callbacks.py:105 INFO train-abinet] epoch 3 iter 139750: loss = 0.7410,  smooth loss = 0.5597
[2022-07-05 22:37:32,920 callbacks.py:105 INFO train-abinet] epoch 3 iter 139800: loss = 0.5598,  smooth loss = 0.5772
[2022-07-05 22:38:14,165 callbacks.py:105 INFO train-abinet] epoch 3 iter 139850: loss = 0.6140,  smooth loss = 0.5691
[2022-07-05 22:38:55,538 callbacks.py:105 INFO train-abinet] epoch 3 iter 139900: loss = 0.5884,  smooth loss = 0.5753
[2022-07-05 22:39:37,605 callbacks.py:105 INFO train-abinet] epoch 3 iter 139950: loss = 0.5519,  smooth loss = 0.5699
[2022-07-05 22:40:20,942 callbacks.py:105 INFO train-abinet] epoch 3 iter 140000: loss = 0.3931,  smooth loss = 0.5728
[2022-07-05 22:41:04,311 callbacks.py:105 INFO train-abinet] epoch 3 iter 140050: loss = 0.5890,  smooth loss = 0.5737
[2022-07-05 22:41:48,202 callbacks.py:105 INFO train-abinet] epoch 3 iter 140100: loss = 0.6404,  smooth loss = 0.5622
[2022-07-05 22:42:30,831 callbacks.py:105 INFO train-abinet] epoch 3 iter 140150: loss = 0.5486,  smooth loss = 0.5648
[2022-07-05 22:43:13,941 callbacks.py:105 INFO train-abinet] epoch 3 iter 140200: loss = 0.5101,  smooth loss = 0.5586
[2022-07-05 22:43:57,292 callbacks.py:105 INFO train-abinet] epoch 3 iter 140250: loss = 0.7199,  smooth loss = 0.5598
[2022-07-05 22:44:41,231 callbacks.py:105 INFO train-abinet] epoch 3 iter 140300: loss = 0.5689,  smooth loss = 0.5540
[2022-07-05 22:45:24,706 callbacks.py:105 INFO train-abinet] epoch 3 iter 140350: loss = 0.6160,  smooth loss = 0.5609
[2022-07-05 22:46:07,465 callbacks.py:105 INFO train-abinet] epoch 3 iter 140400: loss = 0.4998,  smooth loss = 0.5609
[2022-07-05 22:46:49,109 callbacks.py:105 INFO train-abinet] epoch 3 iter 140450: loss = 0.6259,  smooth loss = 0.5677
[2022-07-05 22:47:33,437 callbacks.py:105 INFO train-abinet] epoch 3 iter 140500: loss = 0.4657,  smooth loss = 0.5604
[2022-07-05 22:48:16,599 callbacks.py:105 INFO train-abinet] epoch 3 iter 140550: loss = 0.4511,  smooth loss = 0.5710
[2022-07-05 22:48:58,581 callbacks.py:105 INFO train-abinet] epoch 3 iter 140600: loss = 0.6805,  smooth loss = 0.5699
[2022-07-05 22:49:41,036 callbacks.py:105 INFO train-abinet] epoch 3 iter 140650: loss = 0.7816,  smooth loss = 0.5854
[2022-07-05 22:50:23,777 callbacks.py:105 INFO train-abinet] epoch 3 iter 140700: loss = 0.5570,  smooth loss = 0.5745
[2022-07-05 22:51:06,113 callbacks.py:105 INFO train-abinet] epoch 3 iter 140750: loss = 0.6962,  smooth loss = 0.5675
[2022-07-05 22:51:50,791 callbacks.py:105 INFO train-abinet] epoch 3 iter 140800: loss = 0.6190,  smooth loss = 0.5772
[2022-07-05 22:52:33,224 callbacks.py:105 INFO train-abinet] epoch 3 iter 140850: loss = 0.6242,  smooth loss = 0.5563
[2022-07-05 22:53:16,471 callbacks.py:105 INFO train-abinet] epoch 3 iter 140900: loss = 0.4847,  smooth loss = 0.5596
[2022-07-05 22:53:58,522 callbacks.py:105 INFO train-abinet] epoch 3 iter 140950: loss = 0.4539,  smooth loss = 0.5685
[2022-07-05 22:54:42,288 callbacks.py:105 INFO train-abinet] epoch 3 iter 141000: loss = 0.5330,  smooth loss = 0.5618
[2022-07-05 22:54:42,288 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8811s
█[2022-07-05 22:54:57,560 callbacks.py:123 INFO train-abinet] epoch 3 iter 141000: eval loss = 1.1662,  ccr = 0.9609,  cwr = 0.9205,  ted = 1293.0000,  ned = 261.0124,  ted/w = 0.1784, 
[2022-07-05 22:54:57,561 callbacks.py:130 INFO train-abinet] Better model found at epoch 3, iter 141000 with accuracy value: 0.9205.
[2022-07-05 22:54:58,727 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_141000
[2022-07-05 22:55:41,798 callbacks.py:105 INFO train-abinet] epoch 3 iter 141050: loss = 0.6115,  smooth loss = 0.5565
[2022-07-05 22:56:24,877 callbacks.py:105 INFO train-abinet] epoch 3 iter 141100: loss = 0.7485,  smooth loss = 0.5564
[2022-07-05 22:57:07,491 callbacks.py:105 INFO train-abinet] epoch 3 iter 141150: loss = 0.6181,  smooth loss = 0.5658
[2022-07-05 22:57:50,641 callbacks.py:105 INFO train-abinet] epoch 3 iter 141200: loss = 0.5278,  smooth loss = 0.5583
[2022-07-05 22:58:32,930 callbacks.py:105 INFO train-abinet] epoch 3 iter 141250: loss = 0.5987,  smooth loss = 0.5559
[2022-07-05 22:59:15,424 callbacks.py:105 INFO train-abinet] epoch 3 iter 141300: loss = 0.4098,  smooth loss = 0.5549
[2022-07-05 22:59:57,275 callbacks.py:105 INFO train-abinet] epoch 3 iter 141350: loss = 0.7374,  smooth loss = 0.5786
[2022-07-05 23:00:39,988 callbacks.py:105 INFO train-abinet] epoch 3 iter 141400: loss = 0.6116,  smooth loss = 0.5754
[2022-07-05 23:01:22,529 callbacks.py:105 INFO train-abinet] epoch 3 iter 141450: loss = 0.6157,  smooth loss = 0.5587
[2022-07-05 23:02:06,515 callbacks.py:105 INFO train-abinet] epoch 3 iter 141500: loss = 0.6868,  smooth loss = 0.5562
[2022-07-05 23:02:48,812 callbacks.py:105 INFO train-abinet] epoch 3 iter 141550: loss = 0.5047,  smooth loss = 0.5627
[2022-07-05 23:03:31,238 callbacks.py:105 INFO train-abinet] epoch 3 iter 141600: loss = 0.4023,  smooth loss = 0.5702
[2022-07-05 23:04:14,096 callbacks.py:105 INFO train-abinet] epoch 3 iter 141650: loss = 0.5213,  smooth loss = 0.5651
[2022-07-05 23:04:57,092 callbacks.py:105 INFO train-abinet] epoch 3 iter 141700: loss = 0.6342,  smooth loss = 0.5687
[2022-07-05 23:05:38,723 callbacks.py:105 INFO train-abinet] epoch 3 iter 141750: loss = 0.4716,  smooth loss = 0.5660
[2022-07-05 23:06:20,707 callbacks.py:105 INFO train-abinet] epoch 3 iter 141800: loss = 0.6919,  smooth loss = 0.5724
[2022-07-05 23:07:03,362 callbacks.py:105 INFO train-abinet] epoch 3 iter 141850: loss = 0.5958,  smooth loss = 0.5794
[2022-07-05 23:07:45,472 callbacks.py:105 INFO train-abinet] epoch 3 iter 141900: loss = 0.5495,  smooth loss = 0.5763
[2022-07-05 23:08:27,261 callbacks.py:105 INFO train-abinet] epoch 3 iter 141950: loss = 0.7669,  smooth loss = 0.5822
[2022-07-05 23:09:09,555 callbacks.py:105 INFO train-abinet] epoch 3 iter 142000: loss = 0.4962,  smooth loss = 0.5699
[2022-07-05 23:09:52,392 callbacks.py:105 INFO train-abinet] epoch 3 iter 142050: loss = 0.5598,  smooth loss = 0.5641
[2022-07-05 23:10:34,725 callbacks.py:105 INFO train-abinet] epoch 3 iter 142100: loss = 0.5921,  smooth loss = 0.5541
[2022-07-05 23:11:16,615 callbacks.py:105 INFO train-abinet] epoch 3 iter 142150: loss = 0.5803,  smooth loss = 0.5585
[2022-07-05 23:11:58,142 callbacks.py:105 INFO train-abinet] epoch 3 iter 142200: loss = 0.6777,  smooth loss = 0.5544
[2022-07-05 23:12:40,926 callbacks.py:105 INFO train-abinet] epoch 3 iter 142250: loss = 0.6175,  smooth loss = 0.5603
[2022-07-05 23:13:24,254 callbacks.py:105 INFO train-abinet] epoch 3 iter 142300: loss = 0.4994,  smooth loss = 0.5606
[2022-07-05 23:14:07,252 callbacks.py:105 INFO train-abinet] epoch 3 iter 142350: loss = 0.5788,  smooth loss = 0.5708
[2022-07-05 23:14:50,467 callbacks.py:105 INFO train-abinet] epoch 3 iter 142400: loss = 0.5612,  smooth loss = 0.5560
[2022-07-05 23:15:33,712 callbacks.py:105 INFO train-abinet] epoch 3 iter 142450: loss = 0.5382,  smooth loss = 0.5681
[2022-07-05 23:16:15,930 callbacks.py:105 INFO train-abinet] epoch 3 iter 142500: loss = 0.5612,  smooth loss = 0.5599
[2022-07-05 23:16:58,796 callbacks.py:105 INFO train-abinet] epoch 3 iter 142550: loss = 0.6375,  smooth loss = 0.5543
[2022-07-05 23:17:40,896 callbacks.py:105 INFO train-abinet] epoch 3 iter 142600: loss = 0.6657,  smooth loss = 0.5637
[2022-07-05 23:18:23,718 callbacks.py:105 INFO train-abinet] epoch 3 iter 142650: loss = 0.4633,  smooth loss = 0.5593
[2022-07-05 23:19:06,782 callbacks.py:105 INFO train-abinet] epoch 3 iter 142700: loss = 0.6874,  smooth loss = 0.5846
[2022-07-05 23:19:50,416 callbacks.py:105 INFO train-abinet] epoch 3 iter 142750: loss = 0.5933,  smooth loss = 0.5751
[2022-07-05 23:20:33,657 callbacks.py:105 INFO train-abinet] epoch 3 iter 142800: loss = 0.4453,  smooth loss = 0.5667
[2022-07-05 23:21:17,163 callbacks.py:105 INFO train-abinet] epoch 3 iter 142850: loss = 0.4522,  smooth loss = 0.5651
[2022-07-05 23:21:59,746 callbacks.py:105 INFO train-abinet] epoch 3 iter 142900: loss = 0.6164,  smooth loss = 0.5671
[2022-07-05 23:22:41,815 callbacks.py:105 INFO train-abinet] epoch 3 iter 142950: loss = 0.5371,  smooth loss = 0.5671
[2022-07-05 23:23:24,539 callbacks.py:105 INFO train-abinet] epoch 3 iter 143000: loss = 0.5700,  smooth loss = 0.5655
[2022-07-05 23:24:07,888 callbacks.py:105 INFO train-abinet] epoch 3 iter 143050: loss = 0.4936,  smooth loss = 0.5702
[2022-07-05 23:24:50,589 callbacks.py:105 INFO train-abinet] epoch 3 iter 143100: loss = 0.5672,  smooth loss = 0.5746
[2022-07-05 23:25:33,032 callbacks.py:105 INFO train-abinet] epoch 3 iter 143150: loss = 0.5624,  smooth loss = 0.5714
[2022-07-05 23:26:16,740 callbacks.py:105 INFO train-abinet] epoch 3 iter 143200: loss = 0.5858,  smooth loss = 0.5660
[2022-07-05 23:26:59,286 callbacks.py:105 INFO train-abinet] epoch 3 iter 143250: loss = 0.5036,  smooth loss = 0.5594
[2022-07-05 23:27:42,348 callbacks.py:105 INFO train-abinet] epoch 3 iter 143300: loss = 0.5867,  smooth loss = 0.5576
[2022-07-05 23:28:24,144 callbacks.py:105 INFO train-abinet] epoch 3 iter 143350: loss = 0.5806,  smooth loss = 0.5594
[2022-07-05 23:29:08,045 callbacks.py:105 INFO train-abinet] epoch 3 iter 143400: loss = 0.5889,  smooth loss = 0.5650
[2022-07-05 23:29:51,201 callbacks.py:105 INFO train-abinet] epoch 3 iter 143450: loss = 0.5617,  smooth loss = 0.5587
[2022-07-05 23:30:34,295 callbacks.py:105 INFO train-abinet] epoch 3 iter 143500: loss = 0.5820,  smooth loss = 0.5778
[2022-07-05 23:31:17,027 callbacks.py:105 INFO train-abinet] epoch 3 iter 143550: loss = 0.6216,  smooth loss = 0.5624
[2022-07-05 23:31:59,352 callbacks.py:105 INFO train-abinet] epoch 3 iter 143600: loss = 0.4806,  smooth loss = 0.5596
[2022-07-05 23:32:42,785 callbacks.py:105 INFO train-abinet] epoch 3 iter 143650: loss = 0.5450,  smooth loss = 0.5735
[2022-07-05 23:33:26,059 callbacks.py:105 INFO train-abinet] epoch 3 iter 143700: loss = 0.6679,  smooth loss = 0.5648
[2022-07-05 23:34:10,055 callbacks.py:105 INFO train-abinet] epoch 3 iter 143750: loss = 0.6754,  smooth loss = 0.5570
[2022-07-05 23:34:53,258 callbacks.py:105 INFO train-abinet] epoch 3 iter 143800: loss = 0.6224,  smooth loss = 0.5718
[2022-07-05 23:35:36,229 callbacks.py:105 INFO train-abinet] epoch 3 iter 143850: loss = 0.6787,  smooth loss = 0.5762
[2022-07-05 23:36:19,968 callbacks.py:105 INFO train-abinet] epoch 3 iter 143900: loss = 0.4301,  smooth loss = 0.5612
[2022-07-05 23:37:03,148 callbacks.py:105 INFO train-abinet] epoch 3 iter 143950: loss = 0.6477,  smooth loss = 0.5785
[2022-07-05 23:37:45,453 callbacks.py:105 INFO train-abinet] epoch 3 iter 144000: loss = 0.6409,  smooth loss = 0.5776
[2022-07-05 23:37:45,454 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8806s
█[2022-07-05 23:38:00,736 callbacks.py:123 INFO train-abinet] epoch 3 iter 144000: eval loss = 1.1515,  ccr = 0.9593,  cwr = 0.9164,  ted = 1363.0000,  ned = 267.0242,  ted/w = 0.1881, 
[2022-07-05 23:38:00,737 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_144000
[2022-07-05 23:38:45,222 callbacks.py:105 INFO train-abinet] epoch 3 iter 144050: loss = 0.6062,  smooth loss = 0.5686
[2022-07-05 23:39:28,054 callbacks.py:105 INFO train-abinet] epoch 3 iter 144100: loss = 0.5972,  smooth loss = 0.5782
[2022-07-05 23:40:11,049 callbacks.py:105 INFO train-abinet] epoch 3 iter 144150: loss = 0.6597,  smooth loss = 0.5798
[2022-07-05 23:40:55,465 callbacks.py:105 INFO train-abinet] epoch 3 iter 144200: loss = 0.6216,  smooth loss = 0.5801
[2022-07-05 23:41:39,620 callbacks.py:105 INFO train-abinet] epoch 3 iter 144250: loss = 0.6187,  smooth loss = 0.5666
[2022-07-05 23:42:24,313 callbacks.py:105 INFO train-abinet] epoch 3 iter 144300: loss = 0.6410,  smooth loss = 0.5685
[2022-07-05 23:43:07,420 callbacks.py:105 INFO train-abinet] epoch 3 iter 144350: loss = 0.5278,  smooth loss = 0.5734
[2022-07-05 23:43:50,830 callbacks.py:105 INFO train-abinet] epoch 3 iter 144400: loss = 0.4614,  smooth loss = 0.5831
[2022-07-05 23:44:33,966 callbacks.py:105 INFO train-abinet] epoch 3 iter 144450: loss = 0.5144,  smooth loss = 0.5691
[2022-07-05 23:45:15,800 callbacks.py:105 INFO train-abinet] epoch 3 iter 144500: loss = 0.4209,  smooth loss = 0.5514
[2022-07-05 23:45:58,502 callbacks.py:105 INFO train-abinet] epoch 3 iter 144550: loss = 0.5832,  smooth loss = 0.5494
[2022-07-05 23:46:40,108 callbacks.py:105 INFO train-abinet] epoch 3 iter 144600: loss = 0.7400,  smooth loss = 0.5591
[2022-07-05 23:47:22,974 callbacks.py:105 INFO train-abinet] epoch 3 iter 144650: loss = 0.4509,  smooth loss = 0.5669
[2022-07-05 23:48:05,548 callbacks.py:105 INFO train-abinet] epoch 3 iter 144700: loss = 0.5526,  smooth loss = 0.5652
[2022-07-05 23:48:47,927 callbacks.py:105 INFO train-abinet] epoch 3 iter 144750: loss = 0.5442,  smooth loss = 0.5617
[2022-07-05 23:49:30,824 callbacks.py:105 INFO train-abinet] epoch 3 iter 144800: loss = 0.5632,  smooth loss = 0.5724
[2022-07-05 23:50:13,420 callbacks.py:105 INFO train-abinet] epoch 3 iter 144850: loss = 0.5597,  smooth loss = 0.5666
[2022-07-05 23:50:56,233 callbacks.py:105 INFO train-abinet] epoch 3 iter 144900: loss = 0.6080,  smooth loss = 0.5751
[2022-07-05 23:51:38,801 callbacks.py:105 INFO train-abinet] epoch 3 iter 144950: loss = 0.5056,  smooth loss = 0.5641
[2022-07-05 23:52:22,135 callbacks.py:105 INFO train-abinet] epoch 3 iter 145000: loss = 0.4238,  smooth loss = 0.5612
[2022-07-05 23:53:04,619 callbacks.py:105 INFO train-abinet] epoch 3 iter 145050: loss = 0.5309,  smooth loss = 0.5638
[2022-07-05 23:53:47,375 callbacks.py:105 INFO train-abinet] epoch 3 iter 145100: loss = 0.5944,  smooth loss = 0.5647
[2022-07-05 23:54:30,131 callbacks.py:105 INFO train-abinet] epoch 3 iter 145150: loss = 0.6314,  smooth loss = 0.5608
[2022-07-05 23:55:12,807 callbacks.py:105 INFO train-abinet] epoch 3 iter 145200: loss = 0.6387,  smooth loss = 0.5699
[2022-07-05 23:55:56,928 callbacks.py:105 INFO train-abinet] epoch 3 iter 145250: loss = 0.5504,  smooth loss = 0.5821
[2022-07-05 23:56:39,218 callbacks.py:105 INFO train-abinet] epoch 3 iter 145300: loss = 0.4826,  smooth loss = 0.5684
[2022-07-05 23:57:22,455 callbacks.py:105 INFO train-abinet] epoch 3 iter 145350: loss = 0.5173,  smooth loss = 0.5609
[2022-07-05 23:58:05,702 callbacks.py:105 INFO train-abinet] epoch 3 iter 145400: loss = 0.5870,  smooth loss = 0.5675
[2022-07-05 23:58:49,067 callbacks.py:105 INFO train-abinet] epoch 3 iter 145450: loss = 0.5188,  smooth loss = 0.5681
[2022-07-05 23:59:31,835 callbacks.py:105 INFO train-abinet] epoch 3 iter 145500: loss = 0.4894,  smooth loss = 0.5540
[2022-07-06 00:00:14,167 callbacks.py:105 INFO train-abinet] epoch 3 iter 145550: loss = 0.5754,  smooth loss = 0.5552
[2022-07-06 00:00:58,135 callbacks.py:105 INFO train-abinet] epoch 3 iter 145600: loss = 0.5690,  smooth loss = 0.5481
[2022-07-06 00:01:40,694 callbacks.py:105 INFO train-abinet] epoch 3 iter 145650: loss = 0.5466,  smooth loss = 0.5613
[2022-07-06 00:02:23,448 callbacks.py:105 INFO train-abinet] epoch 3 iter 145700: loss = 0.5434,  smooth loss = 0.5678
[2022-07-06 00:03:06,303 callbacks.py:105 INFO train-abinet] epoch 3 iter 145750: loss = 0.7757,  smooth loss = 0.5849
[2022-07-06 00:03:48,808 callbacks.py:105 INFO train-abinet] epoch 3 iter 145800: loss = 0.6595,  smooth loss = 0.5766
[2022-07-06 00:04:31,397 callbacks.py:105 INFO train-abinet] epoch 3 iter 145850: loss = 0.6287,  smooth loss = 0.5710
[2022-07-06 00:05:13,357 callbacks.py:105 INFO train-abinet] epoch 3 iter 145900: loss = 0.5866,  smooth loss = 0.5812
[2022-07-06 00:05:56,132 callbacks.py:105 INFO train-abinet] epoch 3 iter 145950: loss = 0.4858,  smooth loss = 0.5655
[2022-07-06 00:06:38,828 callbacks.py:105 INFO train-abinet] epoch 3 iter 146000: loss = 0.6584,  smooth loss = 0.5808
[2022-07-06 00:07:21,387 callbacks.py:105 INFO train-abinet] epoch 3 iter 146050: loss = 0.5591,  smooth loss = 0.5665
[2022-07-06 00:08:03,216 callbacks.py:105 INFO train-abinet] epoch 3 iter 146100: loss = 0.5284,  smooth loss = 0.5831
[2022-07-06 00:08:45,745 callbacks.py:105 INFO train-abinet] epoch 3 iter 146150: loss = 0.6059,  smooth loss = 0.5838
[2022-07-06 00:09:28,477 callbacks.py:105 INFO train-abinet] epoch 3 iter 146200: loss = 0.4587,  smooth loss = 0.5707
[2022-07-06 00:10:11,293 callbacks.py:105 INFO train-abinet] epoch 3 iter 146250: loss = 0.5894,  smooth loss = 0.5714
[2022-07-06 00:10:54,024 callbacks.py:105 INFO train-abinet] epoch 3 iter 146300: loss = 0.5738,  smooth loss = 0.5673
[2022-07-06 00:11:36,489 callbacks.py:105 INFO train-abinet] epoch 3 iter 146350: loss = 0.4885,  smooth loss = 0.5571
[2022-07-06 00:12:17,802 callbacks.py:105 INFO train-abinet] epoch 3 iter 146400: loss = 0.4937,  smooth loss = 0.5671
[2022-07-06 00:13:00,954 callbacks.py:105 INFO train-abinet] epoch 3 iter 146450: loss = 0.5187,  smooth loss = 0.5605
[2022-07-06 00:13:42,839 callbacks.py:105 INFO train-abinet] epoch 3 iter 146500: loss = 0.4704,  smooth loss = 0.5693
[2022-07-06 00:14:25,382 callbacks.py:105 INFO train-abinet] epoch 3 iter 146550: loss = 0.7224,  smooth loss = 0.5790
[2022-07-06 00:15:07,300 callbacks.py:105 INFO train-abinet] epoch 3 iter 146600: loss = 0.7340,  smooth loss = 0.5661
[2022-07-06 00:15:51,129 callbacks.py:105 INFO train-abinet] epoch 3 iter 146650: loss = 0.6270,  smooth loss = 0.5743
[2022-07-06 00:16:34,667 callbacks.py:105 INFO train-abinet] epoch 3 iter 146700: loss = 0.4761,  smooth loss = 0.5717
[2022-07-06 00:17:17,658 callbacks.py:105 INFO train-abinet] epoch 3 iter 146750: loss = 0.6768,  smooth loss = 0.5777
[2022-07-06 00:17:59,683 callbacks.py:105 INFO train-abinet] epoch 3 iter 146800: loss = 0.5333,  smooth loss = 0.5860
[2022-07-06 00:18:42,490 callbacks.py:105 INFO train-abinet] epoch 3 iter 146850: loss = 0.5059,  smooth loss = 0.5692
[2022-07-06 00:19:23,915 callbacks.py:105 INFO train-abinet] epoch 3 iter 146900: loss = 0.6010,  smooth loss = 0.5622
[2022-07-06 00:20:07,165 callbacks.py:105 INFO train-abinet] epoch 3 iter 146950: loss = 0.5305,  smooth loss = 0.5590
[2022-07-06 00:20:49,673 callbacks.py:105 INFO train-abinet] epoch 3 iter 147000: loss = 0.7357,  smooth loss = 0.5589
[2022-07-06 00:20:49,674 callbacks.py:114 INFO train-abinet] average data time = 0.0056s, average running time = 0.8801s
█[2022-07-06 00:21:05,548 callbacks.py:123 INFO train-abinet] epoch 3 iter 147000: eval loss = 1.1743,  ccr = 0.9581,  cwr = 0.9139,  ted = 1358.0000,  ned = 268.7611,  ted/w = 0.1874, 
[2022-07-06 00:21:05,550 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_147000
[2022-07-06 00:21:49,161 callbacks.py:105 INFO train-abinet] epoch 3 iter 147050: loss = 0.7405,  smooth loss = 0.5774
[2022-07-06 00:22:31,553 callbacks.py:105 INFO train-abinet] epoch 3 iter 147100: loss = 0.7086,  smooth loss = 0.5786
[2022-07-06 00:23:13,789 callbacks.py:105 INFO train-abinet] epoch 3 iter 147150: loss = 0.5924,  smooth loss = 0.5780
[2022-07-06 00:23:56,284 callbacks.py:105 INFO train-abinet] epoch 3 iter 147200: loss = 0.4520,  smooth loss = 0.5686
[2022-07-06 00:24:39,412 callbacks.py:105 INFO train-abinet] epoch 3 iter 147250: loss = 0.4691,  smooth loss = 0.5738
[2022-07-06 00:25:22,671 callbacks.py:105 INFO train-abinet] epoch 3 iter 147300: loss = 0.5912,  smooth loss = 0.5662
[2022-07-06 00:26:05,054 callbacks.py:105 INFO train-abinet] epoch 3 iter 147350: loss = 0.4559,  smooth loss = 0.5766
[2022-07-06 00:26:47,649 callbacks.py:105 INFO train-abinet] epoch 3 iter 147400: loss = 0.4639,  smooth loss = 0.5657
[2022-07-06 00:27:29,869 callbacks.py:105 INFO train-abinet] epoch 3 iter 147450: loss = 0.4329,  smooth loss = 0.5593
[2022-07-06 00:28:12,264 callbacks.py:105 INFO train-abinet] epoch 3 iter 147500: loss = 0.5381,  smooth loss = 0.5650
[2022-07-06 00:28:54,948 callbacks.py:105 INFO train-abinet] epoch 3 iter 147550: loss = 0.4823,  smooth loss = 0.5611
[2022-07-06 00:29:36,903 callbacks.py:105 INFO train-abinet] epoch 3 iter 147600: loss = 0.6130,  smooth loss = 0.5548
[2022-07-06 00:30:18,996 callbacks.py:105 INFO train-abinet] epoch 3 iter 147650: loss = 0.6565,  smooth loss = 0.5591
[2022-07-06 00:31:01,625 callbacks.py:105 INFO train-abinet] epoch 3 iter 147700: loss = 0.4943,  smooth loss = 0.5708
[2022-07-06 00:31:44,049 callbacks.py:105 INFO train-abinet] epoch 3 iter 147750: loss = 0.5280,  smooth loss = 0.5666
[2022-07-06 00:32:26,465 callbacks.py:105 INFO train-abinet] epoch 3 iter 147800: loss = 0.5664,  smooth loss = 0.5695
[2022-07-06 00:33:09,406 callbacks.py:105 INFO train-abinet] epoch 3 iter 147850: loss = 0.5741,  smooth loss = 0.5532
[2022-07-06 00:33:51,401 callbacks.py:105 INFO train-abinet] epoch 3 iter 147900: loss = 0.4920,  smooth loss = 0.5614
[2022-07-06 00:34:33,278 callbacks.py:105 INFO train-abinet] epoch 3 iter 147950: loss = 0.5880,  smooth loss = 0.5483
[2022-07-06 00:35:15,238 callbacks.py:105 INFO train-abinet] epoch 3 iter 148000: loss = 0.7100,  smooth loss = 0.5560
[2022-07-06 00:35:57,783 callbacks.py:105 INFO train-abinet] epoch 3 iter 148050: loss = 0.6126,  smooth loss = 0.5554
[2022-07-06 00:36:40,134 callbacks.py:105 INFO train-abinet] epoch 3 iter 148100: loss = 0.5860,  smooth loss = 0.5664
[2022-07-06 00:37:22,967 callbacks.py:105 INFO train-abinet] epoch 3 iter 148150: loss = 0.5368,  smooth loss = 0.5572
[2022-07-06 00:38:04,387 callbacks.py:105 INFO train-abinet] epoch 3 iter 148200: loss = 0.5179,  smooth loss = 0.5434
[2022-07-06 00:38:46,758 callbacks.py:105 INFO train-abinet] epoch 3 iter 148250: loss = 0.5175,  smooth loss = 0.5533
[2022-07-06 00:39:28,592 callbacks.py:105 INFO train-abinet] epoch 3 iter 148300: loss = 0.5713,  smooth loss = 0.5636
[2022-07-06 00:40:12,382 callbacks.py:105 INFO train-abinet] epoch 3 iter 148350: loss = 0.5538,  smooth loss = 0.5655
[2022-07-06 00:40:54,781 callbacks.py:105 INFO train-abinet] epoch 3 iter 148400: loss = 0.4821,  smooth loss = 0.5712
[2022-07-06 00:41:37,421 callbacks.py:105 INFO train-abinet] epoch 3 iter 148450: loss = 0.5279,  smooth loss = 0.5670
[2022-07-06 00:42:19,027 callbacks.py:105 INFO train-abinet] epoch 3 iter 148500: loss = 0.6337,  smooth loss = 0.5664
[2022-07-06 00:43:01,061 callbacks.py:105 INFO train-abinet] epoch 3 iter 148550: loss = 0.5845,  smooth loss = 0.5658
[2022-07-06 00:43:43,781 callbacks.py:105 INFO train-abinet] epoch 3 iter 148600: loss = 0.4792,  smooth loss = 0.5665
[2022-07-06 00:44:25,947 callbacks.py:105 INFO train-abinet] epoch 3 iter 148650: loss = 0.7264,  smooth loss = 0.5650
[2022-07-06 00:45:07,852 callbacks.py:105 INFO train-abinet] epoch 3 iter 148700: loss = 0.5210,  smooth loss = 0.5695
[2022-07-06 00:45:49,784 callbacks.py:105 INFO train-abinet] epoch 3 iter 148750: loss = 0.5724,  smooth loss = 0.5673
[2022-07-06 00:46:32,282 callbacks.py:105 INFO train-abinet] epoch 3 iter 148800: loss = 0.5685,  smooth loss = 0.5795
[2022-07-06 00:47:13,936 callbacks.py:105 INFO train-abinet] epoch 3 iter 148850: loss = 0.6832,  smooth loss = 0.5644
[2022-07-06 00:47:55,966 callbacks.py:105 INFO train-abinet] epoch 3 iter 148900: loss = 0.3769,  smooth loss = 0.5675
[2022-07-06 00:48:37,311 callbacks.py:105 INFO train-abinet] epoch 3 iter 148950: loss = 0.5354,  smooth loss = 0.5692
[2022-07-06 00:49:19,996 callbacks.py:105 INFO train-abinet] epoch 3 iter 149000: loss = 0.6172,  smooth loss = 0.5687
[2022-07-06 00:50:03,165 callbacks.py:105 INFO train-abinet] epoch 3 iter 149050: loss = 0.6366,  smooth loss = 0.5739
[2022-07-06 00:50:45,742 callbacks.py:105 INFO train-abinet] epoch 3 iter 149100: loss = 0.6145,  smooth loss = 0.5664
[2022-07-06 00:51:28,141 callbacks.py:105 INFO train-abinet] epoch 3 iter 149150: loss = 0.5391,  smooth loss = 0.5720
[2022-07-06 00:52:10,496 callbacks.py:105 INFO train-abinet] epoch 3 iter 149200: loss = 0.4523,  smooth loss = 0.5678
[2022-07-06 00:52:52,511 callbacks.py:105 INFO train-abinet] epoch 3 iter 149250: loss = 0.5756,  smooth loss = 0.5745
[2022-07-06 00:53:33,893 callbacks.py:105 INFO train-abinet] epoch 3 iter 149300: loss = 0.5566,  smooth loss = 0.5700
[2022-07-06 00:54:16,448 callbacks.py:105 INFO train-abinet] epoch 3 iter 149350: loss = 0.4960,  smooth loss = 0.5716
[2022-07-06 00:54:58,103 callbacks.py:105 INFO train-abinet] epoch 3 iter 149400: loss = 0.5003,  smooth loss = 0.5817
[2022-07-06 00:55:40,183 callbacks.py:105 INFO train-abinet] epoch 3 iter 149450: loss = 0.6546,  smooth loss = 0.5731
[2022-07-06 00:56:21,850 callbacks.py:105 INFO train-abinet] epoch 3 iter 149500: loss = 0.4435,  smooth loss = 0.5624
[2022-07-06 00:57:03,629 callbacks.py:105 INFO train-abinet] epoch 3 iter 149550: loss = 0.6222,  smooth loss = 0.5653
[2022-07-06 00:57:45,494 callbacks.py:105 INFO train-abinet] epoch 3 iter 149600: loss = 0.6587,  smooth loss = 0.5652
[2022-07-06 00:58:27,015 callbacks.py:105 INFO train-abinet] epoch 3 iter 149650: loss = 0.6307,  smooth loss = 0.5619
[2022-07-06 00:59:08,947 callbacks.py:105 INFO train-abinet] epoch 3 iter 149700: loss = 0.5867,  smooth loss = 0.5616
[2022-07-06 00:59:51,452 callbacks.py:105 INFO train-abinet] epoch 3 iter 149750: loss = 0.5623,  smooth loss = 0.5566
[2022-07-06 01:00:35,063 callbacks.py:105 INFO train-abinet] epoch 3 iter 149800: loss = 0.6070,  smooth loss = 0.5678
[2022-07-06 01:01:18,247 callbacks.py:105 INFO train-abinet] epoch 3 iter 149850: loss = 0.4318,  smooth loss = 0.5445
[2022-07-06 01:02:00,996 callbacks.py:105 INFO train-abinet] epoch 3 iter 149900: loss = 0.7094,  smooth loss = 0.5556
[2022-07-06 01:02:43,348 callbacks.py:105 INFO train-abinet] epoch 3 iter 149950: loss = 0.5200,  smooth loss = 0.5574
[2022-07-06 01:03:25,842 callbacks.py:105 INFO train-abinet] epoch 3 iter 150000: loss = 0.4750,  smooth loss = 0.5502
[2022-07-06 01:03:25,842 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8795s
█[2022-07-06 01:03:40,430 callbacks.py:123 INFO train-abinet] epoch 3 iter 150000: eval loss = 1.1771,  ccr = 0.9573,  cwr = 0.9127,  ted = 1407.0000,  ned = 280.7137,  ted/w = 0.1941, 
[2022-07-06 01:03:40,432 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_150000
[2022-07-06 01:04:23,663 callbacks.py:105 INFO train-abinet] epoch 3 iter 150050: loss = 0.5453,  smooth loss = 0.5602
[2022-07-06 01:05:06,691 callbacks.py:105 INFO train-abinet] epoch 3 iter 150100: loss = 0.5748,  smooth loss = 0.5603
[2022-07-06 01:05:49,283 callbacks.py:105 INFO train-abinet] epoch 3 iter 150150: loss = 0.6770,  smooth loss = 0.5615
[2022-07-06 01:06:31,371 callbacks.py:105 INFO train-abinet] epoch 3 iter 150200: loss = 0.5128,  smooth loss = 0.5594
[2022-07-06 01:07:14,172 callbacks.py:105 INFO train-abinet] epoch 3 iter 150250: loss = 0.5659,  smooth loss = 0.5703
[2022-07-06 01:07:56,576 callbacks.py:105 INFO train-abinet] epoch 3 iter 150300: loss = 0.5855,  smooth loss = 0.5718
[2022-07-06 01:08:38,477 callbacks.py:105 INFO train-abinet] epoch 3 iter 150350: loss = 0.5700,  smooth loss = 0.5674
[2022-07-06 01:09:20,041 callbacks.py:105 INFO train-abinet] epoch 3 iter 150400: loss = 0.5623,  smooth loss = 0.5708
[2022-07-06 01:10:02,525 callbacks.py:105 INFO train-abinet] epoch 3 iter 150450: loss = 0.4770,  smooth loss = 0.5755
[2022-07-06 01:10:44,614 callbacks.py:105 INFO train-abinet] epoch 3 iter 150500: loss = 0.4901,  smooth loss = 0.5681
[2022-07-06 01:11:26,645 callbacks.py:105 INFO train-abinet] epoch 3 iter 150550: loss = 0.7512,  smooth loss = 0.5615
[2022-07-06 01:12:09,365 callbacks.py:105 INFO train-abinet] epoch 3 iter 150600: loss = 0.4760,  smooth loss = 0.5744
[2022-07-06 01:12:51,539 callbacks.py:105 INFO train-abinet] epoch 3 iter 150650: loss = 0.5276,  smooth loss = 0.5733
[2022-07-06 01:13:33,763 callbacks.py:105 INFO train-abinet] epoch 3 iter 150700: loss = 0.5757,  smooth loss = 0.5690
[2022-07-06 01:14:15,784 callbacks.py:105 INFO train-abinet] epoch 3 iter 150750: loss = 0.7055,  smooth loss = 0.5706
[2022-07-06 01:14:57,551 callbacks.py:105 INFO train-abinet] epoch 3 iter 150800: loss = 0.3866,  smooth loss = 0.5691
[2022-07-06 01:15:40,289 callbacks.py:105 INFO train-abinet] epoch 3 iter 150850: loss = 0.5391,  smooth loss = 0.5610
[2022-07-06 01:16:22,036 callbacks.py:105 INFO train-abinet] epoch 3 iter 150900: loss = 0.5093,  smooth loss = 0.5734
[2022-07-06 01:17:04,442 callbacks.py:105 INFO train-abinet] epoch 3 iter 150950: loss = 0.5479,  smooth loss = 0.5744
[2022-07-06 01:17:46,168 callbacks.py:105 INFO train-abinet] epoch 3 iter 151000: loss = 0.5677,  smooth loss = 0.5725
[2022-07-06 01:18:28,346 callbacks.py:105 INFO train-abinet] epoch 3 iter 151050: loss = 0.3744,  smooth loss = 0.5635
[2022-07-06 01:19:10,663 callbacks.py:105 INFO train-abinet] epoch 3 iter 151100: loss = 0.6474,  smooth loss = 0.5703
[2022-07-06 01:19:53,374 callbacks.py:105 INFO train-abinet] epoch 3 iter 151150: loss = 0.6930,  smooth loss = 0.5738
[2022-07-06 01:20:35,118 callbacks.py:105 INFO train-abinet] epoch 3 iter 151200: loss = 0.6534,  smooth loss = 0.5637
[2022-07-06 01:21:17,798 callbacks.py:105 INFO train-abinet] epoch 3 iter 151250: loss = 0.5155,  smooth loss = 0.5649
[2022-07-06 01:22:00,138 callbacks.py:105 INFO train-abinet] epoch 3 iter 151300: loss = 0.4791,  smooth loss = 0.5638
[2022-07-06 01:22:42,322 callbacks.py:105 INFO train-abinet] epoch 3 iter 151350: loss = 0.4606,  smooth loss = 0.5666
[2022-07-06 01:23:24,966 callbacks.py:105 INFO train-abinet] epoch 3 iter 151400: loss = 0.5636,  smooth loss = 0.5686
[2022-07-06 01:24:07,290 callbacks.py:105 INFO train-abinet] epoch 3 iter 151450: loss = 0.4651,  smooth loss = 0.5738
[2022-07-06 01:24:49,709 callbacks.py:105 INFO train-abinet] epoch 3 iter 151500: loss = 0.4837,  smooth loss = 0.5721
[2022-07-06 01:25:32,058 callbacks.py:105 INFO train-abinet] epoch 3 iter 151550: loss = 0.5516,  smooth loss = 0.5609
[2022-07-06 01:26:14,079 callbacks.py:105 INFO train-abinet] epoch 3 iter 151600: loss = 0.5607,  smooth loss = 0.5787
[2022-07-06 01:26:56,386 callbacks.py:105 INFO train-abinet] epoch 3 iter 151650: loss = 0.6119,  smooth loss = 0.5839
[2022-07-06 01:27:37,966 callbacks.py:105 INFO train-abinet] epoch 3 iter 151700: loss = 0.6498,  smooth loss = 0.5702
[2022-07-06 01:28:20,668 callbacks.py:105 INFO train-abinet] epoch 3 iter 151750: loss = 0.6940,  smooth loss = 0.5762
[2022-07-06 01:29:02,273 callbacks.py:105 INFO train-abinet] epoch 3 iter 151800: loss = 0.5046,  smooth loss = 0.5573
[2022-07-06 01:29:44,191 callbacks.py:105 INFO train-abinet] epoch 3 iter 151850: loss = 0.6389,  smooth loss = 0.5684
[2022-07-06 01:30:27,715 callbacks.py:105 INFO train-abinet] epoch 3 iter 151900: loss = 0.5413,  smooth loss = 0.5647
[2022-07-06 01:31:10,890 callbacks.py:105 INFO train-abinet] epoch 3 iter 151950: loss = 0.4565,  smooth loss = 0.5677
[2022-07-06 01:31:53,461 callbacks.py:105 INFO train-abinet] epoch 3 iter 152000: loss = 0.5284,  smooth loss = 0.5637
[2022-07-06 01:32:36,035 callbacks.py:105 INFO train-abinet] epoch 3 iter 152050: loss = 0.7230,  smooth loss = 0.5848
[2022-07-06 01:33:18,066 callbacks.py:105 INFO train-abinet] epoch 3 iter 152100: loss = 0.6052,  smooth loss = 0.5793
[2022-07-06 01:34:00,776 callbacks.py:105 INFO train-abinet] epoch 3 iter 152150: loss = 0.5777,  smooth loss = 0.5797
[2022-07-06 01:34:43,513 callbacks.py:105 INFO train-abinet] epoch 3 iter 152200: loss = 0.5602,  smooth loss = 0.5636
[2022-07-06 01:35:26,153 callbacks.py:105 INFO train-abinet] epoch 3 iter 152250: loss = 0.5014,  smooth loss = 0.5715
[2022-07-06 01:36:08,266 callbacks.py:105 INFO train-abinet] epoch 3 iter 152300: loss = 0.5255,  smooth loss = 0.5691
[2022-07-06 01:36:52,183 callbacks.py:105 INFO train-abinet] epoch 3 iter 152350: loss = 0.4398,  smooth loss = 0.5455
[2022-07-06 01:37:34,136 callbacks.py:105 INFO train-abinet] epoch 3 iter 152400: loss = 0.6259,  smooth loss = 0.5448
[2022-07-06 01:38:16,621 callbacks.py:105 INFO train-abinet] epoch 3 iter 152450: loss = 0.4952,  smooth loss = 0.5696
[2022-07-06 01:38:59,586 callbacks.py:105 INFO train-abinet] epoch 3 iter 152500: loss = 0.4323,  smooth loss = 0.5568
[2022-07-06 01:39:41,851 callbacks.py:105 INFO train-abinet] epoch 3 iter 152550: loss = 0.5949,  smooth loss = 0.5472
[2022-07-06 01:40:24,871 callbacks.py:105 INFO train-abinet] epoch 3 iter 152600: loss = 0.5325,  smooth loss = 0.5667
[2022-07-06 01:41:07,121 callbacks.py:105 INFO train-abinet] epoch 3 iter 152650: loss = 0.6691,  smooth loss = 0.5695
[2022-07-06 01:41:49,321 callbacks.py:105 INFO train-abinet] epoch 3 iter 152700: loss = 0.5475,  smooth loss = 0.5745
[2022-07-06 01:42:31,614 callbacks.py:105 INFO train-abinet] epoch 3 iter 152750: loss = 0.5076,  smooth loss = 0.5719
[2022-07-06 01:43:14,261 callbacks.py:105 INFO train-abinet] epoch 3 iter 152800: loss = 0.6879,  smooth loss = 0.5754
[2022-07-06 01:43:56,641 callbacks.py:105 INFO train-abinet] epoch 3 iter 152850: loss = 0.6872,  smooth loss = 0.5778
[2022-07-06 01:44:38,683 callbacks.py:105 INFO train-abinet] epoch 3 iter 152900: loss = 0.5878,  smooth loss = 0.5742
[2022-07-06 01:45:22,117 callbacks.py:105 INFO train-abinet] epoch 3 iter 152950: loss = 0.4623,  smooth loss = 0.5701
[2022-07-06 01:46:04,549 callbacks.py:105 INFO train-abinet] epoch 3 iter 153000: loss = 0.4269,  smooth loss = 0.5796
[2022-07-06 01:46:04,549 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8788s
█[2022-07-06 01:46:19,695 callbacks.py:123 INFO train-abinet] epoch 3 iter 153000: eval loss = 1.1763,  ccr = 0.9580,  cwr = 0.9135,  ted = 1385.0000,  ned = 273.9043,  ted/w = 0.1911, 
[2022-07-06 01:46:19,696 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_153000
[2022-07-06 01:47:03,226 callbacks.py:105 INFO train-abinet] epoch 3 iter 153050: loss = 0.4134,  smooth loss = 0.5648
[2022-07-06 01:47:45,889 callbacks.py:105 INFO train-abinet] epoch 3 iter 153100: loss = 0.5059,  smooth loss = 0.5569
[2022-07-06 01:48:29,010 callbacks.py:105 INFO train-abinet] epoch 3 iter 153150: loss = 0.5988,  smooth loss = 0.5585
[2022-07-06 01:49:11,801 callbacks.py:105 INFO train-abinet] epoch 3 iter 153200: loss = 0.4873,  smooth loss = 0.5637
[2022-07-06 01:49:54,110 callbacks.py:105 INFO train-abinet] epoch 3 iter 153250: loss = 0.8337,  smooth loss = 0.5706
[2022-07-06 01:50:37,522 callbacks.py:105 INFO train-abinet] epoch 3 iter 153300: loss = 0.6170,  smooth loss = 0.5574
[2022-07-06 01:51:20,362 callbacks.py:105 INFO train-abinet] epoch 3 iter 153350: loss = 0.5017,  smooth loss = 0.5608
[2022-07-06 01:52:03,120 callbacks.py:105 INFO train-abinet] epoch 3 iter 153400: loss = 0.4736,  smooth loss = 0.5497
[2022-07-06 01:52:45,795 callbacks.py:105 INFO train-abinet] epoch 3 iter 153450: loss = 0.5534,  smooth loss = 0.5630
[2022-07-06 01:53:28,799 callbacks.py:105 INFO train-abinet] epoch 3 iter 153500: loss = 0.5875,  smooth loss = 0.5744
[2022-07-06 01:54:11,090 callbacks.py:105 INFO train-abinet] epoch 3 iter 153550: loss = 0.4782,  smooth loss = 0.5687
[2022-07-06 01:54:53,246 callbacks.py:105 INFO train-abinet] epoch 3 iter 153600: loss = 0.5661,  smooth loss = 0.5714
[2022-07-06 01:55:35,176 callbacks.py:105 INFO train-abinet] epoch 3 iter 153650: loss = 0.5607,  smooth loss = 0.5657
[2022-07-06 01:56:17,658 callbacks.py:105 INFO train-abinet] epoch 3 iter 153700: loss = 0.5555,  smooth loss = 0.5624
[2022-07-06 01:57:00,150 callbacks.py:105 INFO train-abinet] epoch 3 iter 153750: loss = 0.5292,  smooth loss = 0.5584
[2022-07-06 01:57:42,070 callbacks.py:105 INFO train-abinet] epoch 3 iter 153800: loss = 0.5296,  smooth loss = 0.5661
[2022-07-06 01:58:24,812 callbacks.py:105 INFO train-abinet] epoch 3 iter 153850: loss = 0.4444,  smooth loss = 0.5692
[2022-07-06 01:59:07,424 callbacks.py:105 INFO train-abinet] epoch 3 iter 153900: loss = 0.5362,  smooth loss = 0.5657
[2022-07-06 01:59:49,880 callbacks.py:105 INFO train-abinet] epoch 3 iter 153950: loss = 0.5403,  smooth loss = 0.5674
[2022-07-06 02:00:32,903 callbacks.py:105 INFO train-abinet] epoch 3 iter 154000: loss = 0.6348,  smooth loss = 0.5632
[2022-07-06 02:01:15,357 callbacks.py:105 INFO train-abinet] epoch 3 iter 154050: loss = 0.6481,  smooth loss = 0.5797
[2022-07-06 02:01:57,704 callbacks.py:105 INFO train-abinet] epoch 3 iter 154100: loss = 0.5705,  smooth loss = 0.5750
[2022-07-06 02:02:40,119 callbacks.py:105 INFO train-abinet] epoch 3 iter 154150: loss = 0.5694,  smooth loss = 0.5748
[2022-07-06 02:03:22,364 callbacks.py:105 INFO train-abinet] epoch 3 iter 154200: loss = 0.4825,  smooth loss = 0.5687
[2022-07-06 02:04:05,338 callbacks.py:105 INFO train-abinet] epoch 3 iter 154250: loss = 0.6312,  smooth loss = 0.5718
[2022-07-06 02:04:47,895 callbacks.py:105 INFO train-abinet] epoch 3 iter 154300: loss = 0.4522,  smooth loss = 0.5594
[2022-07-06 02:05:30,762 callbacks.py:105 INFO train-abinet] epoch 3 iter 154350: loss = 0.5969,  smooth loss = 0.5657
[2022-07-06 02:06:13,429 callbacks.py:105 INFO train-abinet] epoch 3 iter 154400: loss = 0.5096,  smooth loss = 0.5677
[2022-07-06 02:06:56,111 callbacks.py:105 INFO train-abinet] epoch 3 iter 154450: loss = 0.5699,  smooth loss = 0.5696
[2022-07-06 02:07:38,706 callbacks.py:105 INFO train-abinet] epoch 3 iter 154500: loss = 0.4637,  smooth loss = 0.5544
[2022-07-06 02:08:20,835 callbacks.py:105 INFO train-abinet] epoch 3 iter 154550: loss = 0.6667,  smooth loss = 0.5624
[2022-07-06 02:09:02,862 callbacks.py:105 INFO train-abinet] epoch 3 iter 154600: loss = 0.6937,  smooth loss = 0.5641
[2022-07-06 02:09:44,554 callbacks.py:105 INFO train-abinet] epoch 3 iter 154650: loss = 0.7553,  smooth loss = 0.5756
[2022-07-06 02:10:26,964 callbacks.py:105 INFO train-abinet] epoch 3 iter 154700: loss = 0.5124,  smooth loss = 0.5610
[2022-07-06 02:11:09,305 callbacks.py:105 INFO train-abinet] epoch 3 iter 154750: loss = 0.6252,  smooth loss = 0.5629
[2022-07-06 02:11:50,877 callbacks.py:105 INFO train-abinet] epoch 3 iter 154800: loss = 0.7066,  smooth loss = 0.5707
[2022-07-06 02:12:33,007 callbacks.py:105 INFO train-abinet] epoch 3 iter 154850: loss = 0.6388,  smooth loss = 0.5556
[2022-07-06 02:13:15,236 callbacks.py:105 INFO train-abinet] epoch 3 iter 154900: loss = 0.4885,  smooth loss = 0.5605
[2022-07-06 02:13:58,057 callbacks.py:105 INFO train-abinet] epoch 3 iter 154950: loss = 0.5751,  smooth loss = 0.5547
[2022-07-06 02:14:39,618 callbacks.py:105 INFO train-abinet] epoch 3 iter 155000: loss = 0.5592,  smooth loss = 0.5639
[2022-07-06 02:15:22,137 callbacks.py:105 INFO train-abinet] epoch 3 iter 155050: loss = 0.4462,  smooth loss = 0.5723
[2022-07-06 02:16:03,918 callbacks.py:105 INFO train-abinet] epoch 3 iter 155100: loss = 0.5914,  smooth loss = 0.5722
[2022-07-06 02:16:46,405 callbacks.py:105 INFO train-abinet] epoch 3 iter 155150: loss = 0.5580,  smooth loss = 0.5711
[2022-07-06 02:17:28,228 callbacks.py:105 INFO train-abinet] epoch 3 iter 155200: loss = 0.4814,  smooth loss = 0.5543
[2022-07-06 02:18:10,045 callbacks.py:105 INFO train-abinet] epoch 3 iter 155250: loss = 0.6485,  smooth loss = 0.5554
[2022-07-06 02:18:52,518 callbacks.py:105 INFO train-abinet] epoch 3 iter 155300: loss = 0.5295,  smooth loss = 0.5634
[2022-07-06 02:19:35,248 callbacks.py:105 INFO train-abinet] epoch 3 iter 155350: loss = 0.5305,  smooth loss = 0.5643
[2022-07-06 02:20:17,821 callbacks.py:105 INFO train-abinet] epoch 3 iter 155400: loss = 0.4779,  smooth loss = 0.5721
[2022-07-06 02:21:00,606 callbacks.py:105 INFO train-abinet] epoch 3 iter 155450: loss = 0.5773,  smooth loss = 0.5839
[2022-07-06 02:21:42,337 callbacks.py:105 INFO train-abinet] epoch 3 iter 155500: loss = 0.5182,  smooth loss = 0.5684
[2022-07-06 02:22:24,397 callbacks.py:105 INFO train-abinet] epoch 3 iter 155550: loss = 0.4852,  smooth loss = 0.5594
[2022-07-06 02:23:07,254 callbacks.py:105 INFO train-abinet] epoch 3 iter 155600: loss = 0.5970,  smooth loss = 0.5599
[2022-07-06 02:23:49,680 callbacks.py:105 INFO train-abinet] epoch 3 iter 155650: loss = 0.4554,  smooth loss = 0.5743
[2022-07-06 02:24:31,721 callbacks.py:105 INFO train-abinet] epoch 3 iter 155700: loss = 0.4731,  smooth loss = 0.5723
[2022-07-06 02:25:13,729 callbacks.py:105 INFO train-abinet] epoch 3 iter 155750: loss = 0.6640,  smooth loss = 0.5619
[2022-07-06 02:25:56,563 callbacks.py:105 INFO train-abinet] epoch 3 iter 155800: loss = 0.5862,  smooth loss = 0.5621
[2022-07-06 02:26:40,338 callbacks.py:105 INFO train-abinet] epoch 3 iter 155850: loss = 0.6012,  smooth loss = 0.5695
[2022-07-06 02:27:21,849 callbacks.py:105 INFO train-abinet] epoch 3 iter 155900: loss = 0.5876,  smooth loss = 0.5609
[2022-07-06 02:28:04,032 callbacks.py:105 INFO train-abinet] epoch 3 iter 155950: loss = 0.6549,  smooth loss = 0.5597
[2022-07-06 02:28:45,974 callbacks.py:105 INFO train-abinet] epoch 3 iter 156000: loss = 0.4453,  smooth loss = 0.5627
[2022-07-06 02:28:45,975 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8783s
█[2022-07-06 02:29:00,671 callbacks.py:123 INFO train-abinet] epoch 3 iter 156000: eval loss = 1.1932,  ccr = 0.9581,  cwr = 0.9176,  ted = 1301.0000,  ned = 261.8907,  ted/w = 0.1795, 
[2022-07-06 02:29:00,673 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_156000
[2022-07-06 02:29:43,765 callbacks.py:105 INFO train-abinet] epoch 3 iter 156050: loss = 0.6297,  smooth loss = 0.5776
[2022-07-06 02:30:25,864 callbacks.py:105 INFO train-abinet] epoch 3 iter 156100: loss = 0.5624,  smooth loss = 0.5650
[2022-07-06 02:31:07,785 callbacks.py:105 INFO train-abinet] epoch 3 iter 156150: loss = 0.6173,  smooth loss = 0.5689
[2022-07-06 02:31:50,389 callbacks.py:105 INFO train-abinet] epoch 3 iter 156200: loss = 0.6575,  smooth loss = 0.5646
[2022-07-06 02:32:32,309 callbacks.py:105 INFO train-abinet] epoch 3 iter 156250: loss = 0.6407,  smooth loss = 0.5657
[2022-07-06 02:33:14,708 callbacks.py:105 INFO train-abinet] epoch 3 iter 156300: loss = 0.5140,  smooth loss = 0.5600
[2022-07-06 02:33:57,507 callbacks.py:105 INFO train-abinet] epoch 3 iter 156350: loss = 0.6354,  smooth loss = 0.5631
[2022-07-06 02:34:40,272 callbacks.py:105 INFO train-abinet] epoch 3 iter 156400: loss = 0.6465,  smooth loss = 0.5648
[2022-07-06 02:35:23,038 callbacks.py:105 INFO train-abinet] epoch 3 iter 156450: loss = 0.5309,  smooth loss = 0.5534
[2022-07-06 02:36:05,806 callbacks.py:105 INFO train-abinet] epoch 3 iter 156500: loss = 0.5489,  smooth loss = 0.5645
[2022-07-06 02:36:47,368 callbacks.py:105 INFO train-abinet] epoch 3 iter 156550: loss = 0.5136,  smooth loss = 0.5690
[2022-07-06 02:37:29,819 callbacks.py:105 INFO train-abinet] epoch 3 iter 156600: loss = 0.4494,  smooth loss = 0.5554
[2022-07-06 02:38:11,900 callbacks.py:105 INFO train-abinet] epoch 3 iter 156650: loss = 0.6429,  smooth loss = 0.5572
[2022-07-06 02:38:53,452 callbacks.py:105 INFO train-abinet] epoch 3 iter 156700: loss = 0.5304,  smooth loss = 0.5639
[2022-07-06 02:39:35,898 callbacks.py:105 INFO train-abinet] epoch 3 iter 156750: loss = 0.5185,  smooth loss = 0.5784
[2022-07-06 02:40:17,711 callbacks.py:105 INFO train-abinet] epoch 3 iter 156800: loss = 0.5160,  smooth loss = 0.5723
[2022-07-06 02:40:59,765 callbacks.py:105 INFO train-abinet] epoch 3 iter 156850: loss = 0.5653,  smooth loss = 0.5610
[2022-07-06 02:41:41,650 callbacks.py:105 INFO train-abinet] epoch 3 iter 156900: loss = 0.5544,  smooth loss = 0.5646
[2022-07-06 02:42:23,005 callbacks.py:105 INFO train-abinet] epoch 3 iter 156950: loss = 0.5564,  smooth loss = 0.5809
[2022-07-06 02:43:05,124 callbacks.py:105 INFO train-abinet] epoch 3 iter 157000: loss = 0.7339,  smooth loss = 0.5663
[2022-07-06 02:43:46,952 callbacks.py:105 INFO train-abinet] epoch 3 iter 157050: loss = 0.5939,  smooth loss = 0.5616
[2022-07-06 02:44:28,855 callbacks.py:105 INFO train-abinet] epoch 3 iter 157100: loss = 0.4553,  smooth loss = 0.5679
[2022-07-06 02:45:10,157 callbacks.py:105 INFO train-abinet] epoch 3 iter 157150: loss = 0.6577,  smooth loss = 0.5611
[2022-07-06 02:45:52,318 callbacks.py:105 INFO train-abinet] epoch 3 iter 157200: loss = 0.7655,  smooth loss = 0.5724
[2022-07-06 02:46:33,896 callbacks.py:105 INFO train-abinet] epoch 3 iter 157250: loss = 0.6523,  smooth loss = 0.5679
[2022-07-06 02:47:16,620 callbacks.py:105 INFO train-abinet] epoch 3 iter 157300: loss = 0.5098,  smooth loss = 0.5587
[2022-07-06 02:47:58,484 callbacks.py:105 INFO train-abinet] epoch 3 iter 157350: loss = 0.5375,  smooth loss = 0.5597
[2022-07-06 02:48:40,401 callbacks.py:105 INFO train-abinet] epoch 3 iter 157400: loss = 0.5488,  smooth loss = 0.5646
[2022-07-06 02:49:22,231 callbacks.py:105 INFO train-abinet] epoch 3 iter 157450: loss = 0.5096,  smooth loss = 0.5505
[2022-07-06 02:50:03,240 callbacks.py:105 INFO train-abinet] epoch 3 iter 157500: loss = 0.6065,  smooth loss = 0.5627
[2022-07-06 02:50:45,737 callbacks.py:105 INFO train-abinet] epoch 3 iter 157550: loss = 0.5474,  smooth loss = 0.5613
[2022-07-06 02:51:27,907 callbacks.py:105 INFO train-abinet] epoch 3 iter 157600: loss = 0.6540,  smooth loss = 0.5580
[2022-07-06 02:52:09,629 callbacks.py:105 INFO train-abinet] epoch 3 iter 157650: loss = 0.5108,  smooth loss = 0.5617
[2022-07-06 02:52:52,203 callbacks.py:105 INFO train-abinet] epoch 3 iter 157700: loss = 0.5265,  smooth loss = 0.5523
[2022-07-06 02:53:33,816 callbacks.py:105 INFO train-abinet] epoch 3 iter 157750: loss = 0.5416,  smooth loss = 0.5588
[2022-07-06 02:54:16,623 callbacks.py:105 INFO train-abinet] epoch 3 iter 157800: loss = 0.6844,  smooth loss = 0.5737
[2022-07-06 02:54:58,294 callbacks.py:105 INFO train-abinet] epoch 3 iter 157850: loss = 0.4761,  smooth loss = 0.5637
[2022-07-06 02:55:40,734 callbacks.py:105 INFO train-abinet] epoch 3 iter 157900: loss = 0.5983,  smooth loss = 0.5544
[2022-07-06 02:56:23,130 callbacks.py:105 INFO train-abinet] epoch 3 iter 157950: loss = 0.5254,  smooth loss = 0.5638
[2022-07-06 02:57:04,894 callbacks.py:105 INFO train-abinet] epoch 3 iter 158000: loss = 0.6640,  smooth loss = 0.5608
[2022-07-06 02:57:46,670 callbacks.py:105 INFO train-abinet] epoch 3 iter 158050: loss = 0.7631,  smooth loss = 0.5595
[2022-07-06 02:58:27,435 callbacks.py:105 INFO train-abinet] epoch 3 iter 158100: loss = 0.6039,  smooth loss = 0.5506
[2022-07-06 02:59:09,269 callbacks.py:105 INFO train-abinet] epoch 3 iter 158150: loss = 0.4849,  smooth loss = 0.5656
[2022-07-06 02:59:50,922 callbacks.py:105 INFO train-abinet] epoch 3 iter 158200: loss = 0.4350,  smooth loss = 0.5789
[2022-07-06 03:00:32,841 callbacks.py:105 INFO train-abinet] epoch 3 iter 158250: loss = 0.5906,  smooth loss = 0.5736
[2022-07-06 03:01:15,103 callbacks.py:105 INFO train-abinet] epoch 3 iter 158300: loss = 0.5325,  smooth loss = 0.5665
[2022-07-06 03:01:56,704 callbacks.py:105 INFO train-abinet] epoch 3 iter 158350: loss = 0.4963,  smooth loss = 0.5554
[2022-07-06 03:02:38,292 callbacks.py:105 INFO train-abinet] epoch 3 iter 158400: loss = 0.6097,  smooth loss = 0.5612
[2022-07-06 03:03:19,947 callbacks.py:105 INFO train-abinet] epoch 3 iter 158450: loss = 0.5358,  smooth loss = 0.5579
[2022-07-06 03:04:01,584 callbacks.py:105 INFO train-abinet] epoch 3 iter 158500: loss = 0.5572,  smooth loss = 0.5668
[2022-07-06 03:04:43,228 callbacks.py:105 INFO train-abinet] epoch 3 iter 158550: loss = 0.5333,  smooth loss = 0.5684
[2022-07-06 03:05:25,373 callbacks.py:105 INFO train-abinet] epoch 3 iter 158600: loss = 0.5300,  smooth loss = 0.5642
[2022-07-06 03:06:07,460 callbacks.py:105 INFO train-abinet] epoch 3 iter 158650: loss = 0.5335,  smooth loss = 0.5593
[2022-07-06 03:06:49,728 callbacks.py:105 INFO train-abinet] epoch 3 iter 158700: loss = 0.5950,  smooth loss = 0.5640
[2022-07-06 03:07:30,963 callbacks.py:105 INFO train-abinet] epoch 3 iter 158750: loss = 0.6055,  smooth loss = 0.5594
[2022-07-06 03:08:12,711 callbacks.py:105 INFO train-abinet] epoch 3 iter 158800: loss = 0.6603,  smooth loss = 0.5703
[2022-07-06 03:08:53,991 callbacks.py:105 INFO train-abinet] epoch 3 iter 158850: loss = 0.6602,  smooth loss = 0.5716
[2022-07-06 03:09:35,461 callbacks.py:105 INFO train-abinet] epoch 3 iter 158900: loss = 0.6436,  smooth loss = 0.5720
[2022-07-06 03:10:17,275 callbacks.py:105 INFO train-abinet] epoch 3 iter 158950: loss = 0.5961,  smooth loss = 0.5694
[2022-07-06 03:10:58,512 callbacks.py:105 INFO train-abinet] epoch 3 iter 159000: loss = 0.6227,  smooth loss = 0.5629
[2022-07-06 03:10:58,512 callbacks.py:114 INFO train-abinet] average data time = 0.0055s, average running time = 0.8776s
█[2022-07-06 03:11:13,097 callbacks.py:123 INFO train-abinet] epoch 3 iter 159000: eval loss = 1.1669,  ccr = 0.9586,  cwr = 0.9128,  ted = 1379.0000,  ned = 275.8715,  ted/w = 0.1903, 
[2022-07-06 03:11:13,099 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_159000
[2022-07-06 03:11:55,738 callbacks.py:105 INFO train-abinet] epoch 3 iter 159050: loss = 0.4661,  smooth loss = 0.5668
[2022-07-06 03:12:37,762 callbacks.py:105 INFO train-abinet] epoch 3 iter 159100: loss = 0.6119,  smooth loss = 0.5634
[2022-07-06 03:13:19,028 callbacks.py:105 INFO train-abinet] epoch 3 iter 159150: loss = 0.5473,  smooth loss = 0.5703
[2022-07-06 03:14:00,820 callbacks.py:105 INFO train-abinet] epoch 3 iter 159200: loss = 0.4756,  smooth loss = 0.5670
[2022-07-06 03:14:42,405 callbacks.py:105 INFO train-abinet] epoch 3 iter 159250: loss = 0.5781,  smooth loss = 0.5663
[2022-07-06 03:15:23,977 callbacks.py:105 INFO train-abinet] epoch 3 iter 159300: loss = 0.5526,  smooth loss = 0.5613
[2022-07-06 03:16:06,085 callbacks.py:105 INFO train-abinet] epoch 3 iter 159350: loss = 0.5302,  smooth loss = 0.5688
[2022-07-06 03:16:47,712 callbacks.py:105 INFO train-abinet] epoch 3 iter 159400: loss = 0.6496,  smooth loss = 0.5587
[2022-07-06 03:17:29,081 callbacks.py:105 INFO train-abinet] epoch 3 iter 159450: loss = 0.6806,  smooth loss = 0.5660
[2022-07-06 03:18:10,621 callbacks.py:105 INFO train-abinet] epoch 3 iter 159500: loss = 0.8304,  smooth loss = 0.5531
[2022-07-06 03:18:52,191 callbacks.py:105 INFO train-abinet] epoch 3 iter 159550: loss = 0.5772,  smooth loss = 0.5613
[2022-07-06 03:19:34,040 callbacks.py:105 INFO train-abinet] epoch 3 iter 159600: loss = 0.6110,  smooth loss = 0.5659
[2022-07-06 03:20:15,377 callbacks.py:105 INFO train-abinet] epoch 3 iter 159650: loss = 0.6202,  smooth loss = 0.5539
[2022-07-06 03:20:57,196 callbacks.py:105 INFO train-abinet] epoch 3 iter 159700: loss = 0.5469,  smooth loss = 0.5579
[2022-07-06 03:21:38,565 callbacks.py:105 INFO train-abinet] epoch 3 iter 159750: loss = 0.6559,  smooth loss = 0.5417
[2022-07-06 03:22:20,348 callbacks.py:105 INFO train-abinet] epoch 3 iter 159800: loss = 0.6756,  smooth loss = 0.5706
[2022-07-06 03:23:01,962 callbacks.py:105 INFO train-abinet] epoch 3 iter 159850: loss = 0.5474,  smooth loss = 0.5721
[2022-07-06 03:23:42,918 callbacks.py:105 INFO train-abinet] epoch 3 iter 159900: loss = 0.5177,  smooth loss = 0.5786
[2022-07-06 03:24:25,346 callbacks.py:105 INFO train-abinet] epoch 3 iter 159950: loss = 0.5441,  smooth loss = 0.5833
[2022-07-06 03:25:06,645 callbacks.py:105 INFO train-abinet] epoch 3 iter 160000: loss = 0.3750,  smooth loss = 0.5676
[2022-07-06 03:25:48,296 callbacks.py:105 INFO train-abinet] epoch 3 iter 160050: loss = 0.3738,  smooth loss = 0.5662
[2022-07-06 03:26:30,615 callbacks.py:105 INFO train-abinet] epoch 3 iter 160100: loss = 0.5857,  smooth loss = 0.5641
[2022-07-06 03:27:11,927 callbacks.py:105 INFO train-abinet] epoch 3 iter 160150: loss = 0.5823,  smooth loss = 0.5512
[2022-07-06 03:27:53,770 callbacks.py:105 INFO train-abinet] epoch 3 iter 160200: loss = 0.3818,  smooth loss = 0.5600
[2022-07-06 03:28:34,998 callbacks.py:105 INFO train-abinet] epoch 3 iter 160250: loss = 0.5613,  smooth loss = 0.5579
[2022-07-06 03:29:16,308 callbacks.py:105 INFO train-abinet] epoch 3 iter 160300: loss = 0.5272,  smooth loss = 0.5566
[2022-07-06 03:29:57,814 callbacks.py:105 INFO train-abinet] epoch 3 iter 160350: loss = 0.4707,  smooth loss = 0.5613
[2022-07-06 03:30:38,899 callbacks.py:105 INFO train-abinet] epoch 3 iter 160400: loss = 0.7241,  smooth loss = 0.5674
[2022-07-06 03:31:20,981 callbacks.py:105 INFO train-abinet] epoch 3 iter 160450: loss = 0.5571,  smooth loss = 0.5657
[2022-07-06 03:32:02,290 callbacks.py:105 INFO train-abinet] epoch 3 iter 160500: loss = 0.5807,  smooth loss = 0.5845
[2022-07-06 03:32:43,086 callbacks.py:105 INFO train-abinet] epoch 3 iter 160550: loss = 0.7053,  smooth loss = 0.5726
[2022-07-06 03:33:24,718 callbacks.py:105 INFO train-abinet] epoch 3 iter 160600: loss = 0.4923,  smooth loss = 0.5574
[2022-07-06 03:34:06,275 callbacks.py:105 INFO train-abinet] epoch 3 iter 160650: loss = 0.5703,  smooth loss = 0.5640
[2022-07-06 03:34:48,333 callbacks.py:105 INFO train-abinet] epoch 3 iter 160700: loss = 0.5094,  smooth loss = 0.5623
[2022-07-06 03:35:29,123 callbacks.py:105 INFO train-abinet] epoch 3 iter 160750: loss = 0.4286,  smooth loss = 0.5666
[2022-07-06 03:36:11,136 callbacks.py:105 INFO train-abinet] epoch 3 iter 160800: loss = 0.5824,  smooth loss = 0.5568
[2022-07-06 03:36:52,364 callbacks.py:105 INFO train-abinet] epoch 3 iter 160850: loss = 0.6915,  smooth loss = 0.5539
[2022-07-06 03:37:33,947 callbacks.py:105 INFO train-abinet] epoch 3 iter 160900: loss = 0.7516,  smooth loss = 0.5535
[2022-07-06 03:38:14,879 callbacks.py:105 INFO train-abinet] epoch 3 iter 160950: loss = 0.4815,  smooth loss = 0.5546
[2022-07-06 03:38:56,753 callbacks.py:105 INFO train-abinet] epoch 3 iter 161000: loss = 0.6399,  smooth loss = 0.5651
[2022-07-06 03:39:39,095 callbacks.py:105 INFO train-abinet] epoch 3 iter 161050: loss = 0.6751,  smooth loss = 0.5693
[2022-07-06 03:40:20,501 callbacks.py:105 INFO train-abinet] epoch 3 iter 161100: loss = 0.4724,  smooth loss = 0.5623
[2022-07-06 03:41:03,377 callbacks.py:105 INFO train-abinet] epoch 3 iter 161150: loss = 0.4724,  smooth loss = 0.5600
[2022-07-06 03:41:45,233 callbacks.py:105 INFO train-abinet] epoch 3 iter 161200: loss = 0.6101,  smooth loss = 0.5666
[2022-07-06 03:42:26,248 callbacks.py:105 INFO train-abinet] epoch 3 iter 161250: loss = 0.6959,  smooth loss = 0.5719
[2022-07-06 03:43:07,647 callbacks.py:105 INFO train-abinet] epoch 3 iter 161300: loss = 0.5349,  smooth loss = 0.5659
[2022-07-06 03:43:48,881 callbacks.py:105 INFO train-abinet] epoch 3 iter 161350: loss = 0.4156,  smooth loss = 0.5655
[2022-07-06 03:44:30,894 callbacks.py:105 INFO train-abinet] epoch 3 iter 161400: loss = 0.6374,  smooth loss = 0.5717
[2022-07-06 03:45:12,699 callbacks.py:105 INFO train-abinet] epoch 3 iter 161450: loss = 0.6408,  smooth loss = 0.5620
[2022-07-06 03:45:54,623 callbacks.py:105 INFO train-abinet] epoch 3 iter 161500: loss = 0.4862,  smooth loss = 0.5593
[2022-07-06 03:46:36,402 callbacks.py:105 INFO train-abinet] epoch 3 iter 161550: loss = 0.6202,  smooth loss = 0.5520
[2022-07-06 03:47:17,777 callbacks.py:105 INFO train-abinet] epoch 3 iter 161600: loss = 0.4879,  smooth loss = 0.5595
[2022-07-06 03:47:59,014 callbacks.py:105 INFO train-abinet] epoch 3 iter 161650: loss = 0.6165,  smooth loss = 0.5568
[2022-07-06 03:48:40,663 callbacks.py:105 INFO train-abinet] epoch 3 iter 161700: loss = 0.6041,  smooth loss = 0.5621
[2022-07-06 03:49:22,125 callbacks.py:105 INFO train-abinet] epoch 3 iter 161750: loss = 0.5790,  smooth loss = 0.5705
[2022-07-06 03:50:03,272 callbacks.py:105 INFO train-abinet] epoch 3 iter 161800: loss = 0.6159,  smooth loss = 0.5559
[2022-07-06 03:50:43,888 callbacks.py:105 INFO train-abinet] epoch 3 iter 161850: loss = 0.6294,  smooth loss = 0.5648
[2022-07-06 03:51:25,455 callbacks.py:105 INFO train-abinet] epoch 3 iter 161900: loss = 0.6698,  smooth loss = 0.5684
[2022-07-06 03:52:06,444 callbacks.py:105 INFO train-abinet] epoch 3 iter 161950: loss = 0.5288,  smooth loss = 0.5674
[2022-07-06 03:52:47,964 callbacks.py:105 INFO train-abinet] epoch 3 iter 162000: loss = 0.6420,  smooth loss = 0.5526
[2022-07-06 03:52:47,965 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8767s
█[2022-07-06 03:53:02,313 callbacks.py:123 INFO train-abinet] epoch 3 iter 162000: eval loss = 1.1498,  ccr = 0.9594,  cwr = 0.9158,  ted = 1317.0000,  ned = 263.7279,  ted/w = 0.1817, 
[2022-07-06 03:53:02,314 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_162000
[2022-07-06 03:53:44,084 callbacks.py:105 INFO train-abinet] epoch 3 iter 162050: loss = 0.5641,  smooth loss = 0.5514
[2022-07-06 03:54:24,849 callbacks.py:105 INFO train-abinet] epoch 3 iter 162100: loss = 0.4701,  smooth loss = 0.5623
[2022-07-06 03:55:06,001 callbacks.py:105 INFO train-abinet] epoch 3 iter 162150: loss = 0.5298,  smooth loss = 0.5559
[2022-07-06 03:55:46,876 callbacks.py:105 INFO train-abinet] epoch 3 iter 162200: loss = 0.5601,  smooth loss = 0.5637
[2022-07-06 03:56:28,723 callbacks.py:105 INFO train-abinet] epoch 3 iter 162250: loss = 0.4858,  smooth loss = 0.5573
[2022-07-06 03:57:09,355 callbacks.py:105 INFO train-abinet] epoch 3 iter 162300: loss = 0.5597,  smooth loss = 0.5547
[2022-07-06 03:57:51,187 callbacks.py:105 INFO train-abinet] epoch 3 iter 162350: loss = 0.4957,  smooth loss = 0.5543
[2022-07-06 03:58:32,484 callbacks.py:105 INFO train-abinet] epoch 3 iter 162400: loss = 0.5297,  smooth loss = 0.5576
[2022-07-06 03:59:12,914 callbacks.py:105 INFO train-abinet] epoch 3 iter 162450: loss = 0.4704,  smooth loss = 0.5551
[2022-07-06 03:59:54,374 callbacks.py:105 INFO train-abinet] epoch 3 iter 162500: loss = 0.4244,  smooth loss = 0.5515
[2022-07-06 04:00:36,244 callbacks.py:105 INFO train-abinet] epoch 3 iter 162550: loss = 0.6683,  smooth loss = 0.5499
[2022-07-06 04:01:17,458 callbacks.py:105 INFO train-abinet] epoch 3 iter 162600: loss = 0.5286,  smooth loss = 0.5548
[2022-07-06 04:01:58,927 callbacks.py:105 INFO train-abinet] epoch 3 iter 162650: loss = 0.4243,  smooth loss = 0.5635
[2022-07-06 04:02:39,573 callbacks.py:105 INFO train-abinet] epoch 3 iter 162700: loss = 0.5513,  smooth loss = 0.5593
[2022-07-06 04:03:20,596 callbacks.py:105 INFO train-abinet] epoch 3 iter 162750: loss = 0.7903,  smooth loss = 0.5625
[2022-07-06 04:04:01,561 callbacks.py:105 INFO train-abinet] epoch 3 iter 162800: loss = 0.6924,  smooth loss = 0.5544
[2022-07-06 04:04:42,226 callbacks.py:105 INFO train-abinet] epoch 3 iter 162850: loss = 0.6113,  smooth loss = 0.5536
[2022-07-06 04:05:24,082 callbacks.py:105 INFO train-abinet] epoch 3 iter 162900: loss = 0.5157,  smooth loss = 0.5541
[2022-07-06 04:06:05,720 callbacks.py:105 INFO train-abinet] epoch 3 iter 162950: loss = 0.6435,  smooth loss = 0.5684
[2022-07-06 04:06:48,394 callbacks.py:105 INFO train-abinet] epoch 3 iter 163000: loss = 0.5485,  smooth loss = 0.5556
[2022-07-06 04:07:29,892 callbacks.py:105 INFO train-abinet] epoch 3 iter 163050: loss = 0.4903,  smooth loss = 0.5625
[2022-07-06 04:08:10,750 callbacks.py:105 INFO train-abinet] epoch 3 iter 163100: loss = 0.6021,  smooth loss = 0.5522
[2022-07-06 04:08:51,385 callbacks.py:105 INFO train-abinet] epoch 3 iter 163150: loss = 0.5708,  smooth loss = 0.5613
[2022-07-06 04:09:33,407 callbacks.py:105 INFO train-abinet] epoch 3 iter 163200: loss = 0.4317,  smooth loss = 0.5653
[2022-07-06 04:10:14,669 callbacks.py:105 INFO train-abinet] epoch 3 iter 163250: loss = 0.6397,  smooth loss = 0.5743
[2022-07-06 04:10:56,810 callbacks.py:105 INFO train-abinet] epoch 3 iter 163300: loss = 0.6660,  smooth loss = 0.5688
[2022-07-06 04:11:39,126 callbacks.py:105 INFO train-abinet] epoch 3 iter 163350: loss = 0.6782,  smooth loss = 0.5595
[2022-07-06 04:12:20,328 callbacks.py:105 INFO train-abinet] epoch 3 iter 163400: loss = 0.5843,  smooth loss = 0.5627
[2022-07-06 04:13:01,273 callbacks.py:105 INFO train-abinet] epoch 3 iter 163450: loss = 0.7242,  smooth loss = 0.5605
[2022-07-06 04:13:42,887 callbacks.py:105 INFO train-abinet] epoch 3 iter 163500: loss = 0.4311,  smooth loss = 0.5592
[2022-07-06 04:14:24,463 callbacks.py:105 INFO train-abinet] epoch 3 iter 163550: loss = 0.5656,  smooth loss = 0.5459
[2022-07-06 04:15:04,956 callbacks.py:105 INFO train-abinet] epoch 3 iter 163600: loss = 0.5380,  smooth loss = 0.5443
[2022-07-06 04:15:46,018 callbacks.py:105 INFO train-abinet] epoch 3 iter 163650: loss = 0.4231,  smooth loss = 0.5511
[2022-07-06 04:16:27,476 callbacks.py:105 INFO train-abinet] epoch 3 iter 163700: loss = 0.5937,  smooth loss = 0.5554
[2022-07-06 04:17:09,217 callbacks.py:105 INFO train-abinet] epoch 3 iter 163750: loss = 0.5215,  smooth loss = 0.5559
[2022-07-06 04:17:51,917 callbacks.py:105 INFO train-abinet] epoch 3 iter 163800: loss = 0.6329,  smooth loss = 0.5649
[2022-07-06 04:18:33,039 callbacks.py:105 INFO train-abinet] epoch 3 iter 163850: loss = 0.3816,  smooth loss = 0.5516
[2022-07-06 04:19:14,848 callbacks.py:105 INFO train-abinet] epoch 3 iter 163900: loss = 0.6810,  smooth loss = 0.5677
[2022-07-06 04:19:56,735 callbacks.py:105 INFO train-abinet] epoch 3 iter 163950: loss = 0.6541,  smooth loss = 0.5665
[2022-07-06 04:20:39,032 callbacks.py:105 INFO train-abinet] epoch 3 iter 164000: loss = 0.5490,  smooth loss = 0.5655
[2022-07-06 04:21:21,170 callbacks.py:105 INFO train-abinet] epoch 3 iter 164050: loss = 0.6042,  smooth loss = 0.5674
[2022-07-06 04:22:01,916 callbacks.py:105 INFO train-abinet] epoch 3 iter 164100: loss = 0.5670,  smooth loss = 0.5548
[2022-07-06 04:22:43,633 callbacks.py:105 INFO train-abinet] epoch 3 iter 164150: loss = 0.6536,  smooth loss = 0.5611
[2022-07-06 04:23:25,157 callbacks.py:105 INFO train-abinet] epoch 3 iter 164200: loss = 0.5389,  smooth loss = 0.5682
[2022-07-06 04:24:06,370 callbacks.py:105 INFO train-abinet] epoch 3 iter 164250: loss = 0.7172,  smooth loss = 0.5633
[2022-07-06 04:24:47,580 callbacks.py:105 INFO train-abinet] epoch 3 iter 164300: loss = 0.7269,  smooth loss = 0.5546
[2022-07-06 04:25:27,920 callbacks.py:105 INFO train-abinet] epoch 3 iter 164350: loss = 0.5429,  smooth loss = 0.5662
[2022-07-06 04:26:09,536 callbacks.py:105 INFO train-abinet] epoch 3 iter 164400: loss = 0.5662,  smooth loss = 0.5692
[2022-07-06 04:26:50,506 callbacks.py:105 INFO train-abinet] epoch 3 iter 164450: loss = 0.6882,  smooth loss = 0.5558
[2022-07-06 04:27:32,105 callbacks.py:105 INFO train-abinet] epoch 3 iter 164500: loss = 0.5377,  smooth loss = 0.5689
[2022-07-06 04:28:13,351 callbacks.py:105 INFO train-abinet] epoch 3 iter 164550: loss = 0.6152,  smooth loss = 0.5586
[2022-07-06 04:28:55,171 callbacks.py:105 INFO train-abinet] epoch 3 iter 164600: loss = 0.6325,  smooth loss = 0.5704
[2022-07-06 04:29:36,765 callbacks.py:105 INFO train-abinet] epoch 3 iter 164650: loss = 0.6317,  smooth loss = 0.5794
[2022-07-06 04:30:18,168 callbacks.py:105 INFO train-abinet] epoch 3 iter 164700: loss = 0.6021,  smooth loss = 0.5615
[2022-07-06 04:30:58,935 callbacks.py:105 INFO train-abinet] epoch 3 iter 164750: loss = 0.8724,  smooth loss = 0.5584
[2022-07-06 04:31:41,014 callbacks.py:105 INFO train-abinet] epoch 3 iter 164800: loss = 0.4200,  smooth loss = 0.5538
[2022-07-06 04:32:22,600 callbacks.py:105 INFO train-abinet] epoch 3 iter 164850: loss = 0.4668,  smooth loss = 0.5481
[2022-07-06 04:33:03,641 callbacks.py:105 INFO train-abinet] epoch 3 iter 164900: loss = 0.5347,  smooth loss = 0.5614
[2022-07-06 04:33:45,860 callbacks.py:105 INFO train-abinet] epoch 3 iter 164950: loss = 0.5176,  smooth loss = 0.5731
[2022-07-06 04:34:27,162 callbacks.py:105 INFO train-abinet] epoch 3 iter 165000: loss = 0.5595,  smooth loss = 0.5653
[2022-07-06 04:34:27,163 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8759s
█[2022-07-06 04:34:41,948 callbacks.py:123 INFO train-abinet] epoch 3 iter 165000: eval loss = 1.1708,  ccr = 0.9547,  cwr = 0.9109,  ted = 1422.0000,  ned = 285.9310,  ted/w = 0.1962, 
[2022-07-06 04:34:41,950 callbacks.py:136 INFO train-abinet] Save model train-abinet_3_165000
[2022-07-06 04:35:24,845 callbacks.py:105 INFO train-abinet] epoch 3 iter 165050: loss = 0.6289,  smooth loss = 0.5776
[2022-07-06 04:36:06,100 callbacks.py:105 INFO train-abinet] epoch 3 iter 165100: loss = 0.6402,  smooth loss = 0.5798
[2022-07-06 04:36:48,134 callbacks.py:105 INFO train-abinet] epoch 3 iter 165150: loss = 0.5101,  smooth loss = 0.5755
[2022-07-06 04:37:29,606 callbacks.py:105 INFO train-abinet] epoch 3 iter 165200: loss = 0.5645,  smooth loss = 0.5633
[2022-07-06 04:38:11,025 callbacks.py:105 INFO train-abinet] epoch 3 iter 165250: loss = 0.6682,  smooth loss = 0.5580
[2022-07-06 04:38:53,590 callbacks.py:105 INFO train-abinet] epoch 3 iter 165300: loss = 0.7123,  smooth loss = 0.5494
[2022-07-06 04:39:34,751 callbacks.py:105 INFO train-abinet] epoch 3 iter 165350: loss = 0.5287,  smooth loss = 0.5537
[2022-07-06 04:40:16,158 callbacks.py:105 INFO train-abinet] epoch 3 iter 165400: loss = 0.6147,  smooth loss = 0.5686
[2022-07-06 04:40:57,685 callbacks.py:105 INFO train-abinet] epoch 3 iter 165450: loss = 0.6813,  smooth loss = 0.5687
[2022-07-06 04:41:39,625 callbacks.py:105 INFO train-abinet] epoch 3 iter 165500: loss = 0.4353,  smooth loss = 0.5593
[2022-07-06 04:42:23,209 callbacks.py:105 INFO train-abinet] epoch 3 iter 165550: loss = 0.5150,  smooth loss = 0.5603
█[2022-07-06 04:43:09,835 callbacks.py:105 INFO train-abinet] epoch 4 iter 165600: loss = 0.4578,  smooth loss = 0.5675
[2022-07-06 04:43:50,673 callbacks.py:105 INFO train-abinet] epoch 4 iter 165650: loss = 0.3989,  smooth loss = 0.5389
[2022-07-06 04:44:32,101 callbacks.py:105 INFO train-abinet] epoch 4 iter 165700: loss = 0.4573,  smooth loss = 0.5378
[2022-07-06 04:45:13,285 callbacks.py:105 INFO train-abinet] epoch 4 iter 165750: loss = 0.6368,  smooth loss = 0.5591
[2022-07-06 04:45:55,530 callbacks.py:105 INFO train-abinet] epoch 4 iter 165800: loss = 0.6475,  smooth loss = 0.5705
[2022-07-06 04:46:37,178 callbacks.py:105 INFO train-abinet] epoch 4 iter 165850: loss = 0.4368,  smooth loss = 0.5600
[2022-07-06 04:47:19,510 callbacks.py:105 INFO train-abinet] epoch 4 iter 165900: loss = 0.5863,  smooth loss = 0.5682
[2022-07-06 04:48:00,697 callbacks.py:105 INFO train-abinet] epoch 4 iter 165950: loss = 0.5267,  smooth loss = 0.5518
[2022-07-06 04:48:41,591 callbacks.py:105 INFO train-abinet] epoch 4 iter 166000: loss = 0.5537,  smooth loss = 0.5551
[2022-07-06 04:49:23,208 callbacks.py:105 INFO train-abinet] epoch 4 iter 166050: loss = 0.5909,  smooth loss = 0.5511
[2022-07-06 04:50:05,029 callbacks.py:105 INFO train-abinet] epoch 4 iter 166100: loss = 0.4938,  smooth loss = 0.5646
[2022-07-06 04:50:46,357 callbacks.py:105 INFO train-abinet] epoch 4 iter 166150: loss = 0.5093,  smooth loss = 0.5660
[2022-07-06 04:51:28,228 callbacks.py:105 INFO train-abinet] epoch 4 iter 166200: loss = 0.4802,  smooth loss = 0.5552
[2022-07-06 04:52:10,198 callbacks.py:105 INFO train-abinet] epoch 4 iter 166250: loss = 0.6538,  smooth loss = 0.5562
[2022-07-06 04:52:52,099 callbacks.py:105 INFO train-abinet] epoch 4 iter 166300: loss = 0.5388,  smooth loss = 0.5561
[2022-07-06 04:53:34,070 callbacks.py:105 INFO train-abinet] epoch 4 iter 166350: loss = 0.5062,  smooth loss = 0.5452
[2022-07-06 04:54:15,465 callbacks.py:105 INFO train-abinet] epoch 4 iter 166400: loss = 0.7273,  smooth loss = 0.5580
[2022-07-06 04:54:57,067 callbacks.py:105 INFO train-abinet] epoch 4 iter 166450: loss = 0.5874,  smooth loss = 0.5639
[2022-07-06 04:55:38,693 callbacks.py:105 INFO train-abinet] epoch 4 iter 166500: loss = 0.5433,  smooth loss = 0.5571
[2022-07-06 04:56:20,446 callbacks.py:105 INFO train-abinet] epoch 4 iter 166550: loss = 0.4992,  smooth loss = 0.5593
[2022-07-06 04:57:02,597 callbacks.py:105 INFO train-abinet] epoch 4 iter 166600: loss = 0.5331,  smooth loss = 0.5488
[2022-07-06 04:57:44,045 callbacks.py:105 INFO train-abinet] epoch 4 iter 166650: loss = 0.5489,  smooth loss = 0.5553
[2022-07-06 04:58:24,823 callbacks.py:105 INFO train-abinet] epoch 4 iter 166700: loss = 0.8452,  smooth loss = 0.5667
[2022-07-06 04:59:06,138 callbacks.py:105 INFO train-abinet] epoch 4 iter 166750: loss = 0.4983,  smooth loss = 0.5554
[2022-07-06 04:59:47,376 callbacks.py:105 INFO train-abinet] epoch 4 iter 166800: loss = 0.5178,  smooth loss = 0.5537
[2022-07-06 05:00:28,875 callbacks.py:105 INFO train-abinet] epoch 4 iter 166850: loss = 0.4260,  smooth loss = 0.5547
[2022-07-06 05:01:10,425 callbacks.py:105 INFO train-abinet] epoch 4 iter 166900: loss = 0.6295,  smooth loss = 0.5632
[2022-07-06 05:01:51,630 callbacks.py:105 INFO train-abinet] epoch 4 iter 166950: loss = 0.5929,  smooth loss = 0.5578
[2022-07-06 05:02:33,260 callbacks.py:105 INFO train-abinet] epoch 4 iter 167000: loss = 0.5784,  smooth loss = 0.5524
[2022-07-06 05:03:14,681 callbacks.py:105 INFO train-abinet] epoch 4 iter 167050: loss = 0.4970,  smooth loss = 0.5529
[2022-07-06 05:03:55,663 callbacks.py:105 INFO train-abinet] epoch 4 iter 167100: loss = 0.7239,  smooth loss = 0.5626
[2022-07-06 05:04:37,224 callbacks.py:105 INFO train-abinet] epoch 4 iter 167150: loss = 0.5809,  smooth loss = 0.5566
[2022-07-06 05:05:19,045 callbacks.py:105 INFO train-abinet] epoch 4 iter 167200: loss = 0.5947,  smooth loss = 0.5477
[2022-07-06 05:06:00,885 callbacks.py:105 INFO train-abinet] epoch 4 iter 167250: loss = 0.5529,  smooth loss = 0.5524
[2022-07-06 05:06:42,378 callbacks.py:105 INFO train-abinet] epoch 4 iter 167300: loss = 0.5350,  smooth loss = 0.5666
[2022-07-06 05:07:23,306 callbacks.py:105 INFO train-abinet] epoch 4 iter 167350: loss = 0.5457,  smooth loss = 0.5782
[2022-07-06 05:08:04,769 callbacks.py:105 INFO train-abinet] epoch 4 iter 167400: loss = 0.6092,  smooth loss = 0.5572
[2022-07-06 05:08:46,442 callbacks.py:105 INFO train-abinet] epoch 4 iter 167450: loss = 0.5222,  smooth loss = 0.5658
[2022-07-06 05:09:28,316 callbacks.py:105 INFO train-abinet] epoch 4 iter 167500: loss = 0.6792,  smooth loss = 0.5619
[2022-07-06 05:10:09,724 callbacks.py:105 INFO train-abinet] epoch 4 iter 167550: loss = 0.5408,  smooth loss = 0.5559
[2022-07-06 05:10:51,233 callbacks.py:105 INFO train-abinet] epoch 4 iter 167600: loss = 0.6737,  smooth loss = 0.5541
[2022-07-06 05:11:32,632 callbacks.py:105 INFO train-abinet] epoch 4 iter 167650: loss = 0.4573,  smooth loss = 0.5484
[2022-07-06 05:12:14,160 callbacks.py:105 INFO train-abinet] epoch 4 iter 167700: loss = 0.5200,  smooth loss = 0.5458
[2022-07-06 05:12:56,196 callbacks.py:105 INFO train-abinet] epoch 4 iter 167750: loss = 0.6872,  smooth loss = 0.5447
[2022-07-06 05:13:37,631 callbacks.py:105 INFO train-abinet] epoch 4 iter 167800: loss = 0.5065,  smooth loss = 0.5502
[2022-07-06 05:14:19,765 callbacks.py:105 INFO train-abinet] epoch 4 iter 167850: loss = 0.4778,  smooth loss = 0.5632
[2022-07-06 05:15:00,642 callbacks.py:105 INFO train-abinet] epoch 4 iter 167900: loss = 0.5090,  smooth loss = 0.5573
[2022-07-06 05:15:42,033 callbacks.py:105 INFO train-abinet] epoch 4 iter 167950: loss = 0.5084,  smooth loss = 0.5633
[2022-07-06 05:16:23,153 callbacks.py:105 INFO train-abinet] epoch 4 iter 168000: loss = 0.4769,  smooth loss = 0.5559
[2022-07-06 05:16:23,154 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8751s
█[2022-07-06 05:16:37,766 callbacks.py:123 INFO train-abinet] epoch 4 iter 168000: eval loss = 1.1772,  ccr = 0.9610,  cwr = 0.9193,  ted = 1301.0000,  ned = 256.6426,  ted/w = 0.1795, 
[2022-07-06 05:16:37,767 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_168000
[2022-07-06 05:17:20,242 callbacks.py:105 INFO train-abinet] epoch 4 iter 168050: loss = 0.5778,  smooth loss = 0.5567
[2022-07-06 05:18:01,716 callbacks.py:105 INFO train-abinet] epoch 4 iter 168100: loss = 0.5316,  smooth loss = 0.5529
[2022-07-06 05:18:42,795 callbacks.py:105 INFO train-abinet] epoch 4 iter 168150: loss = 0.5742,  smooth loss = 0.5397
[2022-07-06 05:19:23,952 callbacks.py:105 INFO train-abinet] epoch 4 iter 168200: loss = 0.5646,  smooth loss = 0.5515
[2022-07-06 05:20:05,697 callbacks.py:105 INFO train-abinet] epoch 4 iter 168250: loss = 0.4919,  smooth loss = 0.5467
[2022-07-06 05:20:47,070 callbacks.py:105 INFO train-abinet] epoch 4 iter 168300: loss = 0.4392,  smooth loss = 0.5478
[2022-07-06 05:21:28,110 callbacks.py:105 INFO train-abinet] epoch 4 iter 168350: loss = 0.5385,  smooth loss = 0.5461
[2022-07-06 05:22:09,629 callbacks.py:105 INFO train-abinet] epoch 4 iter 168400: loss = 0.4887,  smooth loss = 0.5581
[2022-07-06 05:22:50,731 callbacks.py:105 INFO train-abinet] epoch 4 iter 168450: loss = 0.5491,  smooth loss = 0.5597
[2022-07-06 05:23:32,255 callbacks.py:105 INFO train-abinet] epoch 4 iter 168500: loss = 0.3953,  smooth loss = 0.5465
[2022-07-06 05:24:14,158 callbacks.py:105 INFO train-abinet] epoch 4 iter 168550: loss = 0.5720,  smooth loss = 0.5621
[2022-07-06 05:24:55,585 callbacks.py:105 INFO train-abinet] epoch 4 iter 168600: loss = 0.5260,  smooth loss = 0.5517
[2022-07-06 05:25:36,773 callbacks.py:105 INFO train-abinet] epoch 4 iter 168650: loss = 0.6439,  smooth loss = 0.5639
[2022-07-06 05:26:17,085 callbacks.py:105 INFO train-abinet] epoch 4 iter 168700: loss = 0.5436,  smooth loss = 0.5619
[2022-07-06 05:26:58,468 callbacks.py:105 INFO train-abinet] epoch 4 iter 168750: loss = 0.6197,  smooth loss = 0.5617
[2022-07-06 05:27:40,089 callbacks.py:105 INFO train-abinet] epoch 4 iter 168800: loss = 0.6912,  smooth loss = 0.5662
[2022-07-06 05:28:21,345 callbacks.py:105 INFO train-abinet] epoch 4 iter 168850: loss = 0.4664,  smooth loss = 0.5567
[2022-07-06 05:29:02,491 callbacks.py:105 INFO train-abinet] epoch 4 iter 168900: loss = 0.4222,  smooth loss = 0.5569
[2022-07-06 05:29:43,123 callbacks.py:105 INFO train-abinet] epoch 4 iter 168950: loss = 0.5622,  smooth loss = 0.5574
[2022-07-06 05:30:24,810 callbacks.py:105 INFO train-abinet] epoch 4 iter 169000: loss = 0.5899,  smooth loss = 0.5638
[2022-07-06 05:31:06,565 callbacks.py:105 INFO train-abinet] epoch 4 iter 169050: loss = 0.3932,  smooth loss = 0.5597
[2022-07-06 05:31:47,709 callbacks.py:105 INFO train-abinet] epoch 4 iter 169100: loss = 0.5259,  smooth loss = 0.5654
[2022-07-06 05:32:29,749 callbacks.py:105 INFO train-abinet] epoch 4 iter 169150: loss = 0.5726,  smooth loss = 0.5574
[2022-07-06 05:33:10,508 callbacks.py:105 INFO train-abinet] epoch 4 iter 169200: loss = 0.5560,  smooth loss = 0.5609
[2022-07-06 05:33:51,683 callbacks.py:105 INFO train-abinet] epoch 4 iter 169250: loss = 0.5556,  smooth loss = 0.5593
[2022-07-06 05:34:32,203 callbacks.py:105 INFO train-abinet] epoch 4 iter 169300: loss = 0.6294,  smooth loss = 0.5586
[2022-07-06 05:35:12,880 callbacks.py:105 INFO train-abinet] epoch 4 iter 169350: loss = 0.6088,  smooth loss = 0.5642
[2022-07-06 05:35:54,102 callbacks.py:105 INFO train-abinet] epoch 4 iter 169400: loss = 0.5244,  smooth loss = 0.5796
[2022-07-06 05:36:35,802 callbacks.py:105 INFO train-abinet] epoch 4 iter 169450: loss = 0.5548,  smooth loss = 0.5576
[2022-07-06 05:37:17,339 callbacks.py:105 INFO train-abinet] epoch 4 iter 169500: loss = 0.6079,  smooth loss = 0.5523
[2022-07-06 05:37:58,648 callbacks.py:105 INFO train-abinet] epoch 4 iter 169550: loss = 0.4491,  smooth loss = 0.5509
[2022-07-06 05:38:39,652 callbacks.py:105 INFO train-abinet] epoch 4 iter 169600: loss = 0.5055,  smooth loss = 0.5526
[2022-07-06 05:39:20,015 callbacks.py:105 INFO train-abinet] epoch 4 iter 169650: loss = 0.4657,  smooth loss = 0.5629
[2022-07-06 05:40:02,012 callbacks.py:105 INFO train-abinet] epoch 4 iter 169700: loss = 0.6323,  smooth loss = 0.5538
[2022-07-06 05:40:43,623 callbacks.py:105 INFO train-abinet] epoch 4 iter 169750: loss = 0.6012,  smooth loss = 0.5444
[2022-07-06 05:41:25,300 callbacks.py:105 INFO train-abinet] epoch 4 iter 169800: loss = 0.4783,  smooth loss = 0.5437
[2022-07-06 05:42:06,896 callbacks.py:105 INFO train-abinet] epoch 4 iter 169850: loss = 0.6278,  smooth loss = 0.5531
[2022-07-06 05:42:48,262 callbacks.py:105 INFO train-abinet] epoch 4 iter 169900: loss = 0.6632,  smooth loss = 0.5352
[2022-07-06 05:43:29,900 callbacks.py:105 INFO train-abinet] epoch 4 iter 169950: loss = 0.6820,  smooth loss = 0.5550
[2022-07-06 05:44:10,824 callbacks.py:105 INFO train-abinet] epoch 4 iter 170000: loss = 0.5393,  smooth loss = 0.5648
[2022-07-06 05:44:52,047 callbacks.py:105 INFO train-abinet] epoch 4 iter 170050: loss = 0.5827,  smooth loss = 0.5534
[2022-07-06 05:45:33,648 callbacks.py:105 INFO train-abinet] epoch 4 iter 170100: loss = 0.5206,  smooth loss = 0.5435
[2022-07-06 05:46:14,731 callbacks.py:105 INFO train-abinet] epoch 4 iter 170150: loss = 0.6550,  smooth loss = 0.5535
[2022-07-06 05:46:56,393 callbacks.py:105 INFO train-abinet] epoch 4 iter 170200: loss = 0.5709,  smooth loss = 0.5646
[2022-07-06 05:47:37,695 callbacks.py:105 INFO train-abinet] epoch 4 iter 170250: loss = 0.4252,  smooth loss = 0.5538
[2022-07-06 05:48:18,870 callbacks.py:105 INFO train-abinet] epoch 4 iter 170300: loss = 0.4794,  smooth loss = 0.5494
[2022-07-06 05:49:00,199 callbacks.py:105 INFO train-abinet] epoch 4 iter 170350: loss = 0.5152,  smooth loss = 0.5541
[2022-07-06 05:49:40,608 callbacks.py:105 INFO train-abinet] epoch 4 iter 170400: loss = 0.5933,  smooth loss = 0.5549
[2022-07-06 05:50:21,804 callbacks.py:105 INFO train-abinet] epoch 4 iter 170450: loss = 0.4727,  smooth loss = 0.5470
[2022-07-06 05:51:02,124 callbacks.py:105 INFO train-abinet] epoch 4 iter 170500: loss = 0.6065,  smooth loss = 0.5520
[2022-07-06 05:51:43,921 callbacks.py:105 INFO train-abinet] epoch 4 iter 170550: loss = 0.4570,  smooth loss = 0.5612
[2022-07-06 05:52:25,352 callbacks.py:105 INFO train-abinet] epoch 4 iter 170600: loss = 0.5473,  smooth loss = 0.5645
[2022-07-06 05:53:06,950 callbacks.py:105 INFO train-abinet] epoch 4 iter 170650: loss = 0.4834,  smooth loss = 0.5476
[2022-07-06 05:53:47,849 callbacks.py:105 INFO train-abinet] epoch 4 iter 170700: loss = 0.5486,  smooth loss = 0.5625
[2022-07-06 05:54:29,916 callbacks.py:105 INFO train-abinet] epoch 4 iter 170750: loss = 0.6166,  smooth loss = 0.5696
[2022-07-06 05:55:11,814 callbacks.py:105 INFO train-abinet] epoch 4 iter 170800: loss = 0.5223,  smooth loss = 0.5456
[2022-07-06 05:55:53,119 callbacks.py:105 INFO train-abinet] epoch 4 iter 170850: loss = 0.5440,  smooth loss = 0.5464
[2022-07-06 05:56:34,125 callbacks.py:105 INFO train-abinet] epoch 4 iter 170900: loss = 0.5618,  smooth loss = 0.5527
[2022-07-06 05:57:15,576 callbacks.py:105 INFO train-abinet] epoch 4 iter 170950: loss = 0.6994,  smooth loss = 0.5548
[2022-07-06 05:57:56,978 callbacks.py:105 INFO train-abinet] epoch 4 iter 171000: loss = 0.5842,  smooth loss = 0.5558
[2022-07-06 05:57:56,979 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8743s
█[2022-07-06 05:58:11,658 callbacks.py:123 INFO train-abinet] epoch 4 iter 171000: eval loss = 1.1980,  ccr = 0.9577,  cwr = 0.9165,  ted = 1330.0000,  ned = 264.2947,  ted/w = 0.1835, 
[2022-07-06 05:58:11,659 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_171000
[2022-07-06 05:58:53,800 callbacks.py:105 INFO train-abinet] epoch 4 iter 171050: loss = 0.6376,  smooth loss = 0.5577
[2022-07-06 05:59:36,046 callbacks.py:105 INFO train-abinet] epoch 4 iter 171100: loss = 0.5791,  smooth loss = 0.5480
[2022-07-06 06:00:17,585 callbacks.py:105 INFO train-abinet] epoch 4 iter 171150: loss = 0.4984,  smooth loss = 0.5610
[2022-07-06 06:00:58,928 callbacks.py:105 INFO train-abinet] epoch 4 iter 171200: loss = 0.6187,  smooth loss = 0.5629
[2022-07-06 06:01:40,234 callbacks.py:105 INFO train-abinet] epoch 4 iter 171250: loss = 0.3987,  smooth loss = 0.5552
[2022-07-06 06:02:21,405 callbacks.py:105 INFO train-abinet] epoch 4 iter 171300: loss = 0.5996,  smooth loss = 0.5552
[2022-07-06 06:03:02,244 callbacks.py:105 INFO train-abinet] epoch 4 iter 171350: loss = 0.5070,  smooth loss = 0.5420
[2022-07-06 06:03:43,331 callbacks.py:105 INFO train-abinet] epoch 4 iter 171400: loss = 0.4607,  smooth loss = 0.5548
[2022-07-06 06:04:24,013 callbacks.py:105 INFO train-abinet] epoch 4 iter 171450: loss = 0.5811,  smooth loss = 0.5527
[2022-07-06 06:05:05,018 callbacks.py:105 INFO train-abinet] epoch 4 iter 171500: loss = 0.5554,  smooth loss = 0.5556
[2022-07-06 06:05:46,335 callbacks.py:105 INFO train-abinet] epoch 4 iter 171550: loss = 0.4742,  smooth loss = 0.5558
[2022-07-06 06:06:28,039 callbacks.py:105 INFO train-abinet] epoch 4 iter 171600: loss = 0.5678,  smooth loss = 0.5492
[2022-07-06 06:07:09,027 callbacks.py:105 INFO train-abinet] epoch 4 iter 171650: loss = 0.5768,  smooth loss = 0.5664
[2022-07-06 06:07:50,767 callbacks.py:105 INFO train-abinet] epoch 4 iter 171700: loss = 0.5279,  smooth loss = 0.5655
[2022-07-06 06:08:31,261 callbacks.py:105 INFO train-abinet] epoch 4 iter 171750: loss = 0.5905,  smooth loss = 0.5540
[2022-07-06 06:09:14,092 callbacks.py:105 INFO train-abinet] epoch 4 iter 171800: loss = 0.4083,  smooth loss = 0.5508
[2022-07-06 06:09:57,403 callbacks.py:105 INFO train-abinet] epoch 4 iter 171850: loss = 0.5454,  smooth loss = 0.5469
[2022-07-06 06:10:42,787 callbacks.py:105 INFO train-abinet] epoch 4 iter 171900: loss = 0.5182,  smooth loss = 0.5504
[2022-07-06 06:11:26,083 callbacks.py:105 INFO train-abinet] epoch 4 iter 171950: loss = 0.5825,  smooth loss = 0.5553
[2022-07-06 06:12:08,346 callbacks.py:105 INFO train-abinet] epoch 4 iter 172000: loss = 0.4840,  smooth loss = 0.5488
[2022-07-06 06:12:53,206 callbacks.py:105 INFO train-abinet] epoch 4 iter 172050: loss = 0.8210,  smooth loss = 0.5524
[2022-07-06 06:13:35,364 callbacks.py:105 INFO train-abinet] epoch 4 iter 172100: loss = 0.3909,  smooth loss = 0.5593
[2022-07-06 06:14:17,058 callbacks.py:105 INFO train-abinet] epoch 4 iter 172150: loss = 0.4507,  smooth loss = 0.5607
[2022-07-06 06:15:01,562 callbacks.py:105 INFO train-abinet] epoch 4 iter 172200: loss = 0.5631,  smooth loss = 0.5499
[2022-07-06 06:15:43,980 callbacks.py:105 INFO train-abinet] epoch 4 iter 172250: loss = 0.4841,  smooth loss = 0.5447
[2022-07-06 06:16:25,263 callbacks.py:105 INFO train-abinet] epoch 4 iter 172300: loss = 0.4664,  smooth loss = 0.5564
[2022-07-06 06:17:09,620 callbacks.py:105 INFO train-abinet] epoch 4 iter 172350: loss = 0.8348,  smooth loss = 0.5750
[2022-07-06 06:17:51,671 callbacks.py:105 INFO train-abinet] epoch 4 iter 172400: loss = 0.6061,  smooth loss = 0.5703
[2022-07-06 06:18:34,327 callbacks.py:105 INFO train-abinet] epoch 4 iter 172450: loss = 0.4394,  smooth loss = 0.5590
[2022-07-06 06:19:18,964 callbacks.py:105 INFO train-abinet] epoch 4 iter 172500: loss = 0.5608,  smooth loss = 0.5484
[2022-07-06 06:20:02,982 callbacks.py:105 INFO train-abinet] epoch 4 iter 172550: loss = 0.3539,  smooth loss = 0.5279
[2022-07-06 06:20:44,554 callbacks.py:105 INFO train-abinet] epoch 4 iter 172600: loss = 0.5415,  smooth loss = 0.5558
[2022-07-06 06:21:28,323 callbacks.py:105 INFO train-abinet] epoch 4 iter 172650: loss = 0.4325,  smooth loss = 0.5535
[2022-07-06 06:22:11,182 callbacks.py:105 INFO train-abinet] epoch 4 iter 172700: loss = 0.3831,  smooth loss = 0.5433
[2022-07-06 06:22:53,230 callbacks.py:105 INFO train-abinet] epoch 4 iter 172750: loss = 0.4016,  smooth loss = 0.5486
[2022-07-06 06:23:36,947 callbacks.py:105 INFO train-abinet] epoch 4 iter 172800: loss = 0.7184,  smooth loss = 0.5597
[2022-07-06 06:24:18,165 callbacks.py:105 INFO train-abinet] epoch 4 iter 172850: loss = 0.6335,  smooth loss = 0.5599
[2022-07-06 06:24:58,915 callbacks.py:105 INFO train-abinet] epoch 4 iter 172900: loss = 0.6082,  smooth loss = 0.5732
[2022-07-06 06:25:39,926 callbacks.py:105 INFO train-abinet] epoch 4 iter 172950: loss = 0.5804,  smooth loss = 0.5658
[2022-07-06 06:26:20,910 callbacks.py:105 INFO train-abinet] epoch 4 iter 173000: loss = 0.4815,  smooth loss = 0.5513
[2022-07-06 06:27:02,229 callbacks.py:105 INFO train-abinet] epoch 4 iter 173050: loss = 0.6558,  smooth loss = 0.5652
[2022-07-06 06:27:43,447 callbacks.py:105 INFO train-abinet] epoch 4 iter 173100: loss = 0.5706,  smooth loss = 0.5533
[2022-07-06 06:28:25,078 callbacks.py:105 INFO train-abinet] epoch 4 iter 173150: loss = 0.5070,  smooth loss = 0.5497
[2022-07-06 06:29:06,380 callbacks.py:105 INFO train-abinet] epoch 4 iter 173200: loss = 0.5326,  smooth loss = 0.5507
[2022-07-06 06:29:47,201 callbacks.py:105 INFO train-abinet] epoch 4 iter 173250: loss = 0.6680,  smooth loss = 0.5648
[2022-07-06 06:30:28,688 callbacks.py:105 INFO train-abinet] epoch 4 iter 173300: loss = 0.5618,  smooth loss = 0.5673
[2022-07-06 06:31:12,814 callbacks.py:105 INFO train-abinet] epoch 4 iter 173350: loss = 0.5326,  smooth loss = 0.5629
[2022-07-06 06:31:57,089 callbacks.py:105 INFO train-abinet] epoch 4 iter 173400: loss = 0.5457,  smooth loss = 0.5552
[2022-07-06 06:32:39,262 callbacks.py:105 INFO train-abinet] epoch 4 iter 173450: loss = 0.6155,  smooth loss = 0.5594
[2022-07-06 06:33:23,092 callbacks.py:105 INFO train-abinet] epoch 4 iter 173500: loss = 0.5447,  smooth loss = 0.5568
[2022-07-06 06:34:06,678 callbacks.py:105 INFO train-abinet] epoch 4 iter 173550: loss = 0.3964,  smooth loss = 0.5476
[2022-07-06 06:34:49,184 callbacks.py:105 INFO train-abinet] epoch 4 iter 173600: loss = 0.6634,  smooth loss = 0.5654
[2022-07-06 06:35:34,013 callbacks.py:105 INFO train-abinet] epoch 4 iter 173650: loss = 0.8638,  smooth loss = 0.5677
[2022-07-06 06:36:16,989 callbacks.py:105 INFO train-abinet] epoch 4 iter 173700: loss = 0.4861,  smooth loss = 0.5536
[2022-07-06 06:37:00,121 callbacks.py:105 INFO train-abinet] epoch 4 iter 173750: loss = 0.5177,  smooth loss = 0.5532
[2022-07-06 06:37:46,745 callbacks.py:105 INFO train-abinet] epoch 4 iter 173800: loss = 0.6855,  smooth loss = 0.5527
[2022-07-06 06:38:29,708 callbacks.py:105 INFO train-abinet] epoch 4 iter 173850: loss = 0.4487,  smooth loss = 0.5508
[2022-07-06 06:39:12,851 callbacks.py:105 INFO train-abinet] epoch 4 iter 173900: loss = 0.4816,  smooth loss = 0.5504
[2022-07-06 06:39:57,251 callbacks.py:105 INFO train-abinet] epoch 4 iter 173950: loss = 0.4303,  smooth loss = 0.5488
[2022-07-06 06:40:38,787 callbacks.py:105 INFO train-abinet] epoch 4 iter 174000: loss = 0.4579,  smooth loss = 0.5526
[2022-07-06 06:40:38,788 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8738s
█[2022-07-06 06:40:53,382 callbacks.py:123 INFO train-abinet] epoch 4 iter 174000: eval loss = 1.1492,  ccr = 0.9632,  cwr = 0.9193,  ted = 1282.0000,  ned = 251.9303,  ted/w = 0.1769, 
[2022-07-06 06:40:53,384 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_174000
[2022-07-06 06:41:37,885 callbacks.py:105 INFO train-abinet] epoch 4 iter 174050: loss = 0.7493,  smooth loss = 0.5629
[2022-07-06 06:42:20,857 callbacks.py:105 INFO train-abinet] epoch 4 iter 174100: loss = 0.4862,  smooth loss = 0.5556
[2022-07-06 06:43:03,832 callbacks.py:105 INFO train-abinet] epoch 4 iter 174150: loss = 0.7288,  smooth loss = 0.5476
[2022-07-06 06:43:48,526 callbacks.py:105 INFO train-abinet] epoch 4 iter 174200: loss = 0.5878,  smooth loss = 0.5644
[2022-07-06 06:44:30,678 callbacks.py:105 INFO train-abinet] epoch 4 iter 174250: loss = 0.5442,  smooth loss = 0.5682
[2022-07-06 06:45:12,407 callbacks.py:105 INFO train-abinet] epoch 4 iter 174300: loss = 0.5486,  smooth loss = 0.5546
[2022-07-06 06:45:54,999 callbacks.py:105 INFO train-abinet] epoch 4 iter 174350: loss = 0.5327,  smooth loss = 0.5388
[2022-07-06 06:46:36,155 callbacks.py:105 INFO train-abinet] epoch 4 iter 174400: loss = 0.4736,  smooth loss = 0.5542
[2022-07-06 06:47:18,500 callbacks.py:105 INFO train-abinet] epoch 4 iter 174450: loss = 0.6068,  smooth loss = 0.5640
[2022-07-06 06:48:01,053 callbacks.py:105 INFO train-abinet] epoch 4 iter 174500: loss = 0.4715,  smooth loss = 0.5390
[2022-07-06 06:48:43,164 callbacks.py:105 INFO train-abinet] epoch 4 iter 174550: loss = 0.6395,  smooth loss = 0.5490
[2022-07-06 06:49:24,630 callbacks.py:105 INFO train-abinet] epoch 4 iter 174600: loss = 0.5807,  smooth loss = 0.5579
[2022-07-06 06:50:06,389 callbacks.py:105 INFO train-abinet] epoch 4 iter 174650: loss = 0.6355,  smooth loss = 0.5621
[2022-07-06 06:50:47,628 callbacks.py:105 INFO train-abinet] epoch 4 iter 174700: loss = 0.4834,  smooth loss = 0.5644
[2022-07-06 06:51:29,415 callbacks.py:105 INFO train-abinet] epoch 4 iter 174750: loss = 0.6010,  smooth loss = 0.5740
[2022-07-06 06:52:10,827 callbacks.py:105 INFO train-abinet] epoch 4 iter 174800: loss = 0.5815,  smooth loss = 0.5615
[2022-07-06 06:52:51,922 callbacks.py:105 INFO train-abinet] epoch 4 iter 174850: loss = 0.4704,  smooth loss = 0.5529
[2022-07-06 06:53:33,845 callbacks.py:105 INFO train-abinet] epoch 4 iter 174900: loss = 0.3969,  smooth loss = 0.5540
[2022-07-06 06:54:15,528 callbacks.py:105 INFO train-abinet] epoch 4 iter 174950: loss = 0.6403,  smooth loss = 0.5626
[2022-07-06 06:54:57,787 callbacks.py:105 INFO train-abinet] epoch 4 iter 175000: loss = 0.5053,  smooth loss = 0.5576
[2022-07-06 06:55:39,514 callbacks.py:105 INFO train-abinet] epoch 4 iter 175050: loss = 0.5845,  smooth loss = 0.5524
[2022-07-06 06:56:21,544 callbacks.py:105 INFO train-abinet] epoch 4 iter 175100: loss = 0.4971,  smooth loss = 0.5356
[2022-07-06 06:57:02,810 callbacks.py:105 INFO train-abinet] epoch 4 iter 175150: loss = 0.6295,  smooth loss = 0.5411
[2022-07-06 06:57:44,353 callbacks.py:105 INFO train-abinet] epoch 4 iter 175200: loss = 0.5612,  smooth loss = 0.5526
[2022-07-06 06:58:25,378 callbacks.py:105 INFO train-abinet] epoch 4 iter 175250: loss = 0.4501,  smooth loss = 0.5585
[2022-07-06 06:59:07,349 callbacks.py:105 INFO train-abinet] epoch 4 iter 175300: loss = 0.5783,  smooth loss = 0.5563
[2022-07-06 06:59:49,158 callbacks.py:105 INFO train-abinet] epoch 4 iter 175350: loss = 0.5860,  smooth loss = 0.5485
[2022-07-06 07:00:30,961 callbacks.py:105 INFO train-abinet] epoch 4 iter 175400: loss = 0.5776,  smooth loss = 0.5503
[2022-07-06 07:01:12,102 callbacks.py:105 INFO train-abinet] epoch 4 iter 175450: loss = 0.5153,  smooth loss = 0.5564
[2022-07-06 07:01:53,789 callbacks.py:105 INFO train-abinet] epoch 4 iter 175500: loss = 0.5507,  smooth loss = 0.5665
[2022-07-06 07:02:35,357 callbacks.py:105 INFO train-abinet] epoch 4 iter 175550: loss = 0.7009,  smooth loss = 0.5645
[2022-07-06 07:03:16,668 callbacks.py:105 INFO train-abinet] epoch 4 iter 175600: loss = 0.6055,  smooth loss = 0.5511
[2022-07-06 07:03:58,024 callbacks.py:105 INFO train-abinet] epoch 4 iter 175650: loss = 0.5763,  smooth loss = 0.5785
[2022-07-06 07:04:39,313 callbacks.py:105 INFO train-abinet] epoch 4 iter 175700: loss = 0.5656,  smooth loss = 0.5665
[2022-07-06 07:05:21,029 callbacks.py:105 INFO train-abinet] epoch 4 iter 175750: loss = 0.5558,  smooth loss = 0.5615
[2022-07-06 07:06:02,350 callbacks.py:105 INFO train-abinet] epoch 4 iter 175800: loss = 0.4547,  smooth loss = 0.5615
[2022-07-06 07:06:44,165 callbacks.py:105 INFO train-abinet] epoch 4 iter 175850: loss = 0.6330,  smooth loss = 0.5462
[2022-07-06 07:07:25,529 callbacks.py:105 INFO train-abinet] epoch 4 iter 175900: loss = 0.6173,  smooth loss = 0.5454
[2022-07-06 07:08:07,326 callbacks.py:105 INFO train-abinet] epoch 4 iter 175950: loss = 0.6215,  smooth loss = 0.5673
[2022-07-06 07:08:48,703 callbacks.py:105 INFO train-abinet] epoch 4 iter 176000: loss = 0.4903,  smooth loss = 0.5463
[2022-07-06 07:09:30,191 callbacks.py:105 INFO train-abinet] epoch 4 iter 176050: loss = 0.4828,  smooth loss = 0.5549
[2022-07-06 07:10:10,753 callbacks.py:105 INFO train-abinet] epoch 4 iter 176100: loss = 0.6715,  smooth loss = 0.5550
[2022-07-06 07:10:52,728 callbacks.py:105 INFO train-abinet] epoch 4 iter 176150: loss = 0.6415,  smooth loss = 0.5575
[2022-07-06 07:11:34,459 callbacks.py:105 INFO train-abinet] epoch 4 iter 176200: loss = 0.5484,  smooth loss = 0.5385
[2022-07-06 07:12:15,682 callbacks.py:105 INFO train-abinet] epoch 4 iter 176250: loss = 0.5086,  smooth loss = 0.5416
[2022-07-06 07:12:57,105 callbacks.py:105 INFO train-abinet] epoch 4 iter 176300: loss = 0.6828,  smooth loss = 0.5566
[2022-07-06 07:13:38,476 callbacks.py:105 INFO train-abinet] epoch 4 iter 176350: loss = 0.4834,  smooth loss = 0.5482
[2022-07-06 07:14:20,756 callbacks.py:105 INFO train-abinet] epoch 4 iter 176400: loss = 0.5251,  smooth loss = 0.5539
[2022-07-06 07:15:02,760 callbacks.py:105 INFO train-abinet] epoch 4 iter 176450: loss = 0.6418,  smooth loss = 0.5565
[2022-07-06 07:15:45,276 callbacks.py:105 INFO train-abinet] epoch 4 iter 176500: loss = 0.6196,  smooth loss = 0.5601
[2022-07-06 07:16:27,240 callbacks.py:105 INFO train-abinet] epoch 4 iter 176550: loss = 0.5334,  smooth loss = 0.5466
[2022-07-06 07:17:09,827 callbacks.py:105 INFO train-abinet] epoch 4 iter 176600: loss = 0.5151,  smooth loss = 0.5339
[2022-07-06 07:17:53,149 callbacks.py:105 INFO train-abinet] epoch 4 iter 176650: loss = 0.6183,  smooth loss = 0.5473
[2022-07-06 07:18:34,844 callbacks.py:105 INFO train-abinet] epoch 4 iter 176700: loss = 0.4768,  smooth loss = 0.5758
[2022-07-06 07:19:17,243 callbacks.py:105 INFO train-abinet] epoch 4 iter 176750: loss = 0.5797,  smooth loss = 0.5614
[2022-07-06 07:19:58,950 callbacks.py:105 INFO train-abinet] epoch 4 iter 176800: loss = 0.5612,  smooth loss = 0.5549
[2022-07-06 07:20:41,738 callbacks.py:105 INFO train-abinet] epoch 4 iter 176850: loss = 0.5790,  smooth loss = 0.5607
[2022-07-06 07:21:23,696 callbacks.py:105 INFO train-abinet] epoch 4 iter 176900: loss = 0.5692,  smooth loss = 0.5655
[2022-07-06 07:22:05,733 callbacks.py:105 INFO train-abinet] epoch 4 iter 176950: loss = 0.5383,  smooth loss = 0.5591
[2022-07-06 07:22:48,667 callbacks.py:105 INFO train-abinet] epoch 4 iter 177000: loss = 0.5692,  smooth loss = 0.5554
[2022-07-06 07:22:48,667 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8732s
█[2022-07-06 07:23:03,180 callbacks.py:123 INFO train-abinet] epoch 4 iter 177000: eval loss = 1.2216,  ccr = 0.9552,  cwr = 0.9088,  ted = 1418.0000,  ned = 286.2907,  ted/w = 0.1956, 
[2022-07-06 07:23:03,181 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_177000
[2022-07-06 07:23:46,108 callbacks.py:105 INFO train-abinet] epoch 4 iter 177050: loss = 0.6280,  smooth loss = 0.5772
[2022-07-06 07:24:27,813 callbacks.py:105 INFO train-abinet] epoch 4 iter 177100: loss = 0.5423,  smooth loss = 0.5741
[2022-07-06 07:25:09,058 callbacks.py:105 INFO train-abinet] epoch 4 iter 177150: loss = 0.5802,  smooth loss = 0.5625
[2022-07-06 07:25:50,345 callbacks.py:105 INFO train-abinet] epoch 4 iter 177200: loss = 0.4569,  smooth loss = 0.5631
[2022-07-06 07:26:32,177 callbacks.py:105 INFO train-abinet] epoch 4 iter 177250: loss = 0.4825,  smooth loss = 0.5517
[2022-07-06 07:27:14,233 callbacks.py:105 INFO train-abinet] epoch 4 iter 177300: loss = 0.5459,  smooth loss = 0.5473
[2022-07-06 07:27:56,088 callbacks.py:105 INFO train-abinet] epoch 4 iter 177350: loss = 0.6080,  smooth loss = 0.5521
[2022-07-06 07:28:38,128 callbacks.py:105 INFO train-abinet] epoch 4 iter 177400: loss = 0.5429,  smooth loss = 0.5558
[2022-07-06 07:29:20,087 callbacks.py:105 INFO train-abinet] epoch 4 iter 177450: loss = 0.4251,  smooth loss = 0.5468
[2022-07-06 07:30:01,670 callbacks.py:105 INFO train-abinet] epoch 4 iter 177500: loss = 0.5739,  smooth loss = 0.5466
[2022-07-06 07:30:44,175 callbacks.py:105 INFO train-abinet] epoch 4 iter 177550: loss = 0.6223,  smooth loss = 0.5364
[2022-07-06 07:31:26,046 callbacks.py:105 INFO train-abinet] epoch 4 iter 177600: loss = 0.4305,  smooth loss = 0.5455
[2022-07-06 07:32:07,229 callbacks.py:105 INFO train-abinet] epoch 4 iter 177650: loss = 0.4561,  smooth loss = 0.5562
[2022-07-06 07:32:49,522 callbacks.py:105 INFO train-abinet] epoch 4 iter 177700: loss = 0.5582,  smooth loss = 0.5487
[2022-07-06 07:33:30,477 callbacks.py:105 INFO train-abinet] epoch 4 iter 177750: loss = 0.5767,  smooth loss = 0.5597
[2022-07-06 07:34:11,928 callbacks.py:105 INFO train-abinet] epoch 4 iter 177800: loss = 0.6401,  smooth loss = 0.5675
[2022-07-06 07:34:53,758 callbacks.py:105 INFO train-abinet] epoch 4 iter 177850: loss = 0.4081,  smooth loss = 0.5474
[2022-07-06 07:35:35,249 callbacks.py:105 INFO train-abinet] epoch 4 iter 177900: loss = 0.7223,  smooth loss = 0.5591
[2022-07-06 07:36:16,258 callbacks.py:105 INFO train-abinet] epoch 4 iter 177950: loss = 0.5150,  smooth loss = 0.5645
[2022-07-06 07:36:58,631 callbacks.py:105 INFO train-abinet] epoch 4 iter 178000: loss = 0.5980,  smooth loss = 0.5598
[2022-07-06 07:37:39,817 callbacks.py:105 INFO train-abinet] epoch 4 iter 178050: loss = 0.5440,  smooth loss = 0.5505
[2022-07-06 07:38:21,897 callbacks.py:105 INFO train-abinet] epoch 4 iter 178100: loss = 0.6030,  smooth loss = 0.5553
[2022-07-06 07:39:03,246 callbacks.py:105 INFO train-abinet] epoch 4 iter 178150: loss = 0.4087,  smooth loss = 0.5413
[2022-07-06 07:39:45,316 callbacks.py:105 INFO train-abinet] epoch 4 iter 178200: loss = 0.5785,  smooth loss = 0.5512
[2022-07-06 07:40:27,227 callbacks.py:105 INFO train-abinet] epoch 4 iter 178250: loss = 0.5112,  smooth loss = 0.5545
[2022-07-06 07:41:09,242 callbacks.py:105 INFO train-abinet] epoch 4 iter 178300: loss = 0.4333,  smooth loss = 0.5525
[2022-07-06 07:41:50,795 callbacks.py:105 INFO train-abinet] epoch 4 iter 178350: loss = 0.5501,  smooth loss = 0.5549
[2022-07-06 07:42:33,607 callbacks.py:105 INFO train-abinet] epoch 4 iter 178400: loss = 0.5460,  smooth loss = 0.5623
[2022-07-06 07:43:15,838 callbacks.py:105 INFO train-abinet] epoch 4 iter 178450: loss = 0.5022,  smooth loss = 0.5600
[2022-07-06 07:43:57,854 callbacks.py:105 INFO train-abinet] epoch 4 iter 178500: loss = 0.4517,  smooth loss = 0.5647
[2022-07-06 07:44:39,773 callbacks.py:105 INFO train-abinet] epoch 4 iter 178550: loss = 0.3774,  smooth loss = 0.5547
[2022-07-06 07:45:21,748 callbacks.py:105 INFO train-abinet] epoch 4 iter 178600: loss = 0.4817,  smooth loss = 0.5564
[2022-07-06 07:46:03,612 callbacks.py:105 INFO train-abinet] epoch 4 iter 178650: loss = 0.6432,  smooth loss = 0.5431
[2022-07-06 07:46:43,867 callbacks.py:105 INFO train-abinet] epoch 4 iter 178700: loss = 0.5519,  smooth loss = 0.5560
[2022-07-06 07:47:26,149 callbacks.py:105 INFO train-abinet] epoch 4 iter 178750: loss = 0.5955,  smooth loss = 0.5407
[2022-07-06 07:48:08,490 callbacks.py:105 INFO train-abinet] epoch 4 iter 178800: loss = 0.6643,  smooth loss = 0.5549
[2022-07-06 07:48:50,627 callbacks.py:105 INFO train-abinet] epoch 4 iter 178850: loss = 0.4057,  smooth loss = 0.5522
[2022-07-06 07:49:32,340 callbacks.py:105 INFO train-abinet] epoch 4 iter 178900: loss = 0.6135,  smooth loss = 0.5615
[2022-07-06 07:50:14,616 callbacks.py:105 INFO train-abinet] epoch 4 iter 178950: loss = 0.6057,  smooth loss = 0.5516
[2022-07-06 07:50:56,119 callbacks.py:105 INFO train-abinet] epoch 4 iter 179000: loss = 0.4021,  smooth loss = 0.5471
[2022-07-06 07:51:37,573 callbacks.py:105 INFO train-abinet] epoch 4 iter 179050: loss = 0.4165,  smooth loss = 0.5512
[2022-07-06 07:52:18,886 callbacks.py:105 INFO train-abinet] epoch 4 iter 179100: loss = 0.4711,  smooth loss = 0.5584
[2022-07-06 07:53:01,816 callbacks.py:105 INFO train-abinet] epoch 4 iter 179150: loss = 0.4202,  smooth loss = 0.5536
[2022-07-06 07:53:43,608 callbacks.py:105 INFO train-abinet] epoch 4 iter 179200: loss = 0.5823,  smooth loss = 0.5577
[2022-07-06 07:54:24,534 callbacks.py:105 INFO train-abinet] epoch 4 iter 179250: loss = 0.6945,  smooth loss = 0.5616
[2022-07-06 07:55:06,345 callbacks.py:105 INFO train-abinet] epoch 4 iter 179300: loss = 0.5584,  smooth loss = 0.5636
[2022-07-06 07:55:47,353 callbacks.py:105 INFO train-abinet] epoch 4 iter 179350: loss = 0.4945,  smooth loss = 0.5654
[2022-07-06 07:56:29,371 callbacks.py:105 INFO train-abinet] epoch 4 iter 179400: loss = 0.5268,  smooth loss = 0.5577
[2022-07-06 07:57:11,308 callbacks.py:105 INFO train-abinet] epoch 4 iter 179450: loss = 0.4861,  smooth loss = 0.5530
[2022-07-06 07:57:52,370 callbacks.py:105 INFO train-abinet] epoch 4 iter 179500: loss = 0.4119,  smooth loss = 0.5531
[2022-07-06 07:58:33,250 callbacks.py:105 INFO train-abinet] epoch 4 iter 179550: loss = 0.5343,  smooth loss = 0.5474
[2022-07-06 07:59:15,196 callbacks.py:105 INFO train-abinet] epoch 4 iter 179600: loss = 0.4880,  smooth loss = 0.5473
[2022-07-06 07:59:56,132 callbacks.py:105 INFO train-abinet] epoch 4 iter 179650: loss = 0.5094,  smooth loss = 0.5428
[2022-07-06 08:00:38,023 callbacks.py:105 INFO train-abinet] epoch 4 iter 179700: loss = 0.5492,  smooth loss = 0.5544
[2022-07-06 08:01:19,471 callbacks.py:105 INFO train-abinet] epoch 4 iter 179750: loss = 0.5218,  smooth loss = 0.5493
[2022-07-06 08:02:00,923 callbacks.py:105 INFO train-abinet] epoch 4 iter 179800: loss = 0.5468,  smooth loss = 0.5509
[2022-07-06 08:02:43,028 callbacks.py:105 INFO train-abinet] epoch 4 iter 179850: loss = 0.3935,  smooth loss = 0.5497
[2022-07-06 08:03:25,335 callbacks.py:105 INFO train-abinet] epoch 4 iter 179900: loss = 0.4874,  smooth loss = 0.5525
[2022-07-06 08:04:08,262 callbacks.py:105 INFO train-abinet] epoch 4 iter 179950: loss = 0.4311,  smooth loss = 0.5446
[2022-07-06 08:04:49,362 callbacks.py:105 INFO train-abinet] epoch 4 iter 180000: loss = 0.4679,  smooth loss = 0.5471
[2022-07-06 08:04:49,363 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8726s
█[2022-07-06 08:05:04,054 callbacks.py:123 INFO train-abinet] epoch 4 iter 180000: eval loss = 1.1800,  ccr = 0.9607,  cwr = 0.9163,  ted = 1337.0000,  ned = 273.6505,  ted/w = 0.1845, 
[2022-07-06 08:05:04,055 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_180000
[2022-07-06 08:05:46,807 callbacks.py:105 INFO train-abinet] epoch 4 iter 180050: loss = 0.7063,  smooth loss = 0.5600
[2022-07-06 08:06:28,103 callbacks.py:105 INFO train-abinet] epoch 4 iter 180100: loss = 0.4947,  smooth loss = 0.5513
[2022-07-06 08:07:10,285 callbacks.py:105 INFO train-abinet] epoch 4 iter 180150: loss = 0.6289,  smooth loss = 0.5673
[2022-07-06 08:07:51,730 callbacks.py:105 INFO train-abinet] epoch 4 iter 180200: loss = 0.5096,  smooth loss = 0.5571
[2022-07-06 08:08:33,997 callbacks.py:105 INFO train-abinet] epoch 4 iter 180250: loss = 0.4355,  smooth loss = 0.5464
[2022-07-06 08:09:15,255 callbacks.py:105 INFO train-abinet] epoch 4 iter 180300: loss = 0.7161,  smooth loss = 0.5637
[2022-07-06 08:09:57,282 callbacks.py:105 INFO train-abinet] epoch 4 iter 180350: loss = 0.6323,  smooth loss = 0.5445
[2022-07-06 08:10:39,082 callbacks.py:105 INFO train-abinet] epoch 4 iter 180400: loss = 0.6555,  smooth loss = 0.5636
[2022-07-06 08:11:20,128 callbacks.py:105 INFO train-abinet] epoch 4 iter 180450: loss = 0.6044,  smooth loss = 0.5529
[2022-07-06 08:12:01,776 callbacks.py:105 INFO train-abinet] epoch 4 iter 180500: loss = 0.4634,  smooth loss = 0.5478
[2022-07-06 08:12:43,612 callbacks.py:105 INFO train-abinet] epoch 4 iter 180550: loss = 0.4722,  smooth loss = 0.5633
[2022-07-06 08:13:24,046 callbacks.py:105 INFO train-abinet] epoch 4 iter 180600: loss = 0.6736,  smooth loss = 0.5742
[2022-07-06 08:14:05,324 callbacks.py:105 INFO train-abinet] epoch 4 iter 180650: loss = 0.4131,  smooth loss = 0.5546
[2022-07-06 08:14:46,630 callbacks.py:105 INFO train-abinet] epoch 4 iter 180700: loss = 0.7412,  smooth loss = 0.5430
[2022-07-06 08:15:27,895 callbacks.py:105 INFO train-abinet] epoch 4 iter 180750: loss = 0.5338,  smooth loss = 0.5558
[2022-07-06 08:16:09,896 callbacks.py:105 INFO train-abinet] epoch 4 iter 180800: loss = 0.7485,  smooth loss = 0.5522
[2022-07-06 08:16:51,994 callbacks.py:105 INFO train-abinet] epoch 4 iter 180850: loss = 0.5484,  smooth loss = 0.5523
[2022-07-06 08:17:36,252 callbacks.py:105 INFO train-abinet] epoch 4 iter 180900: loss = 0.6268,  smooth loss = 0.5599
[2022-07-06 08:18:19,432 callbacks.py:105 INFO train-abinet] epoch 4 iter 180950: loss = 0.6679,  smooth loss = 0.5617
[2022-07-06 08:19:03,703 callbacks.py:105 INFO train-abinet] epoch 4 iter 181000: loss = 0.3695,  smooth loss = 0.5664
[2022-07-06 08:19:46,073 callbacks.py:105 INFO train-abinet] epoch 4 iter 181050: loss = 0.5875,  smooth loss = 0.5728
[2022-07-06 08:20:27,907 callbacks.py:105 INFO train-abinet] epoch 4 iter 181100: loss = 0.6144,  smooth loss = 0.5766
[2022-07-06 08:21:10,249 callbacks.py:105 INFO train-abinet] epoch 4 iter 181150: loss = 0.5702,  smooth loss = 0.5652
[2022-07-06 08:21:52,583 callbacks.py:105 INFO train-abinet] epoch 4 iter 181200: loss = 0.5708,  smooth loss = 0.5565
[2022-07-06 08:22:35,302 callbacks.py:105 INFO train-abinet] epoch 4 iter 181250: loss = 0.5963,  smooth loss = 0.5629
[2022-07-06 08:23:18,153 callbacks.py:105 INFO train-abinet] epoch 4 iter 181300: loss = 0.5838,  smooth loss = 0.5480
[2022-07-06 08:24:00,820 callbacks.py:105 INFO train-abinet] epoch 4 iter 181350: loss = 0.6708,  smooth loss = 0.5680
[2022-07-06 08:24:42,991 callbacks.py:105 INFO train-abinet] epoch 4 iter 181400: loss = 0.7243,  smooth loss = 0.5670
[2022-07-06 08:25:24,740 callbacks.py:105 INFO train-abinet] epoch 4 iter 181450: loss = 0.4026,  smooth loss = 0.5511
[2022-07-06 08:26:06,718 callbacks.py:105 INFO train-abinet] epoch 4 iter 181500: loss = 0.5531,  smooth loss = 0.5632
[2022-07-06 08:26:48,920 callbacks.py:105 INFO train-abinet] epoch 4 iter 181550: loss = 0.6910,  smooth loss = 0.5517
[2022-07-06 08:27:30,897 callbacks.py:105 INFO train-abinet] epoch 4 iter 181600: loss = 0.3630,  smooth loss = 0.5526
[2022-07-06 08:28:13,186 callbacks.py:105 INFO train-abinet] epoch 4 iter 181650: loss = 0.5143,  smooth loss = 0.5398
[2022-07-06 08:28:55,611 callbacks.py:105 INFO train-abinet] epoch 4 iter 181700: loss = 0.5611,  smooth loss = 0.5418
[2022-07-06 08:29:38,546 callbacks.py:105 INFO train-abinet] epoch 4 iter 181750: loss = 0.4966,  smooth loss = 0.5610
[2022-07-06 08:30:20,878 callbacks.py:105 INFO train-abinet] epoch 4 iter 181800: loss = 0.4468,  smooth loss = 0.5612
[2022-07-06 08:31:04,315 callbacks.py:105 INFO train-abinet] epoch 4 iter 181850: loss = 0.4970,  smooth loss = 0.5614
[2022-07-06 08:31:49,898 callbacks.py:105 INFO train-abinet] epoch 4 iter 181900: loss = 0.6828,  smooth loss = 0.5617
[2022-07-06 08:32:31,792 callbacks.py:105 INFO train-abinet] epoch 4 iter 181950: loss = 0.5859,  smooth loss = 0.5429
[2022-07-06 08:33:14,222 callbacks.py:105 INFO train-abinet] epoch 4 iter 182000: loss = 0.4342,  smooth loss = 0.5549
[2022-07-06 08:33:56,243 callbacks.py:105 INFO train-abinet] epoch 4 iter 182050: loss = 0.6963,  smooth loss = 0.5733
[2022-07-06 08:34:37,605 callbacks.py:105 INFO train-abinet] epoch 4 iter 182100: loss = 0.4011,  smooth loss = 0.5444
[2022-07-06 08:35:19,155 callbacks.py:105 INFO train-abinet] epoch 4 iter 182150: loss = 0.4557,  smooth loss = 0.5462
[2022-07-06 08:35:59,913 callbacks.py:105 INFO train-abinet] epoch 4 iter 182200: loss = 0.5582,  smooth loss = 0.5502
[2022-07-06 08:36:42,012 callbacks.py:105 INFO train-abinet] epoch 4 iter 182250: loss = 0.5531,  smooth loss = 0.5535
[2022-07-06 08:37:24,413 callbacks.py:105 INFO train-abinet] epoch 4 iter 182300: loss = 0.5410,  smooth loss = 0.5449
[2022-07-06 08:38:06,022 callbacks.py:105 INFO train-abinet] epoch 4 iter 182350: loss = 0.6935,  smooth loss = 0.5486
[2022-07-06 08:38:48,083 callbacks.py:105 INFO train-abinet] epoch 4 iter 182400: loss = 0.5901,  smooth loss = 0.5550
[2022-07-06 08:39:30,537 callbacks.py:105 INFO train-abinet] epoch 4 iter 182450: loss = 0.6490,  smooth loss = 0.5589
[2022-07-06 08:40:12,237 callbacks.py:105 INFO train-abinet] epoch 4 iter 182500: loss = 0.6459,  smooth loss = 0.5443
[2022-07-06 08:40:53,935 callbacks.py:105 INFO train-abinet] epoch 4 iter 182550: loss = 0.5980,  smooth loss = 0.5652
[2022-07-06 08:41:36,125 callbacks.py:105 INFO train-abinet] epoch 4 iter 182600: loss = 0.4848,  smooth loss = 0.5590
[2022-07-06 08:42:17,400 callbacks.py:105 INFO train-abinet] epoch 4 iter 182650: loss = 0.5891,  smooth loss = 0.5607
[2022-07-06 08:42:59,167 callbacks.py:105 INFO train-abinet] epoch 4 iter 182700: loss = 0.5970,  smooth loss = 0.5589
[2022-07-06 08:43:40,334 callbacks.py:105 INFO train-abinet] epoch 4 iter 182750: loss = 0.5064,  smooth loss = 0.5511
[2022-07-06 08:44:23,274 callbacks.py:105 INFO train-abinet] epoch 4 iter 182800: loss = 0.4600,  smooth loss = 0.5532
[2022-07-06 08:45:05,881 callbacks.py:105 INFO train-abinet] epoch 4 iter 182850: loss = 0.4762,  smooth loss = 0.5433
[2022-07-06 08:45:47,922 callbacks.py:105 INFO train-abinet] epoch 4 iter 182900: loss = 0.6319,  smooth loss = 0.5421
[2022-07-06 08:46:30,081 callbacks.py:105 INFO train-abinet] epoch 4 iter 182950: loss = 0.8497,  smooth loss = 0.5496
[2022-07-06 08:47:11,327 callbacks.py:105 INFO train-abinet] epoch 4 iter 183000: loss = 0.5878,  smooth loss = 0.5473
[2022-07-06 08:47:11,327 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8721s
█[2022-07-06 08:47:25,825 callbacks.py:123 INFO train-abinet] epoch 4 iter 183000: eval loss = 1.1439,  ccr = 0.9611,  cwr = 0.9207,  ted = 1306.0000,  ned = 257.3980,  ted/w = 0.1802, 
[2022-07-06 08:47:25,826 callbacks.py:130 INFO train-abinet] Better model found at epoch 4, iter 183000 with accuracy value: 0.9207.
[2022-07-06 08:47:26,971 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_183000
[2022-07-06 08:48:10,208 callbacks.py:105 INFO train-abinet] epoch 4 iter 183050: loss = 0.5929,  smooth loss = 0.5454
[2022-07-06 08:48:51,381 callbacks.py:105 INFO train-abinet] epoch 4 iter 183100: loss = 0.4686,  smooth loss = 0.5488
[2022-07-06 08:49:32,609 callbacks.py:105 INFO train-abinet] epoch 4 iter 183150: loss = 0.4876,  smooth loss = 0.5473
[2022-07-06 08:50:14,657 callbacks.py:105 INFO train-abinet] epoch 4 iter 183200: loss = 0.6552,  smooth loss = 0.5532
[2022-07-06 08:50:56,115 callbacks.py:105 INFO train-abinet] epoch 4 iter 183250: loss = 0.5726,  smooth loss = 0.5666
[2022-07-06 08:51:38,075 callbacks.py:105 INFO train-abinet] epoch 4 iter 183300: loss = 0.4931,  smooth loss = 0.5592
[2022-07-06 08:52:19,910 callbacks.py:105 INFO train-abinet] epoch 4 iter 183350: loss = 0.5985,  smooth loss = 0.5511
[2022-07-06 08:53:02,121 callbacks.py:105 INFO train-abinet] epoch 4 iter 183400: loss = 0.5030,  smooth loss = 0.5611
[2022-07-06 08:53:43,462 callbacks.py:105 INFO train-abinet] epoch 4 iter 183450: loss = 0.5337,  smooth loss = 0.5539
[2022-07-06 08:54:26,015 callbacks.py:105 INFO train-abinet] epoch 4 iter 183500: loss = 0.5245,  smooth loss = 0.5669
[2022-07-06 08:55:07,596 callbacks.py:105 INFO train-abinet] epoch 4 iter 183550: loss = 0.4887,  smooth loss = 0.5647
[2022-07-06 08:55:49,494 callbacks.py:105 INFO train-abinet] epoch 4 iter 183600: loss = 0.4883,  smooth loss = 0.5589
[2022-07-06 08:56:31,406 callbacks.py:105 INFO train-abinet] epoch 4 iter 183650: loss = 0.5323,  smooth loss = 0.5589
[2022-07-06 08:57:13,330 callbacks.py:105 INFO train-abinet] epoch 4 iter 183700: loss = 0.5498,  smooth loss = 0.5543
[2022-07-06 08:57:55,714 callbacks.py:105 INFO train-abinet] epoch 4 iter 183750: loss = 0.4324,  smooth loss = 0.5493
[2022-07-06 08:58:36,666 callbacks.py:105 INFO train-abinet] epoch 4 iter 183800: loss = 0.6123,  smooth loss = 0.5370
[2022-07-06 08:59:17,597 callbacks.py:105 INFO train-abinet] epoch 4 iter 183850: loss = 0.6119,  smooth loss = 0.5516
[2022-07-06 08:59:58,985 callbacks.py:105 INFO train-abinet] epoch 4 iter 183900: loss = 0.6048,  smooth loss = 0.5645
[2022-07-06 09:00:40,467 callbacks.py:105 INFO train-abinet] epoch 4 iter 183950: loss = 0.5036,  smooth loss = 0.5551
[2022-07-06 09:01:21,887 callbacks.py:105 INFO train-abinet] epoch 4 iter 184000: loss = 0.7011,  smooth loss = 0.5521
[2022-07-06 09:02:03,448 callbacks.py:105 INFO train-abinet] epoch 4 iter 184050: loss = 0.5575,  smooth loss = 0.5398
[2022-07-06 09:02:45,484 callbacks.py:105 INFO train-abinet] epoch 4 iter 184100: loss = 0.4811,  smooth loss = 0.5443
[2022-07-06 09:03:27,610 callbacks.py:105 INFO train-abinet] epoch 4 iter 184150: loss = 0.4499,  smooth loss = 0.5446
[2022-07-06 09:04:09,036 callbacks.py:105 INFO train-abinet] epoch 4 iter 184200: loss = 0.5260,  smooth loss = 0.5548
[2022-07-06 09:04:50,705 callbacks.py:105 INFO train-abinet] epoch 4 iter 184250: loss = 0.3794,  smooth loss = 0.5435
[2022-07-06 09:05:31,436 callbacks.py:105 INFO train-abinet] epoch 4 iter 184300: loss = 0.5568,  smooth loss = 0.5530
[2022-07-06 09:06:12,708 callbacks.py:105 INFO train-abinet] epoch 4 iter 184350: loss = 0.5098,  smooth loss = 0.5419
[2022-07-06 09:06:54,223 callbacks.py:105 INFO train-abinet] epoch 4 iter 184400: loss = 0.4723,  smooth loss = 0.5575
[2022-07-06 09:07:35,224 callbacks.py:105 INFO train-abinet] epoch 4 iter 184450: loss = 0.5066,  smooth loss = 0.5429
[2022-07-06 09:08:16,408 callbacks.py:105 INFO train-abinet] epoch 4 iter 184500: loss = 0.4973,  smooth loss = 0.5455
[2022-07-06 09:08:57,587 callbacks.py:105 INFO train-abinet] epoch 4 iter 184550: loss = 0.6833,  smooth loss = 0.5568
[2022-07-06 09:09:39,099 callbacks.py:105 INFO train-abinet] epoch 4 iter 184600: loss = 0.5692,  smooth loss = 0.5566
[2022-07-06 09:10:20,184 callbacks.py:105 INFO train-abinet] epoch 4 iter 184650: loss = 0.4265,  smooth loss = 0.5509
[2022-07-06 09:11:00,620 callbacks.py:105 INFO train-abinet] epoch 4 iter 184700: loss = 0.5268,  smooth loss = 0.5559
[2022-07-06 09:11:42,443 callbacks.py:105 INFO train-abinet] epoch 4 iter 184750: loss = 0.5388,  smooth loss = 0.5566
[2022-07-06 09:12:23,426 callbacks.py:105 INFO train-abinet] epoch 4 iter 184800: loss = 0.4649,  smooth loss = 0.5545
[2022-07-06 09:13:04,373 callbacks.py:105 INFO train-abinet] epoch 4 iter 184850: loss = 0.7026,  smooth loss = 0.5570
[2022-07-06 09:13:46,317 callbacks.py:105 INFO train-abinet] epoch 4 iter 184900: loss = 0.4812,  smooth loss = 0.5511
[2022-07-06 09:14:27,610 callbacks.py:105 INFO train-abinet] epoch 4 iter 184950: loss = 0.4694,  smooth loss = 0.5438
[2022-07-06 09:15:09,150 callbacks.py:105 INFO train-abinet] epoch 4 iter 185000: loss = 0.5392,  smooth loss = 0.5596
[2022-07-06 09:15:50,612 callbacks.py:105 INFO train-abinet] epoch 4 iter 185050: loss = 0.5263,  smooth loss = 0.5567
[2022-07-06 09:16:32,242 callbacks.py:105 INFO train-abinet] epoch 4 iter 185100: loss = 0.5756,  smooth loss = 0.5625
[2022-07-06 09:17:13,231 callbacks.py:105 INFO train-abinet] epoch 4 iter 185150: loss = 0.5665,  smooth loss = 0.5528
[2022-07-06 09:17:55,557 callbacks.py:105 INFO train-abinet] epoch 4 iter 185200: loss = 0.6354,  smooth loss = 0.5527
[2022-07-06 09:18:38,088 callbacks.py:105 INFO train-abinet] epoch 4 iter 185250: loss = 0.4960,  smooth loss = 0.5630
[2022-07-06 09:19:19,544 callbacks.py:105 INFO train-abinet] epoch 4 iter 185300: loss = 0.5303,  smooth loss = 0.5596
[2022-07-06 09:20:00,809 callbacks.py:105 INFO train-abinet] epoch 4 iter 185350: loss = 0.5039,  smooth loss = 0.5553
[2022-07-06 09:20:41,868 callbacks.py:105 INFO train-abinet] epoch 4 iter 185400: loss = 0.5027,  smooth loss = 0.5611
[2022-07-06 09:21:23,936 callbacks.py:105 INFO train-abinet] epoch 4 iter 185450: loss = 0.5755,  smooth loss = 0.5656
[2022-07-06 09:22:05,971 callbacks.py:105 INFO train-abinet] epoch 4 iter 185500: loss = 0.5197,  smooth loss = 0.5547
[2022-07-06 09:22:47,335 callbacks.py:105 INFO train-abinet] epoch 4 iter 185550: loss = 0.4310,  smooth loss = 0.5363
[2022-07-06 09:23:29,594 callbacks.py:105 INFO train-abinet] epoch 4 iter 185600: loss = 0.6113,  smooth loss = 0.5521
[2022-07-06 09:24:10,836 callbacks.py:105 INFO train-abinet] epoch 4 iter 185650: loss = 0.4917,  smooth loss = 0.5461
[2022-07-06 09:24:52,692 callbacks.py:105 INFO train-abinet] epoch 4 iter 185700: loss = 0.5062,  smooth loss = 0.5429
[2022-07-06 09:25:34,652 callbacks.py:105 INFO train-abinet] epoch 4 iter 185750: loss = 0.4466,  smooth loss = 0.5447
[2022-07-06 09:26:16,558 callbacks.py:105 INFO train-abinet] epoch 4 iter 185800: loss = 0.5423,  smooth loss = 0.5469
[2022-07-06 09:26:57,983 callbacks.py:105 INFO train-abinet] epoch 4 iter 185850: loss = 0.6282,  smooth loss = 0.5558
[2022-07-06 09:27:40,340 callbacks.py:105 INFO train-abinet] epoch 4 iter 185900: loss = 0.4994,  smooth loss = 0.5597
[2022-07-06 09:28:22,319 callbacks.py:105 INFO train-abinet] epoch 4 iter 185950: loss = 0.4665,  smooth loss = 0.5445
[2022-07-06 09:29:04,277 callbacks.py:105 INFO train-abinet] epoch 4 iter 186000: loss = 0.4211,  smooth loss = 0.5553
[2022-07-06 09:29:04,277 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8715s
█[2022-07-06 09:29:18,583 callbacks.py:123 INFO train-abinet] epoch 4 iter 186000: eval loss = 1.1714,  ccr = 0.9602,  cwr = 0.9209,  ted = 1318.0000,  ned = 260.0772,  ted/w = 0.1818, 
[2022-07-06 09:29:18,584 callbacks.py:130 INFO train-abinet] Better model found at epoch 4, iter 186000 with accuracy value: 0.9209.
[2022-07-06 09:29:19,758 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_186000
[2022-07-06 09:30:01,935 callbacks.py:105 INFO train-abinet] epoch 4 iter 186050: loss = 0.6422,  smooth loss = 0.5628
[2022-07-06 09:30:43,478 callbacks.py:105 INFO train-abinet] epoch 4 iter 186100: loss = 0.5941,  smooth loss = 0.5544
[2022-07-06 09:31:24,708 callbacks.py:105 INFO train-abinet] epoch 4 iter 186150: loss = 0.6118,  smooth loss = 0.5588
[2022-07-06 09:32:06,407 callbacks.py:105 INFO train-abinet] epoch 4 iter 186200: loss = 0.5578,  smooth loss = 0.5537
[2022-07-06 09:32:48,639 callbacks.py:105 INFO train-abinet] epoch 4 iter 186250: loss = 0.6150,  smooth loss = 0.5561
[2022-07-06 09:33:30,732 callbacks.py:105 INFO train-abinet] epoch 4 iter 186300: loss = 0.4968,  smooth loss = 0.5614
[2022-07-06 09:34:13,736 callbacks.py:105 INFO train-abinet] epoch 4 iter 186350: loss = 0.4378,  smooth loss = 0.5680
[2022-07-06 09:34:57,713 callbacks.py:105 INFO train-abinet] epoch 4 iter 186400: loss = 0.4623,  smooth loss = 0.5447
[2022-07-06 09:35:40,281 callbacks.py:105 INFO train-abinet] epoch 4 iter 186450: loss = 0.6097,  smooth loss = 0.5493
[2022-07-06 09:36:23,335 callbacks.py:105 INFO train-abinet] epoch 4 iter 186500: loss = 0.4734,  smooth loss = 0.5460
[2022-07-06 09:37:07,155 callbacks.py:105 INFO train-abinet] epoch 4 iter 186550: loss = 0.6528,  smooth loss = 0.5487
[2022-07-06 09:37:50,056 callbacks.py:105 INFO train-abinet] epoch 4 iter 186600: loss = 0.5486,  smooth loss = 0.5463
[2022-07-06 09:38:32,674 callbacks.py:105 INFO train-abinet] epoch 4 iter 186650: loss = 0.6222,  smooth loss = 0.5453
[2022-07-06 09:39:18,092 callbacks.py:105 INFO train-abinet] epoch 4 iter 186700: loss = 0.6122,  smooth loss = 0.5477
[2022-07-06 09:40:01,288 callbacks.py:105 INFO train-abinet] epoch 4 iter 186750: loss = 0.5930,  smooth loss = 0.5557
[2022-07-06 09:40:44,593 callbacks.py:105 INFO train-abinet] epoch 4 iter 186800: loss = 0.5397,  smooth loss = 0.5510
[2022-07-06 09:41:28,774 callbacks.py:105 INFO train-abinet] epoch 4 iter 186850: loss = 0.6273,  smooth loss = 0.5511
[2022-07-06 09:42:13,302 callbacks.py:105 INFO train-abinet] epoch 4 iter 186900: loss = 0.4266,  smooth loss = 0.5422
[2022-07-06 09:42:56,906 callbacks.py:105 INFO train-abinet] epoch 4 iter 186950: loss = 0.5005,  smooth loss = 0.5489
[2022-07-06 09:43:41,585 callbacks.py:105 INFO train-abinet] epoch 4 iter 187000: loss = 0.5214,  smooth loss = 0.5605
[2022-07-06 09:44:25,502 callbacks.py:105 INFO train-abinet] epoch 4 iter 187050: loss = 0.4558,  smooth loss = 0.5460
[2022-07-06 09:45:11,151 callbacks.py:105 INFO train-abinet] epoch 4 iter 187100: loss = 0.6683,  smooth loss = 0.5537
[2022-07-06 09:45:56,442 callbacks.py:105 INFO train-abinet] epoch 4 iter 187150: loss = 0.5630,  smooth loss = 0.5514
[2022-07-06 09:46:40,314 callbacks.py:105 INFO train-abinet] epoch 4 iter 187200: loss = 0.3479,  smooth loss = 0.5523
[2022-07-06 09:47:25,411 callbacks.py:105 INFO train-abinet] epoch 4 iter 187250: loss = 0.5709,  smooth loss = 0.5562
[2022-07-06 09:48:10,813 callbacks.py:105 INFO train-abinet] epoch 4 iter 187300: loss = 0.4267,  smooth loss = 0.5475
[2022-07-06 09:48:55,917 callbacks.py:105 INFO train-abinet] epoch 4 iter 187350: loss = 0.4919,  smooth loss = 0.5322
[2022-07-06 09:49:41,034 callbacks.py:105 INFO train-abinet] epoch 4 iter 187400: loss = 0.5136,  smooth loss = 0.5478
[2022-07-06 09:50:25,283 callbacks.py:105 INFO train-abinet] epoch 4 iter 187450: loss = 0.4085,  smooth loss = 0.5493
[2022-07-06 09:51:09,674 callbacks.py:105 INFO train-abinet] epoch 4 iter 187500: loss = 0.5959,  smooth loss = 0.5472
[2022-07-06 09:51:55,445 callbacks.py:105 INFO train-abinet] epoch 4 iter 187550: loss = 0.5103,  smooth loss = 0.5540
[2022-07-06 09:52:40,605 callbacks.py:105 INFO train-abinet] epoch 4 iter 187600: loss = 0.6564,  smooth loss = 0.5586
[2022-07-06 09:53:25,486 callbacks.py:105 INFO train-abinet] epoch 4 iter 187650: loss = 0.6493,  smooth loss = 0.5353
[2022-07-06 09:54:10,217 callbacks.py:105 INFO train-abinet] epoch 4 iter 187700: loss = 0.5774,  smooth loss = 0.5490
[2022-07-06 09:54:56,438 callbacks.py:105 INFO train-abinet] epoch 4 iter 187750: loss = 0.4557,  smooth loss = 0.5473
[2022-07-06 09:55:40,786 callbacks.py:105 INFO train-abinet] epoch 4 iter 187800: loss = 0.4839,  smooth loss = 0.5460
[2022-07-06 09:56:25,483 callbacks.py:105 INFO train-abinet] epoch 4 iter 187850: loss = 0.5695,  smooth loss = 0.5576
[2022-07-06 09:57:13,424 callbacks.py:105 INFO train-abinet] epoch 4 iter 187900: loss = 0.4467,  smooth loss = 0.5377
[2022-07-06 09:57:58,435 callbacks.py:105 INFO train-abinet] epoch 4 iter 187950: loss = 0.7197,  smooth loss = 0.5482
[2022-07-06 09:58:43,472 callbacks.py:105 INFO train-abinet] epoch 4 iter 188000: loss = 0.8274,  smooth loss = 0.5432
[2022-07-06 09:59:31,399 callbacks.py:105 INFO train-abinet] epoch 4 iter 188050: loss = 0.5634,  smooth loss = 0.5579
[2022-07-06 10:00:17,101 callbacks.py:105 INFO train-abinet] epoch 4 iter 188100: loss = 0.4530,  smooth loss = 0.5468
[2022-07-06 10:01:01,216 callbacks.py:105 INFO train-abinet] epoch 4 iter 188150: loss = 0.6197,  smooth loss = 0.5600
[2022-07-06 10:01:44,674 callbacks.py:105 INFO train-abinet] epoch 4 iter 188200: loss = 0.6435,  smooth loss = 0.5704
[2022-07-06 10:02:28,506 callbacks.py:105 INFO train-abinet] epoch 4 iter 188250: loss = 0.3719,  smooth loss = 0.5535
[2022-07-06 10:03:13,659 callbacks.py:105 INFO train-abinet] epoch 4 iter 188300: loss = 0.5354,  smooth loss = 0.5517
[2022-07-06 10:03:57,977 callbacks.py:105 INFO train-abinet] epoch 4 iter 188350: loss = 0.4900,  smooth loss = 0.5498
[2022-07-06 10:04:42,529 callbacks.py:105 INFO train-abinet] epoch 4 iter 188400: loss = 0.6941,  smooth loss = 0.5723
[2022-07-06 10:05:27,298 callbacks.py:105 INFO train-abinet] epoch 4 iter 188450: loss = 0.6550,  smooth loss = 0.5625
[2022-07-06 10:06:11,390 callbacks.py:105 INFO train-abinet] epoch 4 iter 188500: loss = 0.5937,  smooth loss = 0.5584
[2022-07-06 10:06:56,219 callbacks.py:105 INFO train-abinet] epoch 4 iter 188550: loss = 0.5440,  smooth loss = 0.5459
[2022-07-06 10:07:41,069 callbacks.py:105 INFO train-abinet] epoch 4 iter 188600: loss = 0.6227,  smooth loss = 0.5600
[2022-07-06 10:08:25,818 callbacks.py:105 INFO train-abinet] epoch 4 iter 188650: loss = 0.5101,  smooth loss = 0.5504
[2022-07-06 10:09:10,020 callbacks.py:105 INFO train-abinet] epoch 4 iter 188700: loss = 0.4156,  smooth loss = 0.5587
[2022-07-06 10:09:55,240 callbacks.py:105 INFO train-abinet] epoch 4 iter 188750: loss = 0.5514,  smooth loss = 0.5514
[2022-07-06 10:10:40,033 callbacks.py:105 INFO train-abinet] epoch 4 iter 188800: loss = 0.7246,  smooth loss = 0.5543
[2022-07-06 10:11:25,987 callbacks.py:105 INFO train-abinet] epoch 4 iter 188850: loss = 0.5458,  smooth loss = 0.5408
[2022-07-06 10:12:11,185 callbacks.py:105 INFO train-abinet] epoch 4 iter 188900: loss = 0.5710,  smooth loss = 0.5346
[2022-07-06 10:12:55,523 callbacks.py:105 INFO train-abinet] epoch 4 iter 188950: loss = 0.4836,  smooth loss = 0.5474
[2022-07-06 10:13:40,549 callbacks.py:105 INFO train-abinet] epoch 4 iter 189000: loss = 0.5608,  smooth loss = 0.5435
[2022-07-06 10:13:40,550 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8718s
█[2022-07-06 10:13:56,212 callbacks.py:123 INFO train-abinet] epoch 4 iter 189000: eval loss = 1.1530,  ccr = 0.9599,  cwr = 0.9171,  ted = 1361.0000,  ned = 270.8273,  ted/w = 0.1878, 
[2022-07-06 10:13:56,215 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_189000
[2022-07-06 10:14:41,266 callbacks.py:105 INFO train-abinet] epoch 4 iter 189050: loss = 0.4467,  smooth loss = 0.5491
[2022-07-06 10:15:26,875 callbacks.py:105 INFO train-abinet] epoch 4 iter 189100: loss = 0.5102,  smooth loss = 0.5357
[2022-07-06 10:16:12,436 callbacks.py:105 INFO train-abinet] epoch 4 iter 189150: loss = 0.5586,  smooth loss = 0.5541
[2022-07-06 10:16:57,056 callbacks.py:105 INFO train-abinet] epoch 4 iter 189200: loss = 0.6859,  smooth loss = 0.5537
[2022-07-06 10:17:41,577 callbacks.py:105 INFO train-abinet] epoch 4 iter 189250: loss = 0.4269,  smooth loss = 0.5513
[2022-07-06 10:18:25,605 callbacks.py:105 INFO train-abinet] epoch 4 iter 189300: loss = 0.4618,  smooth loss = 0.5528
[2022-07-06 10:19:09,215 callbacks.py:105 INFO train-abinet] epoch 4 iter 189350: loss = 0.4546,  smooth loss = 0.5481
[2022-07-06 10:19:53,592 callbacks.py:105 INFO train-abinet] epoch 4 iter 189400: loss = 0.5946,  smooth loss = 0.5588
[2022-07-06 10:20:38,011 callbacks.py:105 INFO train-abinet] epoch 4 iter 189450: loss = 0.4068,  smooth loss = 0.5549
[2022-07-06 10:21:22,008 callbacks.py:105 INFO train-abinet] epoch 4 iter 189500: loss = 0.6531,  smooth loss = 0.5562
[2022-07-06 10:22:06,800 callbacks.py:105 INFO train-abinet] epoch 4 iter 189550: loss = 0.6209,  smooth loss = 0.5376
[2022-07-06 10:22:51,653 callbacks.py:105 INFO train-abinet] epoch 4 iter 189600: loss = 0.6690,  smooth loss = 0.5492
[2022-07-06 10:23:37,344 callbacks.py:105 INFO train-abinet] epoch 4 iter 189650: loss = 0.4406,  smooth loss = 0.5436
[2022-07-06 10:24:22,188 callbacks.py:105 INFO train-abinet] epoch 4 iter 189700: loss = 0.5466,  smooth loss = 0.5506
[2022-07-06 10:25:06,523 callbacks.py:105 INFO train-abinet] epoch 4 iter 189750: loss = 0.5259,  smooth loss = 0.5363
[2022-07-06 10:25:50,325 callbacks.py:105 INFO train-abinet] epoch 4 iter 189800: loss = 0.6217,  smooth loss = 0.5452
[2022-07-06 10:26:35,601 callbacks.py:105 INFO train-abinet] epoch 4 iter 189850: loss = 0.6481,  smooth loss = 0.5445
[2022-07-06 10:27:20,922 callbacks.py:105 INFO train-abinet] epoch 4 iter 189900: loss = 0.4549,  smooth loss = 0.5486
[2022-07-06 10:28:04,987 callbacks.py:105 INFO train-abinet] epoch 4 iter 189950: loss = 0.4257,  smooth loss = 0.5575
[2022-07-06 10:28:49,719 callbacks.py:105 INFO train-abinet] epoch 4 iter 190000: loss = 0.6097,  smooth loss = 0.5539
[2022-07-06 10:29:32,663 callbacks.py:105 INFO train-abinet] epoch 4 iter 190050: loss = 0.5162,  smooth loss = 0.5428
[2022-07-06 10:30:16,252 callbacks.py:105 INFO train-abinet] epoch 4 iter 190100: loss = 0.5657,  smooth loss = 0.5518
[2022-07-06 10:31:00,193 callbacks.py:105 INFO train-abinet] epoch 4 iter 190150: loss = 0.5362,  smooth loss = 0.5414
[2022-07-06 10:31:44,813 callbacks.py:105 INFO train-abinet] epoch 4 iter 190200: loss = 0.4235,  smooth loss = 0.5470
[2022-07-06 10:32:28,515 callbacks.py:105 INFO train-abinet] epoch 4 iter 190250: loss = 0.5859,  smooth loss = 0.5561
[2022-07-06 10:33:14,612 callbacks.py:105 INFO train-abinet] epoch 4 iter 190300: loss = 0.4305,  smooth loss = 0.5583
[2022-07-06 10:33:58,437 callbacks.py:105 INFO train-abinet] epoch 4 iter 190350: loss = 0.4810,  smooth loss = 0.5474
[2022-07-06 10:34:42,897 callbacks.py:105 INFO train-abinet] epoch 4 iter 190400: loss = 0.5255,  smooth loss = 0.5504
[2022-07-06 10:35:26,832 callbacks.py:105 INFO train-abinet] epoch 4 iter 190450: loss = 0.4910,  smooth loss = 0.5423
[2022-07-06 10:36:10,530 callbacks.py:105 INFO train-abinet] epoch 4 iter 190500: loss = 0.6586,  smooth loss = 0.5757
[2022-07-06 10:36:54,505 callbacks.py:105 INFO train-abinet] epoch 4 iter 190550: loss = 0.6704,  smooth loss = 0.5856
[2022-07-06 10:37:38,837 callbacks.py:105 INFO train-abinet] epoch 4 iter 190600: loss = 0.4566,  smooth loss = 0.5688
[2022-07-06 10:38:23,606 callbacks.py:105 INFO train-abinet] epoch 4 iter 190650: loss = 0.5409,  smooth loss = 0.5655
[2022-07-06 10:39:08,587 callbacks.py:105 INFO train-abinet] epoch 4 iter 190700: loss = 0.4899,  smooth loss = 0.5507
[2022-07-06 10:39:51,925 callbacks.py:105 INFO train-abinet] epoch 4 iter 190750: loss = 0.5889,  smooth loss = 0.5513
[2022-07-06 10:40:37,400 callbacks.py:105 INFO train-abinet] epoch 4 iter 190800: loss = 0.5870,  smooth loss = 0.5451
[2022-07-06 10:41:21,096 callbacks.py:105 INFO train-abinet] epoch 4 iter 190850: loss = 0.5881,  smooth loss = 0.5538
[2022-07-06 10:42:06,131 callbacks.py:105 INFO train-abinet] epoch 4 iter 190900: loss = 0.4894,  smooth loss = 0.5428
[2022-07-06 10:42:49,574 callbacks.py:105 INFO train-abinet] epoch 4 iter 190950: loss = 0.5660,  smooth loss = 0.5510
[2022-07-06 10:43:33,676 callbacks.py:105 INFO train-abinet] epoch 4 iter 191000: loss = 0.5115,  smooth loss = 0.5511
[2022-07-06 10:44:17,669 callbacks.py:105 INFO train-abinet] epoch 4 iter 191050: loss = 0.5990,  smooth loss = 0.5668
[2022-07-06 10:45:01,255 callbacks.py:105 INFO train-abinet] epoch 4 iter 191100: loss = 0.6110,  smooth loss = 0.5770
[2022-07-06 10:45:44,753 callbacks.py:105 INFO train-abinet] epoch 4 iter 191150: loss = 0.5899,  smooth loss = 0.5691
[2022-07-06 10:46:28,048 callbacks.py:105 INFO train-abinet] epoch 4 iter 191200: loss = 0.5455,  smooth loss = 0.5657
[2022-07-06 10:47:12,692 callbacks.py:105 INFO train-abinet] epoch 4 iter 191250: loss = 0.5285,  smooth loss = 0.5698
[2022-07-06 10:47:55,023 callbacks.py:105 INFO train-abinet] epoch 4 iter 191300: loss = 0.5822,  smooth loss = 0.5573
[2022-07-06 10:48:39,489 callbacks.py:105 INFO train-abinet] epoch 4 iter 191350: loss = 0.5157,  smooth loss = 0.5754
[2022-07-06 10:49:22,993 callbacks.py:105 INFO train-abinet] epoch 4 iter 191400: loss = 0.4467,  smooth loss = 0.5630
[2022-07-06 10:50:07,319 callbacks.py:105 INFO train-abinet] epoch 4 iter 191450: loss = 0.5506,  smooth loss = 0.5601
[2022-07-06 10:50:50,115 callbacks.py:105 INFO train-abinet] epoch 4 iter 191500: loss = 0.5819,  smooth loss = 0.5455
[2022-07-06 10:51:34,083 callbacks.py:105 INFO train-abinet] epoch 4 iter 191550: loss = 0.5927,  smooth loss = 0.5487
[2022-07-06 10:52:18,285 callbacks.py:105 INFO train-abinet] epoch 4 iter 191600: loss = 0.5708,  smooth loss = 0.5513
[2022-07-06 10:53:01,610 callbacks.py:105 INFO train-abinet] epoch 4 iter 191650: loss = 0.6598,  smooth loss = 0.5408
[2022-07-06 10:53:44,083 callbacks.py:105 INFO train-abinet] epoch 4 iter 191700: loss = 0.6442,  smooth loss = 0.5472
[2022-07-06 10:54:28,264 callbacks.py:105 INFO train-abinet] epoch 4 iter 191750: loss = 0.5574,  smooth loss = 0.5464
[2022-07-06 10:55:11,384 callbacks.py:105 INFO train-abinet] epoch 4 iter 191800: loss = 0.5063,  smooth loss = 0.5441
[2022-07-06 10:55:55,316 callbacks.py:105 INFO train-abinet] epoch 4 iter 191850: loss = 0.6122,  smooth loss = 0.5500
[2022-07-06 10:56:38,372 callbacks.py:105 INFO train-abinet] epoch 4 iter 191900: loss = 0.5829,  smooth loss = 0.5452
[2022-07-06 10:57:21,580 callbacks.py:105 INFO train-abinet] epoch 4 iter 191950: loss = 0.4061,  smooth loss = 0.5469
[2022-07-06 10:58:05,749 callbacks.py:105 INFO train-abinet] epoch 4 iter 192000: loss = 0.6066,  smooth loss = 0.5490
[2022-07-06 10:58:05,749 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8719s
█[2022-07-06 10:58:21,053 callbacks.py:123 INFO train-abinet] epoch 4 iter 192000: eval loss = 1.1861,  ccr = 0.9572,  cwr = 0.9146,  ted = 1396.0000,  ned = 283.3986,  ted/w = 0.1926, 
[2022-07-06 10:58:21,054 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_192000
[2022-07-06 10:59:05,827 callbacks.py:105 INFO train-abinet] epoch 4 iter 192050: loss = 0.4810,  smooth loss = 0.5473
[2022-07-06 10:59:50,144 callbacks.py:105 INFO train-abinet] epoch 4 iter 192100: loss = 0.4142,  smooth loss = 0.5494
[2022-07-06 11:00:35,291 callbacks.py:105 INFO train-abinet] epoch 4 iter 192150: loss = 0.7352,  smooth loss = 0.5507
[2022-07-06 11:01:18,748 callbacks.py:105 INFO train-abinet] epoch 4 iter 192200: loss = 0.4876,  smooth loss = 0.5514
[2022-07-06 11:02:02,856 callbacks.py:105 INFO train-abinet] epoch 4 iter 192250: loss = 0.6608,  smooth loss = 0.5474
[2022-07-06 11:02:46,419 callbacks.py:105 INFO train-abinet] epoch 4 iter 192300: loss = 0.5616,  smooth loss = 0.5466
[2022-07-06 11:03:32,328 callbacks.py:105 INFO train-abinet] epoch 4 iter 192350: loss = 0.5508,  smooth loss = 0.5362
[2022-07-06 11:04:16,561 callbacks.py:105 INFO train-abinet] epoch 4 iter 192400: loss = 0.6875,  smooth loss = 0.5488
[2022-07-06 11:05:00,704 callbacks.py:105 INFO train-abinet] epoch 4 iter 192450: loss = 0.4076,  smooth loss = 0.5561
[2022-07-06 11:05:43,596 callbacks.py:105 INFO train-abinet] epoch 4 iter 192500: loss = 0.5490,  smooth loss = 0.5529
[2022-07-06 11:06:27,181 callbacks.py:105 INFO train-abinet] epoch 4 iter 192550: loss = 0.5363,  smooth loss = 0.5486
[2022-07-06 11:07:11,238 callbacks.py:105 INFO train-abinet] epoch 4 iter 192600: loss = 0.4797,  smooth loss = 0.5488
[2022-07-06 11:07:55,249 callbacks.py:105 INFO train-abinet] epoch 4 iter 192650: loss = 0.4823,  smooth loss = 0.5450
[2022-07-06 11:08:39,263 callbacks.py:105 INFO train-abinet] epoch 4 iter 192700: loss = 0.6576,  smooth loss = 0.5425
[2022-07-06 11:09:22,683 callbacks.py:105 INFO train-abinet] epoch 4 iter 192750: loss = 0.6681,  smooth loss = 0.5567
[2022-07-06 11:10:06,581 callbacks.py:105 INFO train-abinet] epoch 4 iter 192800: loss = 0.5446,  smooth loss = 0.5554
[2022-07-06 11:10:49,852 callbacks.py:105 INFO train-abinet] epoch 4 iter 192850: loss = 0.4178,  smooth loss = 0.5598
[2022-07-06 11:11:33,523 callbacks.py:105 INFO train-abinet] epoch 4 iter 192900: loss = 0.5984,  smooth loss = 0.5552
[2022-07-06 11:12:15,581 callbacks.py:105 INFO train-abinet] epoch 4 iter 192950: loss = 0.6144,  smooth loss = 0.5519
[2022-07-06 11:12:58,979 callbacks.py:105 INFO train-abinet] epoch 4 iter 193000: loss = 0.5944,  smooth loss = 0.5579
[2022-07-06 11:13:43,924 callbacks.py:105 INFO train-abinet] epoch 4 iter 193050: loss = 0.5987,  smooth loss = 0.5514
[2022-07-06 11:14:28,131 callbacks.py:105 INFO train-abinet] epoch 4 iter 193100: loss = 0.4332,  smooth loss = 0.5446
[2022-07-06 11:15:11,686 callbacks.py:105 INFO train-abinet] epoch 4 iter 193150: loss = 0.5795,  smooth loss = 0.5472
[2022-07-06 11:15:55,766 callbacks.py:105 INFO train-abinet] epoch 4 iter 193200: loss = 0.5286,  smooth loss = 0.5566
[2022-07-06 11:16:39,499 callbacks.py:105 INFO train-abinet] epoch 4 iter 193250: loss = 0.6440,  smooth loss = 0.5553
[2022-07-06 11:17:23,420 callbacks.py:105 INFO train-abinet] epoch 4 iter 193300: loss = 0.5411,  smooth loss = 0.5492
[2022-07-06 11:18:07,312 callbacks.py:105 INFO train-abinet] epoch 4 iter 193350: loss = 0.6084,  smooth loss = 0.5604
[2022-07-06 11:18:50,123 callbacks.py:105 INFO train-abinet] epoch 4 iter 193400: loss = 0.6270,  smooth loss = 0.5507
[2022-07-06 11:19:33,140 callbacks.py:105 INFO train-abinet] epoch 4 iter 193450: loss = 0.5360,  smooth loss = 0.5501
[2022-07-06 11:20:15,829 callbacks.py:105 INFO train-abinet] epoch 4 iter 193500: loss = 0.4609,  smooth loss = 0.5372
[2022-07-06 11:21:02,743 callbacks.py:105 INFO train-abinet] epoch 4 iter 193550: loss = 0.5533,  smooth loss = 0.5422
[2022-07-06 11:21:50,491 callbacks.py:105 INFO train-abinet] epoch 4 iter 193600: loss = 0.6928,  smooth loss = 0.5541
[2022-07-06 11:22:33,663 callbacks.py:105 INFO train-abinet] epoch 4 iter 193650: loss = 0.5306,  smooth loss = 0.5587
[2022-07-06 11:23:17,761 callbacks.py:105 INFO train-abinet] epoch 4 iter 193700: loss = 0.7195,  smooth loss = 0.5701
[2022-07-06 11:24:00,516 callbacks.py:105 INFO train-abinet] epoch 4 iter 193750: loss = 0.4773,  smooth loss = 0.5789
[2022-07-06 11:24:44,911 callbacks.py:105 INFO train-abinet] epoch 4 iter 193800: loss = 0.6078,  smooth loss = 0.5641
[2022-07-06 11:25:29,799 callbacks.py:105 INFO train-abinet] epoch 4 iter 193850: loss = 0.6050,  smooth loss = 0.5522
[2022-07-06 11:26:13,292 callbacks.py:105 INFO train-abinet] epoch 4 iter 193900: loss = 0.5804,  smooth loss = 0.5477
[2022-07-06 11:26:58,015 callbacks.py:105 INFO train-abinet] epoch 4 iter 193950: loss = 0.4013,  smooth loss = 0.5321
[2022-07-06 11:27:40,337 callbacks.py:105 INFO train-abinet] epoch 4 iter 194000: loss = 0.5764,  smooth loss = 0.5285
[2022-07-06 11:28:23,637 callbacks.py:105 INFO train-abinet] epoch 4 iter 194050: loss = 0.5106,  smooth loss = 0.5424
[2022-07-06 11:29:06,284 callbacks.py:105 INFO train-abinet] epoch 4 iter 194100: loss = 0.6543,  smooth loss = 0.5496
[2022-07-06 11:29:49,992 callbacks.py:105 INFO train-abinet] epoch 4 iter 194150: loss = 0.6933,  smooth loss = 0.5584
[2022-07-06 11:30:35,895 callbacks.py:105 INFO train-abinet] epoch 4 iter 194200: loss = 0.7688,  smooth loss = 0.5597
[2022-07-06 11:31:21,280 callbacks.py:105 INFO train-abinet] epoch 4 iter 194250: loss = 0.6413,  smooth loss = 0.5569
[2022-07-06 11:32:05,768 callbacks.py:105 INFO train-abinet] epoch 4 iter 194300: loss = 0.5480,  smooth loss = 0.5623
[2022-07-06 11:32:49,805 callbacks.py:105 INFO train-abinet] epoch 4 iter 194350: loss = 0.6429,  smooth loss = 0.5622
[2022-07-06 11:33:34,351 callbacks.py:105 INFO train-abinet] epoch 4 iter 194400: loss = 0.4530,  smooth loss = 0.5448
[2022-07-06 11:34:18,383 callbacks.py:105 INFO train-abinet] epoch 4 iter 194450: loss = 0.5650,  smooth loss = 0.5396
[2022-07-06 11:35:01,807 callbacks.py:105 INFO train-abinet] epoch 4 iter 194500: loss = 0.4859,  smooth loss = 0.5370
[2022-07-06 11:35:49,658 callbacks.py:105 INFO train-abinet] epoch 4 iter 194550: loss = 0.5719,  smooth loss = 0.5465
[2022-07-06 11:36:36,761 callbacks.py:105 INFO train-abinet] epoch 4 iter 194600: loss = 0.4828,  smooth loss = 0.5587
[2022-07-06 11:37:22,393 callbacks.py:105 INFO train-abinet] epoch 4 iter 194650: loss = 0.5870,  smooth loss = 0.5480
[2022-07-06 11:38:08,298 callbacks.py:105 INFO train-abinet] epoch 4 iter 194700: loss = 0.4593,  smooth loss = 0.5347
[2022-07-06 11:38:59,213 callbacks.py:105 INFO train-abinet] epoch 4 iter 194750: loss = 0.4120,  smooth loss = 0.5472
[2022-07-06 11:39:44,035 callbacks.py:105 INFO train-abinet] epoch 4 iter 194800: loss = 0.7038,  smooth loss = 0.5468
[2022-07-06 11:40:28,055 callbacks.py:105 INFO train-abinet] epoch 4 iter 194850: loss = 0.6158,  smooth loss = 0.5564
[2022-07-06 11:41:11,757 callbacks.py:105 INFO train-abinet] epoch 4 iter 194900: loss = 0.4729,  smooth loss = 0.5551
[2022-07-06 11:41:55,829 callbacks.py:105 INFO train-abinet] epoch 4 iter 194950: loss = 0.4590,  smooth loss = 0.5686
[2022-07-06 11:42:38,084 callbacks.py:105 INFO train-abinet] epoch 4 iter 195000: loss = 0.5273,  smooth loss = 0.5569
[2022-07-06 11:42:38,085 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8722s
█[2022-07-06 11:42:53,131 callbacks.py:123 INFO train-abinet] epoch 4 iter 195000: eval loss = 1.1508,  ccr = 0.9577,  cwr = 0.9129,  ted = 1412.0000,  ned = 278.2904,  ted/w = 0.1948, 
[2022-07-06 11:42:53,132 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_195000
[2022-07-06 11:43:38,878 callbacks.py:105 INFO train-abinet] epoch 4 iter 195050: loss = 0.6470,  smooth loss = 0.5549
[2022-07-06 11:44:22,761 callbacks.py:105 INFO train-abinet] epoch 4 iter 195100: loss = 0.5823,  smooth loss = 0.5497
[2022-07-06 11:45:05,448 callbacks.py:105 INFO train-abinet] epoch 4 iter 195150: loss = 0.5045,  smooth loss = 0.5502
[2022-07-06 11:45:48,112 callbacks.py:105 INFO train-abinet] epoch 4 iter 195200: loss = 0.5256,  smooth loss = 0.5539
[2022-07-06 11:46:32,474 callbacks.py:105 INFO train-abinet] epoch 4 iter 195250: loss = 0.4924,  smooth loss = 0.5384
[2022-07-06 11:47:17,031 callbacks.py:105 INFO train-abinet] epoch 4 iter 195300: loss = 0.4863,  smooth loss = 0.5429
[2022-07-06 11:48:01,962 callbacks.py:105 INFO train-abinet] epoch 4 iter 195350: loss = 0.4834,  smooth loss = 0.5467
[2022-07-06 11:48:46,599 callbacks.py:105 INFO train-abinet] epoch 4 iter 195400: loss = 0.4838,  smooth loss = 0.5478
[2022-07-06 11:49:30,167 callbacks.py:105 INFO train-abinet] epoch 4 iter 195450: loss = 0.5811,  smooth loss = 0.5550
[2022-07-06 11:50:13,273 callbacks.py:105 INFO train-abinet] epoch 4 iter 195500: loss = 0.6071,  smooth loss = 0.5457
[2022-07-06 11:50:56,983 callbacks.py:105 INFO train-abinet] epoch 4 iter 195550: loss = 0.5149,  smooth loss = 0.5422
[2022-07-06 11:51:40,579 callbacks.py:105 INFO train-abinet] epoch 4 iter 195600: loss = 0.5057,  smooth loss = 0.5481
[2022-07-06 11:52:25,267 callbacks.py:105 INFO train-abinet] epoch 4 iter 195650: loss = 0.5096,  smooth loss = 0.5417
[2022-07-06 11:53:10,925 callbacks.py:105 INFO train-abinet] epoch 4 iter 195700: loss = 0.6826,  smooth loss = 0.5525
[2022-07-06 11:53:56,878 callbacks.py:105 INFO train-abinet] epoch 4 iter 195750: loss = 0.5197,  smooth loss = 0.5554
[2022-07-06 11:54:41,429 callbacks.py:105 INFO train-abinet] epoch 4 iter 195800: loss = 0.6097,  smooth loss = 0.5544
[2022-07-06 11:55:27,267 callbacks.py:105 INFO train-abinet] epoch 4 iter 195850: loss = 0.5283,  smooth loss = 0.5434
[2022-07-06 11:56:14,268 callbacks.py:105 INFO train-abinet] epoch 4 iter 195900: loss = 0.5584,  smooth loss = 0.5573
[2022-07-06 11:56:58,914 callbacks.py:105 INFO train-abinet] epoch 4 iter 195950: loss = 0.5918,  smooth loss = 0.5532
[2022-07-06 11:57:44,459 callbacks.py:105 INFO train-abinet] epoch 4 iter 196000: loss = 0.6731,  smooth loss = 0.5480
[2022-07-06 11:58:29,081 callbacks.py:105 INFO train-abinet] epoch 4 iter 196050: loss = 0.6586,  smooth loss = 0.5671
[2022-07-06 11:59:14,631 callbacks.py:105 INFO train-abinet] epoch 4 iter 196100: loss = 0.4869,  smooth loss = 0.5634
[2022-07-06 12:00:01,040 callbacks.py:105 INFO train-abinet] epoch 4 iter 196150: loss = 0.5960,  smooth loss = 0.5625
[2022-07-06 12:00:44,909 callbacks.py:105 INFO train-abinet] epoch 4 iter 196200: loss = 0.6088,  smooth loss = 0.5680
[2022-07-06 12:01:31,036 callbacks.py:105 INFO train-abinet] epoch 4 iter 196250: loss = 0.6199,  smooth loss = 0.5642
[2022-07-06 12:02:14,098 callbacks.py:105 INFO train-abinet] epoch 4 iter 196300: loss = 0.5253,  smooth loss = 0.5373
[2022-07-06 12:02:56,576 callbacks.py:105 INFO train-abinet] epoch 4 iter 196350: loss = 0.5916,  smooth loss = 0.5470
[2022-07-06 12:03:40,703 callbacks.py:105 INFO train-abinet] epoch 4 iter 196400: loss = 0.6326,  smooth loss = 0.5582
[2022-07-06 12:04:23,903 callbacks.py:105 INFO train-abinet] epoch 4 iter 196450: loss = 0.7317,  smooth loss = 0.5511
[2022-07-06 12:05:07,402 callbacks.py:105 INFO train-abinet] epoch 4 iter 196500: loss = 0.4263,  smooth loss = 0.5567
[2022-07-06 12:05:51,163 callbacks.py:105 INFO train-abinet] epoch 4 iter 196550: loss = 0.5986,  smooth loss = 0.5429
[2022-07-06 12:06:32,847 callbacks.py:105 INFO train-abinet] epoch 4 iter 196600: loss = 0.6371,  smooth loss = 0.5447
[2022-07-06 12:07:16,749 callbacks.py:105 INFO train-abinet] epoch 4 iter 196650: loss = 0.5364,  smooth loss = 0.5455
[2022-07-06 12:08:00,431 callbacks.py:105 INFO train-abinet] epoch 4 iter 196700: loss = 0.4826,  smooth loss = 0.5467
[2022-07-06 12:08:44,734 callbacks.py:105 INFO train-abinet] epoch 4 iter 196750: loss = 0.6028,  smooth loss = 0.5482
[2022-07-06 12:09:28,095 callbacks.py:105 INFO train-abinet] epoch 4 iter 196800: loss = 0.5543,  smooth loss = 0.5364
[2022-07-06 12:10:14,178 callbacks.py:105 INFO train-abinet] epoch 4 iter 196850: loss = 0.6182,  smooth loss = 0.5434
[2022-07-06 12:11:01,303 callbacks.py:105 INFO train-abinet] epoch 4 iter 196900: loss = 0.6948,  smooth loss = 0.5626
[2022-07-06 12:11:51,936 callbacks.py:105 INFO train-abinet] epoch 4 iter 196950: loss = 0.4958,  smooth loss = 0.5568
[2022-07-06 12:12:39,223 callbacks.py:105 INFO train-abinet] epoch 4 iter 197000: loss = 0.4702,  smooth loss = 0.5631
[2022-07-06 12:13:26,981 callbacks.py:105 INFO train-abinet] epoch 4 iter 197050: loss = 0.4737,  smooth loss = 0.5548
[2022-07-06 12:14:10,446 callbacks.py:105 INFO train-abinet] epoch 4 iter 197100: loss = 0.4679,  smooth loss = 0.5479
[2022-07-06 12:14:53,587 callbacks.py:105 INFO train-abinet] epoch 4 iter 197150: loss = 0.3744,  smooth loss = 0.5541
[2022-07-06 12:15:36,591 callbacks.py:105 INFO train-abinet] epoch 4 iter 197200: loss = 0.5531,  smooth loss = 0.5583
[2022-07-06 12:16:20,305 callbacks.py:105 INFO train-abinet] epoch 4 iter 197250: loss = 0.6157,  smooth loss = 0.5404
[2022-07-06 12:17:03,595 callbacks.py:105 INFO train-abinet] epoch 4 iter 197300: loss = 0.6157,  smooth loss = 0.5613
[2022-07-06 12:17:46,521 callbacks.py:105 INFO train-abinet] epoch 4 iter 197350: loss = 0.4487,  smooth loss = 0.5545
[2022-07-06 12:18:30,172 callbacks.py:105 INFO train-abinet] epoch 4 iter 197400: loss = 0.5454,  smooth loss = 0.5582
[2022-07-06 12:19:13,442 callbacks.py:105 INFO train-abinet] epoch 4 iter 197450: loss = 0.4856,  smooth loss = 0.5497
[2022-07-06 12:19:56,323 callbacks.py:105 INFO train-abinet] epoch 4 iter 197500: loss = 0.4986,  smooth loss = 0.5487
[2022-07-06 12:20:40,346 callbacks.py:105 INFO train-abinet] epoch 4 iter 197550: loss = 0.3034,  smooth loss = 0.5404
[2022-07-06 12:21:22,892 callbacks.py:105 INFO train-abinet] epoch 4 iter 197600: loss = 0.5312,  smooth loss = 0.5490
[2022-07-06 12:22:05,491 callbacks.py:105 INFO train-abinet] epoch 4 iter 197650: loss = 0.5468,  smooth loss = 0.5409
[2022-07-06 12:22:47,279 callbacks.py:105 INFO train-abinet] epoch 4 iter 197700: loss = 0.4925,  smooth loss = 0.5405
[2022-07-06 12:23:31,921 callbacks.py:105 INFO train-abinet] epoch 4 iter 197750: loss = 0.5214,  smooth loss = 0.5438
[2022-07-06 12:24:15,673 callbacks.py:105 INFO train-abinet] epoch 4 iter 197800: loss = 0.6114,  smooth loss = 0.5427
[2022-07-06 12:25:00,001 callbacks.py:105 INFO train-abinet] epoch 4 iter 197850: loss = 0.5959,  smooth loss = 0.5477
[2022-07-06 12:25:43,130 callbacks.py:105 INFO train-abinet] epoch 4 iter 197900: loss = 0.6595,  smooth loss = 0.5547
[2022-07-06 12:26:26,481 callbacks.py:105 INFO train-abinet] epoch 4 iter 197950: loss = 0.4699,  smooth loss = 0.5440
[2022-07-06 12:27:10,823 callbacks.py:105 INFO train-abinet] epoch 4 iter 198000: loss = 0.4806,  smooth loss = 0.5421
[2022-07-06 12:27:10,824 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8724s
█[2022-07-06 12:27:25,705 callbacks.py:123 INFO train-abinet] epoch 4 iter 198000: eval loss = 1.1863,  ccr = 0.9591,  cwr = 0.9178,  ted = 1328.0000,  ned = 266.6054,  ted/w = 0.1832, 
[2022-07-06 12:27:25,707 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_198000
[2022-07-06 12:28:09,819 callbacks.py:105 INFO train-abinet] epoch 4 iter 198050: loss = 0.6067,  smooth loss = 0.5387
[2022-07-06 12:28:52,913 callbacks.py:105 INFO train-abinet] epoch 4 iter 198100: loss = 0.6275,  smooth loss = 0.5486
[2022-07-06 12:29:36,321 callbacks.py:105 INFO train-abinet] epoch 4 iter 198150: loss = 0.5578,  smooth loss = 0.5413
[2022-07-06 12:30:19,633 callbacks.py:105 INFO train-abinet] epoch 4 iter 198200: loss = 0.5438,  smooth loss = 0.5554
[2022-07-06 12:31:03,096 callbacks.py:105 INFO train-abinet] epoch 4 iter 198250: loss = 0.5029,  smooth loss = 0.5354
[2022-07-06 12:31:46,010 callbacks.py:105 INFO train-abinet] epoch 4 iter 198300: loss = 0.5217,  smooth loss = 0.5500
[2022-07-06 12:32:30,013 callbacks.py:105 INFO train-abinet] epoch 4 iter 198350: loss = 0.5819,  smooth loss = 0.5424
[2022-07-06 12:33:14,296 callbacks.py:105 INFO train-abinet] epoch 4 iter 198400: loss = 0.5520,  smooth loss = 0.5518
[2022-07-06 12:33:58,480 callbacks.py:105 INFO train-abinet] epoch 4 iter 198450: loss = 0.6057,  smooth loss = 0.5469
[2022-07-06 12:34:40,822 callbacks.py:105 INFO train-abinet] epoch 4 iter 198500: loss = 0.5851,  smooth loss = 0.5606
[2022-07-06 12:35:23,697 callbacks.py:105 INFO train-abinet] epoch 4 iter 198550: loss = 0.5578,  smooth loss = 0.5541
[2022-07-06 12:36:07,209 callbacks.py:105 INFO train-abinet] epoch 4 iter 198600: loss = 0.4661,  smooth loss = 0.5556
[2022-07-06 12:36:50,165 callbacks.py:105 INFO train-abinet] epoch 4 iter 198650: loss = 0.6659,  smooth loss = 0.5583
[2022-07-06 12:37:34,316 callbacks.py:105 INFO train-abinet] epoch 4 iter 198700: loss = 0.6159,  smooth loss = 0.5656
[2022-07-06 12:38:17,822 callbacks.py:105 INFO train-abinet] epoch 4 iter 198750: loss = 0.5346,  smooth loss = 0.5548
[2022-07-06 12:39:02,003 callbacks.py:105 INFO train-abinet] epoch 4 iter 198800: loss = 0.5254,  smooth loss = 0.5550
[2022-07-06 12:39:44,743 callbacks.py:105 INFO train-abinet] epoch 4 iter 198850: loss = 0.5921,  smooth loss = 0.5490
[2022-07-06 12:40:28,847 callbacks.py:105 INFO train-abinet] epoch 4 iter 198900: loss = 0.5867,  smooth loss = 0.5525
[2022-07-06 12:41:12,148 callbacks.py:105 INFO train-abinet] epoch 4 iter 198950: loss = 0.4050,  smooth loss = 0.5582
[2022-07-06 12:41:55,873 callbacks.py:105 INFO train-abinet] epoch 4 iter 199000: loss = 0.5718,  smooth loss = 0.5566
[2022-07-06 12:42:40,375 callbacks.py:105 INFO train-abinet] epoch 4 iter 199050: loss = 0.4935,  smooth loss = 0.5424
[2022-07-06 12:43:24,480 callbacks.py:105 INFO train-abinet] epoch 4 iter 199100: loss = 0.5318,  smooth loss = 0.5535
[2022-07-06 12:44:08,612 callbacks.py:105 INFO train-abinet] epoch 4 iter 199150: loss = 0.4260,  smooth loss = 0.5452
[2022-07-06 12:44:52,930 callbacks.py:105 INFO train-abinet] epoch 4 iter 199200: loss = 0.6774,  smooth loss = 0.5573
[2022-07-06 12:45:36,609 callbacks.py:105 INFO train-abinet] epoch 4 iter 199250: loss = 0.5969,  smooth loss = 0.5627
[2022-07-06 12:46:21,028 callbacks.py:105 INFO train-abinet] epoch 4 iter 199300: loss = 0.4226,  smooth loss = 0.5586
[2022-07-06 12:47:04,821 callbacks.py:105 INFO train-abinet] epoch 4 iter 199350: loss = 0.6296,  smooth loss = 0.5529
[2022-07-06 12:47:48,896 callbacks.py:105 INFO train-abinet] epoch 4 iter 199400: loss = 0.5883,  smooth loss = 0.5625
[2022-07-06 12:48:31,687 callbacks.py:105 INFO train-abinet] epoch 4 iter 199450: loss = 0.4151,  smooth loss = 0.5555
[2022-07-06 12:49:16,608 callbacks.py:105 INFO train-abinet] epoch 4 iter 199500: loss = 0.5530,  smooth loss = 0.5502
[2022-07-06 12:49:59,988 callbacks.py:105 INFO train-abinet] epoch 4 iter 199550: loss = 0.5773,  smooth loss = 0.5676
[2022-07-06 12:50:43,465 callbacks.py:105 INFO train-abinet] epoch 4 iter 199600: loss = 0.4342,  smooth loss = 0.5567
[2022-07-06 12:51:26,063 callbacks.py:105 INFO train-abinet] epoch 4 iter 199650: loss = 0.5232,  smooth loss = 0.5589
[2022-07-06 12:52:09,491 callbacks.py:105 INFO train-abinet] epoch 4 iter 199700: loss = 0.7471,  smooth loss = 0.5617
[2022-07-06 12:52:53,920 callbacks.py:105 INFO train-abinet] epoch 4 iter 199750: loss = 0.4667,  smooth loss = 0.5483
[2022-07-06 12:53:37,519 callbacks.py:105 INFO train-abinet] epoch 4 iter 199800: loss = 0.5766,  smooth loss = 0.5448
[2022-07-06 12:54:20,582 callbacks.py:105 INFO train-abinet] epoch 4 iter 199850: loss = 0.5313,  smooth loss = 0.5546
[2022-07-06 12:55:04,736 callbacks.py:105 INFO train-abinet] epoch 4 iter 199900: loss = 0.4953,  smooth loss = 0.5500
[2022-07-06 12:55:47,568 callbacks.py:105 INFO train-abinet] epoch 4 iter 199950: loss = 0.5347,  smooth loss = 0.5466
[2022-07-06 12:56:32,076 callbacks.py:105 INFO train-abinet] epoch 4 iter 200000: loss = 0.5439,  smooth loss = 0.5511
[2022-07-06 12:57:19,973 callbacks.py:105 INFO train-abinet] epoch 4 iter 200050: loss = 0.5734,  smooth loss = 0.5610
[2022-07-06 12:58:03,665 callbacks.py:105 INFO train-abinet] epoch 4 iter 200100: loss = 0.4069,  smooth loss = 0.5563
[2022-07-06 12:58:47,865 callbacks.py:105 INFO train-abinet] epoch 4 iter 200150: loss = 0.5922,  smooth loss = 0.5461
[2022-07-06 12:59:31,821 callbacks.py:105 INFO train-abinet] epoch 4 iter 200200: loss = 0.6743,  smooth loss = 0.5465
[2022-07-06 13:00:16,113 callbacks.py:105 INFO train-abinet] epoch 4 iter 200250: loss = 0.4602,  smooth loss = 0.5537
[2022-07-06 13:00:58,937 callbacks.py:105 INFO train-abinet] epoch 4 iter 200300: loss = 0.5261,  smooth loss = 0.5572
[2022-07-06 13:01:42,572 callbacks.py:105 INFO train-abinet] epoch 4 iter 200350: loss = 0.4366,  smooth loss = 0.5527
[2022-07-06 13:02:26,680 callbacks.py:105 INFO train-abinet] epoch 4 iter 200400: loss = 0.6984,  smooth loss = 0.5591
[2022-07-06 13:03:10,275 callbacks.py:105 INFO train-abinet] epoch 4 iter 200450: loss = 0.5263,  smooth loss = 0.5594
[2022-07-06 13:03:52,370 callbacks.py:105 INFO train-abinet] epoch 4 iter 200500: loss = 0.5107,  smooth loss = 0.5647
[2022-07-06 13:04:37,724 callbacks.py:105 INFO train-abinet] epoch 4 iter 200550: loss = 0.5728,  smooth loss = 0.5552
[2022-07-06 13:05:31,093 callbacks.py:105 INFO train-abinet] epoch 4 iter 200600: loss = 0.5735,  smooth loss = 0.5494
[2022-07-06 13:06:27,335 callbacks.py:105 INFO train-abinet] epoch 4 iter 200650: loss = 0.5845,  smooth loss = 0.5452
[2022-07-06 13:07:22,709 callbacks.py:105 INFO train-abinet] epoch 4 iter 200700: loss = 0.6056,  smooth loss = 0.5427
[2022-07-06 13:08:16,664 callbacks.py:105 INFO train-abinet] epoch 4 iter 200750: loss = 0.4349,  smooth loss = 0.5504
[2022-07-06 13:09:11,477 callbacks.py:105 INFO train-abinet] epoch 4 iter 200800: loss = 0.6950,  smooth loss = 0.5534
[2022-07-06 13:10:08,153 callbacks.py:105 INFO train-abinet] epoch 4 iter 200850: loss = 0.5592,  smooth loss = 0.5577
[2022-07-06 13:10:59,700 callbacks.py:105 INFO train-abinet] epoch 4 iter 200900: loss = 0.4874,  smooth loss = 0.5639
[2022-07-06 13:11:43,078 callbacks.py:105 INFO train-abinet] epoch 4 iter 200950: loss = 0.4717,  smooth loss = 0.5453
[2022-07-06 13:12:25,981 callbacks.py:105 INFO train-abinet] epoch 4 iter 201000: loss = 0.6985,  smooth loss = 0.5555
[2022-07-06 13:12:25,982 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8728s
█[2022-07-06 13:12:41,914 callbacks.py:123 INFO train-abinet] epoch 4 iter 201000: eval loss = 1.1993,  ccr = 0.9575,  cwr = 0.9157,  ted = 1363.0000,  ned = 276.4651,  ted/w = 0.1881, 
[2022-07-06 13:12:41,919 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_201000
[2022-07-06 13:13:33,996 callbacks.py:105 INFO train-abinet] epoch 4 iter 201050: loss = 0.4131,  smooth loss = 0.5495
[2022-07-06 13:14:28,994 callbacks.py:105 INFO train-abinet] epoch 4 iter 201100: loss = 0.4411,  smooth loss = 0.5456
[2022-07-06 13:15:18,603 callbacks.py:105 INFO train-abinet] epoch 4 iter 201150: loss = 0.4063,  smooth loss = 0.5389
[2022-07-06 13:16:02,988 callbacks.py:105 INFO train-abinet] epoch 4 iter 201200: loss = 0.5068,  smooth loss = 0.5365
[2022-07-06 13:16:53,254 callbacks.py:105 INFO train-abinet] epoch 4 iter 201250: loss = 0.4117,  smooth loss = 0.5437
[2022-07-06 13:17:45,269 callbacks.py:105 INFO train-abinet] epoch 4 iter 201300: loss = 0.5524,  smooth loss = 0.5477
[2022-07-06 13:18:36,844 callbacks.py:105 INFO train-abinet] epoch 4 iter 201350: loss = 0.4533,  smooth loss = 0.5400
[2022-07-06 13:19:32,160 callbacks.py:105 INFO train-abinet] epoch 4 iter 201400: loss = 0.5021,  smooth loss = 0.5403
[2022-07-06 13:20:26,814 callbacks.py:105 INFO train-abinet] epoch 4 iter 201450: loss = 0.4549,  smooth loss = 0.5594
[2022-07-06 13:21:22,338 callbacks.py:105 INFO train-abinet] epoch 4 iter 201500: loss = 0.5677,  smooth loss = 0.5541
[2022-07-06 13:22:16,077 callbacks.py:105 INFO train-abinet] epoch 4 iter 201550: loss = 0.4657,  smooth loss = 0.5545
[2022-07-06 13:23:10,034 callbacks.py:105 INFO train-abinet] epoch 4 iter 201600: loss = 0.5853,  smooth loss = 0.5437
[2022-07-06 13:24:03,036 callbacks.py:105 INFO train-abinet] epoch 4 iter 201650: loss = 0.5849,  smooth loss = 0.5401
[2022-07-06 13:24:56,413 callbacks.py:105 INFO train-abinet] epoch 4 iter 201700: loss = 0.5156,  smooth loss = 0.5348
[2022-07-06 13:25:50,527 callbacks.py:105 INFO train-abinet] epoch 4 iter 201750: loss = 0.6106,  smooth loss = 0.5338
[2022-07-06 13:26:44,912 callbacks.py:105 INFO train-abinet] epoch 4 iter 201800: loss = 0.4970,  smooth loss = 0.5433
[2022-07-06 13:27:38,829 callbacks.py:105 INFO train-abinet] epoch 4 iter 201850: loss = 0.4794,  smooth loss = 0.5475
[2022-07-06 13:28:32,251 callbacks.py:105 INFO train-abinet] epoch 4 iter 201900: loss = 0.4550,  smooth loss = 0.5472
[2022-07-06 13:29:25,503 callbacks.py:105 INFO train-abinet] epoch 4 iter 201950: loss = 0.4491,  smooth loss = 0.5542
[2022-07-06 13:30:20,619 callbacks.py:105 INFO train-abinet] epoch 4 iter 202000: loss = 0.4309,  smooth loss = 0.5501
[2022-07-06 13:31:15,506 callbacks.py:105 INFO train-abinet] epoch 4 iter 202050: loss = 0.4615,  smooth loss = 0.5526
[2022-07-06 13:32:02,680 callbacks.py:105 INFO train-abinet] epoch 4 iter 202100: loss = 0.6164,  smooth loss = 0.5510
[2022-07-06 13:32:46,881 callbacks.py:105 INFO train-abinet] epoch 4 iter 202150: loss = 0.5759,  smooth loss = 0.5487
[2022-07-06 13:33:30,488 callbacks.py:105 INFO train-abinet] epoch 4 iter 202200: loss = 0.5509,  smooth loss = 0.5433
[2022-07-06 13:34:14,311 callbacks.py:105 INFO train-abinet] epoch 4 iter 202250: loss = 0.5240,  smooth loss = 0.5422
[2022-07-06 13:34:59,019 callbacks.py:105 INFO train-abinet] epoch 4 iter 202300: loss = 0.7093,  smooth loss = 0.5468
[2022-07-06 13:35:49,794 callbacks.py:105 INFO train-abinet] epoch 4 iter 202350: loss = 0.4555,  smooth loss = 0.5555
[2022-07-06 13:36:44,107 callbacks.py:105 INFO train-abinet] epoch 4 iter 202400: loss = 0.4667,  smooth loss = 0.5484
[2022-07-06 13:37:38,823 callbacks.py:105 INFO train-abinet] epoch 4 iter 202450: loss = 0.4511,  smooth loss = 0.5487
[2022-07-06 13:38:32,518 callbacks.py:105 INFO train-abinet] epoch 4 iter 202500: loss = 0.5877,  smooth loss = 0.5397
[2022-07-06 13:39:26,267 callbacks.py:105 INFO train-abinet] epoch 4 iter 202550: loss = 0.4414,  smooth loss = 0.5302
[2022-07-06 13:40:20,989 callbacks.py:105 INFO train-abinet] epoch 4 iter 202600: loss = 0.4948,  smooth loss = 0.5404
[2022-07-06 13:41:13,704 callbacks.py:105 INFO train-abinet] epoch 4 iter 202650: loss = 0.5864,  smooth loss = 0.5483
[2022-07-06 13:41:58,830 callbacks.py:105 INFO train-abinet] epoch 4 iter 202700: loss = 0.4863,  smooth loss = 0.5611
[2022-07-06 13:42:49,957 callbacks.py:105 INFO train-abinet] epoch 4 iter 202750: loss = 0.5977,  smooth loss = 0.5432
[2022-07-06 13:43:43,323 callbacks.py:105 INFO train-abinet] epoch 4 iter 202800: loss = 0.5566,  smooth loss = 0.5460
[2022-07-06 13:44:36,958 callbacks.py:105 INFO train-abinet] epoch 4 iter 202850: loss = 0.5333,  smooth loss = 0.5572
[2022-07-06 13:45:30,249 callbacks.py:105 INFO train-abinet] epoch 4 iter 202900: loss = 0.7118,  smooth loss = 0.5730
[2022-07-06 13:46:24,271 callbacks.py:105 INFO train-abinet] epoch 4 iter 202950: loss = 0.5590,  smooth loss = 0.5588
[2022-07-06 13:47:20,188 callbacks.py:105 INFO train-abinet] epoch 4 iter 203000: loss = 0.4222,  smooth loss = 0.5468
[2022-07-06 13:48:16,641 callbacks.py:105 INFO train-abinet] epoch 4 iter 203050: loss = 0.4744,  smooth loss = 0.5285
[2022-07-06 13:49:10,981 callbacks.py:105 INFO train-abinet] epoch 4 iter 203100: loss = 0.4532,  smooth loss = 0.5433
[2022-07-06 13:50:02,799 callbacks.py:105 INFO train-abinet] epoch 4 iter 203150: loss = 0.6659,  smooth loss = 0.5549
[2022-07-06 13:50:49,267 callbacks.py:105 INFO train-abinet] epoch 4 iter 203200: loss = 0.5974,  smooth loss = 0.5535
[2022-07-06 13:51:33,630 callbacks.py:105 INFO train-abinet] epoch 4 iter 203250: loss = 0.6479,  smooth loss = 0.5510
[2022-07-06 13:52:17,264 callbacks.py:105 INFO train-abinet] epoch 4 iter 203300: loss = 0.6411,  smooth loss = 0.5480
[2022-07-06 13:53:02,515 callbacks.py:105 INFO train-abinet] epoch 4 iter 203350: loss = 0.4772,  smooth loss = 0.5532
[2022-07-06 13:53:55,487 callbacks.py:105 INFO train-abinet] epoch 4 iter 203400: loss = 0.4582,  smooth loss = 0.5411
[2022-07-06 13:54:49,881 callbacks.py:105 INFO train-abinet] epoch 4 iter 203450: loss = 0.4708,  smooth loss = 0.5538
[2022-07-06 13:55:44,112 callbacks.py:105 INFO train-abinet] epoch 4 iter 203500: loss = 0.4197,  smooth loss = 0.5472
[2022-07-06 13:56:38,897 callbacks.py:105 INFO train-abinet] epoch 4 iter 203550: loss = 0.6537,  smooth loss = 0.5480
[2022-07-06 13:57:35,538 callbacks.py:105 INFO train-abinet] epoch 4 iter 203600: loss = 0.4708,  smooth loss = 0.5482
[2022-07-06 13:58:29,529 callbacks.py:105 INFO train-abinet] epoch 4 iter 203650: loss = 0.6319,  smooth loss = 0.5548
[2022-07-06 13:59:23,936 callbacks.py:105 INFO train-abinet] epoch 4 iter 203700: loss = 0.5792,  smooth loss = 0.5532
[2022-07-06 14:00:16,678 callbacks.py:105 INFO train-abinet] epoch 4 iter 203750: loss = 0.4798,  smooth loss = 0.5408
[2022-07-06 14:01:11,006 callbacks.py:105 INFO train-abinet] epoch 4 iter 203800: loss = 0.7014,  smooth loss = 0.5390
[2022-07-06 14:02:05,604 callbacks.py:105 INFO train-abinet] epoch 4 iter 203850: loss = 0.5786,  smooth loss = 0.5390
[2022-07-06 14:02:59,653 callbacks.py:105 INFO train-abinet] epoch 4 iter 203900: loss = 0.6626,  smooth loss = 0.5469
[2022-07-06 14:03:53,406 callbacks.py:105 INFO train-abinet] epoch 4 iter 203950: loss = 0.5765,  smooth loss = 0.5477
[2022-07-06 14:04:46,742 callbacks.py:105 INFO train-abinet] epoch 4 iter 204000: loss = 0.4139,  smooth loss = 0.5518
[2022-07-06 14:04:46,743 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8752s
█[2022-07-06 14:05:05,262 callbacks.py:123 INFO train-abinet] epoch 4 iter 204000: eval loss = 1.1684,  ccr = 0.9587,  cwr = 0.9176,  ted = 1332.0000,  ned = 265.4227,  ted/w = 0.1838, 
[2022-07-06 14:05:05,263 callbacks.py:136 INFO train-abinet] Save model train-abinet_4_204000
[2022-07-06 14:05:59,336 callbacks.py:105 INFO train-abinet] epoch 4 iter 204050: loss = 0.5292,  smooth loss = 0.5400
[2022-07-06 14:06:51,272 callbacks.py:105 INFO train-abinet] epoch 4 iter 204100: loss = 0.4820,  smooth loss = 0.5353
[2022-07-06 14:07:36,951 callbacks.py:105 INFO train-abinet] epoch 4 iter 204150: loss = 0.6430,  smooth loss = 0.5371
[2022-07-06 14:08:23,678 callbacks.py:105 INFO train-abinet] epoch 4 iter 204200: loss = 0.5743,  smooth loss = 0.5495
[2022-07-06 14:09:10,737 callbacks.py:105 INFO train-abinet] epoch 4 iter 204250: loss = 0.4582,  smooth loss = 0.5417
[2022-07-06 14:09:56,600 callbacks.py:105 INFO train-abinet] epoch 4 iter 204300: loss = 0.4620,  smooth loss = 0.5491
[2022-07-06 14:10:43,689 callbacks.py:105 INFO train-abinet] epoch 4 iter 204350: loss = 0.6591,  smooth loss = 0.5573
[2022-07-06 14:11:33,257 callbacks.py:105 INFO train-abinet] epoch 4 iter 204400: loss = 0.5647,  smooth loss = 0.5610
[2022-07-06 14:12:22,401 callbacks.py:105 INFO train-abinet] epoch 4 iter 204450: loss = 0.5091,  smooth loss = 0.5472
[2022-07-06 14:13:17,488 callbacks.py:105 INFO train-abinet] epoch 4 iter 204500: loss = 0.4333,  smooth loss = 0.5487
[2022-07-06 14:14:04,357 callbacks.py:105 INFO train-abinet] epoch 4 iter 204550: loss = 0.6049,  smooth loss = 0.5495
[2022-07-06 14:14:49,072 callbacks.py:105 INFO train-abinet] epoch 4 iter 204600: loss = 0.6452,  smooth loss = 0.5489
[2022-07-06 14:15:35,684 callbacks.py:105 INFO train-abinet] epoch 4 iter 204650: loss = 0.3613,  smooth loss = 0.5445
[2022-07-06 14:16:20,827 callbacks.py:105 INFO train-abinet] epoch 4 iter 204700: loss = 0.5380,  smooth loss = 0.5494
[2022-07-06 14:17:05,004 callbacks.py:105 INFO train-abinet] epoch 4 iter 204750: loss = 0.5112,  smooth loss = 0.5446
[2022-07-06 14:17:49,012 callbacks.py:105 INFO train-abinet] epoch 4 iter 204800: loss = 0.5057,  smooth loss = 0.5402
[2022-07-06 14:18:33,844 callbacks.py:105 INFO train-abinet] epoch 4 iter 204850: loss = 0.5046,  smooth loss = 0.5486
[2022-07-06 14:19:17,818 callbacks.py:105 INFO train-abinet] epoch 4 iter 204900: loss = 0.4201,  smooth loss = 0.5424
[2022-07-06 14:20:01,979 callbacks.py:105 INFO train-abinet] epoch 4 iter 204950: loss = 0.4539,  smooth loss = 0.5385
[2022-07-06 14:20:47,328 callbacks.py:105 INFO train-abinet] epoch 4 iter 205000: loss = 0.5199,  smooth loss = 0.5522
[2022-07-06 14:21:32,608 callbacks.py:105 INFO train-abinet] epoch 4 iter 205050: loss = 0.5638,  smooth loss = 0.5435
[2022-07-06 14:22:17,546 callbacks.py:105 INFO train-abinet] epoch 4 iter 205100: loss = 0.6602,  smooth loss = 0.5321
[2022-07-06 14:23:02,334 callbacks.py:105 INFO train-abinet] epoch 4 iter 205150: loss = 0.6778,  smooth loss = 0.5543
[2022-07-06 14:23:46,491 callbacks.py:105 INFO train-abinet] epoch 4 iter 205200: loss = 0.5306,  smooth loss = 0.5511
[2022-07-06 14:24:30,595 callbacks.py:105 INFO train-abinet] epoch 4 iter 205250: loss = 0.6197,  smooth loss = 0.5504
[2022-07-06 14:25:14,689 callbacks.py:105 INFO train-abinet] epoch 4 iter 205300: loss = 0.6301,  smooth loss = 0.5589
[2022-07-06 14:25:59,704 callbacks.py:105 INFO train-abinet] epoch 4 iter 205350: loss = 0.5643,  smooth loss = 0.5519
[2022-07-06 14:26:44,330 callbacks.py:105 INFO train-abinet] epoch 4 iter 205400: loss = 0.4729,  smooth loss = 0.5419
[2022-07-06 14:27:27,555 callbacks.py:105 INFO train-abinet] epoch 4 iter 205450: loss = 0.5871,  smooth loss = 0.5398
[2022-07-06 14:28:11,479 callbacks.py:105 INFO train-abinet] epoch 4 iter 205500: loss = 0.4447,  smooth loss = 0.5346
[2022-07-06 14:28:54,270 callbacks.py:105 INFO train-abinet] epoch 4 iter 205550: loss = 0.4292,  smooth loss = 0.5352
[2022-07-06 14:29:37,541 callbacks.py:105 INFO train-abinet] epoch 4 iter 205600: loss = 0.5419,  smooth loss = 0.5427
[2022-07-06 14:30:21,017 callbacks.py:105 INFO train-abinet] epoch 4 iter 205650: loss = 0.5083,  smooth loss = 0.5521
[2022-07-06 14:31:04,665 callbacks.py:105 INFO train-abinet] epoch 4 iter 205700: loss = 0.4758,  smooth loss = 0.5540
[2022-07-06 14:31:48,234 callbacks.py:105 INFO train-abinet] epoch 4 iter 205750: loss = 0.5138,  smooth loss = 0.5442
[2022-07-06 14:32:31,526 callbacks.py:105 INFO train-abinet] epoch 4 iter 205800: loss = 0.6353,  smooth loss = 0.5426
[2022-07-06 14:33:14,283 callbacks.py:105 INFO train-abinet] epoch 4 iter 205850: loss = 0.6982,  smooth loss = 0.5435
[2022-07-06 14:33:57,912 callbacks.py:105 INFO train-abinet] epoch 4 iter 205900: loss = 0.6204,  smooth loss = 0.5531
[2022-07-06 14:34:41,697 callbacks.py:105 INFO train-abinet] epoch 4 iter 205950: loss = 0.5179,  smooth loss = 0.5449
[2022-07-06 14:35:26,283 callbacks.py:105 INFO train-abinet] epoch 4 iter 206000: loss = 0.6067,  smooth loss = 0.5466
[2022-07-06 14:36:09,480 callbacks.py:105 INFO train-abinet] epoch 4 iter 206050: loss = 0.5265,  smooth loss = 0.5479
[2022-07-06 14:36:52,518 callbacks.py:105 INFO train-abinet] epoch 4 iter 206100: loss = 0.4722,  smooth loss = 0.5434
[2022-07-06 14:37:36,128 callbacks.py:105 INFO train-abinet] epoch 4 iter 206150: loss = 0.5521,  smooth loss = 0.5501
[2022-07-06 14:38:19,172 callbacks.py:105 INFO train-abinet] epoch 4 iter 206200: loss = 0.5233,  smooth loss = 0.5499
[2022-07-06 14:39:02,494 callbacks.py:105 INFO train-abinet] epoch 4 iter 206250: loss = 0.6279,  smooth loss = 0.5623
[2022-07-06 14:39:45,587 callbacks.py:105 INFO train-abinet] epoch 4 iter 206300: loss = 0.5239,  smooth loss = 0.5419
[2022-07-06 14:40:28,812 callbacks.py:105 INFO train-abinet] epoch 4 iter 206350: loss = 0.5532,  smooth loss = 0.5418
[2022-07-06 14:41:12,032 callbacks.py:105 INFO train-abinet] epoch 4 iter 206400: loss = 0.4700,  smooth loss = 0.5462
[2022-07-06 14:41:55,907 callbacks.py:105 INFO train-abinet] epoch 4 iter 206450: loss = 0.6259,  smooth loss = 0.5453
[2022-07-06 14:42:39,528 callbacks.py:105 INFO train-abinet] epoch 4 iter 206500: loss = 0.6278,  smooth loss = 0.5390
[2022-07-06 14:43:23,358 callbacks.py:105 INFO train-abinet] epoch 4 iter 206550: loss = 0.5387,  smooth loss = 0.5608
[2022-07-06 14:44:07,166 callbacks.py:105 INFO train-abinet] epoch 4 iter 206600: loss = 0.5041,  smooth loss = 0.5450
[2022-07-06 14:44:51,019 callbacks.py:105 INFO train-abinet] epoch 4 iter 206650: loss = 0.4876,  smooth loss = 0.5414
[2022-07-06 14:45:34,199 callbacks.py:105 INFO train-abinet] epoch 4 iter 206700: loss = 0.5861,  smooth loss = 0.5465
[2022-07-06 14:46:18,037 callbacks.py:105 INFO train-abinet] epoch 4 iter 206750: loss = 0.5269,  smooth loss = 0.5535
[2022-07-06 14:47:00,984 callbacks.py:105 INFO train-abinet] epoch 4 iter 206800: loss = 0.5005,  smooth loss = 0.5537
[2022-07-06 14:47:43,142 callbacks.py:105 INFO train-abinet] epoch 4 iter 206850: loss = 0.4793,  smooth loss = 0.5470
[2022-07-06 14:48:26,764 callbacks.py:105 INFO train-abinet] epoch 4 iter 206900: loss = 0.5803,  smooth loss = 0.5380
[2022-07-06 14:49:11,719 callbacks.py:105 INFO train-abinet] epoch 4 iter 206950: loss = 0.4759,  smooth loss = 0.5394
█[2022-07-06 14:49:59,976 callbacks.py:105 INFO train-abinet] epoch 5 iter 207000: loss = 0.5590,  smooth loss = 0.5487
[2022-07-06 14:49:59,977 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8755s
█[2022-07-06 14:50:14,520 callbacks.py:123 INFO train-abinet] epoch 5 iter 207000: eval loss = 1.1561,  ccr = 0.9601,  cwr = 0.9179,  ted = 1313.0000,  ned = 260.2597,  ted/w = 0.1812, 
[2022-07-06 14:50:14,523 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_207000
[2022-07-06 14:50:59,689 callbacks.py:105 INFO train-abinet] epoch 5 iter 207050: loss = 0.6248,  smooth loss = 0.5512
[2022-07-06 14:51:43,759 callbacks.py:105 INFO train-abinet] epoch 5 iter 207100: loss = 0.5216,  smooth loss = 0.5543
[2022-07-06 14:52:27,621 callbacks.py:105 INFO train-abinet] epoch 5 iter 207150: loss = 0.7029,  smooth loss = 0.5552
[2022-07-06 14:53:12,434 callbacks.py:105 INFO train-abinet] epoch 5 iter 207200: loss = 0.5516,  smooth loss = 0.5455
[2022-07-06 14:53:56,024 callbacks.py:105 INFO train-abinet] epoch 5 iter 207250: loss = 0.6832,  smooth loss = 0.5474
[2022-07-06 14:54:39,993 callbacks.py:105 INFO train-abinet] epoch 5 iter 207300: loss = 0.5076,  smooth loss = 0.5443
[2022-07-06 14:55:22,783 callbacks.py:105 INFO train-abinet] epoch 5 iter 207350: loss = 0.7754,  smooth loss = 0.5316
[2022-07-06 14:56:07,005 callbacks.py:105 INFO train-abinet] epoch 5 iter 207400: loss = 0.4338,  smooth loss = 0.5478
[2022-07-06 14:56:51,189 callbacks.py:105 INFO train-abinet] epoch 5 iter 207450: loss = 0.5989,  smooth loss = 0.5532
[2022-07-06 14:57:34,151 callbacks.py:105 INFO train-abinet] epoch 5 iter 207500: loss = 0.4157,  smooth loss = 0.5539
[2022-07-06 14:58:17,167 callbacks.py:105 INFO train-abinet] epoch 5 iter 207550: loss = 0.6201,  smooth loss = 0.5535
[2022-07-06 14:59:01,592 callbacks.py:105 INFO train-abinet] epoch 5 iter 207600: loss = 0.6138,  smooth loss = 0.5382
[2022-07-06 14:59:45,679 callbacks.py:105 INFO train-abinet] epoch 5 iter 207650: loss = 0.3163,  smooth loss = 0.5285
[2022-07-06 15:00:28,894 callbacks.py:105 INFO train-abinet] epoch 5 iter 207700: loss = 0.4490,  smooth loss = 0.5335
[2022-07-06 15:01:12,758 callbacks.py:105 INFO train-abinet] epoch 5 iter 207750: loss = 0.5710,  smooth loss = 0.5372
[2022-07-06 15:01:55,424 callbacks.py:105 INFO train-abinet] epoch 5 iter 207800: loss = 0.3924,  smooth loss = 0.5386
[2022-07-06 15:02:38,397 callbacks.py:105 INFO train-abinet] epoch 5 iter 207850: loss = 0.5217,  smooth loss = 0.5422
[2022-07-06 15:03:22,093 callbacks.py:105 INFO train-abinet] epoch 5 iter 207900: loss = 0.5267,  smooth loss = 0.5449
[2022-07-06 15:04:05,765 callbacks.py:105 INFO train-abinet] epoch 5 iter 207950: loss = 0.6776,  smooth loss = 0.5414
[2022-07-06 15:04:49,178 callbacks.py:105 INFO train-abinet] epoch 5 iter 208000: loss = 0.6412,  smooth loss = 0.5302
[2022-07-06 15:05:31,755 callbacks.py:105 INFO train-abinet] epoch 5 iter 208050: loss = 0.5214,  smooth loss = 0.5294
[2022-07-06 15:06:15,231 callbacks.py:105 INFO train-abinet] epoch 5 iter 208100: loss = 0.5471,  smooth loss = 0.5340
[2022-07-06 15:06:58,245 callbacks.py:105 INFO train-abinet] epoch 5 iter 208150: loss = 0.4937,  smooth loss = 0.5362
[2022-07-06 15:07:40,791 callbacks.py:105 INFO train-abinet] epoch 5 iter 208200: loss = 0.4630,  smooth loss = 0.5310
[2022-07-06 15:08:24,725 callbacks.py:105 INFO train-abinet] epoch 5 iter 208250: loss = 0.6175,  smooth loss = 0.5417
[2022-07-06 15:09:06,640 callbacks.py:105 INFO train-abinet] epoch 5 iter 208300: loss = 0.4932,  smooth loss = 0.5295
[2022-07-06 15:09:49,898 callbacks.py:105 INFO train-abinet] epoch 5 iter 208350: loss = 0.5703,  smooth loss = 0.5375
[2022-07-06 15:10:32,958 callbacks.py:105 INFO train-abinet] epoch 5 iter 208400: loss = 0.6558,  smooth loss = 0.5437
[2022-07-06 15:11:16,911 callbacks.py:105 INFO train-abinet] epoch 5 iter 208450: loss = 0.4713,  smooth loss = 0.5429
[2022-07-06 15:12:00,940 callbacks.py:105 INFO train-abinet] epoch 5 iter 208500: loss = 0.6142,  smooth loss = 0.5562
[2022-07-06 15:12:43,374 callbacks.py:105 INFO train-abinet] epoch 5 iter 208550: loss = 0.5677,  smooth loss = 0.5485
[2022-07-06 15:13:26,033 callbacks.py:105 INFO train-abinet] epoch 5 iter 208600: loss = 0.5788,  smooth loss = 0.5522
[2022-07-06 15:14:09,055 callbacks.py:105 INFO train-abinet] epoch 5 iter 208650: loss = 0.3658,  smooth loss = 0.5532
[2022-07-06 15:14:52,571 callbacks.py:105 INFO train-abinet] epoch 5 iter 208700: loss = 0.4034,  smooth loss = 0.5480
[2022-07-06 15:15:35,929 callbacks.py:105 INFO train-abinet] epoch 5 iter 208750: loss = 0.5940,  smooth loss = 0.5454
[2022-07-06 15:16:19,882 callbacks.py:105 INFO train-abinet] epoch 5 iter 208800: loss = 0.4180,  smooth loss = 0.5486
[2022-07-06 15:17:02,566 callbacks.py:105 INFO train-abinet] epoch 5 iter 208850: loss = 0.4889,  smooth loss = 0.5387
[2022-07-06 15:17:45,889 callbacks.py:105 INFO train-abinet] epoch 5 iter 208900: loss = 0.5567,  smooth loss = 0.5260
[2022-07-06 15:18:28,932 callbacks.py:105 INFO train-abinet] epoch 5 iter 208950: loss = 0.4292,  smooth loss = 0.5442
[2022-07-06 15:19:11,711 callbacks.py:105 INFO train-abinet] epoch 5 iter 209000: loss = 0.5968,  smooth loss = 0.5419
[2022-07-06 15:19:54,510 callbacks.py:105 INFO train-abinet] epoch 5 iter 209050: loss = 0.6292,  smooth loss = 0.5481
[2022-07-06 15:20:37,872 callbacks.py:105 INFO train-abinet] epoch 5 iter 209100: loss = 0.4415,  smooth loss = 0.5369
[2022-07-06 15:21:22,281 callbacks.py:105 INFO train-abinet] epoch 5 iter 209150: loss = 0.4745,  smooth loss = 0.5353
[2022-07-06 15:22:06,033 callbacks.py:105 INFO train-abinet] epoch 5 iter 209200: loss = 0.4808,  smooth loss = 0.5371
[2022-07-06 15:22:49,281 callbacks.py:105 INFO train-abinet] epoch 5 iter 209250: loss = 0.4500,  smooth loss = 0.5416
[2022-07-06 15:23:32,848 callbacks.py:105 INFO train-abinet] epoch 5 iter 209300: loss = 0.5540,  smooth loss = 0.5434
[2022-07-06 15:24:16,250 callbacks.py:105 INFO train-abinet] epoch 5 iter 209350: loss = 0.4357,  smooth loss = 0.5382
[2022-07-06 15:24:59,131 callbacks.py:105 INFO train-abinet] epoch 5 iter 209400: loss = 0.4629,  smooth loss = 0.5497
[2022-07-06 15:25:42,804 callbacks.py:105 INFO train-abinet] epoch 5 iter 209450: loss = 0.5874,  smooth loss = 0.5435
[2022-07-06 15:26:26,352 callbacks.py:105 INFO train-abinet] epoch 5 iter 209500: loss = 0.5110,  smooth loss = 0.5412
[2022-07-06 15:27:10,318 callbacks.py:105 INFO train-abinet] epoch 5 iter 209550: loss = 0.5239,  smooth loss = 0.5358
[2022-07-06 15:27:52,511 callbacks.py:105 INFO train-abinet] epoch 5 iter 209600: loss = 0.5126,  smooth loss = 0.5397
[2022-07-06 15:28:35,121 callbacks.py:105 INFO train-abinet] epoch 5 iter 209650: loss = 0.4822,  smooth loss = 0.5463
[2022-07-06 15:29:17,430 callbacks.py:105 INFO train-abinet] epoch 5 iter 209700: loss = 0.6059,  smooth loss = 0.5467
[2022-07-06 15:29:59,441 callbacks.py:105 INFO train-abinet] epoch 5 iter 209750: loss = 0.4758,  smooth loss = 0.5455
[2022-07-06 15:30:41,715 callbacks.py:105 INFO train-abinet] epoch 5 iter 209800: loss = 0.5776,  smooth loss = 0.5439
[2022-07-06 15:31:24,502 callbacks.py:105 INFO train-abinet] epoch 5 iter 209850: loss = 0.6215,  smooth loss = 0.5485
[2022-07-06 15:32:07,689 callbacks.py:105 INFO train-abinet] epoch 5 iter 209900: loss = 0.5803,  smooth loss = 0.5479
[2022-07-06 15:32:51,717 callbacks.py:105 INFO train-abinet] epoch 5 iter 209950: loss = 0.5475,  smooth loss = 0.5449
[2022-07-06 15:33:35,194 callbacks.py:105 INFO train-abinet] epoch 5 iter 210000: loss = 0.6119,  smooth loss = 0.5423
[2022-07-06 15:33:35,195 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8754s
█[2022-07-06 15:33:50,445 callbacks.py:123 INFO train-abinet] epoch 5 iter 210000: eval loss = 1.1688,  ccr = 0.9602,  cwr = 0.9157,  ted = 1319.0000,  ned = 267.4660,  ted/w = 0.1820, 
[2022-07-06 15:33:50,446 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_210000
[2022-07-06 15:34:35,029 callbacks.py:105 INFO train-abinet] epoch 5 iter 210050: loss = 0.5656,  smooth loss = 0.5438
[2022-07-06 15:35:19,529 callbacks.py:105 INFO train-abinet] epoch 5 iter 210100: loss = 0.4406,  smooth loss = 0.5342
[2022-07-06 15:36:01,574 callbacks.py:105 INFO train-abinet] epoch 5 iter 210150: loss = 0.5985,  smooth loss = 0.5348
[2022-07-06 15:36:45,418 callbacks.py:105 INFO train-abinet] epoch 5 iter 210200: loss = 0.4922,  smooth loss = 0.5334
[2022-07-06 15:37:27,910 callbacks.py:105 INFO train-abinet] epoch 5 iter 210250: loss = 0.6330,  smooth loss = 0.5575
[2022-07-06 15:38:11,241 callbacks.py:105 INFO train-abinet] epoch 5 iter 210300: loss = 0.5365,  smooth loss = 0.5407
[2022-07-06 15:38:54,616 callbacks.py:105 INFO train-abinet] epoch 5 iter 210350: loss = 0.3706,  smooth loss = 0.5433
[2022-07-06 15:39:38,303 callbacks.py:105 INFO train-abinet] epoch 5 iter 210400: loss = 0.5509,  smooth loss = 0.5403
[2022-07-06 15:40:20,805 callbacks.py:105 INFO train-abinet] epoch 5 iter 210450: loss = 0.3923,  smooth loss = 0.5492
[2022-07-06 15:41:03,212 callbacks.py:105 INFO train-abinet] epoch 5 iter 210500: loss = 0.6069,  smooth loss = 0.5446
[2022-07-06 15:41:45,357 callbacks.py:105 INFO train-abinet] epoch 5 iter 210550: loss = 0.5296,  smooth loss = 0.5425
[2022-07-06 15:42:28,437 callbacks.py:105 INFO train-abinet] epoch 5 iter 210600: loss = 0.5082,  smooth loss = 0.5401
[2022-07-06 15:43:12,411 callbacks.py:105 INFO train-abinet] epoch 5 iter 210650: loss = 0.6398,  smooth loss = 0.5380
[2022-07-06 15:43:54,914 callbacks.py:105 INFO train-abinet] epoch 5 iter 210700: loss = 0.5885,  smooth loss = 0.5439
[2022-07-06 15:44:37,244 callbacks.py:105 INFO train-abinet] epoch 5 iter 210750: loss = 0.5803,  smooth loss = 0.5514
[2022-07-06 15:45:20,373 callbacks.py:105 INFO train-abinet] epoch 5 iter 210800: loss = 0.5678,  smooth loss = 0.5500
[2022-07-06 15:46:04,641 callbacks.py:105 INFO train-abinet] epoch 5 iter 210850: loss = 0.5281,  smooth loss = 0.5583
[2022-07-06 15:46:47,760 callbacks.py:105 INFO train-abinet] epoch 5 iter 210900: loss = 0.4407,  smooth loss = 0.5464
[2022-07-06 15:47:30,996 callbacks.py:105 INFO train-abinet] epoch 5 iter 210950: loss = 0.6082,  smooth loss = 0.5472
[2022-07-06 15:48:13,782 callbacks.py:105 INFO train-abinet] epoch 5 iter 211000: loss = 0.5628,  smooth loss = 0.5378
[2022-07-06 15:48:57,468 callbacks.py:105 INFO train-abinet] epoch 5 iter 211050: loss = 0.5575,  smooth loss = 0.5350
[2022-07-06 15:49:41,714 callbacks.py:105 INFO train-abinet] epoch 5 iter 211100: loss = 0.4246,  smooth loss = 0.5497
[2022-07-06 15:50:24,781 callbacks.py:105 INFO train-abinet] epoch 5 iter 211150: loss = 0.6409,  smooth loss = 0.5515
[2022-07-06 15:51:06,369 callbacks.py:105 INFO train-abinet] epoch 5 iter 211200: loss = 0.5625,  smooth loss = 0.5401
[2022-07-06 15:51:49,239 callbacks.py:105 INFO train-abinet] epoch 5 iter 211250: loss = 0.5142,  smooth loss = 0.5343
[2022-07-06 15:52:32,641 callbacks.py:105 INFO train-abinet] epoch 5 iter 211300: loss = 0.4958,  smooth loss = 0.5414
[2022-07-06 15:53:14,657 callbacks.py:105 INFO train-abinet] epoch 5 iter 211350: loss = 0.4026,  smooth loss = 0.5256
[2022-07-06 15:53:57,871 callbacks.py:105 INFO train-abinet] epoch 5 iter 211400: loss = 0.5267,  smooth loss = 0.5310
[2022-07-06 15:54:42,310 callbacks.py:105 INFO train-abinet] epoch 5 iter 211450: loss = 0.4828,  smooth loss = 0.5399
[2022-07-06 15:55:25,645 callbacks.py:105 INFO train-abinet] epoch 5 iter 211500: loss = 0.6329,  smooth loss = 0.5539
[2022-07-06 15:56:08,996 callbacks.py:105 INFO train-abinet] epoch 5 iter 211550: loss = 0.5697,  smooth loss = 0.5603
[2022-07-06 15:56:52,167 callbacks.py:105 INFO train-abinet] epoch 5 iter 211600: loss = 0.4760,  smooth loss = 0.5319
[2022-07-06 15:57:35,584 callbacks.py:105 INFO train-abinet] epoch 5 iter 211650: loss = 0.5523,  smooth loss = 0.5411
[2022-07-06 15:58:18,543 callbacks.py:105 INFO train-abinet] epoch 5 iter 211700: loss = 0.5547,  smooth loss = 0.5285
[2022-07-06 15:59:00,984 callbacks.py:105 INFO train-abinet] epoch 5 iter 211750: loss = 0.5130,  smooth loss = 0.5347
[2022-07-06 15:59:43,337 callbacks.py:105 INFO train-abinet] epoch 5 iter 211800: loss = 0.7418,  smooth loss = 0.5309
[2022-07-06 16:00:26,743 callbacks.py:105 INFO train-abinet] epoch 5 iter 211850: loss = 0.5500,  smooth loss = 0.5359
[2022-07-06 16:01:10,137 callbacks.py:105 INFO train-abinet] epoch 5 iter 211900: loss = 0.5622,  smooth loss = 0.5311
[2022-07-06 16:01:52,537 callbacks.py:105 INFO train-abinet] epoch 5 iter 211950: loss = 0.5333,  smooth loss = 0.5512
[2022-07-06 16:02:35,185 callbacks.py:105 INFO train-abinet] epoch 5 iter 212000: loss = 0.5472,  smooth loss = 0.5447
[2022-07-06 16:03:18,936 callbacks.py:105 INFO train-abinet] epoch 5 iter 212050: loss = 0.5403,  smooth loss = 0.5450
[2022-07-06 16:04:02,341 callbacks.py:105 INFO train-abinet] epoch 5 iter 212100: loss = 0.5723,  smooth loss = 0.5416
[2022-07-06 16:04:45,932 callbacks.py:105 INFO train-abinet] epoch 5 iter 212150: loss = 0.5977,  smooth loss = 0.5406
[2022-07-06 16:05:29,337 callbacks.py:105 INFO train-abinet] epoch 5 iter 212200: loss = 0.4542,  smooth loss = 0.5378
[2022-07-06 16:06:12,497 callbacks.py:105 INFO train-abinet] epoch 5 iter 212250: loss = 0.5699,  smooth loss = 0.5424
[2022-07-06 16:06:55,362 callbacks.py:105 INFO train-abinet] epoch 5 iter 212300: loss = 0.4100,  smooth loss = 0.5590
[2022-07-06 16:07:38,825 callbacks.py:105 INFO train-abinet] epoch 5 iter 212350: loss = 0.5079,  smooth loss = 0.5328
[2022-07-06 16:08:21,687 callbacks.py:105 INFO train-abinet] epoch 5 iter 212400: loss = 0.5713,  smooth loss = 0.5412
[2022-07-06 16:09:06,517 callbacks.py:105 INFO train-abinet] epoch 5 iter 212450: loss = 0.4758,  smooth loss = 0.5253
[2022-07-06 16:09:49,747 callbacks.py:105 INFO train-abinet] epoch 5 iter 212500: loss = 0.5553,  smooth loss = 0.5498
[2022-07-06 16:10:32,960 callbacks.py:105 INFO train-abinet] epoch 5 iter 212550: loss = 0.6377,  smooth loss = 0.5366
[2022-07-06 16:11:15,729 callbacks.py:105 INFO train-abinet] epoch 5 iter 212600: loss = 0.5970,  smooth loss = 0.5527
[2022-07-06 16:11:58,097 callbacks.py:105 INFO train-abinet] epoch 5 iter 212650: loss = 0.4705,  smooth loss = 0.5475
[2022-07-06 16:12:40,878 callbacks.py:105 INFO train-abinet] epoch 5 iter 212700: loss = 0.4459,  smooth loss = 0.5409
[2022-07-06 16:13:23,917 callbacks.py:105 INFO train-abinet] epoch 5 iter 212750: loss = 0.5679,  smooth loss = 0.5446
[2022-07-06 16:14:07,680 callbacks.py:105 INFO train-abinet] epoch 5 iter 212800: loss = 0.5253,  smooth loss = 0.5533
[2022-07-06 16:14:50,621 callbacks.py:105 INFO train-abinet] epoch 5 iter 212850: loss = 0.4046,  smooth loss = 0.5355
[2022-07-06 16:15:33,286 callbacks.py:105 INFO train-abinet] epoch 5 iter 212900: loss = 0.5126,  smooth loss = 0.5399
[2022-07-06 16:16:16,820 callbacks.py:105 INFO train-abinet] epoch 5 iter 212950: loss = 0.5169,  smooth loss = 0.5491
[2022-07-06 16:17:00,055 callbacks.py:105 INFO train-abinet] epoch 5 iter 213000: loss = 0.4866,  smooth loss = 0.5499
[2022-07-06 16:17:00,055 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8752s
█[2022-07-06 16:17:14,168 callbacks.py:123 INFO train-abinet] epoch 5 iter 213000: eval loss = 1.1878,  ccr = 0.9616,  cwr = 0.9183,  ted = 1285.0000,  ned = 259.9918,  ted/w = 0.1773, 
[2022-07-06 16:17:14,169 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_213000
[2022-07-06 16:17:57,781 callbacks.py:105 INFO train-abinet] epoch 5 iter 213050: loss = 0.6406,  smooth loss = 0.5489
[2022-07-06 16:18:41,201 callbacks.py:105 INFO train-abinet] epoch 5 iter 213100: loss = 0.5917,  smooth loss = 0.5579
[2022-07-06 16:19:24,517 callbacks.py:105 INFO train-abinet] epoch 5 iter 213150: loss = 0.5715,  smooth loss = 0.5549
[2022-07-06 16:20:08,240 callbacks.py:105 INFO train-abinet] epoch 5 iter 213200: loss = 0.5313,  smooth loss = 0.5512
[2022-07-06 16:20:50,563 callbacks.py:105 INFO train-abinet] epoch 5 iter 213250: loss = 0.4779,  smooth loss = 0.5454
[2022-07-06 16:21:33,609 callbacks.py:105 INFO train-abinet] epoch 5 iter 213300: loss = 0.5076,  smooth loss = 0.5517
[2022-07-06 16:22:16,595 callbacks.py:105 INFO train-abinet] epoch 5 iter 213350: loss = 0.4746,  smooth loss = 0.5516
[2022-07-06 16:22:59,521 callbacks.py:105 INFO train-abinet] epoch 5 iter 213400: loss = 0.4875,  smooth loss = 0.5465
[2022-07-06 16:23:43,487 callbacks.py:105 INFO train-abinet] epoch 5 iter 213450: loss = 0.4710,  smooth loss = 0.5411
[2022-07-06 16:24:26,778 callbacks.py:105 INFO train-abinet] epoch 5 iter 213500: loss = 0.6224,  smooth loss = 0.5364
[2022-07-06 16:25:10,011 callbacks.py:105 INFO train-abinet] epoch 5 iter 213550: loss = 0.6066,  smooth loss = 0.5405
[2022-07-06 16:25:53,834 callbacks.py:105 INFO train-abinet] epoch 5 iter 213600: loss = 0.5930,  smooth loss = 0.5394
[2022-07-06 16:26:36,985 callbacks.py:105 INFO train-abinet] epoch 5 iter 213650: loss = 0.3981,  smooth loss = 0.5369
[2022-07-06 16:27:20,271 callbacks.py:105 INFO train-abinet] epoch 5 iter 213700: loss = 0.5661,  smooth loss = 0.5438
[2022-07-06 16:28:03,107 callbacks.py:105 INFO train-abinet] epoch 5 iter 213750: loss = 0.6694,  smooth loss = 0.5498
[2022-07-06 16:28:47,042 callbacks.py:105 INFO train-abinet] epoch 5 iter 213800: loss = 0.6409,  smooth loss = 0.5436
[2022-07-06 16:29:30,614 callbacks.py:105 INFO train-abinet] epoch 5 iter 213850: loss = 0.5638,  smooth loss = 0.5469
[2022-07-06 16:30:13,639 callbacks.py:105 INFO train-abinet] epoch 5 iter 213900: loss = 0.6271,  smooth loss = 0.5570
[2022-07-06 16:30:57,379 callbacks.py:105 INFO train-abinet] epoch 5 iter 213950: loss = 0.5588,  smooth loss = 0.5475
[2022-07-06 16:31:40,197 callbacks.py:105 INFO train-abinet] epoch 5 iter 214000: loss = 0.5428,  smooth loss = 0.5441
[2022-07-06 16:32:22,807 callbacks.py:105 INFO train-abinet] epoch 5 iter 214050: loss = 0.4703,  smooth loss = 0.5433
[2022-07-06 16:33:05,140 callbacks.py:105 INFO train-abinet] epoch 5 iter 214100: loss = 0.4749,  smooth loss = 0.5490
[2022-07-06 16:33:47,798 callbacks.py:105 INFO train-abinet] epoch 5 iter 214150: loss = 0.6217,  smooth loss = 0.5508
[2022-07-06 16:34:30,445 callbacks.py:105 INFO train-abinet] epoch 5 iter 214200: loss = 0.6353,  smooth loss = 0.5426
[2022-07-06 16:35:13,444 callbacks.py:105 INFO train-abinet] epoch 5 iter 214250: loss = 0.5128,  smooth loss = 0.5277
[2022-07-06 16:35:55,656 callbacks.py:105 INFO train-abinet] epoch 5 iter 214300: loss = 0.5047,  smooth loss = 0.5366
[2022-07-06 16:36:38,386 callbacks.py:105 INFO train-abinet] epoch 5 iter 214350: loss = 0.4119,  smooth loss = 0.5446
[2022-07-06 16:37:19,888 callbacks.py:105 INFO train-abinet] epoch 5 iter 214400: loss = 0.6821,  smooth loss = 0.5596
[2022-07-06 16:38:01,998 callbacks.py:105 INFO train-abinet] epoch 5 iter 214450: loss = 0.5389,  smooth loss = 0.5504
[2022-07-06 16:38:45,273 callbacks.py:105 INFO train-abinet] epoch 5 iter 214500: loss = 0.5463,  smooth loss = 0.5350
[2022-07-06 16:39:27,927 callbacks.py:105 INFO train-abinet] epoch 5 iter 214550: loss = 0.3983,  smooth loss = 0.5301
[2022-07-06 16:40:10,572 callbacks.py:105 INFO train-abinet] epoch 5 iter 214600: loss = 0.5536,  smooth loss = 0.5440
[2022-07-06 16:40:53,617 callbacks.py:105 INFO train-abinet] epoch 5 iter 214650: loss = 0.6041,  smooth loss = 0.5437
[2022-07-06 16:41:36,960 callbacks.py:105 INFO train-abinet] epoch 5 iter 214700: loss = 0.6217,  smooth loss = 0.5427
[2022-07-06 16:42:19,610 callbacks.py:105 INFO train-abinet] epoch 5 iter 214750: loss = 0.4892,  smooth loss = 0.5494
[2022-07-06 16:43:02,284 callbacks.py:105 INFO train-abinet] epoch 5 iter 214800: loss = 0.5971,  smooth loss = 0.5525
[2022-07-06 16:43:44,492 callbacks.py:105 INFO train-abinet] epoch 5 iter 214850: loss = 0.6513,  smooth loss = 0.5430
[2022-07-06 16:44:26,594 callbacks.py:105 INFO train-abinet] epoch 5 iter 214900: loss = 0.5678,  smooth loss = 0.5402
[2022-07-06 16:45:09,739 callbacks.py:105 INFO train-abinet] epoch 5 iter 214950: loss = 0.7617,  smooth loss = 0.5358
[2022-07-06 16:45:52,696 callbacks.py:105 INFO train-abinet] epoch 5 iter 215000: loss = 0.4319,  smooth loss = 0.5305
[2022-07-06 16:46:35,970 callbacks.py:105 INFO train-abinet] epoch 5 iter 215050: loss = 0.6301,  smooth loss = 0.5380
[2022-07-06 16:47:18,054 callbacks.py:105 INFO train-abinet] epoch 5 iter 215100: loss = 0.4551,  smooth loss = 0.5357
[2022-07-06 16:48:01,200 callbacks.py:105 INFO train-abinet] epoch 5 iter 215150: loss = 0.5290,  smooth loss = 0.5437
[2022-07-06 16:48:45,098 callbacks.py:105 INFO train-abinet] epoch 5 iter 215200: loss = 0.6866,  smooth loss = 0.5296
[2022-07-06 16:49:27,579 callbacks.py:105 INFO train-abinet] epoch 5 iter 215250: loss = 0.5054,  smooth loss = 0.5334
[2022-07-06 16:50:09,926 callbacks.py:105 INFO train-abinet] epoch 5 iter 215300: loss = 0.6282,  smooth loss = 0.5352
[2022-07-06 16:50:53,244 callbacks.py:105 INFO train-abinet] epoch 5 iter 215350: loss = 0.5934,  smooth loss = 0.5374
[2022-07-06 16:51:35,920 callbacks.py:105 INFO train-abinet] epoch 5 iter 215400: loss = 0.4813,  smooth loss = 0.5450
[2022-07-06 16:52:17,955 callbacks.py:105 INFO train-abinet] epoch 5 iter 215450: loss = 0.4431,  smooth loss = 0.5378
[2022-07-06 16:53:00,113 callbacks.py:105 INFO train-abinet] epoch 5 iter 215500: loss = 0.4602,  smooth loss = 0.5404
[2022-07-06 16:53:42,052 callbacks.py:105 INFO train-abinet] epoch 5 iter 215550: loss = 0.4830,  smooth loss = 0.5569
[2022-07-06 16:54:25,433 callbacks.py:105 INFO train-abinet] epoch 5 iter 215600: loss = 0.5226,  smooth loss = 0.5511
[2022-07-06 16:55:08,458 callbacks.py:105 INFO train-abinet] epoch 5 iter 215650: loss = 0.6468,  smooth loss = 0.5490
[2022-07-06 16:55:51,543 callbacks.py:105 INFO train-abinet] epoch 5 iter 215700: loss = 0.5313,  smooth loss = 0.5432
[2022-07-06 16:56:33,270 callbacks.py:105 INFO train-abinet] epoch 5 iter 215750: loss = 0.5851,  smooth loss = 0.5351
[2022-07-06 16:57:16,820 callbacks.py:105 INFO train-abinet] epoch 5 iter 215800: loss = 0.5090,  smooth loss = 0.5361
[2022-07-06 16:57:58,544 callbacks.py:105 INFO train-abinet] epoch 5 iter 215850: loss = 0.5839,  smooth loss = 0.5416
[2022-07-06 16:58:40,807 callbacks.py:105 INFO train-abinet] epoch 5 iter 215900: loss = 0.7098,  smooth loss = 0.5329
[2022-07-06 16:59:23,114 callbacks.py:105 INFO train-abinet] epoch 5 iter 215950: loss = 0.6308,  smooth loss = 0.5455
[2022-07-06 17:00:05,285 callbacks.py:105 INFO train-abinet] epoch 5 iter 216000: loss = 0.6696,  smooth loss = 0.5595
[2022-07-06 17:00:05,285 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8749s
█[2022-07-06 17:00:19,928 callbacks.py:123 INFO train-abinet] epoch 5 iter 216000: eval loss = 1.2082,  ccr = 0.9598,  cwr = 0.9197,  ted = 1314.0000,  ned = 258.3364,  ted/w = 0.1813, 
[2022-07-06 17:00:19,931 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_216000
[2022-07-06 17:01:03,935 callbacks.py:105 INFO train-abinet] epoch 5 iter 216050: loss = 0.5773,  smooth loss = 0.5531
[2022-07-06 17:01:47,204 callbacks.py:105 INFO train-abinet] epoch 5 iter 216100: loss = 0.5260,  smooth loss = 0.5471
[2022-07-06 17:02:30,178 callbacks.py:105 INFO train-abinet] epoch 5 iter 216150: loss = 0.6827,  smooth loss = 0.5457
[2022-07-06 17:03:13,035 callbacks.py:105 INFO train-abinet] epoch 5 iter 216200: loss = 0.5303,  smooth loss = 0.5447
[2022-07-06 17:03:55,806 callbacks.py:105 INFO train-abinet] epoch 5 iter 216250: loss = 0.5445,  smooth loss = 0.5573
[2022-07-06 17:04:38,847 callbacks.py:105 INFO train-abinet] epoch 5 iter 216300: loss = 0.3245,  smooth loss = 0.5368
[2022-07-06 17:05:21,530 callbacks.py:105 INFO train-abinet] epoch 5 iter 216350: loss = 0.4978,  smooth loss = 0.5483
[2022-07-06 17:06:04,839 callbacks.py:105 INFO train-abinet] epoch 5 iter 216400: loss = 0.3825,  smooth loss = 0.5363
[2022-07-06 17:06:46,881 callbacks.py:105 INFO train-abinet] epoch 5 iter 216450: loss = 0.5156,  smooth loss = 0.5293
[2022-07-06 17:07:29,510 callbacks.py:105 INFO train-abinet] epoch 5 iter 216500: loss = 0.5616,  smooth loss = 0.5297
[2022-07-06 17:08:11,353 callbacks.py:105 INFO train-abinet] epoch 5 iter 216550: loss = 0.5353,  smooth loss = 0.5412
[2022-07-06 17:08:53,225 callbacks.py:105 INFO train-abinet] epoch 5 iter 216600: loss = 0.6098,  smooth loss = 0.5429
[2022-07-06 17:09:35,470 callbacks.py:105 INFO train-abinet] epoch 5 iter 216650: loss = 0.4896,  smooth loss = 0.5512
[2022-07-06 17:10:18,417 callbacks.py:105 INFO train-abinet] epoch 5 iter 216700: loss = 0.5188,  smooth loss = 0.5591
[2022-07-06 17:11:00,302 callbacks.py:105 INFO train-abinet] epoch 5 iter 216750: loss = 0.5228,  smooth loss = 0.5512
[2022-07-06 17:11:43,073 callbacks.py:105 INFO train-abinet] epoch 5 iter 216800: loss = 0.4702,  smooth loss = 0.5419
[2022-07-06 17:12:25,284 callbacks.py:105 INFO train-abinet] epoch 5 iter 216850: loss = 0.5246,  smooth loss = 0.5361
[2022-07-06 17:13:08,015 callbacks.py:105 INFO train-abinet] epoch 5 iter 216900: loss = 0.5273,  smooth loss = 0.5412
[2022-07-06 17:13:49,533 callbacks.py:105 INFO train-abinet] epoch 5 iter 216950: loss = 0.4187,  smooth loss = 0.5315
[2022-07-06 17:14:33,519 callbacks.py:105 INFO train-abinet] epoch 5 iter 217000: loss = 0.4513,  smooth loss = 0.5314
[2022-07-06 17:15:16,154 callbacks.py:105 INFO train-abinet] epoch 5 iter 217050: loss = 0.6323,  smooth loss = 0.5309
[2022-07-06 17:15:58,816 callbacks.py:105 INFO train-abinet] epoch 5 iter 217100: loss = 0.6127,  smooth loss = 0.5390
[2022-07-06 17:16:40,968 callbacks.py:105 INFO train-abinet] epoch 5 iter 217150: loss = 0.4483,  smooth loss = 0.5314
[2022-07-06 17:17:22,801 callbacks.py:105 INFO train-abinet] epoch 5 iter 217200: loss = 0.5599,  smooth loss = 0.5521
[2022-07-06 17:18:05,057 callbacks.py:105 INFO train-abinet] epoch 5 iter 217250: loss = 0.5584,  smooth loss = 0.5512
[2022-07-06 17:18:47,148 callbacks.py:105 INFO train-abinet] epoch 5 iter 217300: loss = 0.5174,  smooth loss = 0.5331
[2022-07-06 17:19:30,779 callbacks.py:105 INFO train-abinet] epoch 5 iter 217350: loss = 0.5082,  smooth loss = 0.5262
[2022-07-06 17:20:12,982 callbacks.py:105 INFO train-abinet] epoch 5 iter 217400: loss = 0.5425,  smooth loss = 0.5496
[2022-07-06 17:20:55,210 callbacks.py:105 INFO train-abinet] epoch 5 iter 217450: loss = 0.5020,  smooth loss = 0.5422
[2022-07-06 17:21:37,892 callbacks.py:105 INFO train-abinet] epoch 5 iter 217500: loss = 0.6415,  smooth loss = 0.5411
[2022-07-06 17:22:21,024 callbacks.py:105 INFO train-abinet] epoch 5 iter 217550: loss = 0.5794,  smooth loss = 0.5211
[2022-07-06 17:23:03,541 callbacks.py:105 INFO train-abinet] epoch 5 iter 217600: loss = 0.5628,  smooth loss = 0.5274
[2022-07-06 17:23:46,335 callbacks.py:105 INFO train-abinet] epoch 5 iter 217650: loss = 0.5244,  smooth loss = 0.5390
[2022-07-06 17:24:29,036 callbacks.py:105 INFO train-abinet] epoch 5 iter 217700: loss = 0.3988,  smooth loss = 0.5422
[2022-07-06 17:25:11,992 callbacks.py:105 INFO train-abinet] epoch 5 iter 217750: loss = 0.5697,  smooth loss = 0.5615
[2022-07-06 17:25:55,732 callbacks.py:105 INFO train-abinet] epoch 5 iter 217800: loss = 0.5181,  smooth loss = 0.5368
[2022-07-06 17:26:38,552 callbacks.py:105 INFO train-abinet] epoch 5 iter 217850: loss = 0.5438,  smooth loss = 0.5407
[2022-07-06 17:27:20,904 callbacks.py:105 INFO train-abinet] epoch 5 iter 217900: loss = 0.5725,  smooth loss = 0.5431
[2022-07-06 17:28:03,862 callbacks.py:105 INFO train-abinet] epoch 5 iter 217950: loss = 0.5312,  smooth loss = 0.5433
[2022-07-06 17:28:47,080 callbacks.py:105 INFO train-abinet] epoch 5 iter 218000: loss = 0.6398,  smooth loss = 0.5463
[2022-07-06 17:29:29,787 callbacks.py:105 INFO train-abinet] epoch 5 iter 218050: loss = 0.5149,  smooth loss = 0.5411
[2022-07-06 17:30:12,148 callbacks.py:105 INFO train-abinet] epoch 5 iter 218100: loss = 0.6305,  smooth loss = 0.5332
[2022-07-06 17:30:54,984 callbacks.py:105 INFO train-abinet] epoch 5 iter 218150: loss = 0.4539,  smooth loss = 0.5397
[2022-07-06 17:31:37,055 callbacks.py:105 INFO train-abinet] epoch 5 iter 218200: loss = 0.5164,  smooth loss = 0.5442
[2022-07-06 17:32:19,931 callbacks.py:105 INFO train-abinet] epoch 5 iter 218250: loss = 0.5813,  smooth loss = 0.5499
[2022-07-06 17:33:02,525 callbacks.py:105 INFO train-abinet] epoch 5 iter 218300: loss = 0.4669,  smooth loss = 0.5453
[2022-07-06 17:33:45,325 callbacks.py:105 INFO train-abinet] epoch 5 iter 218350: loss = 0.6217,  smooth loss = 0.5463
[2022-07-06 17:34:27,573 callbacks.py:105 INFO train-abinet] epoch 5 iter 218400: loss = 0.4751,  smooth loss = 0.5466
[2022-07-06 17:35:09,938 callbacks.py:105 INFO train-abinet] epoch 5 iter 218450: loss = 0.5126,  smooth loss = 0.5522
[2022-07-06 17:35:52,425 callbacks.py:105 INFO train-abinet] epoch 5 iter 218500: loss = 0.4901,  smooth loss = 0.5467
[2022-07-06 17:36:34,661 callbacks.py:105 INFO train-abinet] epoch 5 iter 218550: loss = 0.6290,  smooth loss = 0.5511
[2022-07-06 17:37:16,418 callbacks.py:105 INFO train-abinet] epoch 5 iter 218600: loss = 0.6049,  smooth loss = 0.5413
[2022-07-06 17:37:57,660 callbacks.py:105 INFO train-abinet] epoch 5 iter 218650: loss = 0.5224,  smooth loss = 0.5332
[2022-07-06 17:38:39,399 callbacks.py:105 INFO train-abinet] epoch 5 iter 218700: loss = 0.6478,  smooth loss = 0.5439
[2022-07-06 17:39:20,508 callbacks.py:105 INFO train-abinet] epoch 5 iter 218750: loss = 0.4910,  smooth loss = 0.5371
[2022-07-06 17:40:02,079 callbacks.py:105 INFO train-abinet] epoch 5 iter 218800: loss = 0.6372,  smooth loss = 0.5387
[2022-07-06 17:40:43,620 callbacks.py:105 INFO train-abinet] epoch 5 iter 218850: loss = 0.5560,  smooth loss = 0.5334
[2022-07-06 17:41:25,097 callbacks.py:105 INFO train-abinet] epoch 5 iter 218900: loss = 0.4907,  smooth loss = 0.5274
[2022-07-06 17:42:06,392 callbacks.py:105 INFO train-abinet] epoch 5 iter 218950: loss = 0.5438,  smooth loss = 0.5260
[2022-07-06 17:42:47,388 callbacks.py:105 INFO train-abinet] epoch 5 iter 219000: loss = 0.6034,  smooth loss = 0.5392
[2022-07-06 17:42:47,389 callbacks.py:114 INFO train-abinet] average data time = 0.0054s, average running time = 0.8746s
█[2022-07-06 17:43:02,001 callbacks.py:123 INFO train-abinet] epoch 5 iter 219000: eval loss = 1.1825,  ccr = 0.9591,  cwr = 0.9172,  ted = 1335.0000,  ned = 265.6264,  ted/w = 0.1842, 
[2022-07-06 17:43:02,002 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_219000
[2022-07-06 17:43:44,506 callbacks.py:105 INFO train-abinet] epoch 5 iter 219050: loss = 0.5391,  smooth loss = 0.5342
[2022-07-06 17:44:26,810 callbacks.py:105 INFO train-abinet] epoch 5 iter 219100: loss = 0.5192,  smooth loss = 0.5300
[2022-07-06 17:45:08,378 callbacks.py:105 INFO train-abinet] epoch 5 iter 219150: loss = 0.6175,  smooth loss = 0.5367
[2022-07-06 17:45:50,890 callbacks.py:105 INFO train-abinet] epoch 5 iter 219200: loss = 0.3717,  smooth loss = 0.5281
[2022-07-06 17:46:32,387 callbacks.py:105 INFO train-abinet] epoch 5 iter 219250: loss = 0.6001,  smooth loss = 0.5214
[2022-07-06 17:47:13,367 callbacks.py:105 INFO train-abinet] epoch 5 iter 219300: loss = 0.5926,  smooth loss = 0.5346
[2022-07-06 17:47:55,026 callbacks.py:105 INFO train-abinet] epoch 5 iter 219350: loss = 0.6767,  smooth loss = 0.5485
[2022-07-06 17:48:36,485 callbacks.py:105 INFO train-abinet] epoch 5 iter 219400: loss = 0.5437,  smooth loss = 0.5452
[2022-07-06 17:49:18,795 callbacks.py:105 INFO train-abinet] epoch 5 iter 219450: loss = 0.5432,  smooth loss = 0.5342
[2022-07-06 17:49:59,739 callbacks.py:105 INFO train-abinet] epoch 5 iter 219500: loss = 0.4866,  smooth loss = 0.5375
[2022-07-06 17:50:40,935 callbacks.py:105 INFO train-abinet] epoch 5 iter 219550: loss = 0.5428,  smooth loss = 0.5413
[2022-07-06 17:51:22,675 callbacks.py:105 INFO train-abinet] epoch 5 iter 219600: loss = 0.5350,  smooth loss = 0.5347
[2022-07-06 17:52:03,923 callbacks.py:105 INFO train-abinet] epoch 5 iter 219650: loss = 0.5170,  smooth loss = 0.5378
[2022-07-06 17:52:46,443 callbacks.py:105 INFO train-abinet] epoch 5 iter 219700: loss = 0.6052,  smooth loss = 0.5367
[2022-07-06 17:53:27,329 callbacks.py:105 INFO train-abinet] epoch 5 iter 219750: loss = 0.4256,  smooth loss = 0.5369
[2022-07-06 17:54:08,516 callbacks.py:105 INFO train-abinet] epoch 5 iter 219800: loss = 0.4959,  smooth loss = 0.5468
[2022-07-06 17:54:49,403 callbacks.py:105 INFO train-abinet] epoch 5 iter 219850: loss = 0.4334,  smooth loss = 0.5453
[2022-07-06 17:55:30,798 callbacks.py:105 INFO train-abinet] epoch 5 iter 219900: loss = 0.5295,  smooth loss = 0.5486
[2022-07-06 17:56:12,709 callbacks.py:105 INFO train-abinet] epoch 5 iter 219950: loss = 0.5637,  smooth loss = 0.5398
[2022-07-06 17:56:54,768 callbacks.py:105 INFO train-abinet] epoch 5 iter 220000: loss = 0.4546,  smooth loss = 0.5355
[2022-07-06 17:57:36,446 callbacks.py:105 INFO train-abinet] epoch 5 iter 220050: loss = 0.4328,  smooth loss = 0.5359
[2022-07-06 17:58:18,029 callbacks.py:105 INFO train-abinet] epoch 5 iter 220100: loss = 0.6004,  smooth loss = 0.5361
[2022-07-06 17:58:59,168 callbacks.py:105 INFO train-abinet] epoch 5 iter 220150: loss = 0.5571,  smooth loss = 0.5498
[2022-07-06 17:59:40,654 callbacks.py:105 INFO train-abinet] epoch 5 iter 220200: loss = 0.6820,  smooth loss = 0.5425
[2022-07-06 18:00:22,828 callbacks.py:105 INFO train-abinet] epoch 5 iter 220250: loss = 0.4663,  smooth loss = 0.5393
[2022-07-06 18:01:04,104 callbacks.py:105 INFO train-abinet] epoch 5 iter 220300: loss = 0.6055,  smooth loss = 0.5431
[2022-07-06 18:01:45,304 callbacks.py:105 INFO train-abinet] epoch 5 iter 220350: loss = 0.6175,  smooth loss = 0.5448
[2022-07-06 18:02:26,303 callbacks.py:105 INFO train-abinet] epoch 5 iter 220400: loss = 0.4849,  smooth loss = 0.5241
[2022-07-06 18:03:07,172 callbacks.py:105 INFO train-abinet] epoch 5 iter 220450: loss = 0.6206,  smooth loss = 0.5381
[2022-07-06 18:03:48,404 callbacks.py:105 INFO train-abinet] epoch 5 iter 220500: loss = 0.6477,  smooth loss = 0.5461
[2022-07-06 18:04:30,291 callbacks.py:105 INFO train-abinet] epoch 5 iter 220550: loss = 0.4184,  smooth loss = 0.5384
[2022-07-06 18:05:12,042 callbacks.py:105 INFO train-abinet] epoch 5 iter 220600: loss = 0.6586,  smooth loss = 0.5412
[2022-07-06 18:05:54,543 callbacks.py:105 INFO train-abinet] epoch 5 iter 220650: loss = 0.6149,  smooth loss = 0.5585
[2022-07-06 18:06:35,917 callbacks.py:105 INFO train-abinet] epoch 5 iter 220700: loss = 0.3169,  smooth loss = 0.5458
[2022-07-06 18:07:17,195 callbacks.py:105 INFO train-abinet] epoch 5 iter 220750: loss = 0.4809,  smooth loss = 0.5446
[2022-07-06 18:07:58,064 callbacks.py:105 INFO train-abinet] epoch 5 iter 220800: loss = 0.5743,  smooth loss = 0.5503
[2022-07-06 18:08:39,341 callbacks.py:105 INFO train-abinet] epoch 5 iter 220850: loss = 0.3873,  smooth loss = 0.5506
[2022-07-06 18:09:21,008 callbacks.py:105 INFO train-abinet] epoch 5 iter 220900: loss = 0.5476,  smooth loss = 0.5555
[2022-07-06 18:10:02,491 callbacks.py:105 INFO train-abinet] epoch 5 iter 220950: loss = 0.4935,  smooth loss = 0.5496
[2022-07-06 18:10:43,470 callbacks.py:105 INFO train-abinet] epoch 5 iter 221000: loss = 0.5681,  smooth loss = 0.5419
[2022-07-06 18:11:24,548 callbacks.py:105 INFO train-abinet] epoch 5 iter 221050: loss = 0.5685,  smooth loss = 0.5380
[2022-07-06 18:12:06,051 callbacks.py:105 INFO train-abinet] epoch 5 iter 221100: loss = 0.5160,  smooth loss = 0.5392
[2022-07-06 18:12:47,487 callbacks.py:105 INFO train-abinet] epoch 5 iter 221150: loss = 0.5682,  smooth loss = 0.5418
[2022-07-06 18:13:28,939 callbacks.py:105 INFO train-abinet] epoch 5 iter 221200: loss = 0.4837,  smooth loss = 0.5287
[2022-07-06 18:14:10,451 callbacks.py:105 INFO train-abinet] epoch 5 iter 221250: loss = 0.5446,  smooth loss = 0.5410
[2022-07-06 18:14:51,825 callbacks.py:105 INFO train-abinet] epoch 5 iter 221300: loss = 0.5323,  smooth loss = 0.5504
[2022-07-06 18:15:33,212 callbacks.py:105 INFO train-abinet] epoch 5 iter 221350: loss = 0.5705,  smooth loss = 0.5318
[2022-07-06 18:16:14,295 callbacks.py:105 INFO train-abinet] epoch 5 iter 221400: loss = 0.5904,  smooth loss = 0.5381
[2022-07-06 18:16:55,353 callbacks.py:105 INFO train-abinet] epoch 5 iter 221450: loss = 0.5501,  smooth loss = 0.5394
[2022-07-06 18:17:36,393 callbacks.py:105 INFO train-abinet] epoch 5 iter 221500: loss = 0.4980,  smooth loss = 0.5370
[2022-07-06 18:18:18,155 callbacks.py:105 INFO train-abinet] epoch 5 iter 221550: loss = 0.5942,  smooth loss = 0.5581
[2022-07-06 18:18:58,519 callbacks.py:105 INFO train-abinet] epoch 5 iter 221600: loss = 0.5263,  smooth loss = 0.5615
[2022-07-06 18:19:39,604 callbacks.py:105 INFO train-abinet] epoch 5 iter 221650: loss = 0.5093,  smooth loss = 0.5522
[2022-07-06 18:20:20,479 callbacks.py:105 INFO train-abinet] epoch 5 iter 221700: loss = 0.4305,  smooth loss = 0.5597
[2022-07-06 18:21:01,329 callbacks.py:105 INFO train-abinet] epoch 5 iter 221750: loss = 0.4743,  smooth loss = 0.5405
[2022-07-06 18:21:42,739 callbacks.py:105 INFO train-abinet] epoch 5 iter 221800: loss = 0.6017,  smooth loss = 0.5377
[2022-07-06 18:22:24,489 callbacks.py:105 INFO train-abinet] epoch 5 iter 221850: loss = 0.4598,  smooth loss = 0.5392
[2022-07-06 18:23:05,094 callbacks.py:105 INFO train-abinet] epoch 5 iter 221900: loss = 0.5840,  smooth loss = 0.5454
[2022-07-06 18:23:46,012 callbacks.py:105 INFO train-abinet] epoch 5 iter 221950: loss = 0.4546,  smooth loss = 0.5507
[2022-07-06 18:24:27,532 callbacks.py:105 INFO train-abinet] epoch 5 iter 222000: loss = 0.5134,  smooth loss = 0.5410
[2022-07-06 18:24:27,533 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8740s
█[2022-07-06 18:24:42,315 callbacks.py:123 INFO train-abinet] epoch 5 iter 222000: eval loss = 1.1589,  ccr = 0.9589,  cwr = 0.9169,  ted = 1352.0000,  ned = 272.3058,  ted/w = 0.1865, 
[2022-07-06 18:24:42,316 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_222000
[2022-07-06 18:25:25,149 callbacks.py:105 INFO train-abinet] epoch 5 iter 222050: loss = 0.4979,  smooth loss = 0.5525
[2022-07-06 18:26:07,329 callbacks.py:105 INFO train-abinet] epoch 5 iter 222100: loss = 0.5911,  smooth loss = 0.5343
[2022-07-06 18:26:49,536 callbacks.py:105 INFO train-abinet] epoch 5 iter 222150: loss = 0.4648,  smooth loss = 0.5280
[2022-07-06 18:27:30,407 callbacks.py:105 INFO train-abinet] epoch 5 iter 222200: loss = 0.4820,  smooth loss = 0.5347
[2022-07-06 18:28:12,720 callbacks.py:105 INFO train-abinet] epoch 5 iter 222250: loss = 0.5062,  smooth loss = 0.5318
[2022-07-06 18:28:54,027 callbacks.py:105 INFO train-abinet] epoch 5 iter 222300: loss = 0.4520,  smooth loss = 0.5430
[2022-07-06 18:29:35,270 callbacks.py:105 INFO train-abinet] epoch 5 iter 222350: loss = 0.4910,  smooth loss = 0.5314
[2022-07-06 18:30:17,040 callbacks.py:105 INFO train-abinet] epoch 5 iter 222400: loss = 0.5478,  smooth loss = 0.5314
[2022-07-06 18:30:58,919 callbacks.py:105 INFO train-abinet] epoch 5 iter 222450: loss = 0.4796,  smooth loss = 0.5378
[2022-07-06 18:31:41,116 callbacks.py:105 INFO train-abinet] epoch 5 iter 222500: loss = 0.3680,  smooth loss = 0.5413
[2022-07-06 18:32:22,124 callbacks.py:105 INFO train-abinet] epoch 5 iter 222550: loss = 0.4999,  smooth loss = 0.5344
[2022-07-06 18:33:03,637 callbacks.py:105 INFO train-abinet] epoch 5 iter 222600: loss = 0.4954,  smooth loss = 0.5354
[2022-07-06 18:33:45,073 callbacks.py:105 INFO train-abinet] epoch 5 iter 222650: loss = 0.5818,  smooth loss = 0.5409
[2022-07-06 18:34:27,222 callbacks.py:105 INFO train-abinet] epoch 5 iter 222700: loss = 0.4895,  smooth loss = 0.5358
[2022-07-06 18:35:08,437 callbacks.py:105 INFO train-abinet] epoch 5 iter 222750: loss = 0.3809,  smooth loss = 0.5366
[2022-07-06 18:35:50,101 callbacks.py:105 INFO train-abinet] epoch 5 iter 222800: loss = 0.5323,  smooth loss = 0.5377
[2022-07-06 18:36:31,220 callbacks.py:105 INFO train-abinet] epoch 5 iter 222850: loss = 0.7224,  smooth loss = 0.5488
[2022-07-06 18:37:12,854 callbacks.py:105 INFO train-abinet] epoch 5 iter 222900: loss = 0.5970,  smooth loss = 0.5474
[2022-07-06 18:37:54,075 callbacks.py:105 INFO train-abinet] epoch 5 iter 222950: loss = 0.6116,  smooth loss = 0.5327
[2022-07-06 18:38:35,336 callbacks.py:105 INFO train-abinet] epoch 5 iter 223000: loss = 0.4954,  smooth loss = 0.5353
[2022-07-06 18:39:16,709 callbacks.py:105 INFO train-abinet] epoch 5 iter 223050: loss = 0.6811,  smooth loss = 0.5324
[2022-07-06 18:39:57,888 callbacks.py:105 INFO train-abinet] epoch 5 iter 223100: loss = 0.5174,  smooth loss = 0.5221
[2022-07-06 18:40:39,278 callbacks.py:105 INFO train-abinet] epoch 5 iter 223150: loss = 0.5160,  smooth loss = 0.5293
[2022-07-06 18:41:21,071 callbacks.py:105 INFO train-abinet] epoch 5 iter 223200: loss = 0.4700,  smooth loss = 0.5362
[2022-07-06 18:42:02,155 callbacks.py:105 INFO train-abinet] epoch 5 iter 223250: loss = 0.5269,  smooth loss = 0.5517
[2022-07-06 18:42:42,928 callbacks.py:105 INFO train-abinet] epoch 5 iter 223300: loss = 0.4980,  smooth loss = 0.5366
[2022-07-06 18:43:23,897 callbacks.py:105 INFO train-abinet] epoch 5 iter 223350: loss = 0.5482,  smooth loss = 0.5451
[2022-07-06 18:44:05,463 callbacks.py:105 INFO train-abinet] epoch 5 iter 223400: loss = 0.5658,  smooth loss = 0.5385
[2022-07-06 18:44:47,069 callbacks.py:105 INFO train-abinet] epoch 5 iter 223450: loss = 0.5528,  smooth loss = 0.5319
[2022-07-06 18:45:28,608 callbacks.py:105 INFO train-abinet] epoch 5 iter 223500: loss = 0.6743,  smooth loss = 0.5546
[2022-07-06 18:46:10,194 callbacks.py:105 INFO train-abinet] epoch 5 iter 223550: loss = 0.5607,  smooth loss = 0.5481
[2022-07-06 18:46:51,546 callbacks.py:105 INFO train-abinet] epoch 5 iter 223600: loss = 0.5050,  smooth loss = 0.5465
[2022-07-06 18:47:32,983 callbacks.py:105 INFO train-abinet] epoch 5 iter 223650: loss = 0.5928,  smooth loss = 0.5462
[2022-07-06 18:48:14,427 callbacks.py:105 INFO train-abinet] epoch 5 iter 223700: loss = 0.4580,  smooth loss = 0.5283
[2022-07-06 18:48:55,711 callbacks.py:105 INFO train-abinet] epoch 5 iter 223750: loss = 0.4502,  smooth loss = 0.5439
[2022-07-06 18:49:36,761 callbacks.py:105 INFO train-abinet] epoch 5 iter 223800: loss = 0.5957,  smooth loss = 0.5519
[2022-07-06 18:50:17,533 callbacks.py:105 INFO train-abinet] epoch 5 iter 223850: loss = 0.4884,  smooth loss = 0.5587
[2022-07-06 18:50:58,158 callbacks.py:105 INFO train-abinet] epoch 5 iter 223900: loss = 0.6320,  smooth loss = 0.5500
[2022-07-06 18:51:39,460 callbacks.py:105 INFO train-abinet] epoch 5 iter 223950: loss = 0.5410,  smooth loss = 0.5437
[2022-07-06 18:52:20,922 callbacks.py:105 INFO train-abinet] epoch 5 iter 224000: loss = 0.4259,  smooth loss = 0.5249
[2022-07-06 18:53:02,095 callbacks.py:105 INFO train-abinet] epoch 5 iter 224050: loss = 0.4590,  smooth loss = 0.5295
[2022-07-06 18:53:43,102 callbacks.py:105 INFO train-abinet] epoch 5 iter 224100: loss = 0.5677,  smooth loss = 0.5194
[2022-07-06 18:54:24,031 callbacks.py:105 INFO train-abinet] epoch 5 iter 224150: loss = 0.5713,  smooth loss = 0.5477
[2022-07-06 18:55:05,494 callbacks.py:105 INFO train-abinet] epoch 5 iter 224200: loss = 0.4930,  smooth loss = 0.5418
[2022-07-06 18:55:46,637 callbacks.py:105 INFO train-abinet] epoch 5 iter 224250: loss = 0.7138,  smooth loss = 0.5452
[2022-07-06 18:56:28,457 callbacks.py:105 INFO train-abinet] epoch 5 iter 224300: loss = 0.6659,  smooth loss = 0.5489
[2022-07-06 18:57:10,104 callbacks.py:105 INFO train-abinet] epoch 5 iter 224350: loss = 0.5410,  smooth loss = 0.5462
[2022-07-06 18:57:51,851 callbacks.py:105 INFO train-abinet] epoch 5 iter 224400: loss = 0.4779,  smooth loss = 0.5348
[2022-07-06 18:58:32,917 callbacks.py:105 INFO train-abinet] epoch 5 iter 224450: loss = 0.7486,  smooth loss = 0.5534
[2022-07-06 18:59:14,183 callbacks.py:105 INFO train-abinet] epoch 5 iter 224500: loss = 0.7147,  smooth loss = 0.5450
[2022-07-06 18:59:55,719 callbacks.py:105 INFO train-abinet] epoch 5 iter 224550: loss = 0.5252,  smooth loss = 0.5339
[2022-07-06 19:00:37,717 callbacks.py:105 INFO train-abinet] epoch 5 iter 224600: loss = 0.5512,  smooth loss = 0.5376
[2022-07-06 19:01:18,665 callbacks.py:105 INFO train-abinet] epoch 5 iter 224650: loss = 0.5278,  smooth loss = 0.5332
[2022-07-06 19:02:00,445 callbacks.py:105 INFO train-abinet] epoch 5 iter 224700: loss = 0.4370,  smooth loss = 0.5387
[2022-07-06 19:02:41,830 callbacks.py:105 INFO train-abinet] epoch 5 iter 224750: loss = 0.6143,  smooth loss = 0.5377
[2022-07-06 19:03:23,318 callbacks.py:105 INFO train-abinet] epoch 5 iter 224800: loss = 0.5064,  smooth loss = 0.5420
[2022-07-06 19:04:04,841 callbacks.py:105 INFO train-abinet] epoch 5 iter 224850: loss = 0.5669,  smooth loss = 0.5497
[2022-07-06 19:04:46,014 callbacks.py:105 INFO train-abinet] epoch 5 iter 224900: loss = 0.5339,  smooth loss = 0.5378
[2022-07-06 19:05:27,069 callbacks.py:105 INFO train-abinet] epoch 5 iter 224950: loss = 0.4448,  smooth loss = 0.5293
[2022-07-06 19:06:08,337 callbacks.py:105 INFO train-abinet] epoch 5 iter 225000: loss = 0.4742,  smooth loss = 0.5257
[2022-07-06 19:06:08,338 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8734s
█[2022-07-06 19:06:22,894 callbacks.py:123 INFO train-abinet] epoch 5 iter 225000: eval loss = 1.1543,  ccr = 0.9604,  cwr = 0.9163,  ted = 1317.0000,  ned = 263.5886,  ted/w = 0.1817, 
[2022-07-06 19:06:22,895 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_225000
[2022-07-06 19:07:05,223 callbacks.py:105 INFO train-abinet] epoch 5 iter 225050: loss = 0.5428,  smooth loss = 0.5418
[2022-07-06 19:07:46,615 callbacks.py:105 INFO train-abinet] epoch 5 iter 225100: loss = 0.4870,  smooth loss = 0.5302
[2022-07-06 19:08:28,511 callbacks.py:105 INFO train-abinet] epoch 5 iter 225150: loss = 0.5549,  smooth loss = 0.5514
[2022-07-06 19:09:09,834 callbacks.py:105 INFO train-abinet] epoch 5 iter 225200: loss = 0.5363,  smooth loss = 0.5567
[2022-07-06 19:09:51,120 callbacks.py:105 INFO train-abinet] epoch 5 iter 225250: loss = 0.5994,  smooth loss = 0.5494
[2022-07-06 19:10:31,967 callbacks.py:105 INFO train-abinet] epoch 5 iter 225300: loss = 0.5274,  smooth loss = 0.5423
[2022-07-06 19:11:13,167 callbacks.py:105 INFO train-abinet] epoch 5 iter 225350: loss = 0.4499,  smooth loss = 0.5481
[2022-07-06 19:11:55,233 callbacks.py:105 INFO train-abinet] epoch 5 iter 225400: loss = 0.5761,  smooth loss = 0.5389
[2022-07-06 19:12:37,303 callbacks.py:105 INFO train-abinet] epoch 5 iter 225450: loss = 0.4364,  smooth loss = 0.5392
[2022-07-06 19:13:18,412 callbacks.py:105 INFO train-abinet] epoch 5 iter 225500: loss = 0.5461,  smooth loss = 0.5354
[2022-07-06 19:14:00,289 callbacks.py:105 INFO train-abinet] epoch 5 iter 225550: loss = 0.5978,  smooth loss = 0.5334
[2022-07-06 19:14:41,953 callbacks.py:105 INFO train-abinet] epoch 5 iter 225600: loss = 0.5913,  smooth loss = 0.5393
[2022-07-06 19:15:24,917 callbacks.py:105 INFO train-abinet] epoch 5 iter 225650: loss = 0.5229,  smooth loss = 0.5435
[2022-07-06 19:16:06,817 callbacks.py:105 INFO train-abinet] epoch 5 iter 225700: loss = 0.5745,  smooth loss = 0.5388
[2022-07-06 19:16:48,352 callbacks.py:105 INFO train-abinet] epoch 5 iter 225750: loss = 0.6305,  smooth loss = 0.5340
[2022-07-06 19:17:29,952 callbacks.py:105 INFO train-abinet] epoch 5 iter 225800: loss = 0.5410,  smooth loss = 0.5410
[2022-07-06 19:18:11,029 callbacks.py:105 INFO train-abinet] epoch 5 iter 225850: loss = 0.4320,  smooth loss = 0.5356
[2022-07-06 19:18:52,275 callbacks.py:105 INFO train-abinet] epoch 5 iter 225900: loss = 0.4125,  smooth loss = 0.5337
[2022-07-06 19:19:33,778 callbacks.py:105 INFO train-abinet] epoch 5 iter 225950: loss = 0.4347,  smooth loss = 0.5463
[2022-07-06 19:20:15,073 callbacks.py:105 INFO train-abinet] epoch 5 iter 226000: loss = 0.5179,  smooth loss = 0.5454
[2022-07-06 19:20:56,314 callbacks.py:105 INFO train-abinet] epoch 5 iter 226050: loss = 0.5404,  smooth loss = 0.5466
[2022-07-06 19:21:37,772 callbacks.py:105 INFO train-abinet] epoch 5 iter 226100: loss = 0.4577,  smooth loss = 0.5472
[2022-07-06 19:22:20,352 callbacks.py:105 INFO train-abinet] epoch 5 iter 226150: loss = 0.5323,  smooth loss = 0.5388
[2022-07-06 19:23:01,712 callbacks.py:105 INFO train-abinet] epoch 5 iter 226200: loss = 0.5051,  smooth loss = 0.5403
[2022-07-06 19:23:43,102 callbacks.py:105 INFO train-abinet] epoch 5 iter 226250: loss = 0.3498,  smooth loss = 0.5405
[2022-07-06 19:24:24,662 callbacks.py:105 INFO train-abinet] epoch 5 iter 226300: loss = 0.4399,  smooth loss = 0.5293
[2022-07-06 19:25:05,937 callbacks.py:105 INFO train-abinet] epoch 5 iter 226350: loss = 0.5440,  smooth loss = 0.5506
[2022-07-06 19:25:47,859 callbacks.py:105 INFO train-abinet] epoch 5 iter 226400: loss = 0.5188,  smooth loss = 0.5487
[2022-07-06 19:26:29,680 callbacks.py:105 INFO train-abinet] epoch 5 iter 226450: loss = 0.4972,  smooth loss = 0.5503
[2022-07-06 19:27:11,089 callbacks.py:105 INFO train-abinet] epoch 5 iter 226500: loss = 0.5319,  smooth loss = 0.5565
[2022-07-06 19:27:52,601 callbacks.py:105 INFO train-abinet] epoch 5 iter 226550: loss = 0.5445,  smooth loss = 0.5514
[2022-07-06 19:28:34,065 callbacks.py:105 INFO train-abinet] epoch 5 iter 226600: loss = 0.5001,  smooth loss = 0.5605
[2022-07-06 19:29:14,537 callbacks.py:105 INFO train-abinet] epoch 5 iter 226650: loss = 0.7359,  smooth loss = 0.5414
[2022-07-06 19:29:56,559 callbacks.py:105 INFO train-abinet] epoch 5 iter 226700: loss = 0.5464,  smooth loss = 0.5471
[2022-07-06 19:30:37,905 callbacks.py:105 INFO train-abinet] epoch 5 iter 226750: loss = 0.6019,  smooth loss = 0.5408
[2022-07-06 19:31:18,912 callbacks.py:105 INFO train-abinet] epoch 5 iter 226800: loss = 0.5806,  smooth loss = 0.5464
[2022-07-06 19:31:59,555 callbacks.py:105 INFO train-abinet] epoch 5 iter 226850: loss = 0.5456,  smooth loss = 0.5464
[2022-07-06 19:32:39,864 callbacks.py:105 INFO train-abinet] epoch 5 iter 226900: loss = 0.5085,  smooth loss = 0.5401
[2022-07-06 19:33:20,938 callbacks.py:105 INFO train-abinet] epoch 5 iter 226950: loss = 0.4966,  smooth loss = 0.5415
[2022-07-06 19:34:01,773 callbacks.py:105 INFO train-abinet] epoch 5 iter 227000: loss = 0.6162,  smooth loss = 0.5475
[2022-07-06 19:34:42,587 callbacks.py:105 INFO train-abinet] epoch 5 iter 227050: loss = 0.4767,  smooth loss = 0.5601
[2022-07-06 19:35:23,711 callbacks.py:105 INFO train-abinet] epoch 5 iter 227100: loss = 0.5598,  smooth loss = 0.5471
[2022-07-06 19:36:04,221 callbacks.py:105 INFO train-abinet] epoch 5 iter 227150: loss = 0.6070,  smooth loss = 0.5478
[2022-07-06 19:36:45,724 callbacks.py:105 INFO train-abinet] epoch 5 iter 227200: loss = 0.4017,  smooth loss = 0.5342
[2022-07-06 19:37:26,993 callbacks.py:105 INFO train-abinet] epoch 5 iter 227250: loss = 0.5263,  smooth loss = 0.5273
[2022-07-06 19:38:08,320 callbacks.py:105 INFO train-abinet] epoch 5 iter 227300: loss = 0.5643,  smooth loss = 0.5387
[2022-07-06 19:38:49,178 callbacks.py:105 INFO train-abinet] epoch 5 iter 227350: loss = 0.5126,  smooth loss = 0.5359
[2022-07-06 19:39:29,752 callbacks.py:105 INFO train-abinet] epoch 5 iter 227400: loss = 0.5267,  smooth loss = 0.5329
[2022-07-06 19:40:10,793 callbacks.py:105 INFO train-abinet] epoch 5 iter 227450: loss = 0.6066,  smooth loss = 0.5406
[2022-07-06 19:40:51,908 callbacks.py:105 INFO train-abinet] epoch 5 iter 227500: loss = 0.5275,  smooth loss = 0.5416
[2022-07-06 19:41:33,168 callbacks.py:105 INFO train-abinet] epoch 5 iter 227550: loss = 0.3566,  smooth loss = 0.5284
[2022-07-06 19:42:13,713 callbacks.py:105 INFO train-abinet] epoch 5 iter 227600: loss = 0.5635,  smooth loss = 0.5353
[2022-07-06 19:42:53,610 callbacks.py:105 INFO train-abinet] epoch 5 iter 227650: loss = 0.4762,  smooth loss = 0.5395
[2022-07-06 19:43:35,414 callbacks.py:105 INFO train-abinet] epoch 5 iter 227700: loss = 0.4875,  smooth loss = 0.5274
[2022-07-06 19:44:16,689 callbacks.py:105 INFO train-abinet] epoch 5 iter 227750: loss = 0.6650,  smooth loss = 0.5436
[2022-07-06 19:44:57,246 callbacks.py:105 INFO train-abinet] epoch 5 iter 227800: loss = 0.4790,  smooth loss = 0.5386
[2022-07-06 19:45:37,993 callbacks.py:105 INFO train-abinet] epoch 5 iter 227850: loss = 0.4631,  smooth loss = 0.5372
[2022-07-06 19:46:19,349 callbacks.py:105 INFO train-abinet] epoch 5 iter 227900: loss = 0.5482,  smooth loss = 0.5455
[2022-07-06 19:47:00,295 callbacks.py:105 INFO train-abinet] epoch 5 iter 227950: loss = 0.5315,  smooth loss = 0.5349
[2022-07-06 19:47:41,292 callbacks.py:105 INFO train-abinet] epoch 5 iter 228000: loss = 0.5078,  smooth loss = 0.5298
[2022-07-06 19:47:41,293 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8728s
█[2022-07-06 19:47:55,990 callbacks.py:123 INFO train-abinet] epoch 5 iter 228000: eval loss = 1.1854,  ccr = 0.9577,  cwr = 0.9124,  ted = 1374.0000,  ned = 273.1054,  ted/w = 0.1896, 
[2022-07-06 19:47:55,992 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_228000
[2022-07-06 19:48:38,037 callbacks.py:105 INFO train-abinet] epoch 5 iter 228050: loss = 0.5752,  smooth loss = 0.5283
[2022-07-06 19:49:20,124 callbacks.py:105 INFO train-abinet] epoch 5 iter 228100: loss = 0.4715,  smooth loss = 0.5374
[2022-07-06 19:50:00,281 callbacks.py:105 INFO train-abinet] epoch 5 iter 228150: loss = 0.5239,  smooth loss = 0.5409
[2022-07-06 19:50:42,327 callbacks.py:105 INFO train-abinet] epoch 5 iter 228200: loss = 0.5587,  smooth loss = 0.5445
[2022-07-06 19:51:22,850 callbacks.py:105 INFO train-abinet] epoch 5 iter 228250: loss = 0.5494,  smooth loss = 0.5482
[2022-07-06 19:52:04,119 callbacks.py:105 INFO train-abinet] epoch 5 iter 228300: loss = 0.6453,  smooth loss = 0.5511
[2022-07-06 19:52:45,316 callbacks.py:105 INFO train-abinet] epoch 5 iter 228350: loss = 0.5132,  smooth loss = 0.5413
[2022-07-06 19:53:26,471 callbacks.py:105 INFO train-abinet] epoch 5 iter 228400: loss = 0.4405,  smooth loss = 0.5335
[2022-07-06 19:54:07,197 callbacks.py:105 INFO train-abinet] epoch 5 iter 228450: loss = 0.5178,  smooth loss = 0.5342
[2022-07-06 19:54:47,320 callbacks.py:105 INFO train-abinet] epoch 5 iter 228500: loss = 0.5273,  smooth loss = 0.5437
[2022-07-06 19:55:28,969 callbacks.py:105 INFO train-abinet] epoch 5 iter 228550: loss = 0.6300,  smooth loss = 0.5603
[2022-07-06 19:56:09,704 callbacks.py:105 INFO train-abinet] epoch 5 iter 228600: loss = 0.6814,  smooth loss = 0.5497
[2022-07-06 19:56:50,430 callbacks.py:105 INFO train-abinet] epoch 5 iter 228650: loss = 0.7432,  smooth loss = 0.5504
[2022-07-06 19:57:30,946 callbacks.py:105 INFO train-abinet] epoch 5 iter 228700: loss = 0.6302,  smooth loss = 0.5466
[2022-07-06 19:58:12,060 callbacks.py:105 INFO train-abinet] epoch 5 iter 228750: loss = 0.4021,  smooth loss = 0.5415
[2022-07-06 19:58:52,878 callbacks.py:105 INFO train-abinet] epoch 5 iter 228800: loss = 0.4115,  smooth loss = 0.5487
[2022-07-06 19:59:33,350 callbacks.py:105 INFO train-abinet] epoch 5 iter 228850: loss = 0.5716,  smooth loss = 0.5503
[2022-07-06 20:00:14,064 callbacks.py:105 INFO train-abinet] epoch 5 iter 228900: loss = 0.5551,  smooth loss = 0.5430
[2022-07-06 20:00:54,881 callbacks.py:105 INFO train-abinet] epoch 5 iter 228950: loss = 0.6125,  smooth loss = 0.5396
[2022-07-06 20:01:36,158 callbacks.py:105 INFO train-abinet] epoch 5 iter 229000: loss = 0.6055,  smooth loss = 0.5332
[2022-07-06 20:02:16,733 callbacks.py:105 INFO train-abinet] epoch 5 iter 229050: loss = 0.4615,  smooth loss = 0.5351
[2022-07-06 20:02:58,071 callbacks.py:105 INFO train-abinet] epoch 5 iter 229100: loss = 0.4379,  smooth loss = 0.5319
[2022-07-06 20:03:39,130 callbacks.py:105 INFO train-abinet] epoch 5 iter 229150: loss = 0.5923,  smooth loss = 0.5307
[2022-07-06 20:04:20,373 callbacks.py:105 INFO train-abinet] epoch 5 iter 229200: loss = 0.5062,  smooth loss = 0.5444
[2022-07-06 20:05:01,530 callbacks.py:105 INFO train-abinet] epoch 5 iter 229250: loss = 0.5602,  smooth loss = 0.5500
[2022-07-06 20:05:43,072 callbacks.py:105 INFO train-abinet] epoch 5 iter 229300: loss = 0.4796,  smooth loss = 0.5508
[2022-07-06 20:06:23,349 callbacks.py:105 INFO train-abinet] epoch 5 iter 229350: loss = 0.4682,  smooth loss = 0.5358
[2022-07-06 20:07:04,628 callbacks.py:105 INFO train-abinet] epoch 5 iter 229400: loss = 0.5342,  smooth loss = 0.5267
[2022-07-06 20:07:44,956 callbacks.py:105 INFO train-abinet] epoch 5 iter 229450: loss = 0.5984,  smooth loss = 0.5517
[2022-07-06 20:08:26,365 callbacks.py:105 INFO train-abinet] epoch 5 iter 229500: loss = 0.5102,  smooth loss = 0.5557
[2022-07-06 20:09:07,336 callbacks.py:105 INFO train-abinet] epoch 5 iter 229550: loss = 0.4737,  smooth loss = 0.5496
[2022-07-06 20:09:47,944 callbacks.py:105 INFO train-abinet] epoch 5 iter 229600: loss = 0.4486,  smooth loss = 0.5451
[2022-07-06 20:10:29,458 callbacks.py:105 INFO train-abinet] epoch 5 iter 229650: loss = 0.4731,  smooth loss = 0.5458
[2022-07-06 20:11:10,263 callbacks.py:105 INFO train-abinet] epoch 5 iter 229700: loss = 0.4309,  smooth loss = 0.5409
[2022-07-06 20:11:50,602 callbacks.py:105 INFO train-abinet] epoch 5 iter 229750: loss = 0.5937,  smooth loss = 0.5388
[2022-07-06 20:12:31,148 callbacks.py:105 INFO train-abinet] epoch 5 iter 229800: loss = 0.4429,  smooth loss = 0.5272
[2022-07-06 20:13:11,607 callbacks.py:105 INFO train-abinet] epoch 5 iter 229850: loss = 0.3393,  smooth loss = 0.5336
[2022-07-06 20:13:52,389 callbacks.py:105 INFO train-abinet] epoch 5 iter 229900: loss = 0.4910,  smooth loss = 0.5539
[2022-07-06 20:14:32,932 callbacks.py:105 INFO train-abinet] epoch 5 iter 229950: loss = 0.4966,  smooth loss = 0.5385
[2022-07-06 20:15:14,123 callbacks.py:105 INFO train-abinet] epoch 5 iter 230000: loss = 0.5100,  smooth loss = 0.5451
[2022-07-06 20:15:54,768 callbacks.py:105 INFO train-abinet] epoch 5 iter 230050: loss = 0.4877,  smooth loss = 0.5494
[2022-07-06 20:16:36,111 callbacks.py:105 INFO train-abinet] epoch 5 iter 230100: loss = 0.7720,  smooth loss = 0.5500
[2022-07-06 20:17:16,794 callbacks.py:105 INFO train-abinet] epoch 5 iter 230150: loss = 0.5006,  smooth loss = 0.5306
[2022-07-06 20:17:57,554 callbacks.py:105 INFO train-abinet] epoch 5 iter 230200: loss = 0.5489,  smooth loss = 0.5581
[2022-07-06 20:18:38,817 callbacks.py:105 INFO train-abinet] epoch 5 iter 230250: loss = 0.5208,  smooth loss = 0.5410
[2022-07-06 20:19:20,089 callbacks.py:105 INFO train-abinet] epoch 5 iter 230300: loss = 0.6226,  smooth loss = 0.5572
[2022-07-06 20:20:00,897 callbacks.py:105 INFO train-abinet] epoch 5 iter 230350: loss = 0.4855,  smooth loss = 0.5475
[2022-07-06 20:20:42,001 callbacks.py:105 INFO train-abinet] epoch 5 iter 230400: loss = 0.4385,  smooth loss = 0.5358
[2022-07-06 20:21:23,451 callbacks.py:105 INFO train-abinet] epoch 5 iter 230450: loss = 0.5592,  smooth loss = 0.5485
[2022-07-06 20:22:04,969 callbacks.py:105 INFO train-abinet] epoch 5 iter 230500: loss = 0.4185,  smooth loss = 0.5414
[2022-07-06 20:22:45,365 callbacks.py:105 INFO train-abinet] epoch 5 iter 230550: loss = 0.5851,  smooth loss = 0.5551
[2022-07-06 20:23:27,264 callbacks.py:105 INFO train-abinet] epoch 5 iter 230600: loss = 0.5162,  smooth loss = 0.5464
[2022-07-06 20:24:07,576 callbacks.py:105 INFO train-abinet] epoch 5 iter 230650: loss = 0.6254,  smooth loss = 0.5474
[2022-07-06 20:24:48,889 callbacks.py:105 INFO train-abinet] epoch 5 iter 230700: loss = 0.5321,  smooth loss = 0.5498
[2022-07-06 20:25:29,712 callbacks.py:105 INFO train-abinet] epoch 5 iter 230750: loss = 0.6635,  smooth loss = 0.5431
[2022-07-06 20:26:10,915 callbacks.py:105 INFO train-abinet] epoch 5 iter 230800: loss = 0.5320,  smooth loss = 0.5471
[2022-07-06 20:26:51,840 callbacks.py:105 INFO train-abinet] epoch 5 iter 230850: loss = 0.4735,  smooth loss = 0.5461
[2022-07-06 20:27:32,586 callbacks.py:105 INFO train-abinet] epoch 5 iter 230900: loss = 0.6494,  smooth loss = 0.5653
[2022-07-06 20:28:12,988 callbacks.py:105 INFO train-abinet] epoch 5 iter 230950: loss = 0.4847,  smooth loss = 0.5482
[2022-07-06 20:28:53,540 callbacks.py:105 INFO train-abinet] epoch 5 iter 231000: loss = 0.4937,  smooth loss = 0.5411
[2022-07-06 20:28:53,540 callbacks.py:114 INFO train-abinet] average data time = 0.0053s, average running time = 0.8721s
█[2022-07-06 20:29:07,691 callbacks.py:123 INFO train-abinet] epoch 5 iter 231000: eval loss = 1.1772,  ccr = 0.9594,  cwr = 0.9193,  ted = 1341.0000,  ned = 261.6772,  ted/w = 0.1850, 
[2022-07-06 20:29:07,693 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_231000
[2022-07-06 20:29:49,327 callbacks.py:105 INFO train-abinet] epoch 5 iter 231050: loss = 0.4687,  smooth loss = 0.5428
[2022-07-06 20:30:30,088 callbacks.py:105 INFO train-abinet] epoch 5 iter 231100: loss = 0.4994,  smooth loss = 0.5314
[2022-07-06 20:31:10,818 callbacks.py:105 INFO train-abinet] epoch 5 iter 231150: loss = 0.5327,  smooth loss = 0.5398
[2022-07-06 20:31:51,094 callbacks.py:105 INFO train-abinet] epoch 5 iter 231200: loss = 0.6857,  smooth loss = 0.5320
[2022-07-06 20:32:31,868 callbacks.py:105 INFO train-abinet] epoch 5 iter 231250: loss = 0.4902,  smooth loss = 0.5381
[2022-07-06 20:33:12,570 callbacks.py:105 INFO train-abinet] epoch 5 iter 231300: loss = 0.4737,  smooth loss = 0.5441
[2022-07-06 20:33:53,338 callbacks.py:105 INFO train-abinet] epoch 5 iter 231350: loss = 0.4051,  smooth loss = 0.5412
[2022-07-06 20:34:33,856 callbacks.py:105 INFO train-abinet] epoch 5 iter 231400: loss = 0.5868,  smooth loss = 0.5366
[2022-07-06 20:35:14,448 callbacks.py:105 INFO train-abinet] epoch 5 iter 231450: loss = 0.4235,  smooth loss = 0.5348
[2022-07-06 20:35:55,143 callbacks.py:105 INFO train-abinet] epoch 5 iter 231500: loss = 0.6908,  smooth loss = 0.5491
[2022-07-06 20:36:35,757 callbacks.py:105 INFO train-abinet] epoch 5 iter 231550: loss = 0.5519,  smooth loss = 0.5340
[2022-07-06 20:37:17,248 callbacks.py:105 INFO train-abinet] epoch 5 iter 231600: loss = 0.4864,  smooth loss = 0.5296
[2022-07-06 20:37:57,834 callbacks.py:105 INFO train-abinet] epoch 5 iter 231650: loss = 0.5382,  smooth loss = 0.5420
[2022-07-06 20:38:39,125 callbacks.py:105 INFO train-abinet] epoch 5 iter 231700: loss = 0.5597,  smooth loss = 0.5332
[2022-07-06 20:39:19,634 callbacks.py:105 INFO train-abinet] epoch 5 iter 231750: loss = 0.4655,  smooth loss = 0.5435
[2022-07-06 20:39:59,868 callbacks.py:105 INFO train-abinet] epoch 5 iter 231800: loss = 0.5209,  smooth loss = 0.5339
[2022-07-06 20:40:40,750 callbacks.py:105 INFO train-abinet] epoch 5 iter 231850: loss = 0.5357,  smooth loss = 0.5404
[2022-07-06 20:41:21,045 callbacks.py:105 INFO train-abinet] epoch 5 iter 231900: loss = 0.4772,  smooth loss = 0.5383
[2022-07-06 20:42:01,238 callbacks.py:105 INFO train-abinet] epoch 5 iter 231950: loss = 0.4267,  smooth loss = 0.5331
[2022-07-06 20:42:41,855 callbacks.py:105 INFO train-abinet] epoch 5 iter 232000: loss = 0.5945,  smooth loss = 0.5465
[2022-07-06 20:43:23,078 callbacks.py:105 INFO train-abinet] epoch 5 iter 232050: loss = 0.5118,  smooth loss = 0.5395
[2022-07-06 20:44:03,776 callbacks.py:105 INFO train-abinet] epoch 5 iter 232100: loss = 0.3497,  smooth loss = 0.5464
[2022-07-06 20:44:44,867 callbacks.py:105 INFO train-abinet] epoch 5 iter 232150: loss = 0.6307,  smooth loss = 0.5556
[2022-07-06 20:45:25,512 callbacks.py:105 INFO train-abinet] epoch 5 iter 232200: loss = 0.5799,  smooth loss = 0.5434
[2022-07-06 20:46:06,707 callbacks.py:105 INFO train-abinet] epoch 5 iter 232250: loss = 0.5499,  smooth loss = 0.5404
[2022-07-06 20:46:47,816 callbacks.py:105 INFO train-abinet] epoch 5 iter 232300: loss = 0.6018,  smooth loss = 0.5409
[2022-07-06 20:47:28,785 callbacks.py:105 INFO train-abinet] epoch 5 iter 232350: loss = 0.3665,  smooth loss = 0.5419
[2022-07-06 20:48:09,369 callbacks.py:105 INFO train-abinet] epoch 5 iter 232400: loss = 0.5361,  smooth loss = 0.5365
[2022-07-06 20:48:49,831 callbacks.py:105 INFO train-abinet] epoch 5 iter 232450: loss = 0.4800,  smooth loss = 0.5330
[2022-07-06 20:49:29,939 callbacks.py:105 INFO train-abinet] epoch 5 iter 232500: loss = 0.5735,  smooth loss = 0.5371
[2022-07-06 20:50:10,221 callbacks.py:105 INFO train-abinet] epoch 5 iter 232550: loss = 0.5000,  smooth loss = 0.5401
[2022-07-06 20:50:50,273 callbacks.py:105 INFO train-abinet] epoch 5 iter 232600: loss = 0.5097,  smooth loss = 0.5433
[2022-07-06 20:51:30,604 callbacks.py:105 INFO train-abinet] epoch 5 iter 232650: loss = 0.3973,  smooth loss = 0.5326
[2022-07-06 20:52:11,039 callbacks.py:105 INFO train-abinet] epoch 5 iter 232700: loss = 0.5576,  smooth loss = 0.5304
[2022-07-06 20:52:51,575 callbacks.py:105 INFO train-abinet] epoch 5 iter 232750: loss = 0.5990,  smooth loss = 0.5440
[2022-07-06 20:53:31,932 callbacks.py:105 INFO train-abinet] epoch 5 iter 232800: loss = 0.4125,  smooth loss = 0.5424
[2022-07-06 20:54:12,767 callbacks.py:105 INFO train-abinet] epoch 5 iter 232850: loss = 0.3967,  smooth loss = 0.5308
[2022-07-06 20:54:53,495 callbacks.py:105 INFO train-abinet] epoch 5 iter 232900: loss = 0.5240,  smooth loss = 0.5283
[2022-07-06 20:55:33,786 callbacks.py:105 INFO train-abinet] epoch 5 iter 232950: loss = 0.7474,  smooth loss = 0.5535
[2022-07-06 20:56:14,202 callbacks.py:105 INFO train-abinet] epoch 5 iter 233000: loss = 0.5306,  smooth loss = 0.5352
[2022-07-06 20:56:54,870 callbacks.py:105 INFO train-abinet] epoch 5 iter 233050: loss = 0.6216,  smooth loss = 0.5344
[2022-07-06 20:57:35,605 callbacks.py:105 INFO train-abinet] epoch 5 iter 233100: loss = 0.4560,  smooth loss = 0.5560
[2022-07-06 20:58:16,656 callbacks.py:105 INFO train-abinet] epoch 5 iter 233150: loss = 0.7835,  smooth loss = 0.5588
[2022-07-06 20:58:57,017 callbacks.py:105 INFO train-abinet] epoch 5 iter 233200: loss = 0.5314,  smooth loss = 0.5508
[2022-07-06 20:59:37,696 callbacks.py:105 INFO train-abinet] epoch 5 iter 233250: loss = 0.4659,  smooth loss = 0.5374
[2022-07-06 21:00:18,424 callbacks.py:105 INFO train-abinet] epoch 5 iter 233300: loss = 0.5872,  smooth loss = 0.5500
[2022-07-06 21:00:58,812 callbacks.py:105 INFO train-abinet] epoch 5 iter 233350: loss = 0.4910,  smooth loss = 0.5264
[2022-07-06 21:01:40,063 callbacks.py:105 INFO train-abinet] epoch 5 iter 233400: loss = 0.4108,  smooth loss = 0.5301
[2022-07-06 21:02:20,406 callbacks.py:105 INFO train-abinet] epoch 5 iter 233450: loss = 0.5083,  smooth loss = 0.5342
[2022-07-06 21:03:00,442 callbacks.py:105 INFO train-abinet] epoch 5 iter 233500: loss = 0.5066,  smooth loss = 0.5172
[2022-07-06 21:03:41,163 callbacks.py:105 INFO train-abinet] epoch 5 iter 233550: loss = 0.5550,  smooth loss = 0.5288
[2022-07-06 21:04:21,930 callbacks.py:105 INFO train-abinet] epoch 5 iter 233600: loss = 0.4757,  smooth loss = 0.5367
[2022-07-06 21:05:02,558 callbacks.py:105 INFO train-abinet] epoch 5 iter 233650: loss = 0.4492,  smooth loss = 0.5258
[2022-07-06 21:05:43,327 callbacks.py:105 INFO train-abinet] epoch 5 iter 233700: loss = 0.4029,  smooth loss = 0.5376
[2022-07-06 21:06:23,362 callbacks.py:105 INFO train-abinet] epoch 5 iter 233750: loss = 0.4873,  smooth loss = 0.5237
[2022-07-06 21:07:03,657 callbacks.py:105 INFO train-abinet] epoch 5 iter 233800: loss = 0.5254,  smooth loss = 0.5444
[2022-07-06 21:07:43,998 callbacks.py:105 INFO train-abinet] epoch 5 iter 233850: loss = 0.5015,  smooth loss = 0.5317
[2022-07-06 21:08:25,039 callbacks.py:105 INFO train-abinet] epoch 5 iter 233900: loss = 0.4058,  smooth loss = 0.5381
[2022-07-06 21:09:05,480 callbacks.py:105 INFO train-abinet] epoch 5 iter 233950: loss = 0.6234,  smooth loss = 0.5259
[2022-07-06 21:09:45,912 callbacks.py:105 INFO train-abinet] epoch 5 iter 234000: loss = 0.4749,  smooth loss = 0.5187
[2022-07-06 21:09:45,913 callbacks.py:114 INFO train-abinet] average data time = 0.0052s, average running time = 0.8714s
█[2022-07-06 21:10:00,125 callbacks.py:123 INFO train-abinet] epoch 5 iter 234000: eval loss = 1.1954,  ccr = 0.9593,  cwr = 0.9185,  ted = 1351.0000,  ned = 269.6629,  ted/w = 0.1864, 
[2022-07-06 21:10:00,126 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_234000
[2022-07-06 21:10:42,048 callbacks.py:105 INFO train-abinet] epoch 5 iter 234050: loss = 0.4611,  smooth loss = 0.5185
[2022-07-06 21:11:22,416 callbacks.py:105 INFO train-abinet] epoch 5 iter 234100: loss = 0.5533,  smooth loss = 0.5404
[2022-07-06 21:12:03,924 callbacks.py:105 INFO train-abinet] epoch 5 iter 234150: loss = 0.4663,  smooth loss = 0.5433
[2022-07-06 21:12:44,365 callbacks.py:105 INFO train-abinet] epoch 5 iter 234200: loss = 0.7603,  smooth loss = 0.5366
[2022-07-06 21:13:24,979 callbacks.py:105 INFO train-abinet] epoch 5 iter 234250: loss = 0.6382,  smooth loss = 0.5440
[2022-07-06 21:14:05,958 callbacks.py:105 INFO train-abinet] epoch 5 iter 234300: loss = 0.5355,  smooth loss = 0.5392
[2022-07-06 21:14:46,911 callbacks.py:105 INFO train-abinet] epoch 5 iter 234350: loss = 0.5025,  smooth loss = 0.5420
[2022-07-06 21:15:27,586 callbacks.py:105 INFO train-abinet] epoch 5 iter 234400: loss = 0.5506,  smooth loss = 0.5392
[2022-07-06 21:16:08,035 callbacks.py:105 INFO train-abinet] epoch 5 iter 234450: loss = 0.5664,  smooth loss = 0.5523
[2022-07-06 21:16:49,014 callbacks.py:105 INFO train-abinet] epoch 5 iter 234500: loss = 0.4995,  smooth loss = 0.5479
[2022-07-06 21:17:29,724 callbacks.py:105 INFO train-abinet] epoch 5 iter 234550: loss = 0.6181,  smooth loss = 0.5404
[2022-07-06 21:18:10,532 callbacks.py:105 INFO train-abinet] epoch 5 iter 234600: loss = 0.5126,  smooth loss = 0.5391
[2022-07-06 21:18:51,630 callbacks.py:105 INFO train-abinet] epoch 5 iter 234650: loss = 0.6975,  smooth loss = 0.5459
[2022-07-06 21:19:33,091 callbacks.py:105 INFO train-abinet] epoch 5 iter 234700: loss = 0.4662,  smooth loss = 0.5391
[2022-07-06 21:20:13,316 callbacks.py:105 INFO train-abinet] epoch 5 iter 234750: loss = 0.4718,  smooth loss = 0.5364
[2022-07-06 21:20:54,883 callbacks.py:105 INFO train-abinet] epoch 5 iter 234800: loss = 0.4818,  smooth loss = 0.5464
[2022-07-06 21:21:35,930 callbacks.py:105 INFO train-abinet] epoch 5 iter 234850: loss = 0.3429,  smooth loss = 0.5446
[2022-07-06 21:22:16,537 callbacks.py:105 INFO train-abinet] epoch 5 iter 234900: loss = 0.5677,  smooth loss = 0.5456
[2022-07-06 21:22:57,281 callbacks.py:105 INFO train-abinet] epoch 5 iter 234950: loss = 0.5802,  smooth loss = 0.5417
[2022-07-06 21:23:37,108 callbacks.py:105 INFO train-abinet] epoch 5 iter 235000: loss = 0.4922,  smooth loss = 0.5405
[2022-07-06 21:24:17,314 callbacks.py:105 INFO train-abinet] epoch 5 iter 235050: loss = 0.4971,  smooth loss = 0.5448
[2022-07-06 21:24:57,696 callbacks.py:105 INFO train-abinet] epoch 5 iter 235100: loss = 0.4122,  smooth loss = 0.5275
[2022-07-06 21:25:38,430 callbacks.py:105 INFO train-abinet] epoch 5 iter 235150: loss = 0.5101,  smooth loss = 0.5290
[2022-07-06 21:26:18,482 callbacks.py:105 INFO train-abinet] epoch 5 iter 235200: loss = 0.4645,  smooth loss = 0.5250
[2022-07-06 21:26:59,763 callbacks.py:105 INFO train-abinet] epoch 5 iter 235250: loss = 0.6056,  smooth loss = 0.5350
[2022-07-06 21:27:40,338 callbacks.py:105 INFO train-abinet] epoch 5 iter 235300: loss = 0.4875,  smooth loss = 0.5533
[2022-07-06 21:28:20,714 callbacks.py:105 INFO train-abinet] epoch 5 iter 235350: loss = 0.4620,  smooth loss = 0.5360
[2022-07-06 21:29:01,860 callbacks.py:105 INFO train-abinet] epoch 5 iter 235400: loss = 0.5045,  smooth loss = 0.5417
[2022-07-06 21:29:42,024 callbacks.py:105 INFO train-abinet] epoch 5 iter 235450: loss = 0.5143,  smooth loss = 0.5253
[2022-07-06 21:30:22,998 callbacks.py:105 INFO train-abinet] epoch 5 iter 235500: loss = 0.6292,  smooth loss = 0.5378
[2022-07-06 21:31:03,592 callbacks.py:105 INFO train-abinet] epoch 5 iter 235550: loss = 0.5097,  smooth loss = 0.5266
[2022-07-06 21:31:44,216 callbacks.py:105 INFO train-abinet] epoch 5 iter 235600: loss = 0.5368,  smooth loss = 0.5260
[2022-07-06 21:32:25,067 callbacks.py:105 INFO train-abinet] epoch 5 iter 235650: loss = 0.4275,  smooth loss = 0.5317
[2022-07-06 21:33:05,527 callbacks.py:105 INFO train-abinet] epoch 5 iter 235700: loss = 0.4454,  smooth loss = 0.5346
[2022-07-06 21:33:46,103 callbacks.py:105 INFO train-abinet] epoch 5 iter 235750: loss = 0.5390,  smooth loss = 0.5442
[2022-07-06 21:34:26,446 callbacks.py:105 INFO train-abinet] epoch 5 iter 235800: loss = 0.5161,  smooth loss = 0.5399
[2022-07-06 21:35:06,884 callbacks.py:105 INFO train-abinet] epoch 5 iter 235850: loss = 0.5986,  smooth loss = 0.5429
[2022-07-06 21:35:47,448 callbacks.py:105 INFO train-abinet] epoch 5 iter 235900: loss = 0.5803,  smooth loss = 0.5341
[2022-07-06 21:36:27,861 callbacks.py:105 INFO train-abinet] epoch 5 iter 235950: loss = 0.5226,  smooth loss = 0.5404
[2022-07-06 21:37:08,389 callbacks.py:105 INFO train-abinet] epoch 5 iter 236000: loss = 0.5576,  smooth loss = 0.5323
[2022-07-06 21:37:48,730 callbacks.py:105 INFO train-abinet] epoch 5 iter 236050: loss = 0.4872,  smooth loss = 0.5276
[2022-07-06 21:38:29,267 callbacks.py:105 INFO train-abinet] epoch 5 iter 236100: loss = 0.5677,  smooth loss = 0.5352
[2022-07-06 21:39:10,065 callbacks.py:105 INFO train-abinet] epoch 5 iter 236150: loss = 0.4967,  smooth loss = 0.5300
[2022-07-06 21:39:50,518 callbacks.py:105 INFO train-abinet] epoch 5 iter 236200: loss = 0.5585,  smooth loss = 0.5370
[2022-07-06 21:40:31,886 callbacks.py:105 INFO train-abinet] epoch 5 iter 236250: loss = 0.5780,  smooth loss = 0.5468
[2022-07-06 21:41:12,189 callbacks.py:105 INFO train-abinet] epoch 5 iter 236300: loss = 0.6881,  smooth loss = 0.5494
[2022-07-06 21:41:52,703 callbacks.py:105 INFO train-abinet] epoch 5 iter 236350: loss = 0.4933,  smooth loss = 0.5455
[2022-07-06 21:42:32,816 callbacks.py:105 INFO train-abinet] epoch 5 iter 236400: loss = 0.7146,  smooth loss = 0.5414
[2022-07-06 21:43:13,844 callbacks.py:105 INFO train-abinet] epoch 5 iter 236450: loss = 0.5036,  smooth loss = 0.5383
[2022-07-06 21:43:54,730 callbacks.py:105 INFO train-abinet] epoch 5 iter 236500: loss = 0.5447,  smooth loss = 0.5309
[2022-07-06 21:44:34,890 callbacks.py:105 INFO train-abinet] epoch 5 iter 236550: loss = 0.6353,  smooth loss = 0.5348
[2022-07-06 21:45:16,448 callbacks.py:105 INFO train-abinet] epoch 5 iter 236600: loss = 0.4829,  smooth loss = 0.5384
[2022-07-06 21:45:56,850 callbacks.py:105 INFO train-abinet] epoch 5 iter 236650: loss = 0.5362,  smooth loss = 0.5467
[2022-07-06 21:46:37,572 callbacks.py:105 INFO train-abinet] epoch 5 iter 236700: loss = 0.5394,  smooth loss = 0.5476
[2022-07-06 21:47:18,070 callbacks.py:105 INFO train-abinet] epoch 5 iter 236750: loss = 0.4898,  smooth loss = 0.5376
[2022-07-06 21:47:58,985 callbacks.py:105 INFO train-abinet] epoch 5 iter 236800: loss = 0.5911,  smooth loss = 0.5403
[2022-07-06 21:48:39,657 callbacks.py:105 INFO train-abinet] epoch 5 iter 236850: loss = 0.4954,  smooth loss = 0.5344
[2022-07-06 21:49:20,243 callbacks.py:105 INFO train-abinet] epoch 5 iter 236900: loss = 0.5444,  smooth loss = 0.5354
[2022-07-06 21:50:00,997 callbacks.py:105 INFO train-abinet] epoch 5 iter 236950: loss = 0.5345,  smooth loss = 0.5423
[2022-07-06 21:50:41,890 callbacks.py:105 INFO train-abinet] epoch 5 iter 237000: loss = 0.4405,  smooth loss = 0.5349
[2022-07-06 21:50:41,890 callbacks.py:114 INFO train-abinet] average data time = 0.0052s, average running time = 0.8707s
█[2022-07-06 21:50:56,064 callbacks.py:123 INFO train-abinet] epoch 5 iter 237000: eval loss = 1.1552,  ccr = 0.9615,  cwr = 0.9201,  ted = 1299.0000,  ned = 258.5264,  ted/w = 0.1792, 
[2022-07-06 21:50:56,065 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_237000
[2022-07-06 21:51:37,598 callbacks.py:105 INFO train-abinet] epoch 5 iter 237050: loss = 0.4239,  smooth loss = 0.5287
[2022-07-06 21:52:18,716 callbacks.py:105 INFO train-abinet] epoch 5 iter 237100: loss = 0.4599,  smooth loss = 0.5420
[2022-07-06 21:52:59,405 callbacks.py:105 INFO train-abinet] epoch 5 iter 237150: loss = 0.5315,  smooth loss = 0.5405
[2022-07-06 21:53:39,671 callbacks.py:105 INFO train-abinet] epoch 5 iter 237200: loss = 0.4999,  smooth loss = 0.5441
[2022-07-06 21:54:20,279 callbacks.py:105 INFO train-abinet] epoch 5 iter 237250: loss = 0.4063,  smooth loss = 0.5348
[2022-07-06 21:55:00,310 callbacks.py:105 INFO train-abinet] epoch 5 iter 237300: loss = 0.6483,  smooth loss = 0.5473
[2022-07-06 21:55:41,062 callbacks.py:105 INFO train-abinet] epoch 5 iter 237350: loss = 0.6252,  smooth loss = 0.5480
[2022-07-06 21:56:22,385 callbacks.py:105 INFO train-abinet] epoch 5 iter 237400: loss = 0.5276,  smooth loss = 0.5284
[2022-07-06 21:57:02,930 callbacks.py:105 INFO train-abinet] epoch 5 iter 237450: loss = 0.5965,  smooth loss = 0.5245
[2022-07-06 21:57:43,516 callbacks.py:105 INFO train-abinet] epoch 5 iter 237500: loss = 0.5671,  smooth loss = 0.5381
[2022-07-06 21:58:24,309 callbacks.py:105 INFO train-abinet] epoch 5 iter 237550: loss = 0.4503,  smooth loss = 0.5336
[2022-07-06 21:59:05,035 callbacks.py:105 INFO train-abinet] epoch 5 iter 237600: loss = 0.5053,  smooth loss = 0.5298
[2022-07-06 21:59:45,823 callbacks.py:105 INFO train-abinet] epoch 5 iter 237650: loss = 0.5430,  smooth loss = 0.5318
[2022-07-06 22:00:26,352 callbacks.py:105 INFO train-abinet] epoch 5 iter 237700: loss = 0.5819,  smooth loss = 0.5261
[2022-07-06 22:01:06,640 callbacks.py:105 INFO train-abinet] epoch 5 iter 237750: loss = 0.4944,  smooth loss = 0.5318
[2022-07-06 22:01:47,650 callbacks.py:105 INFO train-abinet] epoch 5 iter 237800: loss = 0.5720,  smooth loss = 0.5312
[2022-07-06 22:02:29,025 callbacks.py:105 INFO train-abinet] epoch 5 iter 237850: loss = 0.3671,  smooth loss = 0.5290
[2022-07-06 22:03:09,435 callbacks.py:105 INFO train-abinet] epoch 5 iter 237900: loss = 0.6001,  smooth loss = 0.5335
[2022-07-06 22:03:49,860 callbacks.py:105 INFO train-abinet] epoch 5 iter 237950: loss = 0.6916,  smooth loss = 0.5394
[2022-07-06 22:04:31,094 callbacks.py:105 INFO train-abinet] epoch 5 iter 238000: loss = 0.5388,  smooth loss = 0.5267
[2022-07-06 22:05:10,668 callbacks.py:105 INFO train-abinet] epoch 5 iter 238050: loss = 0.4656,  smooth loss = 0.5288
[2022-07-06 22:05:51,115 callbacks.py:105 INFO train-abinet] epoch 5 iter 238100: loss = 0.4922,  smooth loss = 0.5371
[2022-07-06 22:06:31,127 callbacks.py:105 INFO train-abinet] epoch 5 iter 238150: loss = 0.3687,  smooth loss = 0.5276
[2022-07-06 22:07:11,869 callbacks.py:105 INFO train-abinet] epoch 5 iter 238200: loss = 0.4587,  smooth loss = 0.5326
[2022-07-06 22:07:52,637 callbacks.py:105 INFO train-abinet] epoch 5 iter 238250: loss = 0.6543,  smooth loss = 0.5409
[2022-07-06 22:08:33,052 callbacks.py:105 INFO train-abinet] epoch 5 iter 238300: loss = 0.5869,  smooth loss = 0.5547
[2022-07-06 22:09:14,218 callbacks.py:105 INFO train-abinet] epoch 5 iter 238350: loss = 0.5744,  smooth loss = 0.5484
[2022-07-06 22:09:54,210 callbacks.py:105 INFO train-abinet] epoch 5 iter 238400: loss = 0.3737,  smooth loss = 0.5496
[2022-07-06 22:10:35,204 callbacks.py:105 INFO train-abinet] epoch 5 iter 238450: loss = 0.4396,  smooth loss = 0.5332
[2022-07-06 22:11:15,999 callbacks.py:105 INFO train-abinet] epoch 5 iter 238500: loss = 0.4326,  smooth loss = 0.5243
[2022-07-06 22:11:56,252 callbacks.py:105 INFO train-abinet] epoch 5 iter 238550: loss = 0.5506,  smooth loss = 0.5256
[2022-07-06 22:12:37,174 callbacks.py:105 INFO train-abinet] epoch 5 iter 238600: loss = 0.5743,  smooth loss = 0.5329
[2022-07-06 22:13:18,411 callbacks.py:105 INFO train-abinet] epoch 5 iter 238650: loss = 0.4699,  smooth loss = 0.5328
[2022-07-06 22:13:58,947 callbacks.py:105 INFO train-abinet] epoch 5 iter 238700: loss = 0.5088,  smooth loss = 0.5412
[2022-07-06 22:14:39,819 callbacks.py:105 INFO train-abinet] epoch 5 iter 238750: loss = 0.6237,  smooth loss = 0.5447
[2022-07-06 22:15:20,062 callbacks.py:105 INFO train-abinet] epoch 5 iter 238800: loss = 0.7063,  smooth loss = 0.5531
[2022-07-06 22:16:01,126 callbacks.py:105 INFO train-abinet] epoch 5 iter 238850: loss = 0.4950,  smooth loss = 0.5439
[2022-07-06 22:16:41,730 callbacks.py:105 INFO train-abinet] epoch 5 iter 238900: loss = 0.5859,  smooth loss = 0.5439
[2022-07-06 22:17:21,749 callbacks.py:105 INFO train-abinet] epoch 5 iter 238950: loss = 0.4956,  smooth loss = 0.5170
[2022-07-06 22:18:02,335 callbacks.py:105 INFO train-abinet] epoch 5 iter 239000: loss = 0.5494,  smooth loss = 0.5258
[2022-07-06 22:18:43,170 callbacks.py:105 INFO train-abinet] epoch 5 iter 239050: loss = 0.5260,  smooth loss = 0.5331
[2022-07-06 22:19:23,757 callbacks.py:105 INFO train-abinet] epoch 5 iter 239100: loss = 0.5909,  smooth loss = 0.5369
[2022-07-06 22:20:04,275 callbacks.py:105 INFO train-abinet] epoch 5 iter 239150: loss = 0.4845,  smooth loss = 0.5407
[2022-07-06 22:20:45,788 callbacks.py:105 INFO train-abinet] epoch 5 iter 239200: loss = 0.6511,  smooth loss = 0.5427
[2022-07-06 22:21:28,060 callbacks.py:105 INFO train-abinet] epoch 5 iter 239250: loss = 0.4993,  smooth loss = 0.5290
[2022-07-06 22:22:09,673 callbacks.py:105 INFO train-abinet] epoch 5 iter 239300: loss = 0.5110,  smooth loss = 0.5204
[2022-07-06 22:22:51,029 callbacks.py:105 INFO train-abinet] epoch 5 iter 239350: loss = 0.5021,  smooth loss = 0.5333
[2022-07-06 22:23:33,067 callbacks.py:105 INFO train-abinet] epoch 5 iter 239400: loss = 0.5629,  smooth loss = 0.5302
[2022-07-06 22:24:15,083 callbacks.py:105 INFO train-abinet] epoch 5 iter 239450: loss = 0.4971,  smooth loss = 0.5417
[2022-07-06 22:24:56,693 callbacks.py:105 INFO train-abinet] epoch 5 iter 239500: loss = 0.5229,  smooth loss = 0.5270
[2022-07-06 22:25:38,086 callbacks.py:105 INFO train-abinet] epoch 5 iter 239550: loss = 0.5171,  smooth loss = 0.5376
[2022-07-06 22:26:20,553 callbacks.py:105 INFO train-abinet] epoch 5 iter 239600: loss = 0.4846,  smooth loss = 0.5343
[2022-07-06 22:27:02,334 callbacks.py:105 INFO train-abinet] epoch 5 iter 239650: loss = 0.4538,  smooth loss = 0.5309
[2022-07-06 22:27:44,803 callbacks.py:105 INFO train-abinet] epoch 5 iter 239700: loss = 0.4432,  smooth loss = 0.5239
[2022-07-06 22:28:26,901 callbacks.py:105 INFO train-abinet] epoch 5 iter 239750: loss = 0.5217,  smooth loss = 0.5413
[2022-07-06 22:29:07,773 callbacks.py:105 INFO train-abinet] epoch 5 iter 239800: loss = 0.5057,  smooth loss = 0.5399
[2022-07-06 22:29:49,367 callbacks.py:105 INFO train-abinet] epoch 5 iter 239850: loss = 0.6259,  smooth loss = 0.5329
[2022-07-06 22:30:30,891 callbacks.py:105 INFO train-abinet] epoch 5 iter 239900: loss = 0.4753,  smooth loss = 0.5313
[2022-07-06 22:31:11,892 callbacks.py:105 INFO train-abinet] epoch 5 iter 239950: loss = 0.4117,  smooth loss = 0.5332
[2022-07-06 22:31:52,931 callbacks.py:105 INFO train-abinet] epoch 5 iter 240000: loss = 0.4648,  smooth loss = 0.5433
[2022-07-06 22:31:52,931 callbacks.py:114 INFO train-abinet] average data time = 0.0052s, average running time = 0.8700s
█[2022-07-06 22:32:07,106 callbacks.py:123 INFO train-abinet] epoch 5 iter 240000: eval loss = 1.1722,  ccr = 0.9607,  cwr = 0.9174,  ted = 1320.0000,  ned = 261.6082,  ted/w = 0.1821, 
[2022-07-06 22:32:07,107 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_240000
[2022-07-06 22:32:50,296 callbacks.py:105 INFO train-abinet] epoch 5 iter 240050: loss = 0.4657,  smooth loss = 0.5493
[2022-07-06 22:33:31,862 callbacks.py:105 INFO train-abinet] epoch 5 iter 240100: loss = 0.6173,  smooth loss = 0.5394
[2022-07-06 22:34:13,294 callbacks.py:105 INFO train-abinet] epoch 5 iter 240150: loss = 0.5340,  smooth loss = 0.5415
[2022-07-06 22:34:55,361 callbacks.py:105 INFO train-abinet] epoch 5 iter 240200: loss = 0.5828,  smooth loss = 0.5382
[2022-07-06 22:35:37,610 callbacks.py:105 INFO train-abinet] epoch 5 iter 240250: loss = 0.5290,  smooth loss = 0.5463
[2022-07-06 22:36:18,880 callbacks.py:105 INFO train-abinet] epoch 5 iter 240300: loss = 0.5337,  smooth loss = 0.5442
[2022-07-06 22:37:00,921 callbacks.py:105 INFO train-abinet] epoch 5 iter 240350: loss = 0.6669,  smooth loss = 0.5368
[2022-07-06 22:37:43,727 callbacks.py:105 INFO train-abinet] epoch 5 iter 240400: loss = 0.6203,  smooth loss = 0.5296
[2022-07-06 22:38:25,315 callbacks.py:105 INFO train-abinet] epoch 5 iter 240450: loss = 0.4146,  smooth loss = 0.5496
[2022-07-06 22:39:06,733 callbacks.py:105 INFO train-abinet] epoch 5 iter 240500: loss = 0.4194,  smooth loss = 0.5280
[2022-07-06 22:39:48,421 callbacks.py:105 INFO train-abinet] epoch 5 iter 240550: loss = 0.6475,  smooth loss = 0.5424
[2022-07-06 22:40:30,017 callbacks.py:105 INFO train-abinet] epoch 5 iter 240600: loss = 0.5022,  smooth loss = 0.5386
[2022-07-06 22:41:11,307 callbacks.py:105 INFO train-abinet] epoch 5 iter 240650: loss = 0.5256,  smooth loss = 0.5416
[2022-07-06 22:41:52,682 callbacks.py:105 INFO train-abinet] epoch 5 iter 240700: loss = 0.5721,  smooth loss = 0.5300
[2022-07-06 22:42:34,434 callbacks.py:105 INFO train-abinet] epoch 5 iter 240750: loss = 0.6596,  smooth loss = 0.5275
[2022-07-06 22:43:17,109 callbacks.py:105 INFO train-abinet] epoch 5 iter 240800: loss = 0.4803,  smooth loss = 0.5281
[2022-07-06 22:43:58,683 callbacks.py:105 INFO train-abinet] epoch 5 iter 240850: loss = 0.6166,  smooth loss = 0.5353
[2022-07-06 22:44:40,386 callbacks.py:105 INFO train-abinet] epoch 5 iter 240900: loss = 0.7540,  smooth loss = 0.5339
[2022-07-06 22:45:22,864 callbacks.py:105 INFO train-abinet] epoch 5 iter 240950: loss = 0.4477,  smooth loss = 0.5352
[2022-07-06 22:46:05,412 callbacks.py:105 INFO train-abinet] epoch 5 iter 241000: loss = 0.5008,  smooth loss = 0.5250
[2022-07-06 22:46:46,757 callbacks.py:105 INFO train-abinet] epoch 5 iter 241050: loss = 0.5818,  smooth loss = 0.5347
[2022-07-06 22:47:28,093 callbacks.py:105 INFO train-abinet] epoch 5 iter 241100: loss = 0.5104,  smooth loss = 0.5475
[2022-07-06 22:48:10,178 callbacks.py:105 INFO train-abinet] epoch 5 iter 241150: loss = 0.6932,  smooth loss = 0.5447
[2022-07-06 22:48:53,201 callbacks.py:105 INFO train-abinet] epoch 5 iter 241200: loss = 0.4622,  smooth loss = 0.5466
[2022-07-06 22:49:35,745 callbacks.py:105 INFO train-abinet] epoch 5 iter 241250: loss = 0.5254,  smooth loss = 0.5286
[2022-07-06 22:50:16,710 callbacks.py:105 INFO train-abinet] epoch 5 iter 241300: loss = 0.5090,  smooth loss = 0.5222
[2022-07-06 22:50:57,681 callbacks.py:105 INFO train-abinet] epoch 5 iter 241350: loss = 0.4641,  smooth loss = 0.5422
[2022-07-06 22:51:39,359 callbacks.py:105 INFO train-abinet] epoch 5 iter 241400: loss = 0.5201,  smooth loss = 0.5366
[2022-07-06 22:52:20,780 callbacks.py:105 INFO train-abinet] epoch 5 iter 241450: loss = 0.4541,  smooth loss = 0.5238
[2022-07-06 22:53:02,947 callbacks.py:105 INFO train-abinet] epoch 5 iter 241500: loss = 0.5818,  smooth loss = 0.5320
[2022-07-06 22:53:45,176 callbacks.py:105 INFO train-abinet] epoch 5 iter 241550: loss = 0.4997,  smooth loss = 0.5312
[2022-07-06 22:54:26,673 callbacks.py:105 INFO train-abinet] epoch 5 iter 241600: loss = 0.6538,  smooth loss = 0.5317
[2022-07-06 22:55:07,958 callbacks.py:105 INFO train-abinet] epoch 5 iter 241650: loss = 0.4936,  smooth loss = 0.5362
[2022-07-06 22:55:49,920 callbacks.py:105 INFO train-abinet] epoch 5 iter 241700: loss = 0.5366,  smooth loss = 0.5411
[2022-07-06 22:56:31,843 callbacks.py:105 INFO train-abinet] epoch 5 iter 241750: loss = 0.4961,  smooth loss = 0.5358
[2022-07-06 22:57:13,964 callbacks.py:105 INFO train-abinet] epoch 5 iter 241800: loss = 0.5246,  smooth loss = 0.5329
[2022-07-06 22:57:55,861 callbacks.py:105 INFO train-abinet] epoch 5 iter 241850: loss = 0.5192,  smooth loss = 0.5332
[2022-07-06 22:58:38,074 callbacks.py:105 INFO train-abinet] epoch 5 iter 241900: loss = 0.5296,  smooth loss = 0.5329
[2022-07-06 22:59:21,466 callbacks.py:105 INFO train-abinet] epoch 5 iter 241950: loss = 0.5830,  smooth loss = 0.5578
[2022-07-06 23:00:04,544 callbacks.py:105 INFO train-abinet] epoch 5 iter 242000: loss = 0.4456,  smooth loss = 0.5397
[2022-07-06 23:00:47,141 callbacks.py:105 INFO train-abinet] epoch 5 iter 242050: loss = 0.4453,  smooth loss = 0.5474
[2022-07-06 23:01:29,200 callbacks.py:105 INFO train-abinet] epoch 5 iter 242100: loss = 0.6102,  smooth loss = 0.5447
[2022-07-06 23:02:11,331 callbacks.py:105 INFO train-abinet] epoch 5 iter 242150: loss = 0.4352,  smooth loss = 0.5402
[2022-07-06 23:02:53,192 callbacks.py:105 INFO train-abinet] epoch 5 iter 242200: loss = 0.5041,  smooth loss = 0.5279
[2022-07-06 23:03:34,255 callbacks.py:105 INFO train-abinet] epoch 5 iter 242250: loss = 0.4122,  smooth loss = 0.5243
[2022-07-06 23:04:16,213 callbacks.py:105 INFO train-abinet] epoch 5 iter 242300: loss = 0.5202,  smooth loss = 0.5381
[2022-07-06 23:04:58,607 callbacks.py:105 INFO train-abinet] epoch 5 iter 242350: loss = 0.5570,  smooth loss = 0.5429
[2022-07-06 23:05:41,145 callbacks.py:105 INFO train-abinet] epoch 5 iter 242400: loss = 0.4208,  smooth loss = 0.5461
[2022-07-06 23:06:23,606 callbacks.py:105 INFO train-abinet] epoch 5 iter 242450: loss = 0.5780,  smooth loss = 0.5502
[2022-07-06 23:07:06,062 callbacks.py:105 INFO train-abinet] epoch 5 iter 242500: loss = 0.4950,  smooth loss = 0.5427
[2022-07-06 23:07:47,723 callbacks.py:105 INFO train-abinet] epoch 5 iter 242550: loss = 0.5121,  smooth loss = 0.5399
[2022-07-06 23:08:29,142 callbacks.py:105 INFO train-abinet] epoch 5 iter 242600: loss = 0.4991,  smooth loss = 0.5460
[2022-07-06 23:09:12,774 callbacks.py:105 INFO train-abinet] epoch 5 iter 242650: loss = 0.6229,  smooth loss = 0.5307
[2022-07-06 23:09:54,194 callbacks.py:105 INFO train-abinet] epoch 5 iter 242700: loss = 0.5103,  smooth loss = 0.5206
[2022-07-06 23:10:35,615 callbacks.py:105 INFO train-abinet] epoch 5 iter 242750: loss = 0.6630,  smooth loss = 0.5370
[2022-07-06 23:11:17,545 callbacks.py:105 INFO train-abinet] epoch 5 iter 242800: loss = 0.6004,  smooth loss = 0.5309
[2022-07-06 23:12:00,036 callbacks.py:105 INFO train-abinet] epoch 5 iter 242850: loss = 0.5524,  smooth loss = 0.5197
[2022-07-06 23:12:42,049 callbacks.py:105 INFO train-abinet] epoch 5 iter 242900: loss = 0.5100,  smooth loss = 0.5407
[2022-07-06 23:13:23,751 callbacks.py:105 INFO train-abinet] epoch 5 iter 242950: loss = 0.6530,  smooth loss = 0.5338
[2022-07-06 23:14:05,204 callbacks.py:105 INFO train-abinet] epoch 5 iter 243000: loss = 0.5957,  smooth loss = 0.5363
[2022-07-06 23:14:05,204 callbacks.py:114 INFO train-abinet] average data time = 0.0052s, average running time = 0.8697s
█[2022-07-06 23:14:19,219 callbacks.py:123 INFO train-abinet] epoch 5 iter 243000: eval loss = 1.1921,  ccr = 0.9587,  cwr = 0.9135,  ted = 1341.0000,  ned = 268.5473,  ted/w = 0.1850, 
[2022-07-06 23:14:19,220 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_243000
[2022-07-06 23:15:02,119 callbacks.py:105 INFO train-abinet] epoch 5 iter 243050: loss = 0.6796,  smooth loss = 0.5447
[2022-07-06 23:15:44,461 callbacks.py:105 INFO train-abinet] epoch 5 iter 243100: loss = 0.5494,  smooth loss = 0.5410
[2022-07-06 23:16:26,422 callbacks.py:105 INFO train-abinet] epoch 5 iter 243150: loss = 0.4608,  smooth loss = 0.5446
[2022-07-06 23:17:07,370 callbacks.py:105 INFO train-abinet] epoch 5 iter 243200: loss = 0.6804,  smooth loss = 0.5516
[2022-07-06 23:17:48,895 callbacks.py:105 INFO train-abinet] epoch 5 iter 243250: loss = 0.5801,  smooth loss = 0.5421
[2022-07-06 23:18:30,320 callbacks.py:105 INFO train-abinet] epoch 5 iter 243300: loss = 0.4533,  smooth loss = 0.5363
[2022-07-06 23:19:11,462 callbacks.py:105 INFO train-abinet] epoch 5 iter 243350: loss = 0.7234,  smooth loss = 0.5495
[2022-07-06 23:19:53,711 callbacks.py:105 INFO train-abinet] epoch 5 iter 243400: loss = 0.6568,  smooth loss = 0.5380
[2022-07-06 23:20:34,419 callbacks.py:105 INFO train-abinet] epoch 5 iter 243450: loss = 0.5316,  smooth loss = 0.5312
[2022-07-06 23:21:17,094 callbacks.py:105 INFO train-abinet] epoch 5 iter 243500: loss = 0.4865,  smooth loss = 0.5335
[2022-07-06 23:21:58,175 callbacks.py:105 INFO train-abinet] epoch 5 iter 243550: loss = 0.4506,  smooth loss = 0.5454
[2022-07-06 23:22:39,478 callbacks.py:105 INFO train-abinet] epoch 5 iter 243600: loss = 0.6043,  smooth loss = 0.5418
[2022-07-06 23:23:21,252 callbacks.py:105 INFO train-abinet] epoch 5 iter 243650: loss = 0.5666,  smooth loss = 0.5434
[2022-07-06 23:24:03,005 callbacks.py:105 INFO train-abinet] epoch 5 iter 243700: loss = 0.5756,  smooth loss = 0.5472
[2022-07-06 23:24:43,530 callbacks.py:105 INFO train-abinet] epoch 5 iter 243750: loss = 0.4542,  smooth loss = 0.5400
[2022-07-06 23:25:24,424 callbacks.py:105 INFO train-abinet] epoch 5 iter 243800: loss = 0.6013,  smooth loss = 0.5492
[2022-07-06 23:26:05,664 callbacks.py:105 INFO train-abinet] epoch 5 iter 243850: loss = 0.5324,  smooth loss = 0.5521
[2022-07-06 23:26:46,386 callbacks.py:105 INFO train-abinet] epoch 5 iter 243900: loss = 0.5614,  smooth loss = 0.5444
[2022-07-06 23:27:26,695 callbacks.py:105 INFO train-abinet] epoch 5 iter 243950: loss = 0.5161,  smooth loss = 0.5384
[2022-07-06 23:28:06,975 callbacks.py:105 INFO train-abinet] epoch 5 iter 244000: loss = 0.6102,  smooth loss = 0.5453
[2022-07-06 23:28:48,213 callbacks.py:105 INFO train-abinet] epoch 5 iter 244050: loss = 0.5606,  smooth loss = 0.5451
[2022-07-06 23:29:29,819 callbacks.py:105 INFO train-abinet] epoch 5 iter 244100: loss = 0.5926,  smooth loss = 0.5442
[2022-07-06 23:30:10,299 callbacks.py:105 INFO train-abinet] epoch 5 iter 244150: loss = 0.4029,  smooth loss = 0.5402
[2022-07-06 23:30:51,513 callbacks.py:105 INFO train-abinet] epoch 5 iter 244200: loss = 0.4499,  smooth loss = 0.5303
[2022-07-06 23:31:32,546 callbacks.py:105 INFO train-abinet] epoch 5 iter 244250: loss = 0.5385,  smooth loss = 0.5221
[2022-07-06 23:32:13,561 callbacks.py:105 INFO train-abinet] epoch 5 iter 244300: loss = 0.4951,  smooth loss = 0.5338
[2022-07-06 23:32:55,554 callbacks.py:105 INFO train-abinet] epoch 5 iter 244350: loss = 0.5462,  smooth loss = 0.5356
[2022-07-06 23:33:37,245 callbacks.py:105 INFO train-abinet] epoch 5 iter 244400: loss = 0.4819,  smooth loss = 0.5345
[2022-07-06 23:34:18,702 callbacks.py:105 INFO train-abinet] epoch 5 iter 244450: loss = 0.5732,  smooth loss = 0.5414
[2022-07-06 23:34:59,987 callbacks.py:105 INFO train-abinet] epoch 5 iter 244500: loss = 0.5492,  smooth loss = 0.5465
[2022-07-06 23:35:40,704 callbacks.py:105 INFO train-abinet] epoch 5 iter 244550: loss = 0.4472,  smooth loss = 0.5478
[2022-07-06 23:36:21,807 callbacks.py:105 INFO train-abinet] epoch 5 iter 244600: loss = 0.4334,  smooth loss = 0.5321
[2022-07-06 23:37:03,163 callbacks.py:105 INFO train-abinet] epoch 5 iter 244650: loss = 0.5737,  smooth loss = 0.5420
[2022-07-06 23:37:43,927 callbacks.py:105 INFO train-abinet] epoch 5 iter 244700: loss = 0.6014,  smooth loss = 0.5219
[2022-07-06 23:38:26,201 callbacks.py:105 INFO train-abinet] epoch 5 iter 244750: loss = 0.5206,  smooth loss = 0.5419
[2022-07-06 23:39:07,155 callbacks.py:105 INFO train-abinet] epoch 5 iter 244800: loss = 0.4428,  smooth loss = 0.5367
[2022-07-06 23:39:47,716 callbacks.py:105 INFO train-abinet] epoch 5 iter 244850: loss = 0.6395,  smooth loss = 0.5259
[2022-07-06 23:40:29,276 callbacks.py:105 INFO train-abinet] epoch 5 iter 244900: loss = 0.5583,  smooth loss = 0.5327
[2022-07-06 23:41:09,777 callbacks.py:105 INFO train-abinet] epoch 5 iter 244950: loss = 0.5566,  smooth loss = 0.5274
[2022-07-06 23:41:50,424 callbacks.py:105 INFO train-abinet] epoch 5 iter 245000: loss = 0.5461,  smooth loss = 0.5299
[2022-07-06 23:42:32,789 callbacks.py:105 INFO train-abinet] epoch 5 iter 245050: loss = 0.6314,  smooth loss = 0.5293
[2022-07-06 23:43:13,492 callbacks.py:105 INFO train-abinet] epoch 5 iter 245100: loss = 0.7129,  smooth loss = 0.5408
[2022-07-06 23:43:54,782 callbacks.py:105 INFO train-abinet] epoch 5 iter 245150: loss = 0.5310,  smooth loss = 0.5287
[2022-07-06 23:44:35,201 callbacks.py:105 INFO train-abinet] epoch 5 iter 245200: loss = 0.5856,  smooth loss = 0.5424
[2022-07-06 23:45:16,031 callbacks.py:105 INFO train-abinet] epoch 5 iter 245250: loss = 0.4846,  smooth loss = 0.5394
[2022-07-06 23:45:56,977 callbacks.py:105 INFO train-abinet] epoch 5 iter 245300: loss = 0.4964,  smooth loss = 0.5274
[2022-07-06 23:46:38,384 callbacks.py:105 INFO train-abinet] epoch 5 iter 245350: loss = 0.4873,  smooth loss = 0.5464
[2022-07-06 23:47:19,687 callbacks.py:105 INFO train-abinet] epoch 5 iter 245400: loss = 0.6228,  smooth loss = 0.5489
[2022-07-06 23:48:00,329 callbacks.py:105 INFO train-abinet] epoch 5 iter 245450: loss = 0.5458,  smooth loss = 0.5288
[2022-07-06 23:48:40,829 callbacks.py:105 INFO train-abinet] epoch 5 iter 245500: loss = 0.4133,  smooth loss = 0.5256
[2022-07-06 23:49:21,617 callbacks.py:105 INFO train-abinet] epoch 5 iter 245550: loss = 0.4311,  smooth loss = 0.5316
[2022-07-06 23:50:01,681 callbacks.py:105 INFO train-abinet] epoch 5 iter 245600: loss = 0.5351,  smooth loss = 0.5386
[2022-07-06 23:50:42,513 callbacks.py:105 INFO train-abinet] epoch 5 iter 245650: loss = 0.5037,  smooth loss = 0.5371
[2022-07-06 23:51:23,759 callbacks.py:105 INFO train-abinet] epoch 5 iter 245700: loss = 0.4058,  smooth loss = 0.5413
[2022-07-06 23:52:03,966 callbacks.py:105 INFO train-abinet] epoch 5 iter 245750: loss = 0.6396,  smooth loss = 0.5494
[2022-07-06 23:52:44,134 callbacks.py:105 INFO train-abinet] epoch 5 iter 245800: loss = 0.4585,  smooth loss = 0.5409
[2022-07-06 23:53:25,070 callbacks.py:105 INFO train-abinet] epoch 5 iter 245850: loss = 0.6425,  smooth loss = 0.5511
[2022-07-06 23:54:05,928 callbacks.py:105 INFO train-abinet] epoch 5 iter 245900: loss = 0.4485,  smooth loss = 0.5348
[2022-07-06 23:54:47,531 callbacks.py:105 INFO train-abinet] epoch 5 iter 245950: loss = 0.5808,  smooth loss = 0.5384
[2022-07-06 23:55:28,911 callbacks.py:105 INFO train-abinet] epoch 5 iter 246000: loss = 0.6464,  smooth loss = 0.5366
[2022-07-06 23:55:28,912 callbacks.py:114 INFO train-abinet] average data time = 0.0051s, average running time = 0.8691s
█[2022-07-06 23:55:43,446 callbacks.py:123 INFO train-abinet] epoch 5 iter 246000: eval loss = 1.1765,  ccr = 0.9595,  cwr = 0.9168,  ted = 1348.0000,  ned = 268.8550,  ted/w = 0.1860, 
[2022-07-06 23:55:43,447 callbacks.py:136 INFO train-abinet] Save model train-abinet_5_246000
[2022-07-06 23:56:25,570 callbacks.py:105 INFO train-abinet] epoch 5 iter 246050: loss = 0.6092,  smooth loss = 0.5317
[2022-07-06 23:57:06,613 callbacks.py:105 INFO train-abinet] epoch 5 iter 246100: loss = 0.5113,  smooth loss = 0.5463
[2022-07-06 23:57:46,939 callbacks.py:105 INFO train-abinet] epoch 5 iter 246150: loss = 0.3558,  smooth loss = 0.5326
[2022-07-06 23:58:27,517 callbacks.py:105 INFO train-abinet] epoch 5 iter 246200: loss = 0.5728,  smooth loss = 0.5482
[2022-07-06 23:59:08,402 callbacks.py:105 INFO train-abinet] epoch 5 iter 246250: loss = 0.5390,  smooth loss = 0.5339
[2022-07-06 23:59:49,262 callbacks.py:105 INFO train-abinet] epoch 5 iter 246300: loss = 0.5475,  smooth loss = 0.5183
[2022-07-07 00:00:29,954 callbacks.py:105 INFO train-abinet] epoch 5 iter 246350: loss = 0.5398,  smooth loss = 0.5383
[2022-07-07 00:01:10,103 callbacks.py:105 INFO train-abinet] epoch 5 iter 246400: loss = 0.5612,  smooth loss = 0.5410
[2022-07-07 00:01:51,607 callbacks.py:105 INFO train-abinet] epoch 5 iter 246450: loss = 0.4797,  smooth loss = 0.5326
[2022-07-07 00:02:32,683 callbacks.py:105 INFO train-abinet] epoch 5 iter 246500: loss = 0.5707,  smooth loss = 0.5300
[2022-07-07 00:03:13,630 callbacks.py:105 INFO train-abinet] epoch 5 iter 246550: loss = 0.5255,  smooth loss = 0.5316
[2022-07-07 00:03:54,775 callbacks.py:105 INFO train-abinet] epoch 5 iter 246600: loss = 0.5675,  smooth loss = 0.5379
[2022-07-07 00:04:35,276 callbacks.py:105 INFO train-abinet] epoch 5 iter 246650: loss = 0.6225,  smooth loss = 0.5407
[2022-07-07 00:05:15,619 callbacks.py:105 INFO train-abinet] epoch 5 iter 246700: loss = 0.4789,  smooth loss = 0.5396
[2022-07-07 00:05:56,878 callbacks.py:105 INFO train-abinet] epoch 5 iter 246750: loss = 0.5529,  smooth loss = 0.5371
[2022-07-07 00:06:38,803 callbacks.py:105 INFO train-abinet] epoch 5 iter 246800: loss = 0.4913,  smooth loss = 0.5372
[2022-07-07 00:07:19,509 callbacks.py:105 INFO train-abinet] epoch 5 iter 246850: loss = 0.4441,  smooth loss = 0.5352
[2022-07-07 00:08:00,554 callbacks.py:105 INFO train-abinet] epoch 5 iter 246900: loss = 0.5734,  smooth loss = 0.5352
[2022-07-07 00:08:41,685 callbacks.py:105 INFO train-abinet] epoch 5 iter 246950: loss = 0.5116,  smooth loss = 0.5278
[2022-07-07 00:09:21,925 callbacks.py:105 INFO train-abinet] epoch 5 iter 247000: loss = 0.6766,  smooth loss = 0.5371
[2022-07-07 00:10:02,604 callbacks.py:105 INFO train-abinet] epoch 5 iter 247050: loss = 0.4970,  smooth loss = 0.5383
[2022-07-07 00:10:43,168 callbacks.py:105 INFO train-abinet] epoch 5 iter 247100: loss = 0.4704,  smooth loss = 0.5396
[2022-07-07 00:11:23,688 callbacks.py:105 INFO train-abinet] epoch 5 iter 247150: loss = 0.5161,  smooth loss = 0.5378
[2022-07-07 00:12:04,604 callbacks.py:105 INFO train-abinet] epoch 5 iter 247200: loss = 0.4772,  smooth loss = 0.5426
[2022-07-07 00:12:45,029 callbacks.py:105 INFO train-abinet] epoch 5 iter 247250: loss = 0.5932,  smooth loss = 0.5425
[2022-07-07 00:13:26,069 callbacks.py:105 INFO train-abinet] epoch 5 iter 247300: loss = 0.4187,  smooth loss = 0.5371
[2022-07-07 00:14:07,230 callbacks.py:105 INFO train-abinet] epoch 5 iter 247350: loss = 0.4280,  smooth loss = 0.5396
[2022-07-07 00:14:48,626 callbacks.py:105 INFO train-abinet] epoch 5 iter 247400: loss = 0.5986,  smooth loss = 0.5465
[2022-07-07 00:15:29,956 callbacks.py:105 INFO train-abinet] epoch 5 iter 247450: loss = 0.6862,  smooth loss = 0.5343
[2022-07-07 00:16:12,062 callbacks.py:105 INFO train-abinet] epoch 5 iter 247500: loss = 0.5448,  smooth loss = 0.5479
[2022-07-07 00:16:53,815 callbacks.py:105 INFO train-abinet] epoch 5 iter 247550: loss = 0.4776,  smooth loss = 0.5324
[2022-07-07 00:17:34,692 callbacks.py:105 INFO train-abinet] epoch 5 iter 247600: loss = 0.5777,  smooth loss = 0.5382
[2022-07-07 00:18:15,368 callbacks.py:105 INFO train-abinet] epoch 5 iter 247650: loss = 0.4819,  smooth loss = 0.5451
[2022-07-07 00:18:55,936 callbacks.py:105 INFO train-abinet] epoch 5 iter 247700: loss = 0.4541,  smooth loss = 0.5383
[2022-07-07 00:19:36,653 callbacks.py:105 INFO train-abinet] epoch 5 iter 247750: loss = 0.5221,  smooth loss = 0.5325
[2022-07-07 00:20:18,088 callbacks.py:105 INFO train-abinet] epoch 5 iter 247800: loss = 0.4317,  smooth loss = 0.5287
[2022-07-07 00:20:59,500 callbacks.py:105 INFO train-abinet] epoch 5 iter 247850: loss = 0.4383,  smooth loss = 0.5387
[2022-07-07 00:21:41,364 callbacks.py:105 INFO train-abinet] epoch 5 iter 247900: loss = 0.4408,  smooth loss = 0.5463
[2022-07-07 00:22:23,149 callbacks.py:105 INFO train-abinet] epoch 5 iter 247950: loss = 0.6214,  smooth loss = 0.5436
[2022-07-07 00:23:05,282 callbacks.py:105 INFO train-abinet] epoch 5 iter 248000: loss = 0.5418,  smooth loss = 0.5310
[2022-07-07 00:23:46,252 callbacks.py:105 INFO train-abinet] epoch 5 iter 248050: loss = 0.4322,  smooth loss = 0.5350
[2022-07-07 00:24:27,735 callbacks.py:105 INFO train-abinet] epoch 5 iter 248100: loss = 0.6703,  smooth loss = 0.5310
[2022-07-07 00:25:08,425 callbacks.py:105 INFO train-abinet] epoch 5 iter 248150: loss = 0.4824,  smooth loss = 0.5337
[2022-07-07 00:25:49,779 callbacks.py:105 INFO train-abinet] epoch 5 iter 248200: loss = 0.6078,  smooth loss = 0.5434
[2022-07-07 00:26:31,039 callbacks.py:105 INFO train-abinet] epoch 5 iter 248250: loss = 0.4377,  smooth loss = 0.5347
[2022-07-07 00:27:12,861 callbacks.py:105 INFO train-abinet] epoch 5 iter 248300: loss = 0.6807,  smooth loss = 0.5378
[2022-07-07 00:27:56,175 callbacks.py:105 INFO train-abinet] epoch 5 iter 248350: loss = 0.6096,  smooth loss = 0.5471
█[2022-07-07 00:28:43,272 callbacks.py:105 INFO train-abinet] epoch 6 iter 248400: loss = 0.5636,  smooth loss = 0.5403
[2022-07-07 00:29:24,095 callbacks.py:105 INFO train-abinet] epoch 6 iter 248450: loss = 0.4616,  smooth loss = 0.5294
[2022-07-07 00:30:05,248 callbacks.py:105 INFO train-abinet] epoch 6 iter 248500: loss = 0.5042,  smooth loss = 0.5178
[2022-07-07 00:30:46,965 callbacks.py:105 INFO train-abinet] epoch 6 iter 248550: loss = 0.5229,  smooth loss = 0.5162
[2022-07-07 00:31:28,121 callbacks.py:105 INFO train-abinet] epoch 6 iter 248600: loss = 0.4860,  smooth loss = 0.5152
[2022-07-07 00:32:08,386 callbacks.py:105 INFO train-abinet] epoch 6 iter 248650: loss = 0.5648,  smooth loss = 0.5045
[2022-07-07 00:32:49,390 callbacks.py:105 INFO train-abinet] epoch 6 iter 248700: loss = 0.3676,  smooth loss = 0.5100
[2022-07-07 00:33:29,664 callbacks.py:105 INFO train-abinet] epoch 6 iter 248750: loss = 0.5623,  smooth loss = 0.5149
[2022-07-07 00:34:11,447 callbacks.py:105 INFO train-abinet] epoch 6 iter 248800: loss = 0.5577,  smooth loss = 0.5153
[2022-07-07 00:34:52,227 callbacks.py:105 INFO train-abinet] epoch 6 iter 248850: loss = 0.5267,  smooth loss = 0.5076
[2022-07-07 00:35:34,760 callbacks.py:105 INFO train-abinet] epoch 6 iter 248900: loss = 0.4802,  smooth loss = 0.4921
[2022-07-07 00:36:16,105 callbacks.py:105 INFO train-abinet] epoch 6 iter 248950: loss = 0.4696,  smooth loss = 0.4981
[2022-07-07 00:36:56,928 callbacks.py:105 INFO train-abinet] epoch 6 iter 249000: loss = 0.6335,  smooth loss = 0.5092
[2022-07-07 00:36:56,928 callbacks.py:114 INFO train-abinet] average data time = 0.0051s, average running time = 0.8686s
█[2022-07-07 00:37:11,620 callbacks.py:123 INFO train-abinet] epoch 6 iter 249000: eval loss = 1.1651,  ccr = 0.9613,  cwr = 0.9200,  ted = 1297.0000,  ned = 259.7645,  ted/w = 0.1789, 
[2022-07-07 00:37:11,621 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_249000
[2022-07-07 00:37:54,597 callbacks.py:105 INFO train-abinet] epoch 6 iter 249050: loss = 0.5971,  smooth loss = 0.5048
[2022-07-07 00:38:35,917 callbacks.py:105 INFO train-abinet] epoch 6 iter 249100: loss = 0.4564,  smooth loss = 0.5053
[2022-07-07 00:39:16,442 callbacks.py:105 INFO train-abinet] epoch 6 iter 249150: loss = 0.4611,  smooth loss = 0.5138
[2022-07-07 00:39:58,705 callbacks.py:105 INFO train-abinet] epoch 6 iter 249200: loss = 0.6715,  smooth loss = 0.5095
[2022-07-07 00:40:39,876 callbacks.py:105 INFO train-abinet] epoch 6 iter 249250: loss = 0.4664,  smooth loss = 0.5055
[2022-07-07 00:41:21,661 callbacks.py:105 INFO train-abinet] epoch 6 iter 249300: loss = 0.4740,  smooth loss = 0.5127
[2022-07-07 00:42:02,975 callbacks.py:105 INFO train-abinet] epoch 6 iter 249350: loss = 0.4809,  smooth loss = 0.4976
[2022-07-07 00:42:44,195 callbacks.py:105 INFO train-abinet] epoch 6 iter 249400: loss = 0.5836,  smooth loss = 0.5020
[2022-07-07 00:43:25,256 callbacks.py:105 INFO train-abinet] epoch 6 iter 249450: loss = 0.5293,  smooth loss = 0.5100
[2022-07-07 00:44:06,146 callbacks.py:105 INFO train-abinet] epoch 6 iter 249500: loss = 0.4712,  smooth loss = 0.4968
[2022-07-07 00:44:47,132 callbacks.py:105 INFO train-abinet] epoch 6 iter 249550: loss = 0.4124,  smooth loss = 0.4970
[2022-07-07 00:45:29,605 callbacks.py:105 INFO train-abinet] epoch 6 iter 249600: loss = 0.5713,  smooth loss = 0.4970
[2022-07-07 00:46:11,214 callbacks.py:105 INFO train-abinet] epoch 6 iter 249650: loss = 0.4249,  smooth loss = 0.4873
[2022-07-07 00:46:51,995 callbacks.py:105 INFO train-abinet] epoch 6 iter 249700: loss = 0.4274,  smooth loss = 0.5046
[2022-07-07 00:47:33,233 callbacks.py:105 INFO train-abinet] epoch 6 iter 249750: loss = 0.6049,  smooth loss = 0.5071
[2022-07-07 00:48:14,470 callbacks.py:105 INFO train-abinet] epoch 6 iter 249800: loss = 0.5032,  smooth loss = 0.4842
[2022-07-07 00:48:56,377 callbacks.py:105 INFO train-abinet] epoch 6 iter 249850: loss = 0.5643,  smooth loss = 0.4958
[2022-07-07 00:49:36,910 callbacks.py:105 INFO train-abinet] epoch 6 iter 249900: loss = 0.5111,  smooth loss = 0.4925
[2022-07-07 00:50:17,657 callbacks.py:105 INFO train-abinet] epoch 6 iter 249950: loss = 0.4867,  smooth loss = 0.5019
[2022-07-07 00:50:58,303 callbacks.py:105 INFO train-abinet] epoch 6 iter 250000: loss = 0.6013,  smooth loss = 0.5071
[2022-07-07 00:51:38,671 callbacks.py:105 INFO train-abinet] epoch 6 iter 250050: loss = 0.4511,  smooth loss = 0.4947
[2022-07-07 00:52:20,870 callbacks.py:105 INFO train-abinet] epoch 6 iter 250100: loss = 0.4231,  smooth loss = 0.5005
[2022-07-07 00:53:01,954 callbacks.py:105 INFO train-abinet] epoch 6 iter 250150: loss = 0.4701,  smooth loss = 0.4980
[2022-07-07 00:53:42,696 callbacks.py:105 INFO train-abinet] epoch 6 iter 250200: loss = 0.5352,  smooth loss = 0.4884
[2022-07-07 00:54:24,334 callbacks.py:105 INFO train-abinet] epoch 6 iter 250250: loss = 0.5030,  smooth loss = 0.4974
[2022-07-07 00:55:05,757 callbacks.py:105 INFO train-abinet] epoch 6 iter 250300: loss = 0.5517,  smooth loss = 0.4777
[2022-07-07 00:55:47,492 callbacks.py:105 INFO train-abinet] epoch 6 iter 250350: loss = 0.5340,  smooth loss = 0.4919
[2022-07-07 00:56:30,008 callbacks.py:105 INFO train-abinet] epoch 6 iter 250400: loss = 0.4780,  smooth loss = 0.4829
[2022-07-07 00:57:10,858 callbacks.py:105 INFO train-abinet] epoch 6 iter 250450: loss = 0.4148,  smooth loss = 0.4921
[2022-07-07 00:57:52,140 callbacks.py:105 INFO train-abinet] epoch 6 iter 250500: loss = 0.5268,  smooth loss = 0.4979
[2022-07-07 00:58:32,982 callbacks.py:105 INFO train-abinet] epoch 6 iter 250550: loss = 0.5352,  smooth loss = 0.4952
[2022-07-07 00:59:14,511 callbacks.py:105 INFO train-abinet] epoch 6 iter 250600: loss = 0.5208,  smooth loss = 0.4973
[2022-07-07 00:59:55,871 callbacks.py:105 INFO train-abinet] epoch 6 iter 250650: loss = 0.5295,  smooth loss = 0.4997
[2022-07-07 01:00:37,937 callbacks.py:105 INFO train-abinet] epoch 6 iter 250700: loss = 0.5231,  smooth loss = 0.4958
[2022-07-07 01:01:19,271 callbacks.py:105 INFO train-abinet] epoch 6 iter 250750: loss = 0.4327,  smooth loss = 0.4918
[2022-07-07 01:02:00,391 callbacks.py:105 INFO train-abinet] epoch 6 iter 250800: loss = 0.4291,  smooth loss = 0.4817
[2022-07-07 01:02:41,388 callbacks.py:105 INFO train-abinet] epoch 6 iter 250850: loss = 0.5924,  smooth loss = 0.4935
[2022-07-07 01:03:22,487 callbacks.py:105 INFO train-abinet] epoch 6 iter 250900: loss = 0.4755,  smooth loss = 0.4827
[2022-07-07 01:04:03,473 callbacks.py:105 INFO train-abinet] epoch 6 iter 250950: loss = 0.4022,  smooth loss = 0.4924
[2022-07-07 01:04:45,669 callbacks.py:105 INFO train-abinet] epoch 6 iter 251000: loss = 0.4992,  smooth loss = 0.4878
[2022-07-07 01:05:27,261 callbacks.py:105 INFO train-abinet] epoch 6 iter 251050: loss = 0.5211,  smooth loss = 0.4865
[2022-07-07 01:06:08,303 callbacks.py:105 INFO train-abinet] epoch 6 iter 251100: loss = 0.5122,  smooth loss = 0.4986
[2022-07-07 01:06:49,889 callbacks.py:105 INFO train-abinet] epoch 6 iter 251150: loss = 0.4570,  smooth loss = 0.5015
[2022-07-07 01:07:31,611 callbacks.py:105 INFO train-abinet] epoch 6 iter 251200: loss = 0.4640,  smooth loss = 0.5073
[2022-07-07 01:08:12,400 callbacks.py:105 INFO train-abinet] epoch 6 iter 251250: loss = 0.4911,  smooth loss = 0.4987
[2022-07-07 01:08:53,947 callbacks.py:105 INFO train-abinet] epoch 6 iter 251300: loss = 0.4443,  smooth loss = 0.5036
[2022-07-07 01:09:35,155 callbacks.py:105 INFO train-abinet] epoch 6 iter 251350: loss = 0.7174,  smooth loss = 0.5040
[2022-07-07 01:10:15,859 callbacks.py:105 INFO train-abinet] epoch 6 iter 251400: loss = 0.5500,  smooth loss = 0.4962
[2022-07-07 01:10:56,858 callbacks.py:105 INFO train-abinet] epoch 6 iter 251450: loss = 0.3806,  smooth loss = 0.4886
[2022-07-07 01:11:38,227 callbacks.py:105 INFO train-abinet] epoch 6 iter 251500: loss = 0.4841,  smooth loss = 0.4930
[2022-07-07 01:12:19,532 callbacks.py:105 INFO train-abinet] epoch 6 iter 251550: loss = 0.4883,  smooth loss = 0.4987
[2022-07-07 01:13:00,250 callbacks.py:105 INFO train-abinet] epoch 6 iter 251600: loss = 0.4122,  smooth loss = 0.4945
[2022-07-07 01:13:41,614 callbacks.py:105 INFO train-abinet] epoch 6 iter 251650: loss = 0.5851,  smooth loss = 0.5061
[2022-07-07 01:14:22,998 callbacks.py:105 INFO train-abinet] epoch 6 iter 251700: loss = 0.4956,  smooth loss = 0.5021
[2022-07-07 01:15:04,100 callbacks.py:105 INFO train-abinet] epoch 6 iter 251750: loss = 0.5416,  smooth loss = 0.4999
[2022-07-07 01:15:45,014 callbacks.py:105 INFO train-abinet] epoch 6 iter 251800: loss = 0.3953,  smooth loss = 0.5021
[2022-07-07 01:16:25,993 callbacks.py:105 INFO train-abinet] epoch 6 iter 251850: loss = 0.6049,  smooth loss = 0.4790
[2022-07-07 01:17:06,431 callbacks.py:105 INFO train-abinet] epoch 6 iter 251900: loss = 0.5715,  smooth loss = 0.4885
[2022-07-07 01:17:47,651 callbacks.py:105 INFO train-abinet] epoch 6 iter 251950: loss = 0.4845,  smooth loss = 0.4895
[2022-07-07 01:18:28,644 callbacks.py:105 INFO train-abinet] epoch 6 iter 252000: loss = 0.4606,  smooth loss = 0.4816
[2022-07-07 01:18:28,645 callbacks.py:114 INFO train-abinet] average data time = 0.0051s, average running time = 0.8681s
█[2022-07-07 01:18:42,945 callbacks.py:123 INFO train-abinet] epoch 6 iter 252000: eval loss = 1.1828,  ccr = 0.9623,  cwr = 0.9212,  ted = 1231.0000,  ned = 249.2736,  ted/w = 0.1698, 
[2022-07-07 01:18:42,946 callbacks.py:130 INFO train-abinet] Better model found at epoch 6, iter 252000 with accuracy value: 0.9212.
[2022-07-07 01:18:43,974 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_252000
[2022-07-07 01:19:25,724 callbacks.py:105 INFO train-abinet] epoch 6 iter 252050: loss = 0.4968,  smooth loss = 0.4806
[2022-07-07 01:20:07,124 callbacks.py:105 INFO train-abinet] epoch 6 iter 252100: loss = 0.5160,  smooth loss = 0.4759
[2022-07-07 01:20:48,236 callbacks.py:105 INFO train-abinet] epoch 6 iter 252150: loss = 0.4912,  smooth loss = 0.4971
[2022-07-07 01:21:29,234 callbacks.py:105 INFO train-abinet] epoch 6 iter 252200: loss = 0.5299,  smooth loss = 0.5049
[2022-07-07 01:22:10,233 callbacks.py:105 INFO train-abinet] epoch 6 iter 252250: loss = 0.5292,  smooth loss = 0.4948
[2022-07-07 01:22:50,542 callbacks.py:105 INFO train-abinet] epoch 6 iter 252300: loss = 0.4988,  smooth loss = 0.4854
[2022-07-07 01:23:31,540 callbacks.py:105 INFO train-abinet] epoch 6 iter 252350: loss = 0.5005,  smooth loss = 0.4958
[2022-07-07 01:24:12,924 callbacks.py:105 INFO train-abinet] epoch 6 iter 252400: loss = 0.4629,  smooth loss = 0.4968
[2022-07-07 01:24:54,565 callbacks.py:105 INFO train-abinet] epoch 6 iter 252450: loss = 0.4419,  smooth loss = 0.4899
[2022-07-07 01:25:35,441 callbacks.py:105 INFO train-abinet] epoch 6 iter 252500: loss = 0.4830,  smooth loss = 0.4821
[2022-07-07 01:26:15,582 callbacks.py:105 INFO train-abinet] epoch 6 iter 252550: loss = 0.5855,  smooth loss = 0.4877
[2022-07-07 01:26:56,063 callbacks.py:105 INFO train-abinet] epoch 6 iter 252600: loss = 0.3756,  smooth loss = 0.4791
[2022-07-07 01:27:36,478 callbacks.py:105 INFO train-abinet] epoch 6 iter 252650: loss = 0.3918,  smooth loss = 0.4783
[2022-07-07 01:28:17,666 callbacks.py:105 INFO train-abinet] epoch 6 iter 252700: loss = 0.5819,  smooth loss = 0.4892
[2022-07-07 01:28:59,019 callbacks.py:105 INFO train-abinet] epoch 6 iter 252750: loss = 0.5126,  smooth loss = 0.4769
[2022-07-07 01:29:39,607 callbacks.py:105 INFO train-abinet] epoch 6 iter 252800: loss = 0.4536,  smooth loss = 0.4960
[2022-07-07 01:30:20,883 callbacks.py:105 INFO train-abinet] epoch 6 iter 252850: loss = 0.4563,  smooth loss = 0.4891
[2022-07-07 01:31:01,936 callbacks.py:105 INFO train-abinet] epoch 6 iter 252900: loss = 0.5401,  smooth loss = 0.4957
[2022-07-07 01:31:42,810 callbacks.py:105 INFO train-abinet] epoch 6 iter 252950: loss = 0.4823,  smooth loss = 0.4827
[2022-07-07 01:32:23,730 callbacks.py:105 INFO train-abinet] epoch 6 iter 253000: loss = 0.5063,  smooth loss = 0.4916
[2022-07-07 01:33:04,671 callbacks.py:105 INFO train-abinet] epoch 6 iter 253050: loss = 0.3572,  smooth loss = 0.4911
[2022-07-07 01:33:45,703 callbacks.py:105 INFO train-abinet] epoch 6 iter 253100: loss = 0.5658,  smooth loss = 0.4938
[2022-07-07 01:34:26,922 callbacks.py:105 INFO train-abinet] epoch 6 iter 253150: loss = 0.5701,  smooth loss = 0.5030
[2022-07-07 01:35:09,173 callbacks.py:105 INFO train-abinet] epoch 6 iter 253200: loss = 0.5877,  smooth loss = 0.4801
[2022-07-07 01:35:54,226 callbacks.py:105 INFO train-abinet] epoch 6 iter 253250: loss = 0.4019,  smooth loss = 0.4799
[2022-07-07 01:36:37,338 callbacks.py:105 INFO train-abinet] epoch 6 iter 253300: loss = 0.5099,  smooth loss = 0.4928
[2022-07-07 01:37:21,031 callbacks.py:105 INFO train-abinet] epoch 6 iter 253350: loss = 0.5236,  smooth loss = 0.4905
[2022-07-07 01:38:01,786 callbacks.py:105 INFO train-abinet] epoch 6 iter 253400: loss = 0.6045,  smooth loss = 0.4845
[2022-07-07 01:38:43,605 callbacks.py:105 INFO train-abinet] epoch 6 iter 253450: loss = 0.3724,  smooth loss = 0.4994
[2022-07-07 01:39:24,492 callbacks.py:105 INFO train-abinet] epoch 6 iter 253500: loss = 0.4785,  smooth loss = 0.4896
[2022-07-07 01:40:05,013 callbacks.py:105 INFO train-abinet] epoch 6 iter 253550: loss = 0.4628,  smooth loss = 0.4766
[2022-07-07 01:40:46,305 callbacks.py:105 INFO train-abinet] epoch 6 iter 253600: loss = 0.4782,  smooth loss = 0.4826
[2022-07-07 01:41:27,564 callbacks.py:105 INFO train-abinet] epoch 6 iter 253650: loss = 0.6338,  smooth loss = 0.4916
[2022-07-07 01:42:08,012 callbacks.py:105 INFO train-abinet] epoch 6 iter 253700: loss = 0.4512,  smooth loss = 0.5015
[2022-07-07 01:42:49,462 callbacks.py:105 INFO train-abinet] epoch 6 iter 253750: loss = 0.4867,  smooth loss = 0.4960
[2022-07-07 01:43:30,296 callbacks.py:105 INFO train-abinet] epoch 6 iter 253800: loss = 0.4137,  smooth loss = 0.4887
[2022-07-07 01:44:10,459 callbacks.py:105 INFO train-abinet] epoch 6 iter 253850: loss = 0.7160,  smooth loss = 0.4919
[2022-07-07 01:44:50,905 callbacks.py:105 INFO train-abinet] epoch 6 iter 253900: loss = 0.4494,  smooth loss = 0.4820
[2022-07-07 01:45:33,633 callbacks.py:105 INFO train-abinet] epoch 6 iter 253950: loss = 0.4413,  smooth loss = 0.4879
[2022-07-07 01:46:14,064 callbacks.py:105 INFO train-abinet] epoch 6 iter 254000: loss = 0.4825,  smooth loss = 0.4836
[2022-07-07 01:46:55,703 callbacks.py:105 INFO train-abinet] epoch 6 iter 254050: loss = 0.4676,  smooth loss = 0.4892
[2022-07-07 01:47:37,162 callbacks.py:105 INFO train-abinet] epoch 6 iter 254100: loss = 0.5898,  smooth loss = 0.4965
[2022-07-07 01:48:19,708 callbacks.py:105 INFO train-abinet] epoch 6 iter 254150: loss = 0.4500,  smooth loss = 0.4962
[2022-07-07 01:49:03,323 callbacks.py:105 INFO train-abinet] epoch 6 iter 254200: loss = 0.4292,  smooth loss = 0.4824
[2022-07-07 01:49:46,478 callbacks.py:105 INFO train-abinet] epoch 6 iter 254250: loss = 0.5521,  smooth loss = 0.4910
[2022-07-07 01:50:29,547 callbacks.py:105 INFO train-abinet] epoch 6 iter 254300: loss = 0.4409,  smooth loss = 0.4837
[2022-07-07 01:51:10,860 callbacks.py:105 INFO train-abinet] epoch 6 iter 254350: loss = 0.5404,  smooth loss = 0.4809
[2022-07-07 01:51:51,660 callbacks.py:105 INFO train-abinet] epoch 6 iter 254400: loss = 0.5572,  smooth loss = 0.4695
[2022-07-07 01:52:34,180 callbacks.py:105 INFO train-abinet] epoch 6 iter 254450: loss = 0.4623,  smooth loss = 0.4935
[2022-07-07 01:53:14,264 callbacks.py:105 INFO train-abinet] epoch 6 iter 254500: loss = 0.5145,  smooth loss = 0.4893
[2022-07-07 01:53:55,549 callbacks.py:105 INFO train-abinet] epoch 6 iter 254550: loss = 0.5017,  smooth loss = 0.4825
[2022-07-07 01:54:36,771 callbacks.py:105 INFO train-abinet] epoch 6 iter 254600: loss = 0.4524,  smooth loss = 0.4764
[2022-07-07 01:55:17,258 callbacks.py:105 INFO train-abinet] epoch 6 iter 254650: loss = 0.4886,  smooth loss = 0.4776
[2022-07-07 01:55:58,274 callbacks.py:105 INFO train-abinet] epoch 6 iter 254700: loss = 0.3952,  smooth loss = 0.4762
[2022-07-07 01:56:39,463 callbacks.py:105 INFO train-abinet] epoch 6 iter 254750: loss = 0.3914,  smooth loss = 0.4723
[2022-07-07 01:57:20,159 callbacks.py:105 INFO train-abinet] epoch 6 iter 254800: loss = 0.3995,  smooth loss = 0.4700
[2022-07-07 01:58:00,991 callbacks.py:105 INFO train-abinet] epoch 6 iter 254850: loss = 0.5950,  smooth loss = 0.4825
[2022-07-07 01:58:41,375 callbacks.py:105 INFO train-abinet] epoch 6 iter 254900: loss = 0.4529,  smooth loss = 0.4840
[2022-07-07 01:59:21,734 callbacks.py:105 INFO train-abinet] epoch 6 iter 254950: loss = 0.5272,  smooth loss = 0.4890
[2022-07-07 02:00:02,294 callbacks.py:105 INFO train-abinet] epoch 6 iter 255000: loss = 0.5132,  smooth loss = 0.4962
[2022-07-07 02:00:02,294 callbacks.py:114 INFO train-abinet] average data time = 0.0051s, average running time = 0.8676s
█[2022-07-07 02:00:16,533 callbacks.py:123 INFO train-abinet] epoch 6 iter 255000: eval loss = 1.1592,  ccr = 0.9617,  cwr = 0.9226,  ted = 1242.0000,  ned = 247.3519,  ted/w = 0.1714, 
[2022-07-07 02:00:16,534 callbacks.py:130 INFO train-abinet] Better model found at epoch 6, iter 255000 with accuracy value: 0.9226.
[2022-07-07 02:00:17,691 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_255000
[2022-07-07 02:00:59,968 callbacks.py:105 INFO train-abinet] epoch 6 iter 255050: loss = 0.5890,  smooth loss = 0.4902
[2022-07-07 02:01:40,676 callbacks.py:105 INFO train-abinet] epoch 6 iter 255100: loss = 0.4271,  smooth loss = 0.4851
[2022-07-07 02:02:21,685 callbacks.py:105 INFO train-abinet] epoch 6 iter 255150: loss = 0.6289,  smooth loss = 0.4995
[2022-07-07 02:03:02,264 callbacks.py:105 INFO train-abinet] epoch 6 iter 255200: loss = 0.4509,  smooth loss = 0.4987
[2022-07-07 02:03:42,883 callbacks.py:105 INFO train-abinet] epoch 6 iter 255250: loss = 0.5653,  smooth loss = 0.5081
[2022-07-07 02:04:24,388 callbacks.py:105 INFO train-abinet] epoch 6 iter 255300: loss = 0.4655,  smooth loss = 0.4852
[2022-07-07 02:05:04,802 callbacks.py:105 INFO train-abinet] epoch 6 iter 255350: loss = 0.6316,  smooth loss = 0.4942
[2022-07-07 02:05:46,154 callbacks.py:105 INFO train-abinet] epoch 6 iter 255400: loss = 0.4339,  smooth loss = 0.4876
[2022-07-07 02:06:27,627 callbacks.py:105 INFO train-abinet] epoch 6 iter 255450: loss = 0.5976,  smooth loss = 0.4891
[2022-07-07 02:07:07,879 callbacks.py:105 INFO train-abinet] epoch 6 iter 255500: loss = 0.5917,  smooth loss = 0.4852
[2022-07-07 02:07:49,193 callbacks.py:105 INFO train-abinet] epoch 6 iter 255550: loss = 0.5432,  smooth loss = 0.4965
[2022-07-07 02:08:29,876 callbacks.py:105 INFO train-abinet] epoch 6 iter 255600: loss = 0.6249,  smooth loss = 0.4875
[2022-07-07 02:09:10,398 callbacks.py:105 INFO train-abinet] epoch 6 iter 255650: loss = 0.5683,  smooth loss = 0.4765
[2022-07-07 02:09:51,350 callbacks.py:105 INFO train-abinet] epoch 6 iter 255700: loss = 0.4830,  smooth loss = 0.4839
[2022-07-07 02:10:32,177 callbacks.py:105 INFO train-abinet] epoch 6 iter 255750: loss = 0.4860,  smooth loss = 0.4746
[2022-07-07 02:11:13,456 callbacks.py:105 INFO train-abinet] epoch 6 iter 255800: loss = 0.4589,  smooth loss = 0.4769
[2022-07-07 02:11:54,553 callbacks.py:105 INFO train-abinet] epoch 6 iter 255850: loss = 0.4482,  smooth loss = 0.4797
[2022-07-07 02:12:35,064 callbacks.py:105 INFO train-abinet] epoch 6 iter 255900: loss = 0.5771,  smooth loss = 0.4824
[2022-07-07 02:13:15,368 callbacks.py:105 INFO train-abinet] epoch 6 iter 255950: loss = 0.5857,  smooth loss = 0.4696
[2022-07-07 02:13:56,174 callbacks.py:105 INFO train-abinet] epoch 6 iter 256000: loss = 0.4863,  smooth loss = 0.4752
[2022-07-07 02:14:36,794 callbacks.py:105 INFO train-abinet] epoch 6 iter 256050: loss = 0.5401,  smooth loss = 0.4819
[2022-07-07 02:15:18,014 callbacks.py:105 INFO train-abinet] epoch 6 iter 256100: loss = 0.3468,  smooth loss = 0.4839
[2022-07-07 02:15:59,575 callbacks.py:105 INFO train-abinet] epoch 6 iter 256150: loss = 0.4682,  smooth loss = 0.4785
[2022-07-07 02:16:41,695 callbacks.py:105 INFO train-abinet] epoch 6 iter 256200: loss = 0.3815,  smooth loss = 0.4766
[2022-07-07 02:17:22,352 callbacks.py:105 INFO train-abinet] epoch 6 iter 256250: loss = 0.5052,  smooth loss = 0.4799
[2022-07-07 02:18:03,512 callbacks.py:105 INFO train-abinet] epoch 6 iter 256300: loss = 0.4758,  smooth loss = 0.4810
[2022-07-07 02:18:44,908 callbacks.py:105 INFO train-abinet] epoch 6 iter 256350: loss = 0.3855,  smooth loss = 0.4748
[2022-07-07 02:19:26,207 callbacks.py:105 INFO train-abinet] epoch 6 iter 256400: loss = 0.4917,  smooth loss = 0.4782
[2022-07-07 02:20:06,767 callbacks.py:105 INFO train-abinet] epoch 6 iter 256450: loss = 0.4689,  smooth loss = 0.4838
[2022-07-07 02:20:47,689 callbacks.py:105 INFO train-abinet] epoch 6 iter 256500: loss = 0.6279,  smooth loss = 0.4812
[2022-07-07 02:21:27,963 callbacks.py:105 INFO train-abinet] epoch 6 iter 256550: loss = 0.4071,  smooth loss = 0.4825
[2022-07-07 02:22:09,214 callbacks.py:105 INFO train-abinet] epoch 6 iter 256600: loss = 0.5696,  smooth loss = 0.4847
[2022-07-07 02:22:51,076 callbacks.py:105 INFO train-abinet] epoch 6 iter 256650: loss = 0.4522,  smooth loss = 0.4861
[2022-07-07 02:23:32,761 callbacks.py:105 INFO train-abinet] epoch 6 iter 256700: loss = 0.5857,  smooth loss = 0.4899
[2022-07-07 02:24:14,466 callbacks.py:105 INFO train-abinet] epoch 6 iter 256750: loss = 0.5169,  smooth loss = 0.4799
[2022-07-07 02:24:55,355 callbacks.py:105 INFO train-abinet] epoch 6 iter 256800: loss = 0.3736,  smooth loss = 0.4755
[2022-07-07 02:25:39,085 callbacks.py:105 INFO train-abinet] epoch 6 iter 256850: loss = 0.5203,  smooth loss = 0.4752
[2022-07-07 02:26:22,351 callbacks.py:105 INFO train-abinet] epoch 6 iter 256900: loss = 0.2832,  smooth loss = 0.4712
[2022-07-07 02:27:04,816 callbacks.py:105 INFO train-abinet] epoch 6 iter 256950: loss = 0.4820,  smooth loss = 0.4838
[2022-07-07 02:27:49,428 callbacks.py:105 INFO train-abinet] epoch 6 iter 257000: loss = 0.5020,  smooth loss = 0.4913
[2022-07-07 02:28:29,827 callbacks.py:105 INFO train-abinet] epoch 6 iter 257050: loss = 0.5400,  smooth loss = 0.4877
[2022-07-07 02:29:10,479 callbacks.py:105 INFO train-abinet] epoch 6 iter 257100: loss = 0.3867,  smooth loss = 0.4837
[2022-07-07 02:29:51,401 callbacks.py:105 INFO train-abinet] epoch 6 iter 257150: loss = 0.6007,  smooth loss = 0.4943
[2022-07-07 02:30:31,896 callbacks.py:105 INFO train-abinet] epoch 6 iter 257200: loss = 0.4661,  smooth loss = 0.4957
[2022-07-07 02:31:12,474 callbacks.py:105 INFO train-abinet] epoch 6 iter 257250: loss = 0.4534,  smooth loss = 0.4809
[2022-07-07 02:31:53,326 callbacks.py:105 INFO train-abinet] epoch 6 iter 257300: loss = 0.4041,  smooth loss = 0.4834
[2022-07-07 02:32:34,296 callbacks.py:105 INFO train-abinet] epoch 6 iter 257350: loss = 0.5011,  smooth loss = 0.4868
[2022-07-07 02:33:15,225 callbacks.py:105 INFO train-abinet] epoch 6 iter 257400: loss = 0.4299,  smooth loss = 0.4782
[2022-07-07 02:33:56,252 callbacks.py:105 INFO train-abinet] epoch 6 iter 257450: loss = 0.4997,  smooth loss = 0.4884
[2022-07-07 02:34:37,352 callbacks.py:105 INFO train-abinet] epoch 6 iter 257500: loss = 0.6112,  smooth loss = 0.4956
[2022-07-07 02:35:18,318 callbacks.py:105 INFO train-abinet] epoch 6 iter 257550: loss = 0.4765,  smooth loss = 0.5018
[2022-07-07 02:36:00,254 callbacks.py:105 INFO train-abinet] epoch 6 iter 257600: loss = 0.4946,  smooth loss = 0.5072
[2022-07-07 02:36:42,245 callbacks.py:105 INFO train-abinet] epoch 6 iter 257650: loss = 0.4098,  smooth loss = 0.4891
[2022-07-07 02:37:23,916 callbacks.py:105 INFO train-abinet] epoch 6 iter 257700: loss = 0.4441,  smooth loss = 0.4879
[2022-07-07 02:38:05,460 callbacks.py:105 INFO train-abinet] epoch 6 iter 257750: loss = 0.5404,  smooth loss = 0.4935
[2022-07-07 02:38:46,875 callbacks.py:105 INFO train-abinet] epoch 6 iter 257800: loss = 0.4982,  smooth loss = 0.4777
[2022-07-07 02:39:28,359 callbacks.py:105 INFO train-abinet] epoch 6 iter 257850: loss = 0.3628,  smooth loss = 0.4931
[2022-07-07 02:40:09,730 callbacks.py:105 INFO train-abinet] epoch 6 iter 257900: loss = 0.5475,  smooth loss = 0.4972
[2022-07-07 02:40:50,732 callbacks.py:105 INFO train-abinet] epoch 6 iter 257950: loss = 0.4379,  smooth loss = 0.4993
[2022-07-07 02:41:32,181 callbacks.py:105 INFO train-abinet] epoch 6 iter 258000: loss = 0.4759,  smooth loss = 0.4868
[2022-07-07 02:41:32,182 callbacks.py:114 INFO train-abinet] average data time = 0.0051s, average running time = 0.8672s
█[2022-07-07 02:41:46,880 callbacks.py:123 INFO train-abinet] epoch 6 iter 258000: eval loss = 1.1585,  ccr = 0.9629,  cwr = 0.9245,  ted = 1216.0000,  ned = 245.7751,  ted/w = 0.1678, 
[2022-07-07 02:41:46,883 callbacks.py:130 INFO train-abinet] Better model found at epoch 6, iter 258000 with accuracy value: 0.9245.
[2022-07-07 02:41:47,843 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_258000
[2022-07-07 02:42:30,756 callbacks.py:105 INFO train-abinet] epoch 6 iter 258050: loss = 0.5083,  smooth loss = 0.4893
[2022-07-07 02:43:11,869 callbacks.py:105 INFO train-abinet] epoch 6 iter 258100: loss = 0.5693,  smooth loss = 0.4803
[2022-07-07 02:43:52,320 callbacks.py:105 INFO train-abinet] epoch 6 iter 258150: loss = 0.4538,  smooth loss = 0.4904
[2022-07-07 02:44:33,767 callbacks.py:105 INFO train-abinet] epoch 6 iter 258200: loss = 0.3764,  smooth loss = 0.4917
[2022-07-07 02:45:14,490 callbacks.py:105 INFO train-abinet] epoch 6 iter 258250: loss = 0.6038,  smooth loss = 0.4868
[2022-07-07 02:45:55,491 callbacks.py:105 INFO train-abinet] epoch 6 iter 258300: loss = 0.4633,  smooth loss = 0.4880
[2022-07-07 02:46:35,809 callbacks.py:105 INFO train-abinet] epoch 6 iter 258350: loss = 0.3109,  smooth loss = 0.4814
[2022-07-07 02:47:16,249 callbacks.py:105 INFO train-abinet] epoch 6 iter 258400: loss = 0.4958,  smooth loss = 0.4860
[2022-07-07 02:47:56,898 callbacks.py:105 INFO train-abinet] epoch 6 iter 258450: loss = 0.4658,  smooth loss = 0.4886
[2022-07-07 02:48:38,423 callbacks.py:105 INFO train-abinet] epoch 6 iter 258500: loss = 0.4205,  smooth loss = 0.4794
[2022-07-07 02:49:19,628 callbacks.py:105 INFO train-abinet] epoch 6 iter 258550: loss = 0.4031,  smooth loss = 0.4758
[2022-07-07 02:50:00,267 callbacks.py:105 INFO train-abinet] epoch 6 iter 258600: loss = 0.4233,  smooth loss = 0.4829
[2022-07-07 02:50:41,338 callbacks.py:105 INFO train-abinet] epoch 6 iter 258650: loss = 0.6025,  smooth loss = 0.4839
[2022-07-07 02:51:22,778 callbacks.py:105 INFO train-abinet] epoch 6 iter 258700: loss = 0.5339,  smooth loss = 0.4754
[2022-07-07 02:52:03,484 callbacks.py:105 INFO train-abinet] epoch 6 iter 258750: loss = 0.4226,  smooth loss = 0.4678
[2022-07-07 02:52:44,173 callbacks.py:105 INFO train-abinet] epoch 6 iter 258800: loss = 0.4066,  smooth loss = 0.4619
[2022-07-07 02:53:24,530 callbacks.py:105 INFO train-abinet] epoch 6 iter 258850: loss = 0.4472,  smooth loss = 0.4804
[2022-07-07 02:54:05,610 callbacks.py:105 INFO train-abinet] epoch 6 iter 258900: loss = 0.5572,  smooth loss = 0.4741
[2022-07-07 02:54:45,864 callbacks.py:105 INFO train-abinet] epoch 6 iter 258950: loss = 0.4845,  smooth loss = 0.4765
[2022-07-07 02:55:26,370 callbacks.py:105 INFO train-abinet] epoch 6 iter 259000: loss = 0.5634,  smooth loss = 0.4913
[2022-07-07 02:56:07,155 callbacks.py:105 INFO train-abinet] epoch 6 iter 259050: loss = 0.5664,  smooth loss = 0.4903
[2022-07-07 02:56:47,571 callbacks.py:105 INFO train-abinet] epoch 6 iter 259100: loss = 0.3758,  smooth loss = 0.4731
[2022-07-07 02:57:28,286 callbacks.py:105 INFO train-abinet] epoch 6 iter 259150: loss = 0.5731,  smooth loss = 0.4793
[2022-07-07 02:58:08,661 callbacks.py:105 INFO train-abinet] epoch 6 iter 259200: loss = 0.4928,  smooth loss = 0.4863
[2022-07-07 02:58:49,667 callbacks.py:105 INFO train-abinet] epoch 6 iter 259250: loss = 0.4905,  smooth loss = 0.4820
[2022-07-07 02:59:31,229 callbacks.py:105 INFO train-abinet] epoch 6 iter 259300: loss = 0.4432,  smooth loss = 0.4788
[2022-07-07 03:00:12,912 callbacks.py:105 INFO train-abinet] epoch 6 iter 259350: loss = 0.4568,  smooth loss = 0.4832
[2022-07-07 03:00:54,101 callbacks.py:105 INFO train-abinet] epoch 6 iter 259400: loss = 0.4201,  smooth loss = 0.4863
[2022-07-07 03:01:36,637 callbacks.py:105 INFO train-abinet] epoch 6 iter 259450: loss = 0.4511,  smooth loss = 0.4870
[2022-07-07 03:02:18,805 callbacks.py:105 INFO train-abinet] epoch 6 iter 259500: loss = 0.5175,  smooth loss = 0.4731
[2022-07-07 03:02:59,373 callbacks.py:105 INFO train-abinet] epoch 6 iter 259550: loss = 0.4607,  smooth loss = 0.4739
[2022-07-07 03:03:41,316 callbacks.py:105 INFO train-abinet] epoch 6 iter 259600: loss = 0.4877,  smooth loss = 0.4754
[2022-07-07 03:04:22,728 callbacks.py:105 INFO train-abinet] epoch 6 iter 259650: loss = 0.3489,  smooth loss = 0.4761
[2022-07-07 03:05:03,861 callbacks.py:105 INFO train-abinet] epoch 6 iter 259700: loss = 0.4666,  smooth loss = 0.4743
[2022-07-07 03:05:44,951 callbacks.py:105 INFO train-abinet] epoch 6 iter 259750: loss = 0.5380,  smooth loss = 0.4757
[2022-07-07 03:06:26,566 callbacks.py:105 INFO train-abinet] epoch 6 iter 259800: loss = 0.4815,  smooth loss = 0.4823
[2022-07-07 03:07:08,030 callbacks.py:105 INFO train-abinet] epoch 6 iter 259850: loss = 0.3301,  smooth loss = 0.4785
[2022-07-07 03:07:50,179 callbacks.py:105 INFO train-abinet] epoch 6 iter 259900: loss = 0.5833,  smooth loss = 0.4840
[2022-07-07 03:08:31,430 callbacks.py:105 INFO train-abinet] epoch 6 iter 259950: loss = 0.4921,  smooth loss = 0.4971
[2022-07-07 03:09:13,355 callbacks.py:105 INFO train-abinet] epoch 6 iter 260000: loss = 0.4839,  smooth loss = 0.4842
[2022-07-07 03:09:55,762 callbacks.py:105 INFO train-abinet] epoch 6 iter 260050: loss = 0.4884,  smooth loss = 0.4870
[2022-07-07 03:10:39,120 callbacks.py:105 INFO train-abinet] epoch 6 iter 260100: loss = 0.5108,  smooth loss = 0.4784
[2022-07-07 03:11:22,770 callbacks.py:105 INFO train-abinet] epoch 6 iter 260150: loss = 0.5612,  smooth loss = 0.4784
[2022-07-07 03:12:05,577 callbacks.py:105 INFO train-abinet] epoch 6 iter 260200: loss = 0.6076,  smooth loss = 0.4824
[2022-07-07 03:12:49,125 callbacks.py:105 INFO train-abinet] epoch 6 iter 260250: loss = 0.2774,  smooth loss = 0.4807
[2022-07-07 03:13:30,149 callbacks.py:105 INFO train-abinet] epoch 6 iter 260300: loss = 0.6211,  smooth loss = 0.4817
[2022-07-07 03:14:11,771 callbacks.py:105 INFO train-abinet] epoch 6 iter 260350: loss = 0.5122,  smooth loss = 0.4742
[2022-07-07 03:14:53,311 callbacks.py:105 INFO train-abinet] epoch 6 iter 260400: loss = 0.4674,  smooth loss = 0.4708
[2022-07-07 03:15:35,398 callbacks.py:105 INFO train-abinet] epoch 6 iter 260450: loss = 0.4073,  smooth loss = 0.4754
[2022-07-07 03:16:18,539 callbacks.py:105 INFO train-abinet] epoch 6 iter 260500: loss = 0.4074,  smooth loss = 0.4714
[2022-07-07 03:17:00,749 callbacks.py:105 INFO train-abinet] epoch 6 iter 260550: loss = 0.5578,  smooth loss = 0.4830
[2022-07-07 03:17:45,634 callbacks.py:105 INFO train-abinet] epoch 6 iter 260600: loss = 0.4929,  smooth loss = 0.4771
[2022-07-07 03:18:27,003 callbacks.py:105 INFO train-abinet] epoch 6 iter 260650: loss = 0.5818,  smooth loss = 0.4747
[2022-07-07 03:19:09,234 callbacks.py:105 INFO train-abinet] epoch 6 iter 260700: loss = 0.4088,  smooth loss = 0.4833
[2022-07-07 03:19:50,848 callbacks.py:105 INFO train-abinet] epoch 6 iter 260750: loss = 0.4716,  smooth loss = 0.4782
[2022-07-07 03:20:32,549 callbacks.py:105 INFO train-abinet] epoch 6 iter 260800: loss = 0.3885,  smooth loss = 0.4706
[2022-07-07 03:21:12,735 callbacks.py:105 INFO train-abinet] epoch 6 iter 260850: loss = 0.3592,  smooth loss = 0.4590
[2022-07-07 03:21:53,647 callbacks.py:105 INFO train-abinet] epoch 6 iter 260900: loss = 0.4180,  smooth loss = 0.4641
[2022-07-07 03:22:34,299 callbacks.py:105 INFO train-abinet] epoch 6 iter 260950: loss = 0.5576,  smooth loss = 0.4654
[2022-07-07 03:23:15,307 callbacks.py:105 INFO train-abinet] epoch 6 iter 261000: loss = 0.5128,  smooth loss = 0.4717
[2022-07-07 03:23:15,308 callbacks.py:114 INFO train-abinet] average data time = 0.0050s, average running time = 0.8668s
█[2022-07-07 03:23:29,847 callbacks.py:123 INFO train-abinet] epoch 6 iter 261000: eval loss = 1.1721,  ccr = 0.9628,  cwr = 0.9240,  ted = 1216.0000,  ned = 245.8577,  ted/w = 0.1678, 
[2022-07-07 03:23:29,848 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_261000
[2022-07-07 03:24:11,814 callbacks.py:105 INFO train-abinet] epoch 6 iter 261050: loss = 0.6236,  smooth loss = 0.4861
[2022-07-07 03:24:53,121 callbacks.py:105 INFO train-abinet] epoch 6 iter 261100: loss = 0.4916,  smooth loss = 0.4738
[2022-07-07 03:25:33,519 callbacks.py:105 INFO train-abinet] epoch 6 iter 261150: loss = 0.4696,  smooth loss = 0.4727
[2022-07-07 03:26:14,159 callbacks.py:105 INFO train-abinet] epoch 6 iter 261200: loss = 0.4244,  smooth loss = 0.4660
[2022-07-07 03:26:55,007 callbacks.py:105 INFO train-abinet] epoch 6 iter 261250: loss = 0.4572,  smooth loss = 0.4656
[2022-07-07 03:27:36,174 callbacks.py:105 INFO train-abinet] epoch 6 iter 261300: loss = 0.4576,  smooth loss = 0.4768
[2022-07-07 03:28:17,619 callbacks.py:105 INFO train-abinet] epoch 6 iter 261350: loss = 0.5241,  smooth loss = 0.4736
[2022-07-07 03:28:57,903 callbacks.py:105 INFO train-abinet] epoch 6 iter 261400: loss = 0.3310,  smooth loss = 0.4672
[2022-07-07 03:29:39,006 callbacks.py:105 INFO train-abinet] epoch 6 iter 261450: loss = 0.3735,  smooth loss = 0.4634
[2022-07-07 03:30:20,697 callbacks.py:105 INFO train-abinet] epoch 6 iter 261500: loss = 0.6107,  smooth loss = 0.4665
[2022-07-07 03:31:03,038 callbacks.py:105 INFO train-abinet] epoch 6 iter 261550: loss = 0.5766,  smooth loss = 0.4690
[2022-07-07 03:31:45,455 callbacks.py:105 INFO train-abinet] epoch 6 iter 261600: loss = 0.4677,  smooth loss = 0.4718
[2022-07-07 03:32:29,944 callbacks.py:105 INFO train-abinet] epoch 6 iter 261650: loss = 0.5871,  smooth loss = 0.4703
[2022-07-07 03:33:11,771 callbacks.py:105 INFO train-abinet] epoch 6 iter 261700: loss = 0.4588,  smooth loss = 0.4739
[2022-07-07 03:33:52,491 callbacks.py:105 INFO train-abinet] epoch 6 iter 261750: loss = 0.4170,  smooth loss = 0.4814
[2022-07-07 03:34:33,751 callbacks.py:105 INFO train-abinet] epoch 6 iter 261800: loss = 0.5673,  smooth loss = 0.4808
[2022-07-07 03:35:14,516 callbacks.py:105 INFO train-abinet] epoch 6 iter 261850: loss = 0.4155,  smooth loss = 0.4640
[2022-07-07 03:35:56,520 callbacks.py:105 INFO train-abinet] epoch 6 iter 261900: loss = 0.4795,  smooth loss = 0.4737
[2022-07-07 03:36:37,152 callbacks.py:105 INFO train-abinet] epoch 6 iter 261950: loss = 0.4787,  smooth loss = 0.4662
[2022-07-07 03:37:20,103 callbacks.py:105 INFO train-abinet] epoch 6 iter 262000: loss = 0.4712,  smooth loss = 0.4782
[2022-07-07 03:38:01,679 callbacks.py:105 INFO train-abinet] epoch 6 iter 262050: loss = 0.5760,  smooth loss = 0.4676
[2022-07-07 03:38:42,666 callbacks.py:105 INFO train-abinet] epoch 6 iter 262100: loss = 0.3249,  smooth loss = 0.4790
[2022-07-07 03:39:23,729 callbacks.py:105 INFO train-abinet] epoch 6 iter 262150: loss = 0.5376,  smooth loss = 0.4878
[2022-07-07 03:40:04,447 callbacks.py:105 INFO train-abinet] epoch 6 iter 262200: loss = 0.5242,  smooth loss = 0.4806
[2022-07-07 03:40:45,669 callbacks.py:105 INFO train-abinet] epoch 6 iter 262250: loss = 0.5944,  smooth loss = 0.4858
[2022-07-07 03:41:27,200 callbacks.py:105 INFO train-abinet] epoch 6 iter 262300: loss = 0.4431,  smooth loss = 0.4961
[2022-07-07 03:42:07,949 callbacks.py:105 INFO train-abinet] epoch 6 iter 262350: loss = 0.3955,  smooth loss = 0.5050
[2022-07-07 03:42:49,402 callbacks.py:105 INFO train-abinet] epoch 6 iter 262400: loss = 0.4835,  smooth loss = 0.4944
[2022-07-07 03:43:29,585 callbacks.py:105 INFO train-abinet] epoch 6 iter 262450: loss = 0.4512,  smooth loss = 0.4853
[2022-07-07 03:44:10,318 callbacks.py:105 INFO train-abinet] epoch 6 iter 262500: loss = 0.4459,  smooth loss = 0.4895
[2022-07-07 03:44:51,189 callbacks.py:105 INFO train-abinet] epoch 6 iter 262550: loss = 0.4160,  smooth loss = 0.4808
[2022-07-07 03:45:32,063 callbacks.py:105 INFO train-abinet] epoch 6 iter 262600: loss = 0.4029,  smooth loss = 0.4852
[2022-07-07 03:46:12,577 callbacks.py:105 INFO train-abinet] epoch 6 iter 262650: loss = 0.4186,  smooth loss = 0.4857
[2022-07-07 03:46:53,074 callbacks.py:105 INFO train-abinet] epoch 6 iter 262700: loss = 0.6394,  smooth loss = 0.4780
[2022-07-07 03:47:33,586 callbacks.py:105 INFO train-abinet] epoch 6 iter 262750: loss = 0.5654,  smooth loss = 0.4853
[2022-07-07 03:48:14,221 callbacks.py:105 INFO train-abinet] epoch 6 iter 262800: loss = 0.4295,  smooth loss = 0.4771
[2022-07-07 03:48:55,143 callbacks.py:105 INFO train-abinet] epoch 6 iter 262850: loss = 0.5030,  smooth loss = 0.4875
[2022-07-07 03:49:35,186 callbacks.py:105 INFO train-abinet] epoch 6 iter 262900: loss = 0.4347,  smooth loss = 0.4870
[2022-07-07 03:50:15,533 callbacks.py:105 INFO train-abinet] epoch 6 iter 262950: loss = 0.4956,  smooth loss = 0.4779
[2022-07-07 03:50:56,142 callbacks.py:105 INFO train-abinet] epoch 6 iter 263000: loss = 0.3384,  smooth loss = 0.4694
[2022-07-07 03:51:36,981 callbacks.py:105 INFO train-abinet] epoch 6 iter 263050: loss = 0.4424,  smooth loss = 0.4795
[2022-07-07 03:52:18,425 callbacks.py:105 INFO train-abinet] epoch 6 iter 263100: loss = 0.4832,  smooth loss = 0.4830
[2022-07-07 03:52:59,138 callbacks.py:105 INFO train-abinet] epoch 6 iter 263150: loss = 0.4710,  smooth loss = 0.4765
[2022-07-07 03:53:39,280 callbacks.py:105 INFO train-abinet] epoch 6 iter 263200: loss = 0.5782,  smooth loss = 0.4841
[2022-07-07 03:54:19,657 callbacks.py:105 INFO train-abinet] epoch 6 iter 263250: loss = 0.4966,  smooth loss = 0.4740
[2022-07-07 03:55:00,700 callbacks.py:105 INFO train-abinet] epoch 6 iter 263300: loss = 0.3999,  smooth loss = 0.4700
[2022-07-07 03:55:41,788 callbacks.py:105 INFO train-abinet] epoch 6 iter 263350: loss = 0.4015,  smooth loss = 0.4774
[2022-07-07 03:56:22,171 callbacks.py:105 INFO train-abinet] epoch 6 iter 263400: loss = 0.5889,  smooth loss = 0.4883
[2022-07-07 03:57:02,198 callbacks.py:105 INFO train-abinet] epoch 6 iter 263450: loss = 0.4622,  smooth loss = 0.4776
[2022-07-07 03:57:42,695 callbacks.py:105 INFO train-abinet] epoch 6 iter 263500: loss = 0.4986,  smooth loss = 0.4904
[2022-07-07 03:58:22,793 callbacks.py:105 INFO train-abinet] epoch 6 iter 263550: loss = 0.4426,  smooth loss = 0.4876
[2022-07-07 03:59:02,815 callbacks.py:105 INFO train-abinet] epoch 6 iter 263600: loss = 0.4305,  smooth loss = 0.4683
[2022-07-07 03:59:43,066 callbacks.py:105 INFO train-abinet] epoch 6 iter 263650: loss = 0.3915,  smooth loss = 0.4820
[2022-07-07 04:00:24,136 callbacks.py:105 INFO train-abinet] epoch 6 iter 263700: loss = 0.6142,  smooth loss = 0.4925
[2022-07-07 04:01:04,652 callbacks.py:105 INFO train-abinet] epoch 6 iter 263750: loss = 0.5584,  smooth loss = 0.4904
[2022-07-07 04:01:45,080 callbacks.py:105 INFO train-abinet] epoch 6 iter 263800: loss = 0.5203,  smooth loss = 0.4938
[2022-07-07 04:02:25,636 callbacks.py:105 INFO train-abinet] epoch 6 iter 263850: loss = 0.4816,  smooth loss = 0.4781
[2022-07-07 04:03:06,598 callbacks.py:105 INFO train-abinet] epoch 6 iter 263900: loss = 0.4933,  smooth loss = 0.4671
[2022-07-07 04:03:47,489 callbacks.py:105 INFO train-abinet] epoch 6 iter 263950: loss = 0.5193,  smooth loss = 0.4834
[2022-07-07 04:04:28,102 callbacks.py:105 INFO train-abinet] epoch 6 iter 264000: loss = 0.4393,  smooth loss = 0.4795
[2022-07-07 04:04:28,103 callbacks.py:114 INFO train-abinet] average data time = 0.0050s, average running time = 0.8662s
█[2022-07-07 04:04:41,914 callbacks.py:123 INFO train-abinet] epoch 6 iter 264000: eval loss = 1.1647,  ccr = 0.9627,  cwr = 0.9234,  ted = 1225.0000,  ned = 244.6749,  ted/w = 0.1690, 
[2022-07-07 04:04:41,915 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_264000
[2022-07-07 04:05:23,172 callbacks.py:105 INFO train-abinet] epoch 6 iter 264050: loss = 0.5172,  smooth loss = 0.4799
[2022-07-07 04:06:04,379 callbacks.py:105 INFO train-abinet] epoch 6 iter 264100: loss = 0.6159,  smooth loss = 0.4851
[2022-07-07 04:06:44,548 callbacks.py:105 INFO train-abinet] epoch 6 iter 264150: loss = 0.4616,  smooth loss = 0.4858
[2022-07-07 04:07:25,120 callbacks.py:105 INFO train-abinet] epoch 6 iter 264200: loss = 0.3650,  smooth loss = 0.4777
[2022-07-07 04:08:05,663 callbacks.py:105 INFO train-abinet] epoch 6 iter 264250: loss = 0.6379,  smooth loss = 0.4800
[2022-07-07 04:08:46,125 callbacks.py:105 INFO train-abinet] epoch 6 iter 264300: loss = 0.4293,  smooth loss = 0.4746
[2022-07-07 04:09:26,359 callbacks.py:105 INFO train-abinet] epoch 6 iter 264350: loss = 0.4662,  smooth loss = 0.4890
[2022-07-07 04:10:07,095 callbacks.py:105 INFO train-abinet] epoch 6 iter 264400: loss = 0.4400,  smooth loss = 0.4862
[2022-07-07 04:10:48,706 callbacks.py:105 INFO train-abinet] epoch 6 iter 264450: loss = 0.3853,  smooth loss = 0.4770
[2022-07-07 04:11:28,675 callbacks.py:105 INFO train-abinet] epoch 6 iter 264500: loss = 0.3721,  smooth loss = 0.4810
[2022-07-07 04:12:09,601 callbacks.py:105 INFO train-abinet] epoch 6 iter 264550: loss = 0.6425,  smooth loss = 0.4903
[2022-07-07 04:12:51,011 callbacks.py:105 INFO train-abinet] epoch 6 iter 264600: loss = 0.4386,  smooth loss = 0.4843
[2022-07-07 04:13:32,194 callbacks.py:105 INFO train-abinet] epoch 6 iter 264650: loss = 0.4416,  smooth loss = 0.4903
[2022-07-07 04:14:13,380 callbacks.py:105 INFO train-abinet] epoch 6 iter 264700: loss = 0.4574,  smooth loss = 0.4777
[2022-07-07 04:14:54,723 callbacks.py:105 INFO train-abinet] epoch 6 iter 264750: loss = 0.4627,  smooth loss = 0.4823
[2022-07-07 04:15:34,885 callbacks.py:105 INFO train-abinet] epoch 6 iter 264800: loss = 0.4642,  smooth loss = 0.4796
[2022-07-07 04:16:15,904 callbacks.py:105 INFO train-abinet] epoch 6 iter 264850: loss = 0.5249,  smooth loss = 0.4777
[2022-07-07 04:16:56,681 callbacks.py:105 INFO train-abinet] epoch 6 iter 264900: loss = 0.4663,  smooth loss = 0.4763
[2022-07-07 04:17:37,472 callbacks.py:105 INFO train-abinet] epoch 6 iter 264950: loss = 0.4444,  smooth loss = 0.4830
[2022-07-07 04:18:17,890 callbacks.py:105 INFO train-abinet] epoch 6 iter 265000: loss = 0.4095,  smooth loss = 0.4778
[2022-07-07 04:18:58,338 callbacks.py:105 INFO train-abinet] epoch 6 iter 265050: loss = 0.4941,  smooth loss = 0.4830
[2022-07-07 04:19:39,645 callbacks.py:105 INFO train-abinet] epoch 6 iter 265100: loss = 0.4377,  smooth loss = 0.4766
[2022-07-07 04:20:20,499 callbacks.py:105 INFO train-abinet] epoch 6 iter 265150: loss = 0.3541,  smooth loss = 0.4741
[2022-07-07 04:21:01,078 callbacks.py:105 INFO train-abinet] epoch 6 iter 265200: loss = 0.3761,  smooth loss = 0.4676
[2022-07-07 04:21:42,052 callbacks.py:105 INFO train-abinet] epoch 6 iter 265250: loss = 0.3457,  smooth loss = 0.4735
[2022-07-07 04:22:23,011 callbacks.py:105 INFO train-abinet] epoch 6 iter 265300: loss = 0.5491,  smooth loss = 0.4673
[2022-07-07 04:23:03,908 callbacks.py:105 INFO train-abinet] epoch 6 iter 265350: loss = 0.5700,  smooth loss = 0.4729
[2022-07-07 04:23:45,471 callbacks.py:105 INFO train-abinet] epoch 6 iter 265400: loss = 0.4361,  smooth loss = 0.4788
[2022-07-07 04:24:26,200 callbacks.py:105 INFO train-abinet] epoch 6 iter 265450: loss = 0.5052,  smooth loss = 0.4713
[2022-07-07 04:25:06,966 callbacks.py:105 INFO train-abinet] epoch 6 iter 265500: loss = 0.4266,  smooth loss = 0.4758
[2022-07-07 04:25:47,900 callbacks.py:105 INFO train-abinet] epoch 6 iter 265550: loss = 0.4316,  smooth loss = 0.4675
[2022-07-07 04:26:28,905 callbacks.py:105 INFO train-abinet] epoch 6 iter 265600: loss = 0.3699,  smooth loss = 0.4757
[2022-07-07 04:27:08,876 callbacks.py:105 INFO train-abinet] epoch 6 iter 265650: loss = 0.5287,  smooth loss = 0.4710
[2022-07-07 04:27:49,337 callbacks.py:105 INFO train-abinet] epoch 6 iter 265700: loss = 0.4362,  smooth loss = 0.4666
[2022-07-07 04:28:29,492 callbacks.py:105 INFO train-abinet] epoch 6 iter 265750: loss = 0.3998,  smooth loss = 0.4737
[2022-07-07 04:29:10,543 callbacks.py:105 INFO train-abinet] epoch 6 iter 265800: loss = 0.5377,  smooth loss = 0.4795
[2022-07-07 04:29:51,033 callbacks.py:105 INFO train-abinet] epoch 6 iter 265850: loss = 0.3703,  smooth loss = 0.4833
[2022-07-07 04:30:30,947 callbacks.py:105 INFO train-abinet] epoch 6 iter 265900: loss = 0.3208,  smooth loss = 0.4629
[2022-07-07 04:31:11,463 callbacks.py:105 INFO train-abinet] epoch 6 iter 265950: loss = 0.4922,  smooth loss = 0.4716
[2022-07-07 04:31:52,553 callbacks.py:105 INFO train-abinet] epoch 6 iter 266000: loss = 0.4470,  smooth loss = 0.4831
[2022-07-07 04:32:32,873 callbacks.py:105 INFO train-abinet] epoch 6 iter 266050: loss = 0.5156,  smooth loss = 0.4775
[2022-07-07 04:33:13,586 callbacks.py:105 INFO train-abinet] epoch 6 iter 266100: loss = 0.6923,  smooth loss = 0.4789
[2022-07-07 04:33:54,306 callbacks.py:105 INFO train-abinet] epoch 6 iter 266150: loss = 0.3858,  smooth loss = 0.4775
[2022-07-07 04:34:34,449 callbacks.py:105 INFO train-abinet] epoch 6 iter 266200: loss = 0.4794,  smooth loss = 0.4837
[2022-07-07 04:35:15,225 callbacks.py:105 INFO train-abinet] epoch 6 iter 266250: loss = 0.3787,  smooth loss = 0.4745
[2022-07-07 04:35:55,534 callbacks.py:105 INFO train-abinet] epoch 6 iter 266300: loss = 0.4535,  smooth loss = 0.4733
[2022-07-07 04:36:35,889 callbacks.py:105 INFO train-abinet] epoch 6 iter 266350: loss = 0.4047,  smooth loss = 0.4778
[2022-07-07 04:37:16,050 callbacks.py:105 INFO train-abinet] epoch 6 iter 266400: loss = 0.7438,  smooth loss = 0.4776
[2022-07-07 04:37:56,284 callbacks.py:105 INFO train-abinet] epoch 6 iter 266450: loss = 0.4776,  smooth loss = 0.4832
[2022-07-07 04:38:36,089 callbacks.py:105 INFO train-abinet] epoch 6 iter 266500: loss = 0.4536,  smooth loss = 0.4840
[2022-07-07 04:39:17,338 callbacks.py:105 INFO train-abinet] epoch 6 iter 266550: loss = 0.4136,  smooth loss = 0.4824
[2022-07-07 04:39:57,801 callbacks.py:105 INFO train-abinet] epoch 6 iter 266600: loss = 0.4692,  smooth loss = 0.4777
[2022-07-07 04:40:37,888 callbacks.py:105 INFO train-abinet] epoch 6 iter 266650: loss = 0.4313,  smooth loss = 0.4667
[2022-07-07 04:41:18,048 callbacks.py:105 INFO train-abinet] epoch 6 iter 266700: loss = 0.4666,  smooth loss = 0.4811
[2022-07-07 04:41:58,634 callbacks.py:105 INFO train-abinet] epoch 6 iter 266750: loss = 0.4940,  smooth loss = 0.4694
[2022-07-07 04:42:38,761 callbacks.py:105 INFO train-abinet] epoch 6 iter 266800: loss = 0.6146,  smooth loss = 0.4800
[2022-07-07 04:43:18,609 callbacks.py:105 INFO train-abinet] epoch 6 iter 266850: loss = 0.3296,  smooth loss = 0.4701
[2022-07-07 04:43:59,032 callbacks.py:105 INFO train-abinet] epoch 6 iter 266900: loss = 0.5080,  smooth loss = 0.4731
[2022-07-07 04:44:39,314 callbacks.py:105 INFO train-abinet] epoch 6 iter 266950: loss = 0.5130,  smooth loss = 0.4718
[2022-07-07 04:45:28,624 callbacks.py:105 INFO train-abinet] epoch 6 iter 267000: loss = 0.5677,  smooth loss = 0.4561
[2022-07-07 04:45:28,625 callbacks.py:114 INFO train-abinet] average data time = 0.0050s, average running time = 0.8657s
█[2022-07-07 04:45:42,420 callbacks.py:123 INFO train-abinet] epoch 6 iter 267000: eval loss = 1.1641,  ccr = 0.9629,  cwr = 0.9234,  ted = 1215.0000,  ned = 243.0924,  ted/w = 0.1676, 
[2022-07-07 04:45:42,422 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_267000
[2022-07-07 04:46:24,595 callbacks.py:105 INFO train-abinet] epoch 6 iter 267050: loss = 0.5182,  smooth loss = 0.4607
[2022-07-07 04:47:06,278 callbacks.py:105 INFO train-abinet] epoch 6 iter 267100: loss = 0.3743,  smooth loss = 0.4701
[2022-07-07 04:47:46,762 callbacks.py:105 INFO train-abinet] epoch 6 iter 267150: loss = 0.5978,  smooth loss = 0.4733
[2022-07-07 04:48:27,148 callbacks.py:105 INFO train-abinet] epoch 6 iter 267200: loss = 0.4968,  smooth loss = 0.4795
[2022-07-07 04:49:07,715 callbacks.py:105 INFO train-abinet] epoch 6 iter 267250: loss = 0.4001,  smooth loss = 0.4773
[2022-07-07 04:49:48,191 callbacks.py:105 INFO train-abinet] epoch 6 iter 267300: loss = 0.5720,  smooth loss = 0.4643
[2022-07-07 04:50:31,477 callbacks.py:105 INFO train-abinet] epoch 6 iter 267350: loss = 0.5712,  smooth loss = 0.4727
[2022-07-07 04:51:19,873 callbacks.py:105 INFO train-abinet] epoch 6 iter 267400: loss = 0.4423,  smooth loss = 0.4762
[2022-07-07 04:52:01,476 callbacks.py:105 INFO train-abinet] epoch 6 iter 267450: loss = 0.3924,  smooth loss = 0.4669
[2022-07-07 04:52:43,264 callbacks.py:105 INFO train-abinet] epoch 6 iter 267500: loss = 0.5024,  smooth loss = 0.4711
[2022-07-07 04:53:24,519 callbacks.py:105 INFO train-abinet] epoch 6 iter 267550: loss = 0.4191,  smooth loss = 0.4759
[2022-07-07 04:54:06,197 callbacks.py:105 INFO train-abinet] epoch 6 iter 267600: loss = 0.3995,  smooth loss = 0.4703
[2022-07-07 04:54:47,426 callbacks.py:105 INFO train-abinet] epoch 6 iter 267650: loss = 0.3799,  smooth loss = 0.4558
[2022-07-07 04:55:27,592 callbacks.py:105 INFO train-abinet] epoch 6 iter 267700: loss = 0.4804,  smooth loss = 0.4664
[2022-07-07 04:56:07,536 callbacks.py:105 INFO train-abinet] epoch 6 iter 267750: loss = 0.3839,  smooth loss = 0.4690
[2022-07-07 04:56:48,042 callbacks.py:105 INFO train-abinet] epoch 6 iter 267800: loss = 0.5799,  smooth loss = 0.4764
[2022-07-07 04:57:28,218 callbacks.py:105 INFO train-abinet] epoch 6 iter 267850: loss = 0.4390,  smooth loss = 0.4815
[2022-07-07 04:58:08,186 callbacks.py:105 INFO train-abinet] epoch 6 iter 267900: loss = 0.4027,  smooth loss = 0.4814
[2022-07-07 04:58:49,110 callbacks.py:105 INFO train-abinet] epoch 6 iter 267950: loss = 0.5317,  smooth loss = 0.4827
[2022-07-07 04:59:30,039 callbacks.py:105 INFO train-abinet] epoch 6 iter 268000: loss = 0.3960,  smooth loss = 0.4772
[2022-07-07 05:00:11,347 callbacks.py:105 INFO train-abinet] epoch 6 iter 268050: loss = 0.4435,  smooth loss = 0.4765
[2022-07-07 05:00:51,589 callbacks.py:105 INFO train-abinet] epoch 6 iter 268100: loss = 0.5324,  smooth loss = 0.4900
[2022-07-07 05:01:32,059 callbacks.py:105 INFO train-abinet] epoch 6 iter 268150: loss = 0.4329,  smooth loss = 0.4720
[2022-07-07 05:02:12,842 callbacks.py:105 INFO train-abinet] epoch 6 iter 268200: loss = 0.3969,  smooth loss = 0.4660
[2022-07-07 05:02:53,223 callbacks.py:105 INFO train-abinet] epoch 6 iter 268250: loss = 0.5181,  smooth loss = 0.4745
[2022-07-07 05:03:33,842 callbacks.py:105 INFO train-abinet] epoch 6 iter 268300: loss = 0.4390,  smooth loss = 0.4789
[2022-07-07 05:04:14,082 callbacks.py:105 INFO train-abinet] epoch 6 iter 268350: loss = 0.4440,  smooth loss = 0.4702
[2022-07-07 05:04:54,274 callbacks.py:105 INFO train-abinet] epoch 6 iter 268400: loss = 0.5113,  smooth loss = 0.4816
[2022-07-07 05:05:34,422 callbacks.py:105 INFO train-abinet] epoch 6 iter 268450: loss = 0.5039,  smooth loss = 0.4820
[2022-07-07 05:06:15,040 callbacks.py:105 INFO train-abinet] epoch 6 iter 268500: loss = 0.5790,  smooth loss = 0.4958
[2022-07-07 05:06:56,089 callbacks.py:105 INFO train-abinet] epoch 6 iter 268550: loss = 0.3710,  smooth loss = 0.4764
[2022-07-07 05:07:36,449 callbacks.py:105 INFO train-abinet] epoch 6 iter 268600: loss = 0.6198,  smooth loss = 0.4731
[2022-07-07 05:08:16,665 callbacks.py:105 INFO train-abinet] epoch 6 iter 268650: loss = 0.4431,  smooth loss = 0.4835
[2022-07-07 05:08:57,680 callbacks.py:105 INFO train-abinet] epoch 6 iter 268700: loss = 0.3736,  smooth loss = 0.4828
[2022-07-07 05:09:38,135 callbacks.py:105 INFO train-abinet] epoch 6 iter 268750: loss = 0.4162,  smooth loss = 0.4859
[2022-07-07 05:10:18,834 callbacks.py:105 INFO train-abinet] epoch 6 iter 268800: loss = 0.4309,  smooth loss = 0.4791
[2022-07-07 05:11:01,149 callbacks.py:105 INFO train-abinet] epoch 6 iter 268850: loss = 0.4859,  smooth loss = 0.4792
[2022-07-07 05:11:49,131 callbacks.py:105 INFO train-abinet] epoch 6 iter 268900: loss = 0.3502,  smooth loss = 0.4702
[2022-07-07 05:12:30,654 callbacks.py:105 INFO train-abinet] epoch 6 iter 268950: loss = 0.4667,  smooth loss = 0.4763
[2022-07-07 05:13:11,784 callbacks.py:105 INFO train-abinet] epoch 6 iter 269000: loss = 0.3965,  smooth loss = 0.4751
[2022-07-07 05:13:53,474 callbacks.py:105 INFO train-abinet] epoch 6 iter 269050: loss = 0.6478,  smooth loss = 0.4799
[2022-07-07 05:14:35,330 callbacks.py:105 INFO train-abinet] epoch 6 iter 269100: loss = 0.4307,  smooth loss = 0.4722
[2022-07-07 05:15:15,714 callbacks.py:105 INFO train-abinet] epoch 6 iter 269150: loss = 0.5798,  smooth loss = 0.4752
[2022-07-07 05:15:55,603 callbacks.py:105 INFO train-abinet] epoch 6 iter 269200: loss = 0.4056,  smooth loss = 0.4690
[2022-07-07 05:16:35,994 callbacks.py:105 INFO train-abinet] epoch 6 iter 269250: loss = 0.4334,  smooth loss = 0.4793
[2022-07-07 05:17:16,520 callbacks.py:105 INFO train-abinet] epoch 6 iter 269300: loss = 0.5168,  smooth loss = 0.4809
[2022-07-07 05:17:57,005 callbacks.py:105 INFO train-abinet] epoch 6 iter 269350: loss = 0.3944,  smooth loss = 0.4715
[2022-07-07 05:18:37,689 callbacks.py:105 INFO train-abinet] epoch 6 iter 269400: loss = 0.4863,  smooth loss = 0.4756
[2022-07-07 05:19:18,490 callbacks.py:105 INFO train-abinet] epoch 6 iter 269450: loss = 0.4085,  smooth loss = 0.4754
[2022-07-07 05:19:59,235 callbacks.py:105 INFO train-abinet] epoch 6 iter 269500: loss = 0.4961,  smooth loss = 0.4695
[2022-07-07 05:20:39,915 callbacks.py:105 INFO train-abinet] epoch 6 iter 269550: loss = 0.4386,  smooth loss = 0.4667
[2022-07-07 05:21:20,318 callbacks.py:105 INFO train-abinet] epoch 6 iter 269600: loss = 0.4626,  smooth loss = 0.4769
[2022-07-07 05:22:00,857 callbacks.py:105 INFO train-abinet] epoch 6 iter 269650: loss = 0.3902,  smooth loss = 0.4796
[2022-07-07 05:22:40,966 callbacks.py:105 INFO train-abinet] epoch 6 iter 269700: loss = 0.5091,  smooth loss = 0.4707
[2022-07-07 05:23:21,608 callbacks.py:105 INFO train-abinet] epoch 6 iter 269750: loss = 0.5161,  smooth loss = 0.4745
[2022-07-07 05:24:02,284 callbacks.py:105 INFO train-abinet] epoch 6 iter 269800: loss = 0.4872,  smooth loss = 0.4773
[2022-07-07 05:24:42,668 callbacks.py:105 INFO train-abinet] epoch 6 iter 269850: loss = 0.3726,  smooth loss = 0.4726
[2022-07-07 05:25:23,695 callbacks.py:105 INFO train-abinet] epoch 6 iter 269900: loss = 0.3572,  smooth loss = 0.4656
[2022-07-07 05:26:05,986 callbacks.py:105 INFO train-abinet] epoch 6 iter 269950: loss = 0.4434,  smooth loss = 0.4829
[2022-07-07 05:26:47,893 callbacks.py:105 INFO train-abinet] epoch 6 iter 270000: loss = 0.3821,  smooth loss = 0.4801
[2022-07-07 05:26:47,893 callbacks.py:114 INFO train-abinet] average data time = 0.0050s, average running time = 0.8652s
█[2022-07-07 05:27:02,819 callbacks.py:123 INFO train-abinet] epoch 6 iter 270000: eval loss = 1.1491,  ccr = 0.9644,  cwr = 0.9262,  ted = 1183.0000,  ned = 240.1956,  ted/w = 0.1632, 
[2022-07-07 05:27:02,821 callbacks.py:130 INFO train-abinet] Better model found at epoch 6, iter 270000 with accuracy value: 0.9262.
[2022-07-07 05:27:03,936 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_270000
[2022-07-07 05:27:47,668 callbacks.py:105 INFO train-abinet] epoch 6 iter 270050: loss = 0.5813,  smooth loss = 0.4922
[2022-07-07 05:28:29,724 callbacks.py:105 INFO train-abinet] epoch 6 iter 270100: loss = 0.4013,  smooth loss = 0.4861
[2022-07-07 05:29:10,805 callbacks.py:105 INFO train-abinet] epoch 6 iter 270150: loss = 0.5221,  smooth loss = 0.4828
[2022-07-07 05:29:53,021 callbacks.py:105 INFO train-abinet] epoch 6 iter 270200: loss = 0.4260,  smooth loss = 0.4796
[2022-07-07 05:30:34,860 callbacks.py:105 INFO train-abinet] epoch 6 iter 270250: loss = 0.5495,  smooth loss = 0.4794
[2022-07-07 05:31:16,568 callbacks.py:105 INFO train-abinet] epoch 6 iter 270300: loss = 0.5725,  smooth loss = 0.4959
[2022-07-07 05:31:57,859 callbacks.py:105 INFO train-abinet] epoch 6 iter 270350: loss = 0.4842,  smooth loss = 0.4870
[2022-07-07 05:32:39,466 callbacks.py:105 INFO train-abinet] epoch 6 iter 270400: loss = 0.5426,  smooth loss = 0.4909
[2022-07-07 05:33:19,764 callbacks.py:105 INFO train-abinet] epoch 6 iter 270450: loss = 0.6271,  smooth loss = 0.4922
[2022-07-07 05:34:01,569 callbacks.py:105 INFO train-abinet] epoch 6 iter 270500: loss = 0.5846,  smooth loss = 0.4822
[2022-07-07 05:34:43,150 callbacks.py:105 INFO train-abinet] epoch 6 iter 270550: loss = 0.4947,  smooth loss = 0.4678
[2022-07-07 05:35:24,165 callbacks.py:105 INFO train-abinet] epoch 6 iter 270600: loss = 0.3542,  smooth loss = 0.4715
[2022-07-07 05:36:05,100 callbacks.py:105 INFO train-abinet] epoch 6 iter 270650: loss = 0.5552,  smooth loss = 0.4786
[2022-07-07 05:36:47,738 callbacks.py:105 INFO train-abinet] epoch 6 iter 270700: loss = 0.4968,  smooth loss = 0.4777
[2022-07-07 05:37:30,986 callbacks.py:105 INFO train-abinet] epoch 6 iter 270750: loss = 0.5294,  smooth loss = 0.4737
[2022-07-07 05:38:13,529 callbacks.py:105 INFO train-abinet] epoch 6 iter 270800: loss = 0.5211,  smooth loss = 0.4840
[2022-07-07 05:38:53,972 callbacks.py:105 INFO train-abinet] epoch 6 iter 270850: loss = 0.4967,  smooth loss = 0.4714
[2022-07-07 05:39:34,928 callbacks.py:105 INFO train-abinet] epoch 6 iter 270900: loss = 0.3243,  smooth loss = 0.4717
[2022-07-07 05:40:15,794 callbacks.py:105 INFO train-abinet] epoch 6 iter 270950: loss = 0.4588,  smooth loss = 0.4834
[2022-07-07 05:40:57,102 callbacks.py:105 INFO train-abinet] epoch 6 iter 271000: loss = 0.4114,  smooth loss = 0.4846
[2022-07-07 05:41:37,232 callbacks.py:105 INFO train-abinet] epoch 6 iter 271050: loss = 0.4822,  smooth loss = 0.4901
[2022-07-07 05:42:18,993 callbacks.py:105 INFO train-abinet] epoch 6 iter 271100: loss = 0.4167,  smooth loss = 0.4781
[2022-07-07 05:43:00,061 callbacks.py:105 INFO train-abinet] epoch 6 iter 271150: loss = 0.4571,  smooth loss = 0.4791
[2022-07-07 05:43:40,661 callbacks.py:105 INFO train-abinet] epoch 6 iter 271200: loss = 0.6169,  smooth loss = 0.4686
[2022-07-07 05:44:21,668 callbacks.py:105 INFO train-abinet] epoch 6 iter 271250: loss = 0.5999,  smooth loss = 0.4755
[2022-07-07 05:45:02,876 callbacks.py:105 INFO train-abinet] epoch 6 iter 271300: loss = 0.5247,  smooth loss = 0.4740
[2022-07-07 05:45:44,029 callbacks.py:105 INFO train-abinet] epoch 6 iter 271350: loss = 0.4156,  smooth loss = 0.4652
[2022-07-07 05:46:25,047 callbacks.py:105 INFO train-abinet] epoch 6 iter 271400: loss = 0.5312,  smooth loss = 0.4748
[2022-07-07 05:47:05,772 callbacks.py:105 INFO train-abinet] epoch 6 iter 271450: loss = 0.5190,  smooth loss = 0.4795
[2022-07-07 05:47:46,930 callbacks.py:105 INFO train-abinet] epoch 6 iter 271500: loss = 0.4563,  smooth loss = 0.4805
[2022-07-07 05:48:27,871 callbacks.py:105 INFO train-abinet] epoch 6 iter 271550: loss = 0.6092,  smooth loss = 0.4625
[2022-07-07 05:49:09,196 callbacks.py:105 INFO train-abinet] epoch 6 iter 271600: loss = 0.3784,  smooth loss = 0.4752
[2022-07-07 05:49:49,703 callbacks.py:105 INFO train-abinet] epoch 6 iter 271650: loss = 0.4216,  smooth loss = 0.4773
[2022-07-07 05:50:31,370 callbacks.py:105 INFO train-abinet] epoch 6 iter 271700: loss = 0.5204,  smooth loss = 0.4798
[2022-07-07 05:51:12,289 callbacks.py:105 INFO train-abinet] epoch 6 iter 271750: loss = 0.4630,  smooth loss = 0.4753
[2022-07-07 05:51:52,932 callbacks.py:105 INFO train-abinet] epoch 6 iter 271800: loss = 0.4294,  smooth loss = 0.4734
[2022-07-07 05:52:34,299 callbacks.py:105 INFO train-abinet] epoch 6 iter 271850: loss = 0.4751,  smooth loss = 0.4861
[2022-07-07 05:53:15,159 callbacks.py:105 INFO train-abinet] epoch 6 iter 271900: loss = 0.5037,  smooth loss = 0.4736
[2022-07-07 05:53:56,722 callbacks.py:105 INFO train-abinet] epoch 6 iter 271950: loss = 0.5712,  smooth loss = 0.4720
[2022-07-07 05:54:38,185 callbacks.py:105 INFO train-abinet] epoch 6 iter 272000: loss = 0.5248,  smooth loss = 0.4803
[2022-07-07 05:55:19,553 callbacks.py:105 INFO train-abinet] epoch 6 iter 272050: loss = 0.3929,  smooth loss = 0.4758
[2022-07-07 05:56:00,479 callbacks.py:105 INFO train-abinet] epoch 6 iter 272100: loss = 0.4100,  smooth loss = 0.4870
[2022-07-07 05:56:41,128 callbacks.py:105 INFO train-abinet] epoch 6 iter 272150: loss = 0.4495,  smooth loss = 0.4758
[2022-07-07 05:57:22,242 callbacks.py:105 INFO train-abinet] epoch 6 iter 272200: loss = 0.3872,  smooth loss = 0.4754
[2022-07-07 05:58:03,488 callbacks.py:105 INFO train-abinet] epoch 6 iter 272250: loss = 0.4866,  smooth loss = 0.4798
[2022-07-07 05:58:44,710 callbacks.py:105 INFO train-abinet] epoch 6 iter 272300: loss = 0.5755,  smooth loss = 0.4775
[2022-07-07 05:59:25,826 callbacks.py:105 INFO train-abinet] epoch 6 iter 272350: loss = 0.4234,  smooth loss = 0.4761
[2022-07-07 06:00:06,563 callbacks.py:105 INFO train-abinet] epoch 6 iter 272400: loss = 0.4967,  smooth loss = 0.4837
[2022-07-07 06:00:47,424 callbacks.py:105 INFO train-abinet] epoch 6 iter 272450: loss = 0.4318,  smooth loss = 0.4723
[2022-07-07 06:01:27,964 callbacks.py:105 INFO train-abinet] epoch 6 iter 272500: loss = 0.4020,  smooth loss = 0.4754
[2022-07-07 06:02:09,359 callbacks.py:105 INFO train-abinet] epoch 6 iter 272550: loss = 0.4315,  smooth loss = 0.4740
[2022-07-07 06:02:51,431 callbacks.py:105 INFO train-abinet] epoch 6 iter 272600: loss = 0.4349,  smooth loss = 0.4838
[2022-07-07 06:03:32,193 callbacks.py:105 INFO train-abinet] epoch 6 iter 272650: loss = 0.5694,  smooth loss = 0.4660
[2022-07-07 06:04:13,150 callbacks.py:105 INFO train-abinet] epoch 6 iter 272700: loss = 0.5380,  smooth loss = 0.4769
[2022-07-07 06:04:54,311 callbacks.py:105 INFO train-abinet] epoch 6 iter 272750: loss = 0.5507,  smooth loss = 0.4913
[2022-07-07 06:05:34,964 callbacks.py:105 INFO train-abinet] epoch 6 iter 272800: loss = 0.4522,  smooth loss = 0.4759
[2022-07-07 06:06:15,423 callbacks.py:105 INFO train-abinet] epoch 6 iter 272850: loss = 0.4291,  smooth loss = 0.4733
[2022-07-07 06:06:57,034 callbacks.py:105 INFO train-abinet] epoch 6 iter 272900: loss = 0.3773,  smooth loss = 0.4733
[2022-07-07 06:07:37,470 callbacks.py:105 INFO train-abinet] epoch 6 iter 272950: loss = 0.4475,  smooth loss = 0.4706
[2022-07-07 06:08:18,696 callbacks.py:105 INFO train-abinet] epoch 6 iter 273000: loss = 0.4556,  smooth loss = 0.4635
[2022-07-07 06:08:18,697 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8648s
█[2022-07-07 06:08:33,221 callbacks.py:123 INFO train-abinet] epoch 6 iter 273000: eval loss = 1.1576,  ccr = 0.9638,  cwr = 0.9258,  ted = 1193.0000,  ned = 239.4540,  ted/w = 0.1646, 
[2022-07-07 06:08:33,222 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_273000
[2022-07-07 06:09:15,745 callbacks.py:105 INFO train-abinet] epoch 6 iter 273050: loss = 0.3954,  smooth loss = 0.4698
[2022-07-07 06:09:56,665 callbacks.py:105 INFO train-abinet] epoch 6 iter 273100: loss = 0.4358,  smooth loss = 0.4685
[2022-07-07 06:10:38,177 callbacks.py:105 INFO train-abinet] epoch 6 iter 273150: loss = 0.4463,  smooth loss = 0.4734
[2022-07-07 06:11:19,046 callbacks.py:105 INFO train-abinet] epoch 6 iter 273200: loss = 0.7140,  smooth loss = 0.4899
[2022-07-07 06:11:59,837 callbacks.py:105 INFO train-abinet] epoch 6 iter 273250: loss = 0.3508,  smooth loss = 0.4742
[2022-07-07 06:12:40,776 callbacks.py:105 INFO train-abinet] epoch 6 iter 273300: loss = 0.4969,  smooth loss = 0.4640
[2022-07-07 06:13:21,695 callbacks.py:105 INFO train-abinet] epoch 6 iter 273350: loss = 0.4774,  smooth loss = 0.4680
[2022-07-07 06:14:01,376 callbacks.py:105 INFO train-abinet] epoch 6 iter 273400: loss = 0.4837,  smooth loss = 0.4667
[2022-07-07 06:14:42,465 callbacks.py:105 INFO train-abinet] epoch 6 iter 273450: loss = 0.3871,  smooth loss = 0.4699
[2022-07-07 06:15:22,704 callbacks.py:105 INFO train-abinet] epoch 6 iter 273500: loss = 0.5412,  smooth loss = 0.4594
[2022-07-07 06:16:03,896 callbacks.py:105 INFO train-abinet] epoch 6 iter 273550: loss = 0.4913,  smooth loss = 0.4792
[2022-07-07 06:16:44,577 callbacks.py:105 INFO train-abinet] epoch 6 iter 273600: loss = 0.3699,  smooth loss = 0.4523
[2022-07-07 06:17:24,978 callbacks.py:105 INFO train-abinet] epoch 6 iter 273650: loss = 0.4467,  smooth loss = 0.4639
[2022-07-07 06:18:05,884 callbacks.py:105 INFO train-abinet] epoch 6 iter 273700: loss = 0.4582,  smooth loss = 0.4785
[2022-07-07 06:18:47,321 callbacks.py:105 INFO train-abinet] epoch 6 iter 273750: loss = 0.4545,  smooth loss = 0.4678
[2022-07-07 06:19:28,072 callbacks.py:105 INFO train-abinet] epoch 6 iter 273800: loss = 0.5668,  smooth loss = 0.4829
[2022-07-07 06:20:08,468 callbacks.py:105 INFO train-abinet] epoch 6 iter 273850: loss = 0.4034,  smooth loss = 0.4701
[2022-07-07 06:20:49,096 callbacks.py:105 INFO train-abinet] epoch 6 iter 273900: loss = 0.3923,  smooth loss = 0.4606
[2022-07-07 06:21:29,269 callbacks.py:105 INFO train-abinet] epoch 6 iter 273950: loss = 0.5017,  smooth loss = 0.4724
[2022-07-07 06:22:10,829 callbacks.py:105 INFO train-abinet] epoch 6 iter 274000: loss = 0.4357,  smooth loss = 0.4687
[2022-07-07 06:22:51,873 callbacks.py:105 INFO train-abinet] epoch 6 iter 274050: loss = 0.3091,  smooth loss = 0.4636
[2022-07-07 06:23:32,749 callbacks.py:105 INFO train-abinet] epoch 6 iter 274100: loss = 0.3976,  smooth loss = 0.4696
[2022-07-07 06:24:13,496 callbacks.py:105 INFO train-abinet] epoch 6 iter 274150: loss = 0.5517,  smooth loss = 0.4663
[2022-07-07 06:24:54,540 callbacks.py:105 INFO train-abinet] epoch 6 iter 274200: loss = 0.4765,  smooth loss = 0.4605
[2022-07-07 06:25:35,442 callbacks.py:105 INFO train-abinet] epoch 6 iter 274250: loss = 0.5051,  smooth loss = 0.4622
[2022-07-07 06:26:15,370 callbacks.py:105 INFO train-abinet] epoch 6 iter 274300: loss = 0.5087,  smooth loss = 0.4633
[2022-07-07 06:26:56,281 callbacks.py:105 INFO train-abinet] epoch 6 iter 274350: loss = 0.4365,  smooth loss = 0.4685
[2022-07-07 06:27:37,413 callbacks.py:105 INFO train-abinet] epoch 6 iter 274400: loss = 0.6356,  smooth loss = 0.4771
[2022-07-07 06:28:17,909 callbacks.py:105 INFO train-abinet] epoch 6 iter 274450: loss = 0.5618,  smooth loss = 0.4858
[2022-07-07 06:29:00,532 callbacks.py:105 INFO train-abinet] epoch 6 iter 274500: loss = 0.4530,  smooth loss = 0.4863
[2022-07-07 06:29:41,624 callbacks.py:105 INFO train-abinet] epoch 6 iter 274550: loss = 0.5491,  smooth loss = 0.4886
[2022-07-07 06:30:21,919 callbacks.py:105 INFO train-abinet] epoch 6 iter 274600: loss = 0.4916,  smooth loss = 0.4869
[2022-07-07 06:31:02,370 callbacks.py:105 INFO train-abinet] epoch 6 iter 274650: loss = 0.4255,  smooth loss = 0.4728
[2022-07-07 06:31:42,878 callbacks.py:105 INFO train-abinet] epoch 6 iter 274700: loss = 0.5061,  smooth loss = 0.4693
[2022-07-07 06:32:22,793 callbacks.py:105 INFO train-abinet] epoch 6 iter 274750: loss = 0.4495,  smooth loss = 0.4673
[2022-07-07 06:33:02,923 callbacks.py:105 INFO train-abinet] epoch 6 iter 274800: loss = 0.5298,  smooth loss = 0.4850
[2022-07-07 06:33:43,189 callbacks.py:105 INFO train-abinet] epoch 6 iter 274850: loss = 0.5308,  smooth loss = 0.4735
[2022-07-07 06:34:23,244 callbacks.py:105 INFO train-abinet] epoch 6 iter 274900: loss = 0.4803,  smooth loss = 0.4648
[2022-07-07 06:35:03,035 callbacks.py:105 INFO train-abinet] epoch 6 iter 274950: loss = 0.6027,  smooth loss = 0.4774
[2022-07-07 06:35:43,183 callbacks.py:105 INFO train-abinet] epoch 6 iter 275000: loss = 0.3852,  smooth loss = 0.4725
[2022-07-07 06:36:22,758 callbacks.py:105 INFO train-abinet] epoch 6 iter 275050: loss = 0.5365,  smooth loss = 0.4722
[2022-07-07 06:37:02,743 callbacks.py:105 INFO train-abinet] epoch 6 iter 275100: loss = 0.4214,  smooth loss = 0.4824
[2022-07-07 06:37:42,500 callbacks.py:105 INFO train-abinet] epoch 6 iter 275150: loss = 0.4180,  smooth loss = 0.4746
[2022-07-07 06:38:22,293 callbacks.py:105 INFO train-abinet] epoch 6 iter 275200: loss = 0.2947,  smooth loss = 0.4715
[2022-07-07 06:39:02,305 callbacks.py:105 INFO train-abinet] epoch 6 iter 275250: loss = 0.4432,  smooth loss = 0.4753
[2022-07-07 06:39:42,619 callbacks.py:105 INFO train-abinet] epoch 6 iter 275300: loss = 0.5532,  smooth loss = 0.4806
[2022-07-07 06:40:23,551 callbacks.py:105 INFO train-abinet] epoch 6 iter 275350: loss = 0.4524,  smooth loss = 0.4773
[2022-07-07 06:41:03,964 callbacks.py:105 INFO train-abinet] epoch 6 iter 275400: loss = 0.5339,  smooth loss = 0.4749
[2022-07-07 06:41:44,118 callbacks.py:105 INFO train-abinet] epoch 6 iter 275450: loss = 0.4391,  smooth loss = 0.4638
[2022-07-07 06:42:24,208 callbacks.py:105 INFO train-abinet] epoch 6 iter 275500: loss = 0.4089,  smooth loss = 0.4702
[2022-07-07 06:43:04,467 callbacks.py:105 INFO train-abinet] epoch 6 iter 275550: loss = 0.4444,  smooth loss = 0.4665
[2022-07-07 06:43:44,752 callbacks.py:105 INFO train-abinet] epoch 6 iter 275600: loss = 0.4707,  smooth loss = 0.4804
[2022-07-07 06:44:25,179 callbacks.py:105 INFO train-abinet] epoch 6 iter 275650: loss = 0.4502,  smooth loss = 0.4802
[2022-07-07 06:45:05,019 callbacks.py:105 INFO train-abinet] epoch 6 iter 275700: loss = 0.4937,  smooth loss = 0.4810
[2022-07-07 06:45:44,744 callbacks.py:105 INFO train-abinet] epoch 6 iter 275750: loss = 0.4906,  smooth loss = 0.4759
[2022-07-07 06:46:25,392 callbacks.py:105 INFO train-abinet] epoch 6 iter 275800: loss = 0.3859,  smooth loss = 0.4668
[2022-07-07 06:47:05,668 callbacks.py:105 INFO train-abinet] epoch 6 iter 275850: loss = 0.4157,  smooth loss = 0.4806
[2022-07-07 06:47:45,037 callbacks.py:105 INFO train-abinet] epoch 6 iter 275900: loss = 0.4454,  smooth loss = 0.4658
[2022-07-07 06:48:25,523 callbacks.py:105 INFO train-abinet] epoch 6 iter 275950: loss = 0.3970,  smooth loss = 0.4703
[2022-07-07 06:49:05,407 callbacks.py:105 INFO train-abinet] epoch 6 iter 276000: loss = 0.4818,  smooth loss = 0.4741
[2022-07-07 06:49:05,408 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8642s
█[2022-07-07 06:49:19,853 callbacks.py:123 INFO train-abinet] epoch 6 iter 276000: eval loss = 1.1479,  ccr = 0.9644,  cwr = 0.9258,  ted = 1174.0000,  ned = 238.0484,  ted/w = 0.1620, 
[2022-07-07 06:49:19,855 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_276000
[2022-07-07 06:50:02,183 callbacks.py:105 INFO train-abinet] epoch 6 iter 276050: loss = 0.4848,  smooth loss = 0.4662
[2022-07-07 06:50:43,382 callbacks.py:105 INFO train-abinet] epoch 6 iter 276100: loss = 0.3570,  smooth loss = 0.4828
[2022-07-07 06:51:22,952 callbacks.py:105 INFO train-abinet] epoch 6 iter 276150: loss = 0.4576,  smooth loss = 0.4722
[2022-07-07 06:52:03,828 callbacks.py:105 INFO train-abinet] epoch 6 iter 276200: loss = 0.5927,  smooth loss = 0.4696
[2022-07-07 06:52:44,343 callbacks.py:105 INFO train-abinet] epoch 6 iter 276250: loss = 0.5822,  smooth loss = 0.4704
[2022-07-07 06:53:24,780 callbacks.py:105 INFO train-abinet] epoch 6 iter 276300: loss = 0.5615,  smooth loss = 0.4763
[2022-07-07 06:54:05,317 callbacks.py:105 INFO train-abinet] epoch 6 iter 276350: loss = 0.3961,  smooth loss = 0.4675
[2022-07-07 06:54:44,967 callbacks.py:105 INFO train-abinet] epoch 6 iter 276400: loss = 0.4458,  smooth loss = 0.4751
[2022-07-07 06:55:25,020 callbacks.py:105 INFO train-abinet] epoch 6 iter 276450: loss = 0.5094,  smooth loss = 0.4731
[2022-07-07 06:56:05,236 callbacks.py:105 INFO train-abinet] epoch 6 iter 276500: loss = 0.5301,  smooth loss = 0.4669
[2022-07-07 06:56:44,304 callbacks.py:105 INFO train-abinet] epoch 6 iter 276550: loss = 0.3919,  smooth loss = 0.4669
[2022-07-07 06:57:27,164 callbacks.py:105 INFO train-abinet] epoch 6 iter 276600: loss = 0.5000,  smooth loss = 0.4626
[2022-07-07 06:58:08,893 callbacks.py:105 INFO train-abinet] epoch 6 iter 276650: loss = 0.4868,  smooth loss = 0.4691
[2022-07-07 06:58:49,024 callbacks.py:105 INFO train-abinet] epoch 6 iter 276700: loss = 0.5951,  smooth loss = 0.4728
[2022-07-07 06:59:29,719 callbacks.py:105 INFO train-abinet] epoch 6 iter 276750: loss = 0.4220,  smooth loss = 0.4805
[2022-07-07 07:00:14,210 callbacks.py:105 INFO train-abinet] epoch 6 iter 276800: loss = 0.5321,  smooth loss = 0.4754
[2022-07-07 07:00:55,645 callbacks.py:105 INFO train-abinet] epoch 6 iter 276850: loss = 0.6220,  smooth loss = 0.4781
[2022-07-07 07:01:42,029 callbacks.py:105 INFO train-abinet] epoch 6 iter 276900: loss = 0.5122,  smooth loss = 0.4929
[2022-07-07 07:02:22,402 callbacks.py:105 INFO train-abinet] epoch 6 iter 276950: loss = 0.3007,  smooth loss = 0.4699
[2022-07-07 07:03:02,793 callbacks.py:105 INFO train-abinet] epoch 6 iter 277000: loss = 0.5018,  smooth loss = 0.4669
[2022-07-07 07:03:42,579 callbacks.py:105 INFO train-abinet] epoch 6 iter 277050: loss = 0.5034,  smooth loss = 0.4730
[2022-07-07 07:04:22,811 callbacks.py:105 INFO train-abinet] epoch 6 iter 277100: loss = 0.4842,  smooth loss = 0.4902
[2022-07-07 07:05:02,415 callbacks.py:105 INFO train-abinet] epoch 6 iter 277150: loss = 0.5799,  smooth loss = 0.4793
[2022-07-07 07:05:42,711 callbacks.py:105 INFO train-abinet] epoch 6 iter 277200: loss = 0.3033,  smooth loss = 0.4603
[2022-07-07 07:06:22,849 callbacks.py:105 INFO train-abinet] epoch 6 iter 277250: loss = 0.3897,  smooth loss = 0.4680
[2022-07-07 07:07:02,570 callbacks.py:105 INFO train-abinet] epoch 6 iter 277300: loss = 0.6463,  smooth loss = 0.4717
[2022-07-07 07:07:42,461 callbacks.py:105 INFO train-abinet] epoch 6 iter 277350: loss = 0.4176,  smooth loss = 0.4706
[2022-07-07 07:08:22,068 callbacks.py:105 INFO train-abinet] epoch 6 iter 277400: loss = 0.4205,  smooth loss = 0.4738
[2022-07-07 07:09:02,652 callbacks.py:105 INFO train-abinet] epoch 6 iter 277450: loss = 0.4273,  smooth loss = 0.4854
[2022-07-07 07:09:44,223 callbacks.py:105 INFO train-abinet] epoch 6 iter 277500: loss = 0.5706,  smooth loss = 0.4753
[2022-07-07 07:10:26,692 callbacks.py:105 INFO train-abinet] epoch 6 iter 277550: loss = 0.4619,  smooth loss = 0.4640
[2022-07-07 07:11:09,176 callbacks.py:105 INFO train-abinet] epoch 6 iter 277600: loss = 0.3772,  smooth loss = 0.4720
[2022-07-07 07:11:52,426 callbacks.py:105 INFO train-abinet] epoch 6 iter 277650: loss = 0.4667,  smooth loss = 0.4788
[2022-07-07 07:12:34,738 callbacks.py:105 INFO train-abinet] epoch 6 iter 277700: loss = 0.6065,  smooth loss = 0.4792
[2022-07-07 07:13:16,870 callbacks.py:105 INFO train-abinet] epoch 6 iter 277750: loss = 0.4927,  smooth loss = 0.4776
[2022-07-07 07:13:59,556 callbacks.py:105 INFO train-abinet] epoch 6 iter 277800: loss = 0.4524,  smooth loss = 0.4744
[2022-07-07 07:14:41,837 callbacks.py:105 INFO train-abinet] epoch 6 iter 277850: loss = 0.3962,  smooth loss = 0.4722
[2022-07-07 07:15:25,176 callbacks.py:105 INFO train-abinet] epoch 6 iter 277900: loss = 0.5730,  smooth loss = 0.4643
[2022-07-07 07:16:06,310 callbacks.py:105 INFO train-abinet] epoch 6 iter 277950: loss = 0.6334,  smooth loss = 0.4688
[2022-07-07 07:16:46,266 callbacks.py:105 INFO train-abinet] epoch 6 iter 278000: loss = 0.5420,  smooth loss = 0.4782
[2022-07-07 07:17:26,926 callbacks.py:105 INFO train-abinet] epoch 6 iter 278050: loss = 0.3297,  smooth loss = 0.4762
[2022-07-07 07:18:07,296 callbacks.py:105 INFO train-abinet] epoch 6 iter 278100: loss = 0.4022,  smooth loss = 0.4723
[2022-07-07 07:18:47,948 callbacks.py:105 INFO train-abinet] epoch 6 iter 278150: loss = 0.5025,  smooth loss = 0.4789
[2022-07-07 07:19:28,428 callbacks.py:105 INFO train-abinet] epoch 6 iter 278200: loss = 0.4569,  smooth loss = 0.4837
[2022-07-07 07:20:09,371 callbacks.py:105 INFO train-abinet] epoch 6 iter 278250: loss = 0.6379,  smooth loss = 0.4817
[2022-07-07 07:20:50,144 callbacks.py:105 INFO train-abinet] epoch 6 iter 278300: loss = 0.5934,  smooth loss = 0.4870
[2022-07-07 07:21:30,686 callbacks.py:105 INFO train-abinet] epoch 6 iter 278350: loss = 0.4061,  smooth loss = 0.4719
[2022-07-07 07:22:11,952 callbacks.py:105 INFO train-abinet] epoch 6 iter 278400: loss = 0.5188,  smooth loss = 0.4683
[2022-07-07 07:22:53,381 callbacks.py:105 INFO train-abinet] epoch 6 iter 278450: loss = 0.6172,  smooth loss = 0.4675
[2022-07-07 07:23:33,414 callbacks.py:105 INFO train-abinet] epoch 6 iter 278500: loss = 0.3463,  smooth loss = 0.4796
[2022-07-07 07:24:14,069 callbacks.py:105 INFO train-abinet] epoch 6 iter 278550: loss = 0.4869,  smooth loss = 0.4769
[2022-07-07 07:24:55,632 callbacks.py:105 INFO train-abinet] epoch 6 iter 278600: loss = 0.7489,  smooth loss = 0.4897
[2022-07-07 07:25:38,489 callbacks.py:105 INFO train-abinet] epoch 6 iter 278650: loss = 0.4630,  smooth loss = 0.4714
[2022-07-07 07:26:22,608 callbacks.py:105 INFO train-abinet] epoch 6 iter 278700: loss = 0.5926,  smooth loss = 0.4776
[2022-07-07 07:27:04,637 callbacks.py:105 INFO train-abinet] epoch 6 iter 278750: loss = 0.4518,  smooth loss = 0.4763
[2022-07-07 07:27:47,414 callbacks.py:105 INFO train-abinet] epoch 6 iter 278800: loss = 0.5550,  smooth loss = 0.4843
[2022-07-07 07:28:30,508 callbacks.py:105 INFO train-abinet] epoch 6 iter 278850: loss = 0.4009,  smooth loss = 0.4800
[2022-07-07 07:29:14,910 callbacks.py:105 INFO train-abinet] epoch 6 iter 278900: loss = 0.3822,  smooth loss = 0.4736
[2022-07-07 07:29:58,610 callbacks.py:105 INFO train-abinet] epoch 6 iter 278950: loss = 0.5079,  smooth loss = 0.4711
[2022-07-07 07:30:42,091 callbacks.py:105 INFO train-abinet] epoch 6 iter 279000: loss = 0.5167,  smooth loss = 0.4783
[2022-07-07 07:30:42,091 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8639s
█[2022-07-07 07:30:57,416 callbacks.py:123 INFO train-abinet] epoch 6 iter 279000: eval loss = 1.1461,  ccr = 0.9640,  cwr = 0.9248,  ted = 1198.0000,  ned = 246.1637,  ted/w = 0.1653, 
[2022-07-07 07:30:57,417 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_279000
[2022-07-07 07:31:40,563 callbacks.py:105 INFO train-abinet] epoch 6 iter 279050: loss = 0.6290,  smooth loss = 0.4647
[2022-07-07 07:32:21,747 callbacks.py:105 INFO train-abinet] epoch 6 iter 279100: loss = 0.4684,  smooth loss = 0.4735
[2022-07-07 07:33:05,402 callbacks.py:105 INFO train-abinet] epoch 6 iter 279150: loss = 0.5133,  smooth loss = 0.4761
[2022-07-07 07:33:45,867 callbacks.py:105 INFO train-abinet] epoch 6 iter 279200: loss = 0.5630,  smooth loss = 0.4781
[2022-07-07 07:34:27,441 callbacks.py:105 INFO train-abinet] epoch 6 iter 279250: loss = 0.5481,  smooth loss = 0.4845
[2022-07-07 07:35:07,990 callbacks.py:105 INFO train-abinet] epoch 6 iter 279300: loss = 0.4802,  smooth loss = 0.4814
[2022-07-07 07:35:48,749 callbacks.py:105 INFO train-abinet] epoch 6 iter 279350: loss = 0.4442,  smooth loss = 0.4629
[2022-07-07 07:36:30,649 callbacks.py:105 INFO train-abinet] epoch 6 iter 279400: loss = 0.5608,  smooth loss = 0.4732
[2022-07-07 07:37:11,301 callbacks.py:105 INFO train-abinet] epoch 6 iter 279450: loss = 0.4167,  smooth loss = 0.4742
[2022-07-07 07:37:51,747 callbacks.py:105 INFO train-abinet] epoch 6 iter 279500: loss = 0.4364,  smooth loss = 0.4727
[2022-07-07 07:38:32,545 callbacks.py:105 INFO train-abinet] epoch 6 iter 279550: loss = 0.5921,  smooth loss = 0.4783
[2022-07-07 07:39:13,373 callbacks.py:105 INFO train-abinet] epoch 6 iter 279600: loss = 0.5001,  smooth loss = 0.4788
[2022-07-07 07:39:53,687 callbacks.py:105 INFO train-abinet] epoch 6 iter 279650: loss = 0.4032,  smooth loss = 0.4670
[2022-07-07 07:40:34,273 callbacks.py:105 INFO train-abinet] epoch 6 iter 279700: loss = 0.4716,  smooth loss = 0.4772
[2022-07-07 07:41:14,995 callbacks.py:105 INFO train-abinet] epoch 6 iter 279750: loss = 0.6090,  smooth loss = 0.4810
[2022-07-07 07:41:54,993 callbacks.py:105 INFO train-abinet] epoch 6 iter 279800: loss = 0.4951,  smooth loss = 0.4757
[2022-07-07 07:42:36,102 callbacks.py:105 INFO train-abinet] epoch 6 iter 279850: loss = 0.4941,  smooth loss = 0.4801
[2022-07-07 07:43:17,137 callbacks.py:105 INFO train-abinet] epoch 6 iter 279900: loss = 0.4791,  smooth loss = 0.4901
[2022-07-07 07:43:58,242 callbacks.py:105 INFO train-abinet] epoch 6 iter 279950: loss = 0.4544,  smooth loss = 0.4801
[2022-07-07 07:44:38,588 callbacks.py:105 INFO train-abinet] epoch 6 iter 280000: loss = 0.5691,  smooth loss = 0.4714
[2022-07-07 07:45:19,192 callbacks.py:105 INFO train-abinet] epoch 6 iter 280050: loss = 0.4765,  smooth loss = 0.4644
[2022-07-07 07:45:59,944 callbacks.py:105 INFO train-abinet] epoch 6 iter 280100: loss = 0.4713,  smooth loss = 0.4645
[2022-07-07 07:46:40,167 callbacks.py:105 INFO train-abinet] epoch 6 iter 280150: loss = 0.5403,  smooth loss = 0.4713
[2022-07-07 07:47:20,134 callbacks.py:105 INFO train-abinet] epoch 6 iter 280200: loss = 0.4752,  smooth loss = 0.4853
[2022-07-07 07:47:59,770 callbacks.py:105 INFO train-abinet] epoch 6 iter 280250: loss = 0.4779,  smooth loss = 0.4736
[2022-07-07 07:48:39,990 callbacks.py:105 INFO train-abinet] epoch 6 iter 280300: loss = 0.3459,  smooth loss = 0.4754
[2022-07-07 07:49:20,527 callbacks.py:105 INFO train-abinet] epoch 6 iter 280350: loss = 0.4839,  smooth loss = 0.4738
[2022-07-07 07:50:00,759 callbacks.py:105 INFO train-abinet] epoch 6 iter 280400: loss = 0.4488,  smooth loss = 0.4743
[2022-07-07 07:50:41,500 callbacks.py:105 INFO train-abinet] epoch 6 iter 280450: loss = 0.4021,  smooth loss = 0.4688
[2022-07-07 07:51:22,218 callbacks.py:105 INFO train-abinet] epoch 6 iter 280500: loss = 0.4946,  smooth loss = 0.4661
[2022-07-07 07:52:02,401 callbacks.py:105 INFO train-abinet] epoch 6 iter 280550: loss = 0.4635,  smooth loss = 0.4764
[2022-07-07 07:52:43,119 callbacks.py:105 INFO train-abinet] epoch 6 iter 280600: loss = 0.4113,  smooth loss = 0.4687
[2022-07-07 07:53:23,590 callbacks.py:105 INFO train-abinet] epoch 6 iter 280650: loss = 0.5707,  smooth loss = 0.4710
[2022-07-07 07:54:03,846 callbacks.py:105 INFO train-abinet] epoch 6 iter 280700: loss = 0.4742,  smooth loss = 0.4681
[2022-07-07 07:54:44,872 callbacks.py:105 INFO train-abinet] epoch 6 iter 280750: loss = 0.4562,  smooth loss = 0.4842
[2022-07-07 07:55:25,412 callbacks.py:105 INFO train-abinet] epoch 6 iter 280800: loss = 0.4121,  smooth loss = 0.4720
[2022-07-07 07:56:07,879 callbacks.py:105 INFO train-abinet] epoch 6 iter 280850: loss = 0.4907,  smooth loss = 0.4730
[2022-07-07 07:56:48,167 callbacks.py:105 INFO train-abinet] epoch 6 iter 280900: loss = 0.4408,  smooth loss = 0.4781
[2022-07-07 07:57:29,015 callbacks.py:105 INFO train-abinet] epoch 6 iter 280950: loss = 0.5642,  smooth loss = 0.4751
[2022-07-07 07:58:08,580 callbacks.py:105 INFO train-abinet] epoch 6 iter 281000: loss = 0.4898,  smooth loss = 0.4586
[2022-07-07 07:58:48,647 callbacks.py:105 INFO train-abinet] epoch 6 iter 281050: loss = 0.3997,  smooth loss = 0.4618
[2022-07-07 07:59:28,189 callbacks.py:105 INFO train-abinet] epoch 6 iter 281100: loss = 0.3501,  smooth loss = 0.4750
[2022-07-07 08:00:07,749 callbacks.py:105 INFO train-abinet] epoch 6 iter 281150: loss = 0.5030,  smooth loss = 0.4711
[2022-07-07 08:00:47,987 callbacks.py:105 INFO train-abinet] epoch 6 iter 281200: loss = 0.4086,  smooth loss = 0.4725
[2022-07-07 08:01:28,518 callbacks.py:105 INFO train-abinet] epoch 6 iter 281250: loss = 0.4924,  smooth loss = 0.4821
[2022-07-07 08:02:08,762 callbacks.py:105 INFO train-abinet] epoch 6 iter 281300: loss = 0.4837,  smooth loss = 0.4659
[2022-07-07 08:02:49,362 callbacks.py:105 INFO train-abinet] epoch 6 iter 281350: loss = 0.3839,  smooth loss = 0.4774
[2022-07-07 08:03:29,857 callbacks.py:105 INFO train-abinet] epoch 6 iter 281400: loss = 0.5411,  smooth loss = 0.4735
[2022-07-07 08:04:10,548 callbacks.py:105 INFO train-abinet] epoch 6 iter 281450: loss = 0.4298,  smooth loss = 0.4796
[2022-07-07 08:04:50,795 callbacks.py:105 INFO train-abinet] epoch 6 iter 281500: loss = 0.4695,  smooth loss = 0.4823
[2022-07-07 08:05:31,047 callbacks.py:105 INFO train-abinet] epoch 6 iter 281550: loss = 0.4564,  smooth loss = 0.4710
[2022-07-07 08:06:14,729 callbacks.py:105 INFO train-abinet] epoch 6 iter 281600: loss = 0.4721,  smooth loss = 0.4684
[2022-07-07 08:07:00,297 callbacks.py:105 INFO train-abinet] epoch 6 iter 281650: loss = 0.4281,  smooth loss = 0.4712
[2022-07-07 08:07:45,421 callbacks.py:105 INFO train-abinet] epoch 6 iter 281700: loss = 0.4731,  smooth loss = 0.4786
[2022-07-07 08:08:30,414 callbacks.py:105 INFO train-abinet] epoch 6 iter 281750: loss = 0.4088,  smooth loss = 0.4714
[2022-07-07 08:09:14,993 callbacks.py:105 INFO train-abinet] epoch 6 iter 281800: loss = 0.4816,  smooth loss = 0.4677
[2022-07-07 08:09:58,236 callbacks.py:105 INFO train-abinet] epoch 6 iter 281850: loss = 0.3957,  smooth loss = 0.4575
[2022-07-07 08:10:38,713 callbacks.py:105 INFO train-abinet] epoch 6 iter 281900: loss = 0.3772,  smooth loss = 0.4651
[2022-07-07 08:11:18,910 callbacks.py:105 INFO train-abinet] epoch 6 iter 281950: loss = 0.5331,  smooth loss = 0.4758
[2022-07-07 08:11:59,081 callbacks.py:105 INFO train-abinet] epoch 6 iter 282000: loss = 0.5256,  smooth loss = 0.4850
[2022-07-07 08:11:59,081 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8634s
█[2022-07-07 08:12:13,459 callbacks.py:123 INFO train-abinet] epoch 6 iter 282000: eval loss = 1.1503,  ccr = 0.9641,  cwr = 0.9252,  ted = 1204.0000,  ned = 242.9144,  ted/w = 0.1661, 
[2022-07-07 08:12:13,460 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_282000
[2022-07-07 08:12:55,059 callbacks.py:105 INFO train-abinet] epoch 6 iter 282050: loss = 0.4325,  smooth loss = 0.4895
[2022-07-07 08:13:35,808 callbacks.py:105 INFO train-abinet] epoch 6 iter 282100: loss = 0.4116,  smooth loss = 0.4735
[2022-07-07 08:14:15,544 callbacks.py:105 INFO train-abinet] epoch 6 iter 282150: loss = 0.4324,  smooth loss = 0.4578
[2022-07-07 08:14:56,067 callbacks.py:105 INFO train-abinet] epoch 6 iter 282200: loss = 0.4849,  smooth loss = 0.4627
[2022-07-07 08:15:36,534 callbacks.py:105 INFO train-abinet] epoch 6 iter 282250: loss = 0.4192,  smooth loss = 0.4728
[2022-07-07 08:16:17,181 callbacks.py:105 INFO train-abinet] epoch 6 iter 282300: loss = 0.4732,  smooth loss = 0.4688
[2022-07-07 08:16:57,044 callbacks.py:105 INFO train-abinet] epoch 6 iter 282350: loss = 0.3780,  smooth loss = 0.4697
[2022-07-07 08:17:37,082 callbacks.py:105 INFO train-abinet] epoch 6 iter 282400: loss = 0.4781,  smooth loss = 0.4664
[2022-07-07 08:18:17,986 callbacks.py:105 INFO train-abinet] epoch 6 iter 282450: loss = 0.4731,  smooth loss = 0.4581
[2022-07-07 08:18:58,163 callbacks.py:105 INFO train-abinet] epoch 6 iter 282500: loss = 0.4481,  smooth loss = 0.4600
[2022-07-07 08:19:38,315 callbacks.py:105 INFO train-abinet] epoch 6 iter 282550: loss = 0.5144,  smooth loss = 0.4615
[2022-07-07 08:20:19,010 callbacks.py:105 INFO train-abinet] epoch 6 iter 282600: loss = 0.6003,  smooth loss = 0.4737
[2022-07-07 08:20:59,263 callbacks.py:105 INFO train-abinet] epoch 6 iter 282650: loss = 0.4760,  smooth loss = 0.4740
[2022-07-07 08:21:39,489 callbacks.py:105 INFO train-abinet] epoch 6 iter 282700: loss = 0.3926,  smooth loss = 0.4758
[2022-07-07 08:22:19,906 callbacks.py:105 INFO train-abinet] epoch 6 iter 282750: loss = 0.4020,  smooth loss = 0.4810
[2022-07-07 08:23:00,748 callbacks.py:105 INFO train-abinet] epoch 6 iter 282800: loss = 0.3689,  smooth loss = 0.4714
[2022-07-07 08:23:41,303 callbacks.py:105 INFO train-abinet] epoch 6 iter 282850: loss = 0.6098,  smooth loss = 0.4821
[2022-07-07 08:24:21,852 callbacks.py:105 INFO train-abinet] epoch 6 iter 282900: loss = 0.4164,  smooth loss = 0.4665
[2022-07-07 08:25:01,425 callbacks.py:105 INFO train-abinet] epoch 6 iter 282950: loss = 0.4370,  smooth loss = 0.4659
[2022-07-07 08:25:42,042 callbacks.py:105 INFO train-abinet] epoch 6 iter 283000: loss = 0.5102,  smooth loss = 0.4678
[2022-07-07 08:26:25,680 callbacks.py:105 INFO train-abinet] epoch 6 iter 283050: loss = 0.4463,  smooth loss = 0.4689
[2022-07-07 08:27:11,823 callbacks.py:105 INFO train-abinet] epoch 6 iter 283100: loss = 0.4414,  smooth loss = 0.4843
[2022-07-07 08:27:53,750 callbacks.py:105 INFO train-abinet] epoch 6 iter 283150: loss = 0.4254,  smooth loss = 0.4658
[2022-07-07 08:28:33,858 callbacks.py:105 INFO train-abinet] epoch 6 iter 283200: loss = 0.5583,  smooth loss = 0.4566
[2022-07-07 08:29:13,574 callbacks.py:105 INFO train-abinet] epoch 6 iter 283250: loss = 0.4933,  smooth loss = 0.4762
[2022-07-07 08:29:54,310 callbacks.py:105 INFO train-abinet] epoch 6 iter 283300: loss = 0.4355,  smooth loss = 0.4692
[2022-07-07 08:30:34,893 callbacks.py:105 INFO train-abinet] epoch 6 iter 283350: loss = 0.5781,  smooth loss = 0.4652
[2022-07-07 08:31:14,162 callbacks.py:105 INFO train-abinet] epoch 6 iter 283400: loss = 0.5043,  smooth loss = 0.4681
[2022-07-07 08:31:54,458 callbacks.py:105 INFO train-abinet] epoch 6 iter 283450: loss = 0.4513,  smooth loss = 0.4677
[2022-07-07 08:32:34,917 callbacks.py:105 INFO train-abinet] epoch 6 iter 283500: loss = 0.5244,  smooth loss = 0.4671
[2022-07-07 08:33:15,238 callbacks.py:105 INFO train-abinet] epoch 6 iter 283550: loss = 0.4432,  smooth loss = 0.4764
[2022-07-07 08:33:54,958 callbacks.py:105 INFO train-abinet] epoch 6 iter 283600: loss = 0.5257,  smooth loss = 0.4751
[2022-07-07 08:34:35,333 callbacks.py:105 INFO train-abinet] epoch 6 iter 283650: loss = 0.5402,  smooth loss = 0.4656
[2022-07-07 08:35:16,068 callbacks.py:105 INFO train-abinet] epoch 6 iter 283700: loss = 0.6600,  smooth loss = 0.4778
[2022-07-07 08:35:55,676 callbacks.py:105 INFO train-abinet] epoch 6 iter 283750: loss = 0.4149,  smooth loss = 0.4789
[2022-07-07 08:36:36,071 callbacks.py:105 INFO train-abinet] epoch 6 iter 283800: loss = 0.4301,  smooth loss = 0.4849
[2022-07-07 08:37:16,739 callbacks.py:105 INFO train-abinet] epoch 6 iter 283850: loss = 0.5013,  smooth loss = 0.4746
[2022-07-07 08:37:56,721 callbacks.py:105 INFO train-abinet] epoch 6 iter 283900: loss = 0.4744,  smooth loss = 0.4805
[2022-07-07 08:38:37,131 callbacks.py:105 INFO train-abinet] epoch 6 iter 283950: loss = 0.5634,  smooth loss = 0.4755
[2022-07-07 08:39:17,517 callbacks.py:105 INFO train-abinet] epoch 6 iter 284000: loss = 0.3730,  smooth loss = 0.4719
[2022-07-07 08:39:57,472 callbacks.py:105 INFO train-abinet] epoch 6 iter 284050: loss = 0.5271,  smooth loss = 0.4619
[2022-07-07 08:40:38,276 callbacks.py:105 INFO train-abinet] epoch 6 iter 284100: loss = 0.3967,  smooth loss = 0.4721
[2022-07-07 08:41:18,413 callbacks.py:105 INFO train-abinet] epoch 6 iter 284150: loss = 0.4085,  smooth loss = 0.4579
[2022-07-07 08:41:58,770 callbacks.py:105 INFO train-abinet] epoch 6 iter 284200: loss = 0.4349,  smooth loss = 0.4663
[2022-07-07 08:42:38,814 callbacks.py:105 INFO train-abinet] epoch 6 iter 284250: loss = 0.4950,  smooth loss = 0.4718
[2022-07-07 08:43:19,092 callbacks.py:105 INFO train-abinet] epoch 6 iter 284300: loss = 0.4795,  smooth loss = 0.4644
[2022-07-07 08:43:59,519 callbacks.py:105 INFO train-abinet] epoch 6 iter 284350: loss = 0.4288,  smooth loss = 0.4839
[2022-07-07 08:44:39,672 callbacks.py:105 INFO train-abinet] epoch 6 iter 284400: loss = 0.5843,  smooth loss = 0.4770
[2022-07-07 08:45:19,568 callbacks.py:105 INFO train-abinet] epoch 6 iter 284450: loss = 0.4185,  smooth loss = 0.4813
[2022-07-07 08:45:59,416 callbacks.py:105 INFO train-abinet] epoch 6 iter 284500: loss = 0.4357,  smooth loss = 0.4713
[2022-07-07 08:46:40,633 callbacks.py:105 INFO train-abinet] epoch 6 iter 284550: loss = 0.5477,  smooth loss = 0.4578
[2022-07-07 08:47:20,039 callbacks.py:105 INFO train-abinet] epoch 6 iter 284600: loss = 0.5972,  smooth loss = 0.4721
[2022-07-07 08:48:00,387 callbacks.py:105 INFO train-abinet] epoch 6 iter 284650: loss = 0.5207,  smooth loss = 0.4668
[2022-07-07 08:48:40,318 callbacks.py:105 INFO train-abinet] epoch 6 iter 284700: loss = 0.4164,  smooth loss = 0.4707
[2022-07-07 08:49:21,360 callbacks.py:105 INFO train-abinet] epoch 6 iter 284750: loss = 0.4971,  smooth loss = 0.4727
[2022-07-07 08:50:01,116 callbacks.py:105 INFO train-abinet] epoch 6 iter 284800: loss = 0.4852,  smooth loss = 0.4589
[2022-07-07 08:50:41,878 callbacks.py:105 INFO train-abinet] epoch 6 iter 284850: loss = 0.4690,  smooth loss = 0.4725
[2022-07-07 08:51:21,661 callbacks.py:105 INFO train-abinet] epoch 6 iter 284900: loss = 0.3940,  smooth loss = 0.4689
[2022-07-07 08:52:01,762 callbacks.py:105 INFO train-abinet] epoch 6 iter 284950: loss = 0.4231,  smooth loss = 0.4623
[2022-07-07 08:52:42,070 callbacks.py:105 INFO train-abinet] epoch 6 iter 285000: loss = 0.4697,  smooth loss = 0.4663
[2022-07-07 08:52:42,071 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8629s
█[2022-07-07 08:52:55,766 callbacks.py:123 INFO train-abinet] epoch 6 iter 285000: eval loss = 1.1593,  ccr = 0.9636,  cwr = 0.9248,  ted = 1205.0000,  ned = 243.0331,  ted/w = 0.1663, 
[2022-07-07 08:52:55,768 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_285000
[2022-07-07 08:53:36,854 callbacks.py:105 INFO train-abinet] epoch 6 iter 285050: loss = 0.3856,  smooth loss = 0.4641
[2022-07-07 08:54:17,437 callbacks.py:105 INFO train-abinet] epoch 6 iter 285100: loss = 0.4890,  smooth loss = 0.4613
[2022-07-07 08:54:57,528 callbacks.py:105 INFO train-abinet] epoch 6 iter 285150: loss = 0.4912,  smooth loss = 0.4603
[2022-07-07 08:55:37,627 callbacks.py:105 INFO train-abinet] epoch 6 iter 285200: loss = 0.5348,  smooth loss = 0.4619
[2022-07-07 08:56:18,400 callbacks.py:105 INFO train-abinet] epoch 6 iter 285250: loss = 0.5598,  smooth loss = 0.4710
[2022-07-07 08:56:59,190 callbacks.py:105 INFO train-abinet] epoch 6 iter 285300: loss = 0.3714,  smooth loss = 0.4695
[2022-07-07 08:57:39,932 callbacks.py:105 INFO train-abinet] epoch 6 iter 285350: loss = 0.4148,  smooth loss = 0.4607
[2022-07-07 08:58:20,688 callbacks.py:105 INFO train-abinet] epoch 6 iter 285400: loss = 0.4864,  smooth loss = 0.4651
[2022-07-07 08:59:01,056 callbacks.py:105 INFO train-abinet] epoch 6 iter 285450: loss = 0.4682,  smooth loss = 0.4612
[2022-07-07 08:59:41,359 callbacks.py:105 INFO train-abinet] epoch 6 iter 285500: loss = 0.4741,  smooth loss = 0.4671
[2022-07-07 09:00:21,479 callbacks.py:105 INFO train-abinet] epoch 6 iter 285550: loss = 0.4630,  smooth loss = 0.4628
[2022-07-07 09:01:01,710 callbacks.py:105 INFO train-abinet] epoch 6 iter 285600: loss = 0.3474,  smooth loss = 0.4632
[2022-07-07 09:01:42,413 callbacks.py:105 INFO train-abinet] epoch 6 iter 285650: loss = 0.5401,  smooth loss = 0.4668
[2022-07-07 09:02:22,384 callbacks.py:105 INFO train-abinet] epoch 6 iter 285700: loss = 0.4843,  smooth loss = 0.4627
[2022-07-07 09:03:02,766 callbacks.py:105 INFO train-abinet] epoch 6 iter 285750: loss = 0.5005,  smooth loss = 0.4641
[2022-07-07 09:03:43,273 callbacks.py:105 INFO train-abinet] epoch 6 iter 285800: loss = 0.5354,  smooth loss = 0.4747
[2022-07-07 09:04:24,625 callbacks.py:105 INFO train-abinet] epoch 6 iter 285850: loss = 0.4313,  smooth loss = 0.4639
[2022-07-07 09:05:04,438 callbacks.py:105 INFO train-abinet] epoch 6 iter 285900: loss = 0.5363,  smooth loss = 0.4710
[2022-07-07 09:05:44,960 callbacks.py:105 INFO train-abinet] epoch 6 iter 285950: loss = 0.4619,  smooth loss = 0.4568
[2022-07-07 09:06:25,675 callbacks.py:105 INFO train-abinet] epoch 6 iter 286000: loss = 0.3630,  smooth loss = 0.4649
[2022-07-07 09:07:05,311 callbacks.py:105 INFO train-abinet] epoch 6 iter 286050: loss = 0.4193,  smooth loss = 0.4704
[2022-07-07 09:07:46,158 callbacks.py:105 INFO train-abinet] epoch 6 iter 286100: loss = 0.3675,  smooth loss = 0.4730
[2022-07-07 09:08:25,886 callbacks.py:105 INFO train-abinet] epoch 6 iter 286150: loss = 0.3398,  smooth loss = 0.4620
[2022-07-07 09:09:06,841 callbacks.py:105 INFO train-abinet] epoch 6 iter 286200: loss = 0.4296,  smooth loss = 0.4697
[2022-07-07 09:09:47,554 callbacks.py:105 INFO train-abinet] epoch 6 iter 286250: loss = 0.4406,  smooth loss = 0.4740
[2022-07-07 09:10:28,213 callbacks.py:105 INFO train-abinet] epoch 6 iter 286300: loss = 0.4729,  smooth loss = 0.4654
[2022-07-07 09:11:08,462 callbacks.py:105 INFO train-abinet] epoch 6 iter 286350: loss = 0.5745,  smooth loss = 0.4625
[2022-07-07 09:11:49,115 callbacks.py:105 INFO train-abinet] epoch 6 iter 286400: loss = 0.5070,  smooth loss = 0.4706
[2022-07-07 09:12:29,778 callbacks.py:105 INFO train-abinet] epoch 6 iter 286450: loss = 0.4931,  smooth loss = 0.4826
[2022-07-07 09:13:10,517 callbacks.py:105 INFO train-abinet] epoch 6 iter 286500: loss = 0.4029,  smooth loss = 0.4801
[2022-07-07 09:13:50,630 callbacks.py:105 INFO train-abinet] epoch 6 iter 286550: loss = 0.5132,  smooth loss = 0.4715
[2022-07-07 09:14:30,987 callbacks.py:105 INFO train-abinet] epoch 6 iter 286600: loss = 0.4666,  smooth loss = 0.4755
[2022-07-07 09:15:11,290 callbacks.py:105 INFO train-abinet] epoch 6 iter 286650: loss = 0.3868,  smooth loss = 0.4670
[2022-07-07 09:15:51,854 callbacks.py:105 INFO train-abinet] epoch 6 iter 286700: loss = 0.4241,  smooth loss = 0.4634
[2022-07-07 09:16:31,976 callbacks.py:105 INFO train-abinet] epoch 6 iter 286750: loss = 0.4533,  smooth loss = 0.4670
[2022-07-07 09:17:12,647 callbacks.py:105 INFO train-abinet] epoch 6 iter 286800: loss = 0.3688,  smooth loss = 0.4770
[2022-07-07 09:17:53,896 callbacks.py:105 INFO train-abinet] epoch 6 iter 286850: loss = 0.5067,  smooth loss = 0.4751
[2022-07-07 09:18:33,994 callbacks.py:105 INFO train-abinet] epoch 6 iter 286900: loss = 0.5176,  smooth loss = 0.4642
[2022-07-07 09:19:14,868 callbacks.py:105 INFO train-abinet] epoch 6 iter 286950: loss = 0.4135,  smooth loss = 0.4821
[2022-07-07 09:19:56,218 callbacks.py:105 INFO train-abinet] epoch 6 iter 287000: loss = 0.3048,  smooth loss = 0.4785
[2022-07-07 09:20:36,959 callbacks.py:105 INFO train-abinet] epoch 6 iter 287050: loss = 0.6138,  smooth loss = 0.4796
[2022-07-07 09:21:21,018 callbacks.py:105 INFO train-abinet] epoch 6 iter 287100: loss = 0.4662,  smooth loss = 0.4781
[2022-07-07 09:22:07,171 callbacks.py:105 INFO train-abinet] epoch 6 iter 287150: loss = 0.5697,  smooth loss = 0.4775
[2022-07-07 09:22:51,527 callbacks.py:105 INFO train-abinet] epoch 6 iter 287200: loss = 0.3653,  smooth loss = 0.4642
[2022-07-07 09:23:37,271 callbacks.py:105 INFO train-abinet] epoch 6 iter 287250: loss = 0.3720,  smooth loss = 0.4625
[2022-07-07 09:24:24,331 callbacks.py:105 INFO train-abinet] epoch 6 iter 287300: loss = 0.5440,  smooth loss = 0.4747
[2022-07-07 09:25:07,079 callbacks.py:105 INFO train-abinet] epoch 6 iter 287350: loss = 0.4491,  smooth loss = 0.4654
[2022-07-07 09:25:48,065 callbacks.py:105 INFO train-abinet] epoch 6 iter 287400: loss = 0.5170,  smooth loss = 0.4733
[2022-07-07 09:26:28,779 callbacks.py:105 INFO train-abinet] epoch 6 iter 287450: loss = 0.5264,  smooth loss = 0.4686
[2022-07-07 09:27:09,834 callbacks.py:105 INFO train-abinet] epoch 6 iter 287500: loss = 0.3432,  smooth loss = 0.4672
[2022-07-07 09:27:50,127 callbacks.py:105 INFO train-abinet] epoch 6 iter 287550: loss = 0.5095,  smooth loss = 0.4573
[2022-07-07 09:28:30,953 callbacks.py:105 INFO train-abinet] epoch 6 iter 287600: loss = 0.3896,  smooth loss = 0.4583
[2022-07-07 09:29:11,160 callbacks.py:105 INFO train-abinet] epoch 6 iter 287650: loss = 0.3953,  smooth loss = 0.4644
[2022-07-07 09:29:51,948 callbacks.py:105 INFO train-abinet] epoch 6 iter 287700: loss = 0.4374,  smooth loss = 0.4688
[2022-07-07 09:30:32,467 callbacks.py:105 INFO train-abinet] epoch 6 iter 287750: loss = 0.5082,  smooth loss = 0.4693
[2022-07-07 09:31:12,353 callbacks.py:105 INFO train-abinet] epoch 6 iter 287800: loss = 0.4664,  smooth loss = 0.4636
[2022-07-07 09:31:52,781 callbacks.py:105 INFO train-abinet] epoch 6 iter 287850: loss = 0.4302,  smooth loss = 0.4734
[2022-07-07 09:32:32,409 callbacks.py:105 INFO train-abinet] epoch 6 iter 287900: loss = 0.3944,  smooth loss = 0.4668
[2022-07-07 09:33:12,873 callbacks.py:105 INFO train-abinet] epoch 6 iter 287950: loss = 0.4277,  smooth loss = 0.4641
[2022-07-07 09:33:53,742 callbacks.py:105 INFO train-abinet] epoch 6 iter 288000: loss = 0.4276,  smooth loss = 0.4518
[2022-07-07 09:33:53,743 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8624s
█[2022-07-07 09:34:07,949 callbacks.py:123 INFO train-abinet] epoch 6 iter 288000: eval loss = 1.1629,  ccr = 0.9637,  cwr = 0.9256,  ted = 1195.0000,  ned = 241.7567,  ted/w = 0.1649, 
[2022-07-07 09:34:07,950 callbacks.py:136 INFO train-abinet] Save model train-abinet_6_288000
[2022-07-07 09:34:49,608 callbacks.py:105 INFO train-abinet] epoch 6 iter 288050: loss = 0.3639,  smooth loss = 0.4779
[2022-07-07 09:35:29,471 callbacks.py:105 INFO train-abinet] epoch 6 iter 288100: loss = 0.5704,  smooth loss = 0.4829
[2022-07-07 09:36:10,278 callbacks.py:105 INFO train-abinet] epoch 6 iter 288150: loss = 0.4536,  smooth loss = 0.4804
[2022-07-07 09:36:49,956 callbacks.py:105 INFO train-abinet] epoch 6 iter 288200: loss = 0.4279,  smooth loss = 0.4697
[2022-07-07 09:37:30,947 callbacks.py:105 INFO train-abinet] epoch 6 iter 288250: loss = 0.5736,  smooth loss = 0.4707
[2022-07-07 09:38:11,886 callbacks.py:105 INFO train-abinet] epoch 6 iter 288300: loss = 0.3869,  smooth loss = 0.4664
[2022-07-07 09:38:52,613 callbacks.py:105 INFO train-abinet] epoch 6 iter 288350: loss = 0.4878,  smooth loss = 0.4667
[2022-07-07 09:39:32,487 callbacks.py:105 INFO train-abinet] epoch 6 iter 288400: loss = 0.6094,  smooth loss = 0.4785
[2022-07-07 09:40:12,306 callbacks.py:105 INFO train-abinet] epoch 6 iter 288450: loss = 0.6426,  smooth loss = 0.4822
[2022-07-07 09:40:52,866 callbacks.py:105 INFO train-abinet] epoch 6 iter 288500: loss = 0.3959,  smooth loss = 0.4793
[2022-07-07 09:41:32,889 callbacks.py:105 INFO train-abinet] epoch 6 iter 288550: loss = 0.5628,  smooth loss = 0.4736
[2022-07-07 09:42:12,819 callbacks.py:105 INFO train-abinet] epoch 6 iter 288600: loss = 0.4835,  smooth loss = 0.4738
[2022-07-07 09:42:53,067 callbacks.py:105 INFO train-abinet] epoch 6 iter 288650: loss = 0.3623,  smooth loss = 0.4636
[2022-07-07 09:43:33,369 callbacks.py:105 INFO train-abinet] epoch 6 iter 288700: loss = 0.5525,  smooth loss = 0.4603
[2022-07-07 09:44:13,552 callbacks.py:105 INFO train-abinet] epoch 6 iter 288750: loss = 0.6192,  smooth loss = 0.4686
[2022-07-07 09:44:54,741 callbacks.py:105 INFO train-abinet] epoch 6 iter 288800: loss = 0.5936,  smooth loss = 0.4642
[2022-07-07 09:45:34,452 callbacks.py:105 INFO train-abinet] epoch 6 iter 288850: loss = 0.5038,  smooth loss = 0.4742
[2022-07-07 09:46:15,027 callbacks.py:105 INFO train-abinet] epoch 6 iter 288900: loss = 0.2961,  smooth loss = 0.4628
[2022-07-07 09:46:55,158 callbacks.py:105 INFO train-abinet] epoch 6 iter 288950: loss = 0.3860,  smooth loss = 0.4789
[2022-07-07 09:47:34,917 callbacks.py:105 INFO train-abinet] epoch 6 iter 289000: loss = 0.6612,  smooth loss = 0.4770
[2022-07-07 09:48:15,347 callbacks.py:105 INFO train-abinet] epoch 6 iter 289050: loss = 0.4485,  smooth loss = 0.4692
[2022-07-07 09:48:56,050 callbacks.py:105 INFO train-abinet] epoch 6 iter 289100: loss = 0.3908,  smooth loss = 0.4769
[2022-07-07 09:49:36,289 callbacks.py:105 INFO train-abinet] epoch 6 iter 289150: loss = 0.4023,  smooth loss = 0.4650
[2022-07-07 09:50:16,524 callbacks.py:105 INFO train-abinet] epoch 6 iter 289200: loss = 0.6504,  smooth loss = 0.4776
[2022-07-07 09:50:56,839 callbacks.py:105 INFO train-abinet] epoch 6 iter 289250: loss = 0.5323,  smooth loss = 0.4757
[2022-07-07 09:51:37,176 callbacks.py:105 INFO train-abinet] epoch 6 iter 289300: loss = 0.4468,  smooth loss = 0.4624
[2022-07-07 09:52:16,903 callbacks.py:105 INFO train-abinet] epoch 6 iter 289350: loss = 0.4875,  smooth loss = 0.4731
[2022-07-07 09:52:57,322 callbacks.py:105 INFO train-abinet] epoch 6 iter 289400: loss = 0.2835,  smooth loss = 0.4642
[2022-07-07 09:53:37,284 callbacks.py:105 INFO train-abinet] epoch 6 iter 289450: loss = 0.4173,  smooth loss = 0.4562
[2022-07-07 09:54:18,308 callbacks.py:105 INFO train-abinet] epoch 6 iter 289500: loss = 0.4341,  smooth loss = 0.4802
[2022-07-07 09:54:58,719 callbacks.py:105 INFO train-abinet] epoch 6 iter 289550: loss = 0.5134,  smooth loss = 0.4841
[2022-07-07 09:55:38,451 callbacks.py:105 INFO train-abinet] epoch 6 iter 289600: loss = 0.4353,  smooth loss = 0.4707
[2022-07-07 09:56:19,550 callbacks.py:105 INFO train-abinet] epoch 6 iter 289650: loss = 0.3573,  smooth loss = 0.4698
[2022-07-07 09:56:59,677 callbacks.py:105 INFO train-abinet] epoch 6 iter 289700: loss = 0.4347,  smooth loss = 0.4667
[2022-07-07 09:57:42,086 callbacks.py:105 INFO train-abinet] epoch 6 iter 289750: loss = 0.4661,  smooth loss = 0.4755
█[2022-07-07 09:58:26,966 callbacks.py:105 INFO train-abinet] epoch 7 iter 289800: loss = 0.5481,  smooth loss = 0.4728
[2022-07-07 09:59:07,731 callbacks.py:105 INFO train-abinet] epoch 7 iter 289850: loss = 0.3538,  smooth loss = 0.4701
[2022-07-07 09:59:48,641 callbacks.py:105 INFO train-abinet] epoch 7 iter 289900: loss = 0.4320,  smooth loss = 0.4629
[2022-07-07 10:00:28,702 callbacks.py:105 INFO train-abinet] epoch 7 iter 289950: loss = 0.4978,  smooth loss = 0.4593
[2022-07-07 10:01:09,846 callbacks.py:105 INFO train-abinet] epoch 7 iter 290000: loss = 0.3810,  smooth loss = 0.4638
[2022-07-07 10:01:50,214 callbacks.py:105 INFO train-abinet] epoch 7 iter 290050: loss = 0.3828,  smooth loss = 0.4628
[2022-07-07 10:02:30,354 callbacks.py:105 INFO train-abinet] epoch 7 iter 290100: loss = 0.4987,  smooth loss = 0.4731
[2022-07-07 10:03:10,903 callbacks.py:105 INFO train-abinet] epoch 7 iter 290150: loss = 0.5011,  smooth loss = 0.4700
[2022-07-07 10:03:50,775 callbacks.py:105 INFO train-abinet] epoch 7 iter 290200: loss = 0.4142,  smooth loss = 0.4524
[2022-07-07 10:04:31,402 callbacks.py:105 INFO train-abinet] epoch 7 iter 290250: loss = 0.5267,  smooth loss = 0.4619
[2022-07-07 10:05:11,845 callbacks.py:105 INFO train-abinet] epoch 7 iter 290300: loss = 0.4836,  smooth loss = 0.4637
[2022-07-07 10:05:51,150 callbacks.py:105 INFO train-abinet] epoch 7 iter 290350: loss = 0.5763,  smooth loss = 0.4544
[2022-07-07 10:06:32,259 callbacks.py:105 INFO train-abinet] epoch 7 iter 290400: loss = 0.4951,  smooth loss = 0.4601
[2022-07-07 10:07:12,736 callbacks.py:105 INFO train-abinet] epoch 7 iter 290450: loss = 0.4862,  smooth loss = 0.4668
[2022-07-07 10:07:53,349 callbacks.py:105 INFO train-abinet] epoch 7 iter 290500: loss = 0.5270,  smooth loss = 0.4774
[2022-07-07 10:08:33,879 callbacks.py:105 INFO train-abinet] epoch 7 iter 290550: loss = 0.5088,  smooth loss = 0.4641
[2022-07-07 10:09:13,600 callbacks.py:105 INFO train-abinet] epoch 7 iter 290600: loss = 0.5276,  smooth loss = 0.4710
[2022-07-07 10:09:54,084 callbacks.py:105 INFO train-abinet] epoch 7 iter 290650: loss = 0.4945,  smooth loss = 0.4707
[2022-07-07 10:10:35,015 callbacks.py:105 INFO train-abinet] epoch 7 iter 290700: loss = 0.4617,  smooth loss = 0.4633
[2022-07-07 10:11:16,288 callbacks.py:105 INFO train-abinet] epoch 7 iter 290750: loss = 0.3603,  smooth loss = 0.4761
[2022-07-07 10:11:56,914 callbacks.py:105 INFO train-abinet] epoch 7 iter 290800: loss = 0.6142,  smooth loss = 0.4728
[2022-07-07 10:12:37,245 callbacks.py:105 INFO train-abinet] epoch 7 iter 290850: loss = 0.3554,  smooth loss = 0.4694
[2022-07-07 10:13:17,522 callbacks.py:105 INFO train-abinet] epoch 7 iter 290900: loss = 0.4640,  smooth loss = 0.4691
[2022-07-07 10:13:57,251 callbacks.py:105 INFO train-abinet] epoch 7 iter 290950: loss = 0.4903,  smooth loss = 0.4695
[2022-07-07 10:14:37,587 callbacks.py:105 INFO train-abinet] epoch 7 iter 291000: loss = 0.4633,  smooth loss = 0.4726
[2022-07-07 10:14:37,588 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8619s
█[2022-07-07 10:14:52,117 callbacks.py:123 INFO train-abinet] epoch 7 iter 291000: eval loss = 1.1591,  ccr = 0.9644,  cwr = 0.9272,  ted = 1173.0000,  ned = 236.4915,  ted/w = 0.1618, 
[2022-07-07 10:14:52,118 callbacks.py:130 INFO train-abinet] Better model found at epoch 7, iter 291000 with accuracy value: 0.9272.
[2022-07-07 10:14:53,241 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_291000
[2022-07-07 10:15:34,282 callbacks.py:105 INFO train-abinet] epoch 7 iter 291050: loss = 0.5342,  smooth loss = 0.4694
[2022-07-07 10:16:15,216 callbacks.py:105 INFO train-abinet] epoch 7 iter 291100: loss = 0.4760,  smooth loss = 0.4653
[2022-07-07 10:16:56,179 callbacks.py:105 INFO train-abinet] epoch 7 iter 291150: loss = 0.4539,  smooth loss = 0.4532
[2022-07-07 10:17:37,036 callbacks.py:105 INFO train-abinet] epoch 7 iter 291200: loss = 0.3775,  smooth loss = 0.4624
[2022-07-07 10:18:17,020 callbacks.py:105 INFO train-abinet] epoch 7 iter 291250: loss = 0.5065,  smooth loss = 0.4642
[2022-07-07 10:18:57,514 callbacks.py:105 INFO train-abinet] epoch 7 iter 291300: loss = 0.3416,  smooth loss = 0.4642
[2022-07-07 10:19:38,201 callbacks.py:105 INFO train-abinet] epoch 7 iter 291350: loss = 0.4927,  smooth loss = 0.4713
[2022-07-07 10:20:19,128 callbacks.py:105 INFO train-abinet] epoch 7 iter 291400: loss = 0.5049,  smooth loss = 0.4665
[2022-07-07 10:20:59,115 callbacks.py:105 INFO train-abinet] epoch 7 iter 291450: loss = 0.4654,  smooth loss = 0.4744
[2022-07-07 10:21:40,026 callbacks.py:105 INFO train-abinet] epoch 7 iter 291500: loss = 0.4754,  smooth loss = 0.4625
[2022-07-07 10:22:20,460 callbacks.py:105 INFO train-abinet] epoch 7 iter 291550: loss = 0.5035,  smooth loss = 0.4758
[2022-07-07 10:23:00,311 callbacks.py:105 INFO train-abinet] epoch 7 iter 291600: loss = 0.4447,  smooth loss = 0.4797
[2022-07-07 10:23:40,778 callbacks.py:105 INFO train-abinet] epoch 7 iter 291650: loss = 0.3296,  smooth loss = 0.4797
[2022-07-07 10:24:21,040 callbacks.py:105 INFO train-abinet] epoch 7 iter 291700: loss = 0.4866,  smooth loss = 0.4717
[2022-07-07 10:25:00,975 callbacks.py:105 INFO train-abinet] epoch 7 iter 291750: loss = 0.5307,  smooth loss = 0.4693
[2022-07-07 10:25:41,729 callbacks.py:105 INFO train-abinet] epoch 7 iter 291800: loss = 0.5598,  smooth loss = 0.4651
[2022-07-07 10:26:22,508 callbacks.py:105 INFO train-abinet] epoch 7 iter 291850: loss = 0.4385,  smooth loss = 0.4784
[2022-07-07 10:27:04,305 callbacks.py:105 INFO train-abinet] epoch 7 iter 291900: loss = 0.4240,  smooth loss = 0.4761
[2022-07-07 10:27:45,607 callbacks.py:105 INFO train-abinet] epoch 7 iter 291950: loss = 0.4998,  smooth loss = 0.4787
[2022-07-07 10:28:27,264 callbacks.py:105 INFO train-abinet] epoch 7 iter 292000: loss = 0.4852,  smooth loss = 0.4723
[2022-07-07 10:29:07,822 callbacks.py:105 INFO train-abinet] epoch 7 iter 292050: loss = 0.5900,  smooth loss = 0.4784
[2022-07-07 10:29:48,315 callbacks.py:105 INFO train-abinet] epoch 7 iter 292100: loss = 0.4489,  smooth loss = 0.4658
[2022-07-07 10:30:31,223 callbacks.py:105 INFO train-abinet] epoch 7 iter 292150: loss = 0.2935,  smooth loss = 0.4686
[2022-07-07 10:31:12,105 callbacks.py:105 INFO train-abinet] epoch 7 iter 292200: loss = 0.4401,  smooth loss = 0.4679
[2022-07-07 10:31:54,656 callbacks.py:105 INFO train-abinet] epoch 7 iter 292250: loss = 0.3234,  smooth loss = 0.4666
[2022-07-07 10:32:36,613 callbacks.py:105 INFO train-abinet] epoch 7 iter 292300: loss = 0.3963,  smooth loss = 0.4586
[2022-07-07 10:33:17,697 callbacks.py:105 INFO train-abinet] epoch 7 iter 292350: loss = 0.4394,  smooth loss = 0.4639
[2022-07-07 10:33:59,980 callbacks.py:105 INFO train-abinet] epoch 7 iter 292400: loss = 0.5092,  smooth loss = 0.4719
[2022-07-07 10:34:42,620 callbacks.py:105 INFO train-abinet] epoch 7 iter 292450: loss = 0.3668,  smooth loss = 0.4610
[2022-07-07 10:35:23,816 callbacks.py:105 INFO train-abinet] epoch 7 iter 292500: loss = 0.5048,  smooth loss = 0.4661
[2022-07-07 10:36:11,120 callbacks.py:105 INFO train-abinet] epoch 7 iter 292550: loss = 0.5355,  smooth loss = 0.4772
[2022-07-07 10:37:02,533 callbacks.py:105 INFO train-abinet] epoch 7 iter 292600: loss = 0.5544,  smooth loss = 0.4691
[2022-07-07 10:37:50,136 callbacks.py:105 INFO train-abinet] epoch 7 iter 292650: loss = 0.3902,  smooth loss = 0.4702
[2022-07-07 10:38:57,094 callbacks.py:105 INFO train-abinet] epoch 7 iter 292700: loss = 0.4212,  smooth loss = 0.4693
[2022-07-07 10:39:57,826 callbacks.py:105 INFO train-abinet] epoch 7 iter 292750: loss = 0.4670,  smooth loss = 0.4661
[2022-07-07 10:40:47,923 callbacks.py:105 INFO train-abinet] epoch 7 iter 292800: loss = 0.5265,  smooth loss = 0.4638
[2022-07-07 10:41:34,159 callbacks.py:105 INFO train-abinet] epoch 7 iter 292850: loss = 0.3990,  smooth loss = 0.4620
[2022-07-07 10:42:16,838 callbacks.py:105 INFO train-abinet] epoch 7 iter 292900: loss = 0.4195,  smooth loss = 0.4698
[2022-07-07 10:42:56,899 callbacks.py:105 INFO train-abinet] epoch 7 iter 292950: loss = 0.4711,  smooth loss = 0.4726
[2022-07-07 10:43:37,281 callbacks.py:105 INFO train-abinet] epoch 7 iter 293000: loss = 0.4859,  smooth loss = 0.4777
[2022-07-07 10:44:16,906 callbacks.py:105 INFO train-abinet] epoch 7 iter 293050: loss = 0.4304,  smooth loss = 0.4798
[2022-07-07 10:44:57,176 callbacks.py:105 INFO train-abinet] epoch 7 iter 293100: loss = 0.3980,  smooth loss = 0.4666
[2022-07-07 10:45:37,707 callbacks.py:105 INFO train-abinet] epoch 7 iter 293150: loss = 0.4602,  smooth loss = 0.4729
[2022-07-07 10:46:18,363 callbacks.py:105 INFO train-abinet] epoch 7 iter 293200: loss = 0.5332,  smooth loss = 0.4755
[2022-07-07 10:46:58,448 callbacks.py:105 INFO train-abinet] epoch 7 iter 293250: loss = 0.4658,  smooth loss = 0.4712
[2022-07-07 10:47:38,679 callbacks.py:105 INFO train-abinet] epoch 7 iter 293300: loss = 0.5697,  smooth loss = 0.4674
[2022-07-07 10:48:18,964 callbacks.py:105 INFO train-abinet] epoch 7 iter 293350: loss = 0.4329,  smooth loss = 0.4732
[2022-07-07 10:49:00,004 callbacks.py:105 INFO train-abinet] epoch 7 iter 293400: loss = 0.5828,  smooth loss = 0.4751
[2022-07-07 10:49:40,898 callbacks.py:105 INFO train-abinet] epoch 7 iter 293450: loss = 0.4252,  smooth loss = 0.4695
[2022-07-07 10:50:20,989 callbacks.py:105 INFO train-abinet] epoch 7 iter 293500: loss = 0.4463,  smooth loss = 0.4748
[2022-07-07 10:51:01,926 callbacks.py:105 INFO train-abinet] epoch 7 iter 293550: loss = 0.4697,  smooth loss = 0.4601
[2022-07-07 10:51:42,108 callbacks.py:105 INFO train-abinet] epoch 7 iter 293600: loss = 0.3953,  smooth loss = 0.4578
[2022-07-07 10:52:22,973 callbacks.py:105 INFO train-abinet] epoch 7 iter 293650: loss = 0.3385,  smooth loss = 0.4641
[2022-07-07 10:53:04,741 callbacks.py:105 INFO train-abinet] epoch 7 iter 293700: loss = 0.5858,  smooth loss = 0.4591
[2022-07-07 10:53:45,696 callbacks.py:105 INFO train-abinet] epoch 7 iter 293750: loss = 0.5229,  smooth loss = 0.4595
[2022-07-07 10:54:26,429 callbacks.py:105 INFO train-abinet] epoch 7 iter 293800: loss = 0.3208,  smooth loss = 0.4673
[2022-07-07 10:55:07,185 callbacks.py:105 INFO train-abinet] epoch 7 iter 293850: loss = 0.4588,  smooth loss = 0.4740
[2022-07-07 10:55:47,652 callbacks.py:105 INFO train-abinet] epoch 7 iter 293900: loss = 0.4830,  smooth loss = 0.4836
[2022-07-07 10:56:28,809 callbacks.py:105 INFO train-abinet] epoch 7 iter 293950: loss = 0.4618,  smooth loss = 0.4684
[2022-07-07 10:57:10,280 callbacks.py:105 INFO train-abinet] epoch 7 iter 294000: loss = 0.2767,  smooth loss = 0.4596
[2022-07-07 10:57:10,280 callbacks.py:114 INFO train-abinet] average data time = 0.0049s, average running time = 0.8617s
█[2022-07-07 10:57:24,005 callbacks.py:123 INFO train-abinet] epoch 7 iter 294000: eval loss = 1.1666,  ccr = 0.9645,  cwr = 0.9259,  ted = 1199.0000,  ned = 243.3090,  ted/w = 0.1654, 
[2022-07-07 10:57:24,006 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_294000
[2022-07-07 10:58:05,193 callbacks.py:105 INFO train-abinet] epoch 7 iter 294050: loss = 0.5058,  smooth loss = 0.4640
[2022-07-07 10:58:50,083 callbacks.py:105 INFO train-abinet] epoch 7 iter 294100: loss = 0.4924,  smooth loss = 0.4586
[2022-07-07 10:59:35,261 callbacks.py:105 INFO train-abinet] epoch 7 iter 294150: loss = 0.5513,  smooth loss = 0.4648
[2022-07-07 11:00:20,043 callbacks.py:105 INFO train-abinet] epoch 7 iter 294200: loss = 0.6207,  smooth loss = 0.4794
[2022-07-07 11:01:04,193 callbacks.py:105 INFO train-abinet] epoch 7 iter 294250: loss = 0.5541,  smooth loss = 0.4693
[2022-07-07 11:01:51,944 callbacks.py:105 INFO train-abinet] epoch 7 iter 294300: loss = 0.4766,  smooth loss = 0.4650
[2022-07-07 11:02:37,964 callbacks.py:105 INFO train-abinet] epoch 7 iter 294350: loss = 0.4283,  smooth loss = 0.4547
[2022-07-07 11:03:24,157 callbacks.py:105 INFO train-abinet] epoch 7 iter 294400: loss = 0.3644,  smooth loss = 0.4649
[2022-07-07 11:04:06,237 callbacks.py:105 INFO train-abinet] epoch 7 iter 294450: loss = 0.5774,  smooth loss = 0.4550
[2022-07-07 11:04:46,417 callbacks.py:105 INFO train-abinet] epoch 7 iter 294500: loss = 0.4136,  smooth loss = 0.4591
[2022-07-07 11:05:27,182 callbacks.py:105 INFO train-abinet] epoch 7 iter 294550: loss = 0.5175,  smooth loss = 0.4702
[2022-07-07 11:06:07,195 callbacks.py:105 INFO train-abinet] epoch 7 iter 294600: loss = 0.3917,  smooth loss = 0.4579
[2022-07-07 11:06:47,347 callbacks.py:105 INFO train-abinet] epoch 7 iter 294650: loss = 0.4522,  smooth loss = 0.4728
[2022-07-07 11:07:27,044 callbacks.py:105 INFO train-abinet] epoch 7 iter 294700: loss = 0.4560,  smooth loss = 0.4685
[2022-07-07 11:08:07,848 callbacks.py:105 INFO train-abinet] epoch 7 iter 294750: loss = 0.4584,  smooth loss = 0.4648
[2022-07-07 11:08:48,302 callbacks.py:105 INFO train-abinet] epoch 7 iter 294800: loss = 0.4247,  smooth loss = 0.4559
[2022-07-07 11:09:28,377 callbacks.py:105 INFO train-abinet] epoch 7 iter 294850: loss = 0.3579,  smooth loss = 0.4592
[2022-07-07 11:10:09,220 callbacks.py:105 INFO train-abinet] epoch 7 iter 294900: loss = 0.4514,  smooth loss = 0.4644
[2022-07-07 11:10:49,692 callbacks.py:105 INFO train-abinet] epoch 7 iter 294950: loss = 0.4009,  smooth loss = 0.4599
[2022-07-07 11:11:30,206 callbacks.py:105 INFO train-abinet] epoch 7 iter 295000: loss = 0.4712,  smooth loss = 0.4656
[2022-07-07 11:12:10,230 callbacks.py:105 INFO train-abinet] epoch 7 iter 295050: loss = 0.3952,  smooth loss = 0.4626
[2022-07-07 11:12:50,949 callbacks.py:105 INFO train-abinet] epoch 7 iter 295100: loss = 0.4918,  smooth loss = 0.4693
[2022-07-07 11:13:31,432 callbacks.py:105 INFO train-abinet] epoch 7 iter 295150: loss = 0.4889,  smooth loss = 0.4580
[2022-07-07 11:14:11,057 callbacks.py:105 INFO train-abinet] epoch 7 iter 295200: loss = 0.5562,  smooth loss = 0.4578
[2022-07-07 11:14:51,158 callbacks.py:105 INFO train-abinet] epoch 7 iter 295250: loss = 0.5640,  smooth loss = 0.4691
[2022-07-07 11:15:30,961 callbacks.py:105 INFO train-abinet] epoch 7 iter 295300: loss = 0.4384,  smooth loss = 0.4647
[2022-07-07 11:16:11,445 callbacks.py:105 INFO train-abinet] epoch 7 iter 295350: loss = 0.3605,  smooth loss = 0.4519
[2022-07-07 11:16:51,689 callbacks.py:105 INFO train-abinet] epoch 7 iter 295400: loss = 0.4090,  smooth loss = 0.4682
[2022-07-07 11:17:31,572 callbacks.py:105 INFO train-abinet] epoch 7 iter 295450: loss = 0.4845,  smooth loss = 0.4614
[2022-07-07 11:18:11,996 callbacks.py:105 INFO train-abinet] epoch 7 iter 295500: loss = 0.5018,  smooth loss = 0.4643
[2022-07-07 11:18:52,077 callbacks.py:105 INFO train-abinet] epoch 7 iter 295550: loss = 0.4074,  smooth loss = 0.4753
[2022-07-07 11:19:32,245 callbacks.py:105 INFO train-abinet] epoch 7 iter 295600: loss = 0.5155,  smooth loss = 0.4662
[2022-07-07 11:20:12,697 callbacks.py:105 INFO train-abinet] epoch 7 iter 295650: loss = 0.4016,  smooth loss = 0.4625
[2022-07-07 11:20:53,106 callbacks.py:105 INFO train-abinet] epoch 7 iter 295700: loss = 0.4906,  smooth loss = 0.4693
[2022-07-07 11:21:33,494 callbacks.py:105 INFO train-abinet] epoch 7 iter 295750: loss = 0.4634,  smooth loss = 0.4699
[2022-07-07 11:22:14,435 callbacks.py:105 INFO train-abinet] epoch 7 iter 295800: loss = 0.5270,  smooth loss = 0.4684
[2022-07-07 11:22:54,278 callbacks.py:105 INFO train-abinet] epoch 7 iter 295850: loss = 0.4663,  smooth loss = 0.4701
[2022-07-07 11:23:34,689 callbacks.py:105 INFO train-abinet] epoch 7 iter 295900: loss = 0.5954,  smooth loss = 0.4502
[2022-07-07 11:24:14,698 callbacks.py:105 INFO train-abinet] epoch 7 iter 295950: loss = 0.5463,  smooth loss = 0.4642
[2022-07-07 11:24:55,067 callbacks.py:105 INFO train-abinet] epoch 7 iter 296000: loss = 0.4933,  smooth loss = 0.4742
[2022-07-07 11:25:35,654 callbacks.py:105 INFO train-abinet] epoch 7 iter 296050: loss = 0.3222,  smooth loss = 0.4732
[2022-07-07 11:26:15,580 callbacks.py:105 INFO train-abinet] epoch 7 iter 296100: loss = 0.4906,  smooth loss = 0.4670
[2022-07-07 11:26:56,383 callbacks.py:105 INFO train-abinet] epoch 7 iter 296150: loss = 0.4838,  smooth loss = 0.4636
[2022-07-07 11:27:36,666 callbacks.py:105 INFO train-abinet] epoch 7 iter 296200: loss = 0.3650,  smooth loss = 0.4701
[2022-07-07 11:28:17,227 callbacks.py:105 INFO train-abinet] epoch 7 iter 296250: loss = 0.5501,  smooth loss = 0.4722
[2022-07-07 11:28:57,610 callbacks.py:105 INFO train-abinet] epoch 7 iter 296300: loss = 0.4372,  smooth loss = 0.4531
[2022-07-07 11:29:37,439 callbacks.py:105 INFO train-abinet] epoch 7 iter 296350: loss = 0.3975,  smooth loss = 0.4601
[2022-07-07 11:30:17,803 callbacks.py:105 INFO train-abinet] epoch 7 iter 296400: loss = 0.5818,  smooth loss = 0.4661
[2022-07-07 11:30:57,833 callbacks.py:105 INFO train-abinet] epoch 7 iter 296450: loss = 0.4100,  smooth loss = 0.4644
[2022-07-07 11:31:37,299 callbacks.py:105 INFO train-abinet] epoch 7 iter 296500: loss = 0.5986,  smooth loss = 0.4567
[2022-07-07 11:32:17,339 callbacks.py:105 INFO train-abinet] epoch 7 iter 296550: loss = 0.4411,  smooth loss = 0.4624
[2022-07-07 11:32:58,558 callbacks.py:105 INFO train-abinet] epoch 7 iter 296600: loss = 0.4288,  smooth loss = 0.4691
[2022-07-07 11:33:40,864 callbacks.py:105 INFO train-abinet] epoch 7 iter 296650: loss = 0.4755,  smooth loss = 0.4820
[2022-07-07 11:34:22,254 callbacks.py:105 INFO train-abinet] epoch 7 iter 296700: loss = 0.3758,  smooth loss = 0.4727
[2022-07-07 11:35:03,622 callbacks.py:105 INFO train-abinet] epoch 7 iter 296750: loss = 0.5063,  smooth loss = 0.4655
[2022-07-07 11:35:44,422 callbacks.py:105 INFO train-abinet] epoch 7 iter 296800: loss = 0.4395,  smooth loss = 0.4584
[2022-07-07 11:36:24,929 callbacks.py:105 INFO train-abinet] epoch 7 iter 296850: loss = 0.4649,  smooth loss = 0.4597
[2022-07-07 11:37:05,554 callbacks.py:105 INFO train-abinet] epoch 7 iter 296900: loss = 0.5651,  smooth loss = 0.4566
[2022-07-07 11:37:46,350 callbacks.py:105 INFO train-abinet] epoch 7 iter 296950: loss = 0.4385,  smooth loss = 0.4580
[2022-07-07 11:38:27,577 callbacks.py:105 INFO train-abinet] epoch 7 iter 297000: loss = 0.4874,  smooth loss = 0.4751
[2022-07-07 11:38:27,577 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8613s
█[2022-07-07 11:38:41,881 callbacks.py:123 INFO train-abinet] epoch 7 iter 297000: eval loss = 1.1609,  ccr = 0.9645,  cwr = 0.9266,  ted = 1180.0000,  ned = 239.3434,  ted/w = 0.1628, 
[2022-07-07 11:38:41,883 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_297000
[2022-07-07 11:39:23,706 callbacks.py:105 INFO train-abinet] epoch 7 iter 297050: loss = 0.3581,  smooth loss = 0.4758
[2022-07-07 11:40:03,895 callbacks.py:105 INFO train-abinet] epoch 7 iter 297100: loss = 0.4007,  smooth loss = 0.4747
[2022-07-07 11:40:44,080 callbacks.py:105 INFO train-abinet] epoch 7 iter 297150: loss = 0.5007,  smooth loss = 0.4774
[2022-07-07 11:41:24,856 callbacks.py:105 INFO train-abinet] epoch 7 iter 297200: loss = 0.5093,  smooth loss = 0.4788
[2022-07-07 11:42:05,717 callbacks.py:105 INFO train-abinet] epoch 7 iter 297250: loss = 0.5227,  smooth loss = 0.4760
[2022-07-07 11:42:45,965 callbacks.py:105 INFO train-abinet] epoch 7 iter 297300: loss = 0.4816,  smooth loss = 0.4763
[2022-07-07 11:43:26,285 callbacks.py:105 INFO train-abinet] epoch 7 iter 297350: loss = 0.5136,  smooth loss = 0.4638
[2022-07-07 11:44:06,737 callbacks.py:105 INFO train-abinet] epoch 7 iter 297400: loss = 0.4722,  smooth loss = 0.4585
[2022-07-07 11:44:46,659 callbacks.py:105 INFO train-abinet] epoch 7 iter 297450: loss = 0.4080,  smooth loss = 0.4596
[2022-07-07 11:45:26,592 callbacks.py:105 INFO train-abinet] epoch 7 iter 297500: loss = 0.3884,  smooth loss = 0.4637
[2022-07-07 11:46:07,945 callbacks.py:105 INFO train-abinet] epoch 7 iter 297550: loss = 0.4654,  smooth loss = 0.4696
[2022-07-07 11:46:48,535 callbacks.py:105 INFO train-abinet] epoch 7 iter 297600: loss = 0.4313,  smooth loss = 0.4794
[2022-07-07 11:47:28,769 callbacks.py:105 INFO train-abinet] epoch 7 iter 297650: loss = 0.4404,  smooth loss = 0.4591
[2022-07-07 11:48:08,563 callbacks.py:105 INFO train-abinet] epoch 7 iter 297700: loss = 0.4316,  smooth loss = 0.4612
[2022-07-07 11:48:48,810 callbacks.py:105 INFO train-abinet] epoch 7 iter 297750: loss = 0.4349,  smooth loss = 0.4687
[2022-07-07 11:49:28,468 callbacks.py:105 INFO train-abinet] epoch 7 iter 297800: loss = 0.3934,  smooth loss = 0.4805
[2022-07-07 11:50:08,941 callbacks.py:105 INFO train-abinet] epoch 7 iter 297850: loss = 0.6493,  smooth loss = 0.4681
[2022-07-07 11:50:49,095 callbacks.py:105 INFO train-abinet] epoch 7 iter 297900: loss = 0.4659,  smooth loss = 0.4755
[2022-07-07 11:51:29,492 callbacks.py:105 INFO train-abinet] epoch 7 iter 297950: loss = 0.4667,  smooth loss = 0.4782
[2022-07-07 11:52:09,346 callbacks.py:105 INFO train-abinet] epoch 7 iter 298000: loss = 0.4447,  smooth loss = 0.4769
[2022-07-07 11:52:49,923 callbacks.py:105 INFO train-abinet] epoch 7 iter 298050: loss = 0.3408,  smooth loss = 0.4683
[2022-07-07 11:53:30,548 callbacks.py:105 INFO train-abinet] epoch 7 iter 298100: loss = 0.4129,  smooth loss = 0.4580
[2022-07-07 11:54:11,334 callbacks.py:105 INFO train-abinet] epoch 7 iter 298150: loss = 0.3621,  smooth loss = 0.4694
[2022-07-07 11:54:51,705 callbacks.py:105 INFO train-abinet] epoch 7 iter 298200: loss = 0.4937,  smooth loss = 0.4661
[2022-07-07 11:55:32,230 callbacks.py:105 INFO train-abinet] epoch 7 iter 298250: loss = 0.4742,  smooth loss = 0.4718
[2022-07-07 11:56:13,054 callbacks.py:105 INFO train-abinet] epoch 7 iter 298300: loss = 0.5117,  smooth loss = 0.4642
[2022-07-07 11:56:53,740 callbacks.py:105 INFO train-abinet] epoch 7 iter 298350: loss = 0.5232,  smooth loss = 0.4635
[2022-07-07 11:57:33,846 callbacks.py:105 INFO train-abinet] epoch 7 iter 298400: loss = 0.4434,  smooth loss = 0.4565
[2022-07-07 11:58:14,245 callbacks.py:105 INFO train-abinet] epoch 7 iter 298450: loss = 0.4310,  smooth loss = 0.4595
[2022-07-07 11:58:54,180 callbacks.py:105 INFO train-abinet] epoch 7 iter 298500: loss = 0.5063,  smooth loss = 0.4564
[2022-07-07 11:59:34,778 callbacks.py:105 INFO train-abinet] epoch 7 iter 298550: loss = 0.5146,  smooth loss = 0.4587
[2022-07-07 12:00:15,512 callbacks.py:105 INFO train-abinet] epoch 7 iter 298600: loss = 0.3438,  smooth loss = 0.4594
[2022-07-07 12:00:55,548 callbacks.py:105 INFO train-abinet] epoch 7 iter 298650: loss = 0.3853,  smooth loss = 0.4536
[2022-07-07 12:01:36,405 callbacks.py:105 INFO train-abinet] epoch 7 iter 298700: loss = 0.5183,  smooth loss = 0.4657
[2022-07-07 12:02:16,998 callbacks.py:105 INFO train-abinet] epoch 7 iter 298750: loss = 0.4238,  smooth loss = 0.4702
[2022-07-07 12:02:58,118 callbacks.py:105 INFO train-abinet] epoch 7 iter 298800: loss = 0.4977,  smooth loss = 0.4679
[2022-07-07 12:03:38,432 callbacks.py:105 INFO train-abinet] epoch 7 iter 298850: loss = 0.4516,  smooth loss = 0.4788
[2022-07-07 12:04:19,430 callbacks.py:105 INFO train-abinet] epoch 7 iter 298900: loss = 0.4252,  smooth loss = 0.4705
[2022-07-07 12:04:59,997 callbacks.py:105 INFO train-abinet] epoch 7 iter 298950: loss = 0.4532,  smooth loss = 0.4630
[2022-07-07 12:05:40,260 callbacks.py:105 INFO train-abinet] epoch 7 iter 299000: loss = 0.4361,  smooth loss = 0.4578
[2022-07-07 12:06:19,602 callbacks.py:105 INFO train-abinet] epoch 7 iter 299050: loss = 0.4079,  smooth loss = 0.4587
[2022-07-07 12:07:00,422 callbacks.py:105 INFO train-abinet] epoch 7 iter 299100: loss = 0.4982,  smooth loss = 0.4518
[2022-07-07 12:07:40,378 callbacks.py:105 INFO train-abinet] epoch 7 iter 299150: loss = 0.4627,  smooth loss = 0.4577
[2022-07-07 12:08:20,855 callbacks.py:105 INFO train-abinet] epoch 7 iter 299200: loss = 0.3887,  smooth loss = 0.4620
[2022-07-07 12:09:00,844 callbacks.py:105 INFO train-abinet] epoch 7 iter 299250: loss = 0.4243,  smooth loss = 0.4752
[2022-07-07 12:09:41,412 callbacks.py:105 INFO train-abinet] epoch 7 iter 299300: loss = 0.4606,  smooth loss = 0.4636
[2022-07-07 12:10:21,152 callbacks.py:105 INFO train-abinet] epoch 7 iter 299350: loss = 0.4933,  smooth loss = 0.4727
[2022-07-07 12:11:01,418 callbacks.py:105 INFO train-abinet] epoch 7 iter 299400: loss = 0.3873,  smooth loss = 0.4660
[2022-07-07 12:11:41,621 callbacks.py:105 INFO train-abinet] epoch 7 iter 299450: loss = 0.3919,  smooth loss = 0.4493
[2022-07-07 12:12:22,208 callbacks.py:105 INFO train-abinet] epoch 7 iter 299500: loss = 0.4785,  smooth loss = 0.4578
[2022-07-07 12:13:03,050 callbacks.py:105 INFO train-abinet] epoch 7 iter 299550: loss = 0.5070,  smooth loss = 0.4589
[2022-07-07 12:13:43,049 callbacks.py:105 INFO train-abinet] epoch 7 iter 299600: loss = 0.4236,  smooth loss = 0.4742
[2022-07-07 12:14:23,481 callbacks.py:105 INFO train-abinet] epoch 7 iter 299650: loss = 0.4883,  smooth loss = 0.4772
[2022-07-07 12:15:03,421 callbacks.py:105 INFO train-abinet] epoch 7 iter 299700: loss = 0.3709,  smooth loss = 0.4681
[2022-07-07 12:15:43,454 callbacks.py:105 INFO train-abinet] epoch 7 iter 299750: loss = 0.4453,  smooth loss = 0.4706
[2022-07-07 12:16:23,912 callbacks.py:105 INFO train-abinet] epoch 7 iter 299800: loss = 0.3757,  smooth loss = 0.4657
[2022-07-07 12:17:04,169 callbacks.py:105 INFO train-abinet] epoch 7 iter 299850: loss = 0.5550,  smooth loss = 0.4608
[2022-07-07 12:17:43,958 callbacks.py:105 INFO train-abinet] epoch 7 iter 299900: loss = 0.4811,  smooth loss = 0.4715
[2022-07-07 12:18:24,948 callbacks.py:105 INFO train-abinet] epoch 7 iter 299950: loss = 0.3640,  smooth loss = 0.4633
[2022-07-07 12:19:05,405 callbacks.py:105 INFO train-abinet] epoch 7 iter 300000: loss = 0.4622,  smooth loss = 0.4725
[2022-07-07 12:19:05,405 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8608s
█[2022-07-07 12:19:23,470 callbacks.py:123 INFO train-abinet] epoch 7 iter 300000: eval loss = 1.1631,  ccr = 0.9648,  cwr = 0.9270,  ted = 1147.0000,  ned = 235.4088,  ted/w = 0.1583, 
[2022-07-07 12:19:23,471 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_300000
[2022-07-07 12:20:04,682 callbacks.py:105 INFO train-abinet] epoch 7 iter 300050: loss = 0.4714,  smooth loss = 0.4648
[2022-07-07 12:20:45,621 callbacks.py:105 INFO train-abinet] epoch 7 iter 300100: loss = 0.4290,  smooth loss = 0.4656
[2022-07-07 12:21:25,971 callbacks.py:105 INFO train-abinet] epoch 7 iter 300150: loss = 0.4312,  smooth loss = 0.4522
[2022-07-07 12:22:06,058 callbacks.py:105 INFO train-abinet] epoch 7 iter 300200: loss = 0.4245,  smooth loss = 0.4466
[2022-07-07 12:22:46,693 callbacks.py:105 INFO train-abinet] epoch 7 iter 300250: loss = 0.3904,  smooth loss = 0.4521
[2022-07-07 12:23:26,844 callbacks.py:105 INFO train-abinet] epoch 7 iter 300300: loss = 0.4378,  smooth loss = 0.4614
[2022-07-07 12:24:06,787 callbacks.py:105 INFO train-abinet] epoch 7 iter 300350: loss = 0.3558,  smooth loss = 0.4645
[2022-07-07 12:24:47,104 callbacks.py:105 INFO train-abinet] epoch 7 iter 300400: loss = 0.4697,  smooth loss = 0.4548
[2022-07-07 12:25:27,514 callbacks.py:105 INFO train-abinet] epoch 7 iter 300450: loss = 0.5069,  smooth loss = 0.4721
[2022-07-07 12:26:08,695 callbacks.py:105 INFO train-abinet] epoch 7 iter 300500: loss = 0.3949,  smooth loss = 0.4757
[2022-07-07 12:26:48,954 callbacks.py:105 INFO train-abinet] epoch 7 iter 300550: loss = 0.6966,  smooth loss = 0.4720
[2022-07-07 12:27:29,171 callbacks.py:105 INFO train-abinet] epoch 7 iter 300600: loss = 0.3395,  smooth loss = 0.4627
[2022-07-07 12:28:08,806 callbacks.py:105 INFO train-abinet] epoch 7 iter 300650: loss = 0.4639,  smooth loss = 0.4642
[2022-07-07 12:28:49,402 callbacks.py:105 INFO train-abinet] epoch 7 iter 300700: loss = 0.4417,  smooth loss = 0.4676
[2022-07-07 12:29:30,473 callbacks.py:105 INFO train-abinet] epoch 7 iter 300750: loss = 0.5462,  smooth loss = 0.4594
[2022-07-07 12:30:10,454 callbacks.py:105 INFO train-abinet] epoch 7 iter 300800: loss = 0.4299,  smooth loss = 0.4705
[2022-07-07 12:30:50,644 callbacks.py:105 INFO train-abinet] epoch 7 iter 300850: loss = 0.4678,  smooth loss = 0.4679
[2022-07-07 12:31:30,408 callbacks.py:105 INFO train-abinet] epoch 7 iter 300900: loss = 0.5466,  smooth loss = 0.4626
[2022-07-07 12:32:11,206 callbacks.py:105 INFO train-abinet] epoch 7 iter 300950: loss = 0.4688,  smooth loss = 0.4652
[2022-07-07 12:32:51,171 callbacks.py:105 INFO train-abinet] epoch 7 iter 301000: loss = 0.4859,  smooth loss = 0.4620
[2022-07-07 12:33:32,043 callbacks.py:105 INFO train-abinet] epoch 7 iter 301050: loss = 0.4488,  smooth loss = 0.4743
[2022-07-07 12:34:12,445 callbacks.py:105 INFO train-abinet] epoch 7 iter 301100: loss = 0.4334,  smooth loss = 0.4676
[2022-07-07 12:34:52,261 callbacks.py:105 INFO train-abinet] epoch 7 iter 301150: loss = 0.4695,  smooth loss = 0.4636
[2022-07-07 12:35:33,381 callbacks.py:105 INFO train-abinet] epoch 7 iter 301200: loss = 0.5107,  smooth loss = 0.4731
[2022-07-07 12:36:13,511 callbacks.py:105 INFO train-abinet] epoch 7 iter 301250: loss = 0.5039,  smooth loss = 0.4615
[2022-07-07 12:36:54,209 callbacks.py:105 INFO train-abinet] epoch 7 iter 301300: loss = 0.3759,  smooth loss = 0.4672
[2022-07-07 12:37:34,903 callbacks.py:105 INFO train-abinet] epoch 7 iter 301350: loss = 0.4544,  smooth loss = 0.4561
[2022-07-07 12:38:14,624 callbacks.py:105 INFO train-abinet] epoch 7 iter 301400: loss = 0.3180,  smooth loss = 0.4521
[2022-07-07 12:38:55,166 callbacks.py:105 INFO train-abinet] epoch 7 iter 301450: loss = 0.5437,  smooth loss = 0.4630
[2022-07-07 12:39:35,315 callbacks.py:105 INFO train-abinet] epoch 7 iter 301500: loss = 0.4856,  smooth loss = 0.4687
[2022-07-07 12:40:15,255 callbacks.py:105 INFO train-abinet] epoch 7 iter 301550: loss = 0.4915,  smooth loss = 0.4677
[2022-07-07 12:40:55,793 callbacks.py:105 INFO train-abinet] epoch 7 iter 301600: loss = 0.5204,  smooth loss = 0.4702
[2022-07-07 12:41:36,519 callbacks.py:105 INFO train-abinet] epoch 7 iter 301650: loss = 0.3927,  smooth loss = 0.4592
[2022-07-07 12:42:17,290 callbacks.py:105 INFO train-abinet] epoch 7 iter 301700: loss = 0.4874,  smooth loss = 0.4748
[2022-07-07 12:42:58,060 callbacks.py:105 INFO train-abinet] epoch 7 iter 301750: loss = 0.4968,  smooth loss = 0.4701
[2022-07-07 12:43:38,448 callbacks.py:105 INFO train-abinet] epoch 7 iter 301800: loss = 0.4109,  smooth loss = 0.4694
[2022-07-07 12:44:18,481 callbacks.py:105 INFO train-abinet] epoch 7 iter 301850: loss = 0.4899,  smooth loss = 0.4725
[2022-07-07 12:44:59,600 callbacks.py:105 INFO train-abinet] epoch 7 iter 301900: loss = 0.4712,  smooth loss = 0.4737
[2022-07-07 12:45:39,794 callbacks.py:105 INFO train-abinet] epoch 7 iter 301950: loss = 0.3791,  smooth loss = 0.4673
[2022-07-07 12:46:20,564 callbacks.py:105 INFO train-abinet] epoch 7 iter 302000: loss = 0.4749,  smooth loss = 0.4656
[2022-07-07 12:47:01,083 callbacks.py:105 INFO train-abinet] epoch 7 iter 302050: loss = 0.4491,  smooth loss = 0.4557
[2022-07-07 12:47:41,198 callbacks.py:105 INFO train-abinet] epoch 7 iter 302100: loss = 0.4893,  smooth loss = 0.4620
[2022-07-07 12:48:21,372 callbacks.py:105 INFO train-abinet] epoch 7 iter 302150: loss = 0.4240,  smooth loss = 0.4695
[2022-07-07 12:49:02,439 callbacks.py:105 INFO train-abinet] epoch 7 iter 302200: loss = 0.4600,  smooth loss = 0.4724
[2022-07-07 12:49:41,947 callbacks.py:105 INFO train-abinet] epoch 7 iter 302250: loss = 0.4958,  smooth loss = 0.4749
[2022-07-07 12:50:22,053 callbacks.py:105 INFO train-abinet] epoch 7 iter 302300: loss = 0.3447,  smooth loss = 0.4710
[2022-07-07 12:51:03,383 callbacks.py:105 INFO train-abinet] epoch 7 iter 302350: loss = 0.5484,  smooth loss = 0.4672
[2022-07-07 12:51:43,379 callbacks.py:105 INFO train-abinet] epoch 7 iter 302400: loss = 0.5379,  smooth loss = 0.4644
[2022-07-07 12:52:23,789 callbacks.py:105 INFO train-abinet] epoch 7 iter 302450: loss = 0.5254,  smooth loss = 0.4704
[2022-07-07 12:53:04,342 callbacks.py:105 INFO train-abinet] epoch 7 iter 302500: loss = 0.4504,  smooth loss = 0.4580
[2022-07-07 12:53:45,076 callbacks.py:105 INFO train-abinet] epoch 7 iter 302550: loss = 0.4670,  smooth loss = 0.4563
[2022-07-07 12:54:25,724 callbacks.py:105 INFO train-abinet] epoch 7 iter 302600: loss = 0.3757,  smooth loss = 0.4539
[2022-07-07 12:55:06,347 callbacks.py:105 INFO train-abinet] epoch 7 iter 302650: loss = 0.4812,  smooth loss = 0.4646
[2022-07-07 12:55:46,195 callbacks.py:105 INFO train-abinet] epoch 7 iter 302700: loss = 0.4834,  smooth loss = 0.4635
[2022-07-07 12:56:26,779 callbacks.py:105 INFO train-abinet] epoch 7 iter 302750: loss = 0.5349,  smooth loss = 0.4697
[2022-07-07 12:57:06,982 callbacks.py:105 INFO train-abinet] epoch 7 iter 302800: loss = 0.5048,  smooth loss = 0.4606
[2022-07-07 12:57:47,151 callbacks.py:105 INFO train-abinet] epoch 7 iter 302850: loss = 0.4335,  smooth loss = 0.4674
[2022-07-07 12:58:27,932 callbacks.py:105 INFO train-abinet] epoch 7 iter 302900: loss = 0.5732,  smooth loss = 0.4703
[2022-07-07 12:59:07,855 callbacks.py:105 INFO train-abinet] epoch 7 iter 302950: loss = 0.4563,  smooth loss = 0.4739
[2022-07-07 12:59:48,106 callbacks.py:105 INFO train-abinet] epoch 7 iter 303000: loss = 0.4847,  smooth loss = 0.4754
[2022-07-07 12:59:48,107 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8603s
█[2022-07-07 13:00:02,483 callbacks.py:123 INFO train-abinet] epoch 7 iter 303000: eval loss = 1.1619,  ccr = 0.9645,  cwr = 0.9266,  ted = 1178.0000,  ned = 239.6999,  ted/w = 0.1625, 
[2022-07-07 13:00:02,484 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_303000
[2022-07-07 13:00:44,149 callbacks.py:105 INFO train-abinet] epoch 7 iter 303050: loss = 0.4657,  smooth loss = 0.4691
[2022-07-07 13:01:24,525 callbacks.py:105 INFO train-abinet] epoch 7 iter 303100: loss = 0.4734,  smooth loss = 0.4844
[2022-07-07 13:02:05,717 callbacks.py:105 INFO train-abinet] epoch 7 iter 303150: loss = 0.4214,  smooth loss = 0.4671
[2022-07-07 13:02:45,956 callbacks.py:105 INFO train-abinet] epoch 7 iter 303200: loss = 0.4662,  smooth loss = 0.4538
[2022-07-07 13:03:26,734 callbacks.py:105 INFO train-abinet] epoch 7 iter 303250: loss = 0.4706,  smooth loss = 0.4564
[2022-07-07 13:04:08,156 callbacks.py:105 INFO train-abinet] epoch 7 iter 303300: loss = 0.3472,  smooth loss = 0.4595
[2022-07-07 13:04:49,875 callbacks.py:105 INFO train-abinet] epoch 7 iter 303350: loss = 0.3535,  smooth loss = 0.4650
[2022-07-07 13:05:32,285 callbacks.py:105 INFO train-abinet] epoch 7 iter 303400: loss = 0.3917,  smooth loss = 0.4550
[2022-07-07 13:06:17,501 callbacks.py:105 INFO train-abinet] epoch 7 iter 303450: loss = 0.4101,  smooth loss = 0.4576
[2022-07-07 13:07:04,297 callbacks.py:105 INFO train-abinet] epoch 7 iter 303500: loss = 0.4456,  smooth loss = 0.4681
[2022-07-07 13:07:52,220 callbacks.py:105 INFO train-abinet] epoch 7 iter 303550: loss = 0.4374,  smooth loss = 0.4616
[2022-07-07 13:08:39,663 callbacks.py:105 INFO train-abinet] epoch 7 iter 303600: loss = 0.3573,  smooth loss = 0.4590
[2022-07-07 13:09:27,190 callbacks.py:105 INFO train-abinet] epoch 7 iter 303650: loss = 0.5131,  smooth loss = 0.4600
[2022-07-07 13:10:13,696 callbacks.py:105 INFO train-abinet] epoch 7 iter 303700: loss = 0.5949,  smooth loss = 0.4744
[2022-07-07 13:11:00,763 callbacks.py:105 INFO train-abinet] epoch 7 iter 303750: loss = 0.4505,  smooth loss = 0.4687
[2022-07-07 13:11:50,259 callbacks.py:105 INFO train-abinet] epoch 7 iter 303800: loss = 0.5543,  smooth loss = 0.4583
[2022-07-07 13:12:34,059 callbacks.py:105 INFO train-abinet] epoch 7 iter 303850: loss = 0.5356,  smooth loss = 0.4543
[2022-07-07 13:13:15,436 callbacks.py:105 INFO train-abinet] epoch 7 iter 303900: loss = 0.5445,  smooth loss = 0.4565
[2022-07-07 13:13:56,412 callbacks.py:105 INFO train-abinet] epoch 7 iter 303950: loss = 0.3735,  smooth loss = 0.4744
[2022-07-07 13:14:37,983 callbacks.py:105 INFO train-abinet] epoch 7 iter 304000: loss = 0.5316,  smooth loss = 0.4601
[2022-07-07 13:15:25,111 callbacks.py:105 INFO train-abinet] epoch 7 iter 304050: loss = 0.4002,  smooth loss = 0.4593
[2022-07-07 13:16:13,488 callbacks.py:105 INFO train-abinet] epoch 7 iter 304100: loss = 0.4244,  smooth loss = 0.4600
[2022-07-07 13:16:59,861 callbacks.py:105 INFO train-abinet] epoch 7 iter 304150: loss = 0.5131,  smooth loss = 0.4564
[2022-07-07 13:17:42,963 callbacks.py:105 INFO train-abinet] epoch 7 iter 304200: loss = 0.5234,  smooth loss = 0.4613
[2022-07-07 13:18:26,889 callbacks.py:105 INFO train-abinet] epoch 7 iter 304250: loss = 0.5524,  smooth loss = 0.4636
[2022-07-07 13:19:13,287 callbacks.py:105 INFO train-abinet] epoch 7 iter 304300: loss = 0.4636,  smooth loss = 0.4627
[2022-07-07 13:19:58,334 callbacks.py:105 INFO train-abinet] epoch 7 iter 304350: loss = 0.3640,  smooth loss = 0.4556
[2022-07-07 13:20:47,237 callbacks.py:105 INFO train-abinet] epoch 7 iter 304400: loss = 0.3973,  smooth loss = 0.4539
[2022-07-07 13:21:34,079 callbacks.py:105 INFO train-abinet] epoch 7 iter 304450: loss = 0.6130,  smooth loss = 0.4652
[2022-07-07 13:22:22,414 callbacks.py:105 INFO train-abinet] epoch 7 iter 304500: loss = 0.2967,  smooth loss = 0.4750
[2022-07-07 13:23:09,143 callbacks.py:105 INFO train-abinet] epoch 7 iter 304550: loss = 0.5609,  smooth loss = 0.4602
[2022-07-07 13:23:53,678 callbacks.py:105 INFO train-abinet] epoch 7 iter 304600: loss = 0.4336,  smooth loss = 0.4538
[2022-07-07 13:24:42,904 callbacks.py:105 INFO train-abinet] epoch 7 iter 304650: loss = 0.4742,  smooth loss = 0.4522
[2022-07-07 13:25:30,402 callbacks.py:105 INFO train-abinet] epoch 7 iter 304700: loss = 0.4311,  smooth loss = 0.4541
[2022-07-07 13:26:18,956 callbacks.py:105 INFO train-abinet] epoch 7 iter 304750: loss = 0.3709,  smooth loss = 0.4485
[2022-07-07 13:27:06,364 callbacks.py:105 INFO train-abinet] epoch 7 iter 304800: loss = 0.2936,  smooth loss = 0.4542
[2022-07-07 13:27:55,066 callbacks.py:105 INFO train-abinet] epoch 7 iter 304850: loss = 0.2822,  smooth loss = 0.4532
[2022-07-07 13:28:43,142 callbacks.py:105 INFO train-abinet] epoch 7 iter 304900: loss = 0.4960,  smooth loss = 0.4702
[2022-07-07 13:29:32,072 callbacks.py:105 INFO train-abinet] epoch 7 iter 304950: loss = 0.3758,  smooth loss = 0.4551
[2022-07-07 13:30:19,124 callbacks.py:105 INFO train-abinet] epoch 7 iter 305000: loss = 0.4624,  smooth loss = 0.4559
[2022-07-07 13:31:07,551 callbacks.py:105 INFO train-abinet] epoch 7 iter 305050: loss = 0.5482,  smooth loss = 0.4623
[2022-07-07 13:31:54,702 callbacks.py:105 INFO train-abinet] epoch 7 iter 305100: loss = 0.6230,  smooth loss = 0.4708
[2022-07-07 13:32:44,123 callbacks.py:105 INFO train-abinet] epoch 7 iter 305150: loss = 0.3857,  smooth loss = 0.4635
[2022-07-07 13:33:31,795 callbacks.py:105 INFO train-abinet] epoch 7 iter 305200: loss = 0.4890,  smooth loss = 0.4702
[2022-07-07 13:34:20,201 callbacks.py:105 INFO train-abinet] epoch 7 iter 305250: loss = 0.5226,  smooth loss = 0.4603
[2022-07-07 13:35:07,041 callbacks.py:105 INFO train-abinet] epoch 7 iter 305300: loss = 0.5826,  smooth loss = 0.4672
[2022-07-07 13:35:49,996 callbacks.py:105 INFO train-abinet] epoch 7 iter 305350: loss = 0.4646,  smooth loss = 0.4684
[2022-07-07 13:36:32,370 callbacks.py:105 INFO train-abinet] epoch 7 iter 305400: loss = 0.4053,  smooth loss = 0.4549
[2022-07-07 13:37:15,280 callbacks.py:105 INFO train-abinet] epoch 7 iter 305450: loss = 0.4276,  smooth loss = 0.4557
[2022-07-07 13:37:58,994 callbacks.py:105 INFO train-abinet] epoch 7 iter 305500: loss = 0.4604,  smooth loss = 0.4572
[2022-07-07 13:38:41,249 callbacks.py:105 INFO train-abinet] epoch 7 iter 305550: loss = 0.4839,  smooth loss = 0.4607
[2022-07-07 13:39:26,942 callbacks.py:105 INFO train-abinet] epoch 7 iter 305600: loss = 0.3792,  smooth loss = 0.4574
[2022-07-07 13:40:13,327 callbacks.py:105 INFO train-abinet] epoch 7 iter 305650: loss = 0.3556,  smooth loss = 0.4599
[2022-07-07 13:41:00,034 callbacks.py:105 INFO train-abinet] epoch 7 iter 305700: loss = 0.3725,  smooth loss = 0.4508
[2022-07-07 13:41:48,832 callbacks.py:105 INFO train-abinet] epoch 7 iter 305750: loss = 0.4630,  smooth loss = 0.4642
[2022-07-07 13:42:36,599 callbacks.py:105 INFO train-abinet] epoch 7 iter 305800: loss = 0.4365,  smooth loss = 0.4672
[2022-07-07 13:43:24,206 callbacks.py:105 INFO train-abinet] epoch 7 iter 305850: loss = 0.4459,  smooth loss = 0.4815
[2022-07-07 13:44:09,189 callbacks.py:105 INFO train-abinet] epoch 7 iter 305900: loss = 0.4781,  smooth loss = 0.4693
[2022-07-07 13:44:56,023 callbacks.py:105 INFO train-abinet] epoch 7 iter 305950: loss = 0.4281,  smooth loss = 0.4590
[2022-07-07 13:45:37,844 callbacks.py:105 INFO train-abinet] epoch 7 iter 306000: loss = 0.3168,  smooth loss = 0.4534
[2022-07-07 13:45:37,845 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8608s
█[2022-07-07 13:45:53,151 callbacks.py:123 INFO train-abinet] epoch 7 iter 306000: eval loss = 1.1722,  ccr = 0.9647,  cwr = 0.9263,  ted = 1170.0000,  ned = 238.7001,  ted/w = 0.1614, 
[2022-07-07 13:45:53,153 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_306000
[2022-07-07 13:46:40,012 callbacks.py:105 INFO train-abinet] epoch 7 iter 306050: loss = 0.4252,  smooth loss = 0.4562
[2022-07-07 13:47:31,181 callbacks.py:105 INFO train-abinet] epoch 7 iter 306100: loss = 0.4074,  smooth loss = 0.4519
[2022-07-07 13:48:20,401 callbacks.py:105 INFO train-abinet] epoch 7 iter 306150: loss = 0.4515,  smooth loss = 0.4684
[2022-07-07 13:49:08,822 callbacks.py:105 INFO train-abinet] epoch 7 iter 306200: loss = 0.4212,  smooth loss = 0.4656
[2022-07-07 13:49:58,879 callbacks.py:105 INFO train-abinet] epoch 7 iter 306250: loss = 0.5684,  smooth loss = 0.4666
[2022-07-07 13:50:47,850 callbacks.py:105 INFO train-abinet] epoch 7 iter 306300: loss = 0.4451,  smooth loss = 0.4762
[2022-07-07 13:51:37,127 callbacks.py:105 INFO train-abinet] epoch 7 iter 306350: loss = 0.5806,  smooth loss = 0.4638
[2022-07-07 13:52:24,738 callbacks.py:105 INFO train-abinet] epoch 7 iter 306400: loss = 0.4453,  smooth loss = 0.4518
[2022-07-07 13:53:12,485 callbacks.py:105 INFO train-abinet] epoch 7 iter 306450: loss = 0.5164,  smooth loss = 0.4621
[2022-07-07 13:53:58,260 callbacks.py:105 INFO train-abinet] epoch 7 iter 306500: loss = 0.3936,  smooth loss = 0.4646
[2022-07-07 13:54:44,004 callbacks.py:105 INFO train-abinet] epoch 7 iter 306550: loss = 0.4059,  smooth loss = 0.4651
[2022-07-07 13:55:26,438 callbacks.py:105 INFO train-abinet] epoch 7 iter 306600: loss = 0.4448,  smooth loss = 0.4663
[2022-07-07 13:56:09,457 callbacks.py:105 INFO train-abinet] epoch 7 iter 306650: loss = 0.4677,  smooth loss = 0.4703
[2022-07-07 13:56:50,912 callbacks.py:105 INFO train-abinet] epoch 7 iter 306700: loss = 0.4185,  smooth loss = 0.4706
[2022-07-07 13:57:33,684 callbacks.py:105 INFO train-abinet] epoch 7 iter 306750: loss = 0.5410,  smooth loss = 0.4718
[2022-07-07 13:58:21,403 callbacks.py:105 INFO train-abinet] epoch 7 iter 306800: loss = 0.4296,  smooth loss = 0.4562
[2022-07-07 13:59:10,334 callbacks.py:105 INFO train-abinet] epoch 7 iter 306850: loss = 0.4795,  smooth loss = 0.4684
[2022-07-07 13:59:58,240 callbacks.py:105 INFO train-abinet] epoch 7 iter 306900: loss = 0.4271,  smooth loss = 0.4670
[2022-07-07 14:00:46,594 callbacks.py:105 INFO train-abinet] epoch 7 iter 306950: loss = 0.4610,  smooth loss = 0.4591
[2022-07-07 14:01:34,000 callbacks.py:105 INFO train-abinet] epoch 7 iter 307000: loss = 0.5769,  smooth loss = 0.4633
[2022-07-07 14:02:21,057 callbacks.py:105 INFO train-abinet] epoch 7 iter 307050: loss = 0.3675,  smooth loss = 0.4526
[2022-07-07 14:03:08,402 callbacks.py:105 INFO train-abinet] epoch 7 iter 307100: loss = 0.3689,  smooth loss = 0.4494
[2022-07-07 14:03:52,128 callbacks.py:105 INFO train-abinet] epoch 7 iter 307150: loss = 0.4514,  smooth loss = 0.4515
[2022-07-07 14:04:38,525 callbacks.py:105 INFO train-abinet] epoch 7 iter 307200: loss = 0.7123,  smooth loss = 0.4749
[2022-07-07 14:05:25,342 callbacks.py:105 INFO train-abinet] epoch 7 iter 307250: loss = 0.5292,  smooth loss = 0.4662
[2022-07-07 14:06:13,772 callbacks.py:105 INFO train-abinet] epoch 7 iter 307300: loss = 0.4607,  smooth loss = 0.4686
[2022-07-07 14:07:00,702 callbacks.py:105 INFO train-abinet] epoch 7 iter 307350: loss = 0.3907,  smooth loss = 0.4595
[2022-07-07 14:07:50,561 callbacks.py:105 INFO train-abinet] epoch 7 iter 307400: loss = 0.5265,  smooth loss = 0.4593
[2022-07-07 14:08:37,864 callbacks.py:105 INFO train-abinet] epoch 7 iter 307450: loss = 0.3703,  smooth loss = 0.4513
[2022-07-07 14:09:25,797 callbacks.py:105 INFO train-abinet] epoch 7 iter 307500: loss = 0.4521,  smooth loss = 0.4713
[2022-07-07 14:10:13,050 callbacks.py:105 INFO train-abinet] epoch 7 iter 307550: loss = 0.4358,  smooth loss = 0.4737
[2022-07-07 14:10:58,396 callbacks.py:105 INFO train-abinet] epoch 7 iter 307600: loss = 0.4324,  smooth loss = 0.4685
[2022-07-07 14:11:44,317 callbacks.py:105 INFO train-abinet] epoch 7 iter 307650: loss = 0.4199,  smooth loss = 0.4745
[2022-07-07 14:12:29,928 callbacks.py:105 INFO train-abinet] epoch 7 iter 307700: loss = 0.3270,  smooth loss = 0.4646
[2022-07-07 14:13:10,985 callbacks.py:105 INFO train-abinet] epoch 7 iter 307750: loss = 0.5424,  smooth loss = 0.4598
[2022-07-07 14:13:54,221 callbacks.py:105 INFO train-abinet] epoch 7 iter 307800: loss = 0.5463,  smooth loss = 0.4620
[2022-07-07 14:14:36,663 callbacks.py:105 INFO train-abinet] epoch 7 iter 307850: loss = 0.5871,  smooth loss = 0.4744
[2022-07-07 14:15:18,562 callbacks.py:105 INFO train-abinet] epoch 7 iter 307900: loss = 0.5043,  smooth loss = 0.4773
[2022-07-07 14:16:02,146 callbacks.py:105 INFO train-abinet] epoch 7 iter 307950: loss = 0.4167,  smooth loss = 0.4716
[2022-07-07 14:16:44,289 callbacks.py:105 INFO train-abinet] epoch 7 iter 308000: loss = 0.5187,  smooth loss = 0.4807
[2022-07-07 14:17:30,040 callbacks.py:105 INFO train-abinet] epoch 7 iter 308050: loss = 0.5883,  smooth loss = 0.4880
[2022-07-07 14:18:13,655 callbacks.py:105 INFO train-abinet] epoch 7 iter 308100: loss = 0.4868,  smooth loss = 0.4741
[2022-07-07 14:19:02,044 callbacks.py:105 INFO train-abinet] epoch 7 iter 308150: loss = 0.4658,  smooth loss = 0.4774
[2022-07-07 14:19:43,963 callbacks.py:105 INFO train-abinet] epoch 7 iter 308200: loss = 0.4079,  smooth loss = 0.4654
[2022-07-07 14:20:25,493 callbacks.py:105 INFO train-abinet] epoch 7 iter 308250: loss = 0.5243,  smooth loss = 0.4585
[2022-07-07 14:21:06,011 callbacks.py:105 INFO train-abinet] epoch 7 iter 308300: loss = 0.5158,  smooth loss = 0.4543
[2022-07-07 14:21:47,065 callbacks.py:105 INFO train-abinet] epoch 7 iter 308350: loss = 0.4824,  smooth loss = 0.4596
[2022-07-07 14:22:27,708 callbacks.py:105 INFO train-abinet] epoch 7 iter 308400: loss = 0.4362,  smooth loss = 0.4572
[2022-07-07 14:23:07,869 callbacks.py:105 INFO train-abinet] epoch 7 iter 308450: loss = 0.3804,  smooth loss = 0.4542
[2022-07-07 14:23:49,014 callbacks.py:105 INFO train-abinet] epoch 7 iter 308500: loss = 0.5726,  smooth loss = 0.4742
[2022-07-07 14:24:29,592 callbacks.py:105 INFO train-abinet] epoch 7 iter 308550: loss = 0.5383,  smooth loss = 0.4734
[2022-07-07 14:25:09,658 callbacks.py:105 INFO train-abinet] epoch 7 iter 308600: loss = 0.4692,  smooth loss = 0.4694
[2022-07-07 14:25:50,628 callbacks.py:105 INFO train-abinet] epoch 7 iter 308650: loss = 0.4976,  smooth loss = 0.4663
[2022-07-07 14:26:30,821 callbacks.py:105 INFO train-abinet] epoch 7 iter 308700: loss = 0.4354,  smooth loss = 0.4680
[2022-07-07 14:27:11,391 callbacks.py:105 INFO train-abinet] epoch 7 iter 308750: loss = 0.4792,  smooth loss = 0.4669
[2022-07-07 14:27:51,614 callbacks.py:105 INFO train-abinet] epoch 7 iter 308800: loss = 0.5096,  smooth loss = 0.4628
[2022-07-07 14:28:32,101 callbacks.py:105 INFO train-abinet] epoch 7 iter 308850: loss = 0.4582,  smooth loss = 0.4694
[2022-07-07 14:29:12,551 callbacks.py:105 INFO train-abinet] epoch 7 iter 308900: loss = 0.4490,  smooth loss = 0.4611
[2022-07-07 14:29:51,934 callbacks.py:105 INFO train-abinet] epoch 7 iter 308950: loss = 0.5185,  smooth loss = 0.4655
[2022-07-07 14:30:33,008 callbacks.py:105 INFO train-abinet] epoch 7 iter 309000: loss = 0.4819,  smooth loss = 0.4554
[2022-07-07 14:30:33,008 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8611s
█[2022-07-07 14:30:46,629 callbacks.py:123 INFO train-abinet] epoch 7 iter 309000: eval loss = 1.1680,  ccr = 0.9644,  cwr = 0.9254,  ted = 1187.0000,  ned = 238.1894,  ted/w = 0.1638, 
[2022-07-07 14:30:46,630 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_309000
[2022-07-07 14:31:27,853 callbacks.py:105 INFO train-abinet] epoch 7 iter 309050: loss = 0.5049,  smooth loss = 0.4663
[2022-07-07 14:32:08,623 callbacks.py:105 INFO train-abinet] epoch 7 iter 309100: loss = 0.4223,  smooth loss = 0.4507
[2022-07-07 14:32:48,599 callbacks.py:105 INFO train-abinet] epoch 7 iter 309150: loss = 0.4013,  smooth loss = 0.4587
[2022-07-07 14:33:29,118 callbacks.py:105 INFO train-abinet] epoch 7 iter 309200: loss = 0.4765,  smooth loss = 0.4721
[2022-07-07 14:34:08,819 callbacks.py:105 INFO train-abinet] epoch 7 iter 309250: loss = 0.4761,  smooth loss = 0.4697
[2022-07-07 14:34:49,617 callbacks.py:105 INFO train-abinet] epoch 7 iter 309300: loss = 0.3835,  smooth loss = 0.4611
[2022-07-07 14:35:29,393 callbacks.py:105 INFO train-abinet] epoch 7 iter 309350: loss = 0.4677,  smooth loss = 0.4518
[2022-07-07 14:36:09,749 callbacks.py:105 INFO train-abinet] epoch 7 iter 309400: loss = 0.3689,  smooth loss = 0.4599
[2022-07-07 14:36:50,058 callbacks.py:105 INFO train-abinet] epoch 7 iter 309450: loss = 0.4538,  smooth loss = 0.4599
[2022-07-07 14:37:31,015 callbacks.py:105 INFO train-abinet] epoch 7 iter 309500: loss = 0.4732,  smooth loss = 0.4662
[2022-07-07 14:38:11,728 callbacks.py:105 INFO train-abinet] epoch 7 iter 309550: loss = 0.3124,  smooth loss = 0.4626
[2022-07-07 14:38:52,568 callbacks.py:105 INFO train-abinet] epoch 7 iter 309600: loss = 0.5003,  smooth loss = 0.4673
[2022-07-07 14:39:33,021 callbacks.py:105 INFO train-abinet] epoch 7 iter 309650: loss = 0.3438,  smooth loss = 0.4665
[2022-07-07 14:40:14,405 callbacks.py:105 INFO train-abinet] epoch 7 iter 309700: loss = 0.4386,  smooth loss = 0.4624
[2022-07-07 14:40:55,167 callbacks.py:105 INFO train-abinet] epoch 7 iter 309750: loss = 0.5759,  smooth loss = 0.4557
[2022-07-07 14:41:36,344 callbacks.py:105 INFO train-abinet] epoch 7 iter 309800: loss = 0.4139,  smooth loss = 0.4510
[2022-07-07 14:42:17,809 callbacks.py:105 INFO train-abinet] epoch 7 iter 309850: loss = 0.3738,  smooth loss = 0.4492
[2022-07-07 14:42:58,621 callbacks.py:105 INFO train-abinet] epoch 7 iter 309900: loss = 0.3786,  smooth loss = 0.4583
[2022-07-07 14:43:39,870 callbacks.py:105 INFO train-abinet] epoch 7 iter 309950: loss = 0.4739,  smooth loss = 0.4687
[2022-07-07 14:44:20,664 callbacks.py:105 INFO train-abinet] epoch 7 iter 310000: loss = 0.4624,  smooth loss = 0.4702
[2022-07-07 14:45:01,827 callbacks.py:105 INFO train-abinet] epoch 7 iter 310050: loss = 0.4846,  smooth loss = 0.4715
[2022-07-07 14:45:43,127 callbacks.py:105 INFO train-abinet] epoch 7 iter 310100: loss = 0.4045,  smooth loss = 0.4549
[2022-07-07 14:46:23,900 callbacks.py:105 INFO train-abinet] epoch 7 iter 310150: loss = 0.4464,  smooth loss = 0.4626
[2022-07-07 14:47:05,530 callbacks.py:105 INFO train-abinet] epoch 7 iter 310200: loss = 0.4549,  smooth loss = 0.4722
[2022-07-07 14:47:46,460 callbacks.py:105 INFO train-abinet] epoch 7 iter 310250: loss = 0.4914,  smooth loss = 0.4680
[2022-07-07 14:48:27,253 callbacks.py:105 INFO train-abinet] epoch 7 iter 310300: loss = 0.4462,  smooth loss = 0.4648
[2022-07-07 14:49:07,677 callbacks.py:105 INFO train-abinet] epoch 7 iter 310350: loss = 0.4896,  smooth loss = 0.4670
[2022-07-07 14:49:48,770 callbacks.py:105 INFO train-abinet] epoch 7 iter 310400: loss = 0.4196,  smooth loss = 0.4750
[2022-07-07 14:50:29,699 callbacks.py:105 INFO train-abinet] epoch 7 iter 310450: loss = 0.5051,  smooth loss = 0.4702
[2022-07-07 14:51:10,906 callbacks.py:105 INFO train-abinet] epoch 7 iter 310500: loss = 0.3989,  smooth loss = 0.4791
[2022-07-07 14:51:51,858 callbacks.py:105 INFO train-abinet] epoch 7 iter 310550: loss = 0.4545,  smooth loss = 0.4621
[2022-07-07 14:52:32,715 callbacks.py:105 INFO train-abinet] epoch 7 iter 310600: loss = 0.4413,  smooth loss = 0.4568
[2022-07-07 14:53:13,836 callbacks.py:105 INFO train-abinet] epoch 7 iter 310650: loss = 0.3630,  smooth loss = 0.4697
[2022-07-07 14:53:54,390 callbacks.py:105 INFO train-abinet] epoch 7 iter 310700: loss = 0.4968,  smooth loss = 0.4602
[2022-07-07 14:54:35,260 callbacks.py:105 INFO train-abinet] epoch 7 iter 310750: loss = 0.4629,  smooth loss = 0.4539
[2022-07-07 14:55:15,854 callbacks.py:105 INFO train-abinet] epoch 7 iter 310800: loss = 0.3373,  smooth loss = 0.4584
[2022-07-07 14:55:57,260 callbacks.py:105 INFO train-abinet] epoch 7 iter 310850: loss = 0.5404,  smooth loss = 0.4667
[2022-07-07 14:56:38,092 callbacks.py:105 INFO train-abinet] epoch 7 iter 310900: loss = 0.4364,  smooth loss = 0.4626
[2022-07-07 14:57:19,556 callbacks.py:105 INFO train-abinet] epoch 7 iter 310950: loss = 0.5577,  smooth loss = 0.4613
[2022-07-07 14:58:00,843 callbacks.py:105 INFO train-abinet] epoch 7 iter 311000: loss = 0.3726,  smooth loss = 0.4550
[2022-07-07 14:58:41,544 callbacks.py:105 INFO train-abinet] epoch 7 iter 311050: loss = 0.3700,  smooth loss = 0.4558
[2022-07-07 14:59:22,694 callbacks.py:105 INFO train-abinet] epoch 7 iter 311100: loss = 0.4053,  smooth loss = 0.4529
[2022-07-07 15:00:03,504 callbacks.py:105 INFO train-abinet] epoch 7 iter 311150: loss = 0.4305,  smooth loss = 0.4546
[2022-07-07 15:00:44,503 callbacks.py:105 INFO train-abinet] epoch 7 iter 311200: loss = 0.3370,  smooth loss = 0.4478
[2022-07-07 15:01:25,115 callbacks.py:105 INFO train-abinet] epoch 7 iter 311250: loss = 0.3256,  smooth loss = 0.4614
[2022-07-07 15:02:06,037 callbacks.py:105 INFO train-abinet] epoch 7 iter 311300: loss = 0.4101,  smooth loss = 0.4555
[2022-07-07 15:02:46,636 callbacks.py:105 INFO train-abinet] epoch 7 iter 311350: loss = 0.3419,  smooth loss = 0.4530
[2022-07-07 15:03:27,584 callbacks.py:105 INFO train-abinet] epoch 7 iter 311400: loss = 0.5161,  smooth loss = 0.4774
[2022-07-07 15:04:08,058 callbacks.py:105 INFO train-abinet] epoch 7 iter 311450: loss = 0.4307,  smooth loss = 0.4714
[2022-07-07 15:04:49,124 callbacks.py:105 INFO train-abinet] epoch 7 iter 311500: loss = 0.4447,  smooth loss = 0.4748
[2022-07-07 15:05:30,726 callbacks.py:105 INFO train-abinet] epoch 7 iter 311550: loss = 0.5391,  smooth loss = 0.4622
[2022-07-07 15:06:11,521 callbacks.py:105 INFO train-abinet] epoch 7 iter 311600: loss = 0.4632,  smooth loss = 0.4714
[2022-07-07 15:06:52,584 callbacks.py:105 INFO train-abinet] epoch 7 iter 311650: loss = 0.4720,  smooth loss = 0.4759
[2022-07-07 15:07:33,650 callbacks.py:105 INFO train-abinet] epoch 7 iter 311700: loss = 0.5050,  smooth loss = 0.4707
[2022-07-07 15:08:14,836 callbacks.py:105 INFO train-abinet] epoch 7 iter 311750: loss = 0.4973,  smooth loss = 0.4671
[2022-07-07 15:08:55,595 callbacks.py:105 INFO train-abinet] epoch 7 iter 311800: loss = 0.4942,  smooth loss = 0.4728
[2022-07-07 15:09:36,712 callbacks.py:105 INFO train-abinet] epoch 7 iter 311850: loss = 0.5050,  smooth loss = 0.4548
[2022-07-07 15:10:17,191 callbacks.py:105 INFO train-abinet] epoch 7 iter 311900: loss = 0.4031,  smooth loss = 0.4516
[2022-07-07 15:10:58,285 callbacks.py:105 INFO train-abinet] epoch 7 iter 311950: loss = 0.3861,  smooth loss = 0.4706
[2022-07-07 15:11:39,518 callbacks.py:105 INFO train-abinet] epoch 7 iter 312000: loss = 0.3629,  smooth loss = 0.4729
[2022-07-07 15:11:39,519 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8607s
█[2022-07-07 15:11:53,084 callbacks.py:123 INFO train-abinet] epoch 7 iter 312000: eval loss = 1.1506,  ccr = 0.9661,  cwr = 0.9280,  ted = 1149.0000,  ned = 232.8742,  ted/w = 0.1585, 
[2022-07-07 15:11:53,086 callbacks.py:130 INFO train-abinet] Better model found at epoch 7, iter 312000 with accuracy value: 0.9280.
[2022-07-07 15:11:54,197 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_312000
[2022-07-07 15:12:36,272 callbacks.py:105 INFO train-abinet] epoch 7 iter 312050: loss = 0.5244,  smooth loss = 0.4740
[2022-07-07 15:13:16,955 callbacks.py:105 INFO train-abinet] epoch 7 iter 312100: loss = 0.4275,  smooth loss = 0.4653
[2022-07-07 15:13:58,056 callbacks.py:105 INFO train-abinet] epoch 7 iter 312150: loss = 0.4902,  smooth loss = 0.4571
[2022-07-07 15:14:39,054 callbacks.py:105 INFO train-abinet] epoch 7 iter 312200: loss = 0.4710,  smooth loss = 0.4595
[2022-07-07 15:15:20,548 callbacks.py:105 INFO train-abinet] epoch 7 iter 312250: loss = 0.3771,  smooth loss = 0.4685
[2022-07-07 15:16:02,118 callbacks.py:105 INFO train-abinet] epoch 7 iter 312300: loss = 0.4722,  smooth loss = 0.4573
[2022-07-07 15:16:43,197 callbacks.py:105 INFO train-abinet] epoch 7 iter 312350: loss = 0.5343,  smooth loss = 0.4656
[2022-07-07 15:17:24,548 callbacks.py:105 INFO train-abinet] epoch 7 iter 312400: loss = 0.3987,  smooth loss = 0.4607
[2022-07-07 15:18:05,792 callbacks.py:105 INFO train-abinet] epoch 7 iter 312450: loss = 0.4860,  smooth loss = 0.4621
[2022-07-07 15:18:46,784 callbacks.py:105 INFO train-abinet] epoch 7 iter 312500: loss = 0.4915,  smooth loss = 0.4599
[2022-07-07 15:19:27,346 callbacks.py:105 INFO train-abinet] epoch 7 iter 312550: loss = 0.4915,  smooth loss = 0.4662
[2022-07-07 15:20:08,539 callbacks.py:105 INFO train-abinet] epoch 7 iter 312600: loss = 0.4204,  smooth loss = 0.4716
[2022-07-07 15:20:49,929 callbacks.py:105 INFO train-abinet] epoch 7 iter 312650: loss = 0.5129,  smooth loss = 0.4687
[2022-07-07 15:21:31,108 callbacks.py:105 INFO train-abinet] epoch 7 iter 312700: loss = 0.5322,  smooth loss = 0.4729
[2022-07-07 15:22:12,653 callbacks.py:105 INFO train-abinet] epoch 7 iter 312750: loss = 0.6064,  smooth loss = 0.4623
[2022-07-07 15:22:53,685 callbacks.py:105 INFO train-abinet] epoch 7 iter 312800: loss = 0.4858,  smooth loss = 0.4659
[2022-07-07 15:23:35,048 callbacks.py:105 INFO train-abinet] epoch 7 iter 312850: loss = 0.4903,  smooth loss = 0.4691
[2022-07-07 15:24:16,122 callbacks.py:105 INFO train-abinet] epoch 7 iter 312900: loss = 0.3922,  smooth loss = 0.4762
[2022-07-07 15:24:57,484 callbacks.py:105 INFO train-abinet] epoch 7 iter 312950: loss = 0.4563,  smooth loss = 0.4779
[2022-07-07 15:25:39,047 callbacks.py:105 INFO train-abinet] epoch 7 iter 313000: loss = 0.4596,  smooth loss = 0.4729
[2022-07-07 15:26:20,409 callbacks.py:105 INFO train-abinet] epoch 7 iter 313050: loss = 0.4310,  smooth loss = 0.4709
[2022-07-07 15:27:02,026 callbacks.py:105 INFO train-abinet] epoch 7 iter 313100: loss = 0.6478,  smooth loss = 0.4772
[2022-07-07 15:27:42,841 callbacks.py:105 INFO train-abinet] epoch 7 iter 313150: loss = 0.4995,  smooth loss = 0.4702
[2022-07-07 15:28:23,890 callbacks.py:105 INFO train-abinet] epoch 7 iter 313200: loss = 0.5627,  smooth loss = 0.4600
[2022-07-07 15:29:04,590 callbacks.py:105 INFO train-abinet] epoch 7 iter 313250: loss = 0.3448,  smooth loss = 0.4595
[2022-07-07 15:29:46,188 callbacks.py:105 INFO train-abinet] epoch 7 iter 313300: loss = 0.5009,  smooth loss = 0.4612
[2022-07-07 15:30:27,625 callbacks.py:105 INFO train-abinet] epoch 7 iter 313350: loss = 0.4472,  smooth loss = 0.4630
[2022-07-07 15:31:08,621 callbacks.py:105 INFO train-abinet] epoch 7 iter 313400: loss = 0.4055,  smooth loss = 0.4625
[2022-07-07 15:31:50,094 callbacks.py:105 INFO train-abinet] epoch 7 iter 313450: loss = 0.5721,  smooth loss = 0.4697
[2022-07-07 15:32:30,837 callbacks.py:105 INFO train-abinet] epoch 7 iter 313500: loss = 0.3488,  smooth loss = 0.4653
[2022-07-07 15:33:12,734 callbacks.py:105 INFO train-abinet] epoch 7 iter 313550: loss = 0.3645,  smooth loss = 0.4522
[2022-07-07 15:33:53,982 callbacks.py:105 INFO train-abinet] epoch 7 iter 313600: loss = 0.4233,  smooth loss = 0.4522
[2022-07-07 15:34:35,486 callbacks.py:105 INFO train-abinet] epoch 7 iter 313650: loss = 0.3888,  smooth loss = 0.4628
[2022-07-07 15:35:16,305 callbacks.py:105 INFO train-abinet] epoch 7 iter 313700: loss = 0.3793,  smooth loss = 0.4544
[2022-07-07 15:35:57,695 callbacks.py:105 INFO train-abinet] epoch 7 iter 313750: loss = 0.4678,  smooth loss = 0.4667
[2022-07-07 15:36:39,222 callbacks.py:105 INFO train-abinet] epoch 7 iter 313800: loss = 0.3922,  smooth loss = 0.4509
[2022-07-07 15:37:19,973 callbacks.py:105 INFO train-abinet] epoch 7 iter 313850: loss = 0.5226,  smooth loss = 0.4538
[2022-07-07 15:38:00,881 callbacks.py:105 INFO train-abinet] epoch 7 iter 313900: loss = 0.3967,  smooth loss = 0.4635
[2022-07-07 15:38:41,429 callbacks.py:105 INFO train-abinet] epoch 7 iter 313950: loss = 0.5862,  smooth loss = 0.4602
[2022-07-07 15:39:22,364 callbacks.py:105 INFO train-abinet] epoch 7 iter 314000: loss = 0.7259,  smooth loss = 0.4610
[2022-07-07 15:40:03,640 callbacks.py:105 INFO train-abinet] epoch 7 iter 314050: loss = 0.4599,  smooth loss = 0.4686
[2022-07-07 15:40:44,744 callbacks.py:105 INFO train-abinet] epoch 7 iter 314100: loss = 0.5202,  smooth loss = 0.4744
[2022-07-07 15:41:26,600 callbacks.py:105 INFO train-abinet] epoch 7 iter 314150: loss = 0.5839,  smooth loss = 0.4686
[2022-07-07 15:42:07,851 callbacks.py:105 INFO train-abinet] epoch 7 iter 314200: loss = 0.4729,  smooth loss = 0.4709
[2022-07-07 15:42:49,539 callbacks.py:105 INFO train-abinet] epoch 7 iter 314250: loss = 0.4802,  smooth loss = 0.4666
[2022-07-07 15:43:31,073 callbacks.py:105 INFO train-abinet] epoch 7 iter 314300: loss = 0.5118,  smooth loss = 0.4591
[2022-07-07 15:44:12,274 callbacks.py:105 INFO train-abinet] epoch 7 iter 314350: loss = 0.5234,  smooth loss = 0.4742
[2022-07-07 15:44:53,315 callbacks.py:105 INFO train-abinet] epoch 7 iter 314400: loss = 0.5225,  smooth loss = 0.4658
[2022-07-07 15:45:34,062 callbacks.py:105 INFO train-abinet] epoch 7 iter 314450: loss = 0.5402,  smooth loss = 0.4753
[2022-07-07 15:46:14,913 callbacks.py:105 INFO train-abinet] epoch 7 iter 314500: loss = 0.5372,  smooth loss = 0.4853
[2022-07-07 15:46:56,227 callbacks.py:105 INFO train-abinet] epoch 7 iter 314550: loss = 0.4296,  smooth loss = 0.4900
[2022-07-07 15:47:37,081 callbacks.py:105 INFO train-abinet] epoch 7 iter 314600: loss = 0.4276,  smooth loss = 0.4789
[2022-07-07 15:48:18,388 callbacks.py:105 INFO train-abinet] epoch 7 iter 314650: loss = 0.4852,  smooth loss = 0.4704
[2022-07-07 15:48:59,983 callbacks.py:105 INFO train-abinet] epoch 7 iter 314700: loss = 0.4977,  smooth loss = 0.4508
[2022-07-07 15:49:41,354 callbacks.py:105 INFO train-abinet] epoch 7 iter 314750: loss = 0.5374,  smooth loss = 0.4670
[2022-07-07 15:50:21,998 callbacks.py:105 INFO train-abinet] epoch 7 iter 314800: loss = 0.3651,  smooth loss = 0.4672
[2022-07-07 15:51:03,671 callbacks.py:105 INFO train-abinet] epoch 7 iter 314850: loss = 0.4657,  smooth loss = 0.4682
[2022-07-07 15:51:44,303 callbacks.py:105 INFO train-abinet] epoch 7 iter 314900: loss = 0.4453,  smooth loss = 0.4594
[2022-07-07 15:52:25,438 callbacks.py:105 INFO train-abinet] epoch 7 iter 314950: loss = 0.3290,  smooth loss = 0.4594
[2022-07-07 15:53:06,553 callbacks.py:105 INFO train-abinet] epoch 7 iter 315000: loss = 0.6130,  smooth loss = 0.4614
[2022-07-07 15:53:06,554 callbacks.py:114 INFO train-abinet] average data time = 0.0048s, average running time = 0.8604s
█[2022-07-07 15:53:20,238 callbacks.py:123 INFO train-abinet] epoch 7 iter 315000: eval loss = 1.1513,  ccr = 0.9653,  cwr = 0.9276,  ted = 1144.0000,  ned = 232.0052,  ted/w = 0.1578, 
[2022-07-07 15:53:20,240 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_315000
[2022-07-07 15:54:02,471 callbacks.py:105 INFO train-abinet] epoch 7 iter 315050: loss = 0.6121,  smooth loss = 0.4711
[2022-07-07 15:54:43,928 callbacks.py:105 INFO train-abinet] epoch 7 iter 315100: loss = 0.4009,  smooth loss = 0.4668
[2022-07-07 15:55:25,811 callbacks.py:105 INFO train-abinet] epoch 7 iter 315150: loss = 0.4551,  smooth loss = 0.4613
[2022-07-07 15:56:06,901 callbacks.py:105 INFO train-abinet] epoch 7 iter 315200: loss = 0.4306,  smooth loss = 0.4496
[2022-07-07 15:56:48,587 callbacks.py:105 INFO train-abinet] epoch 7 iter 315250: loss = 0.4560,  smooth loss = 0.4480
[2022-07-07 15:57:29,242 callbacks.py:105 INFO train-abinet] epoch 7 iter 315300: loss = 0.4585,  smooth loss = 0.4581
[2022-07-07 15:58:11,125 callbacks.py:105 INFO train-abinet] epoch 7 iter 315350: loss = 0.3979,  smooth loss = 0.4682
[2022-07-07 15:58:51,802 callbacks.py:105 INFO train-abinet] epoch 7 iter 315400: loss = 0.5105,  smooth loss = 0.4588
[2022-07-07 15:59:32,714 callbacks.py:105 INFO train-abinet] epoch 7 iter 315450: loss = 0.4252,  smooth loss = 0.4651
[2022-07-07 16:00:14,351 callbacks.py:105 INFO train-abinet] epoch 7 iter 315500: loss = 0.3875,  smooth loss = 0.4646
[2022-07-07 16:00:55,319 callbacks.py:105 INFO train-abinet] epoch 7 iter 315550: loss = 0.5058,  smooth loss = 0.4626
[2022-07-07 16:01:36,566 callbacks.py:105 INFO train-abinet] epoch 7 iter 315600: loss = 0.4754,  smooth loss = 0.4585
[2022-07-07 16:02:17,190 callbacks.py:105 INFO train-abinet] epoch 7 iter 315650: loss = 0.3658,  smooth loss = 0.4518
[2022-07-07 16:02:58,657 callbacks.py:105 INFO train-abinet] epoch 7 iter 315700: loss = 0.4124,  smooth loss = 0.4610
[2022-07-07 16:03:39,890 callbacks.py:105 INFO train-abinet] epoch 7 iter 315750: loss = 0.4431,  smooth loss = 0.4632
[2022-07-07 16:04:21,369 callbacks.py:105 INFO train-abinet] epoch 7 iter 315800: loss = 0.6544,  smooth loss = 0.4677
[2022-07-07 16:05:02,458 callbacks.py:105 INFO train-abinet] epoch 7 iter 315850: loss = 0.4126,  smooth loss = 0.4615
[2022-07-07 16:05:43,717 callbacks.py:105 INFO train-abinet] epoch 7 iter 315900: loss = 0.3750,  smooth loss = 0.4507
[2022-07-07 16:06:25,411 callbacks.py:105 INFO train-abinet] epoch 7 iter 315950: loss = 0.4222,  smooth loss = 0.4577
[2022-07-07 16:07:05,877 callbacks.py:105 INFO train-abinet] epoch 7 iter 316000: loss = 0.3617,  smooth loss = 0.4606
[2022-07-07 16:07:47,292 callbacks.py:105 INFO train-abinet] epoch 7 iter 316050: loss = 0.4369,  smooth loss = 0.4681
[2022-07-07 16:08:27,911 callbacks.py:105 INFO train-abinet] epoch 7 iter 316100: loss = 0.4920,  smooth loss = 0.4548
[2022-07-07 16:09:09,001 callbacks.py:105 INFO train-abinet] epoch 7 iter 316150: loss = 0.4446,  smooth loss = 0.4661
[2022-07-07 16:09:49,731 callbacks.py:105 INFO train-abinet] epoch 7 iter 316200: loss = 0.4675,  smooth loss = 0.4718
[2022-07-07 16:10:30,676 callbacks.py:105 INFO train-abinet] epoch 7 iter 316250: loss = 0.4745,  smooth loss = 0.4703
[2022-07-07 16:11:11,347 callbacks.py:105 INFO train-abinet] epoch 7 iter 316300: loss = 0.4647,  smooth loss = 0.4636
[2022-07-07 16:11:51,897 callbacks.py:105 INFO train-abinet] epoch 7 iter 316350: loss = 0.5060,  smooth loss = 0.4702
[2022-07-07 16:12:32,992 callbacks.py:105 INFO train-abinet] epoch 7 iter 316400: loss = 0.5437,  smooth loss = 0.4656
[2022-07-07 16:13:13,831 callbacks.py:105 INFO train-abinet] epoch 7 iter 316450: loss = 0.5121,  smooth loss = 0.4613
[2022-07-07 16:13:55,262 callbacks.py:105 INFO train-abinet] epoch 7 iter 316500: loss = 0.4312,  smooth loss = 0.4658
[2022-07-07 16:14:36,119 callbacks.py:105 INFO train-abinet] epoch 7 iter 316550: loss = 0.4263,  smooth loss = 0.4551
[2022-07-07 16:15:17,385 callbacks.py:105 INFO train-abinet] epoch 7 iter 316600: loss = 0.4150,  smooth loss = 0.4572
[2022-07-07 16:15:57,882 callbacks.py:105 INFO train-abinet] epoch 7 iter 316650: loss = 0.6350,  smooth loss = 0.4670
[2022-07-07 16:16:38,858 callbacks.py:105 INFO train-abinet] epoch 7 iter 316700: loss = 0.4670,  smooth loss = 0.4658
[2022-07-07 16:17:19,779 callbacks.py:105 INFO train-abinet] epoch 7 iter 316750: loss = 0.4584,  smooth loss = 0.4609
[2022-07-07 16:18:01,179 callbacks.py:105 INFO train-abinet] epoch 7 iter 316800: loss = 0.5011,  smooth loss = 0.4702
[2022-07-07 16:18:42,080 callbacks.py:105 INFO train-abinet] epoch 7 iter 316850: loss = 0.5585,  smooth loss = 0.4637
[2022-07-07 16:19:22,967 callbacks.py:105 INFO train-abinet] epoch 7 iter 316900: loss = 0.3151,  smooth loss = 0.4671
[2022-07-07 16:20:03,370 callbacks.py:105 INFO train-abinet] epoch 7 iter 316950: loss = 0.3738,  smooth loss = 0.4570
[2022-07-07 16:20:44,255 callbacks.py:105 INFO train-abinet] epoch 7 iter 317000: loss = 0.4118,  smooth loss = 0.4544
[2022-07-07 16:21:25,578 callbacks.py:105 INFO train-abinet] epoch 7 iter 317050: loss = 0.3995,  smooth loss = 0.4481
[2022-07-07 16:22:06,461 callbacks.py:105 INFO train-abinet] epoch 7 iter 317100: loss = 0.4378,  smooth loss = 0.4575
[2022-07-07 16:22:47,418 callbacks.py:105 INFO train-abinet] epoch 7 iter 317150: loss = 0.3932,  smooth loss = 0.4612
[2022-07-07 16:23:28,238 callbacks.py:105 INFO train-abinet] epoch 7 iter 317200: loss = 0.5174,  smooth loss = 0.4688
[2022-07-07 16:24:09,184 callbacks.py:105 INFO train-abinet] epoch 7 iter 317250: loss = 0.6197,  smooth loss = 0.4725
[2022-07-07 16:24:50,251 callbacks.py:105 INFO train-abinet] epoch 7 iter 317300: loss = 0.4945,  smooth loss = 0.4695
[2022-07-07 16:25:31,726 callbacks.py:105 INFO train-abinet] epoch 7 iter 317350: loss = 0.4262,  smooth loss = 0.4586
[2022-07-07 16:26:12,976 callbacks.py:105 INFO train-abinet] epoch 7 iter 317400: loss = 0.4390,  smooth loss = 0.4629
[2022-07-07 16:26:53,937 callbacks.py:105 INFO train-abinet] epoch 7 iter 317450: loss = 0.4760,  smooth loss = 0.4492
[2022-07-07 16:27:35,343 callbacks.py:105 INFO train-abinet] epoch 7 iter 317500: loss = 0.4168,  smooth loss = 0.4533
[2022-07-07 16:28:16,074 callbacks.py:105 INFO train-abinet] epoch 7 iter 317550: loss = 0.4442,  smooth loss = 0.4607
[2022-07-07 16:28:57,236 callbacks.py:105 INFO train-abinet] epoch 7 iter 317600: loss = 0.3942,  smooth loss = 0.4576
[2022-07-07 16:29:37,726 callbacks.py:105 INFO train-abinet] epoch 7 iter 317650: loss = 0.4194,  smooth loss = 0.4640
[2022-07-07 16:30:18,546 callbacks.py:105 INFO train-abinet] epoch 7 iter 317700: loss = 0.3699,  smooth loss = 0.4512
[2022-07-07 16:31:00,015 callbacks.py:105 INFO train-abinet] epoch 7 iter 317750: loss = 0.4917,  smooth loss = 0.4537
[2022-07-07 16:31:41,394 callbacks.py:105 INFO train-abinet] epoch 7 iter 317800: loss = 0.4705,  smooth loss = 0.4592
[2022-07-07 16:32:23,338 callbacks.py:105 INFO train-abinet] epoch 7 iter 317850: loss = 0.4395,  smooth loss = 0.4550
[2022-07-07 16:33:04,252 callbacks.py:105 INFO train-abinet] epoch 7 iter 317900: loss = 0.3155,  smooth loss = 0.4573
[2022-07-07 16:33:45,756 callbacks.py:105 INFO train-abinet] epoch 7 iter 317950: loss = 0.4739,  smooth loss = 0.4592
[2022-07-07 16:34:26,558 callbacks.py:105 INFO train-abinet] epoch 7 iter 318000: loss = 0.4152,  smooth loss = 0.4428
[2022-07-07 16:34:26,559 callbacks.py:114 INFO train-abinet] average data time = 0.0047s, average running time = 0.8601s
█[2022-07-07 16:34:40,909 callbacks.py:123 INFO train-abinet] epoch 7 iter 318000: eval loss = 1.1653,  ccr = 0.9659,  cwr = 0.9283,  ted = 1141.0000,  ned = 229.3116,  ted/w = 0.1574, 
[2022-07-07 16:34:40,912 callbacks.py:130 INFO train-abinet] Better model found at epoch 7, iter 318000 with accuracy value: 0.9283.
[2022-07-07 16:34:42,001 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_318000
[2022-07-07 16:35:24,039 callbacks.py:105 INFO train-abinet] epoch 7 iter 318050: loss = 0.4173,  smooth loss = 0.4528
[2022-07-07 16:36:05,306 callbacks.py:105 INFO train-abinet] epoch 7 iter 318100: loss = 0.4398,  smooth loss = 0.4567
[2022-07-07 16:36:45,937 callbacks.py:105 INFO train-abinet] epoch 7 iter 318150: loss = 0.3826,  smooth loss = 0.4581
[2022-07-07 16:37:26,753 callbacks.py:105 INFO train-abinet] epoch 7 iter 318200: loss = 0.3911,  smooth loss = 0.4531
[2022-07-07 16:38:07,874 callbacks.py:105 INFO train-abinet] epoch 7 iter 318250: loss = 0.3349,  smooth loss = 0.4471
[2022-07-07 16:38:48,585 callbacks.py:105 INFO train-abinet] epoch 7 iter 318300: loss = 0.5842,  smooth loss = 0.4647
[2022-07-07 16:39:29,817 callbacks.py:105 INFO train-abinet] epoch 7 iter 318350: loss = 0.3553,  smooth loss = 0.4580
[2022-07-07 16:40:10,603 callbacks.py:105 INFO train-abinet] epoch 7 iter 318400: loss = 0.5566,  smooth loss = 0.4565
[2022-07-07 16:40:51,680 callbacks.py:105 INFO train-abinet] epoch 7 iter 318450: loss = 0.4960,  smooth loss = 0.4579
[2022-07-07 16:41:31,879 callbacks.py:105 INFO train-abinet] epoch 7 iter 318500: loss = 0.4723,  smooth loss = 0.4564
[2022-07-07 16:42:12,624 callbacks.py:105 INFO train-abinet] epoch 7 iter 318550: loss = 0.4179,  smooth loss = 0.4597
[2022-07-07 16:42:53,855 callbacks.py:105 INFO train-abinet] epoch 7 iter 318600: loss = 0.6241,  smooth loss = 0.4669
[2022-07-07 16:43:34,413 callbacks.py:105 INFO train-abinet] epoch 7 iter 318650: loss = 0.4254,  smooth loss = 0.4566
[2022-07-07 16:44:15,513 callbacks.py:105 INFO train-abinet] epoch 7 iter 318700: loss = 0.4930,  smooth loss = 0.4490
[2022-07-07 16:44:56,044 callbacks.py:105 INFO train-abinet] epoch 7 iter 318750: loss = 0.3450,  smooth loss = 0.4495
[2022-07-07 16:45:36,459 callbacks.py:105 INFO train-abinet] epoch 7 iter 318800: loss = 0.3664,  smooth loss = 0.4614
[2022-07-07 16:46:17,605 callbacks.py:105 INFO train-abinet] epoch 7 iter 318850: loss = 0.4334,  smooth loss = 0.4585
[2022-07-07 16:46:58,440 callbacks.py:105 INFO train-abinet] epoch 7 iter 318900: loss = 0.4706,  smooth loss = 0.4672
[2022-07-07 16:47:39,531 callbacks.py:105 INFO train-abinet] epoch 7 iter 318950: loss = 0.6261,  smooth loss = 0.4599
[2022-07-07 16:48:19,925 callbacks.py:105 INFO train-abinet] epoch 7 iter 319000: loss = 0.5245,  smooth loss = 0.4677
[2022-07-07 16:49:00,612 callbacks.py:105 INFO train-abinet] epoch 7 iter 319050: loss = 0.4087,  smooth loss = 0.4559
[2022-07-07 16:49:41,484 callbacks.py:105 INFO train-abinet] epoch 7 iter 319100: loss = 0.3825,  smooth loss = 0.4628
[2022-07-07 16:50:22,250 callbacks.py:105 INFO train-abinet] epoch 7 iter 319150: loss = 0.4594,  smooth loss = 0.4561
[2022-07-07 16:51:03,842 callbacks.py:105 INFO train-abinet] epoch 7 iter 319200: loss = 0.3570,  smooth loss = 0.4587
[2022-07-07 16:51:44,216 callbacks.py:105 INFO train-abinet] epoch 7 iter 319250: loss = 0.5792,  smooth loss = 0.4742
[2022-07-07 16:52:25,297 callbacks.py:105 INFO train-abinet] epoch 7 iter 319300: loss = 0.3843,  smooth loss = 0.4719
[2022-07-07 16:53:05,496 callbacks.py:105 INFO train-abinet] epoch 7 iter 319350: loss = 0.4481,  smooth loss = 0.4663
[2022-07-07 16:53:45,994 callbacks.py:105 INFO train-abinet] epoch 7 iter 319400: loss = 0.4228,  smooth loss = 0.4702
[2022-07-07 16:54:27,052 callbacks.py:105 INFO train-abinet] epoch 7 iter 319450: loss = 0.3647,  smooth loss = 0.4602
[2022-07-07 16:55:07,423 callbacks.py:105 INFO train-abinet] epoch 7 iter 319500: loss = 0.5005,  smooth loss = 0.4674
[2022-07-07 16:55:48,348 callbacks.py:105 INFO train-abinet] epoch 7 iter 319550: loss = 0.5164,  smooth loss = 0.4666
[2022-07-07 16:56:29,110 callbacks.py:105 INFO train-abinet] epoch 7 iter 319600: loss = 0.3185,  smooth loss = 0.4699
[2022-07-07 16:57:09,782 callbacks.py:105 INFO train-abinet] epoch 7 iter 319650: loss = 0.5292,  smooth loss = 0.4501
[2022-07-07 16:57:50,806 callbacks.py:105 INFO train-abinet] epoch 7 iter 319700: loss = 0.4429,  smooth loss = 0.4559
[2022-07-07 16:58:31,055 callbacks.py:105 INFO train-abinet] epoch 7 iter 319750: loss = 0.6232,  smooth loss = 0.4733
[2022-07-07 16:59:11,464 callbacks.py:105 INFO train-abinet] epoch 7 iter 319800: loss = 0.3595,  smooth loss = 0.4660
[2022-07-07 16:59:52,509 callbacks.py:105 INFO train-abinet] epoch 7 iter 319850: loss = 0.4329,  smooth loss = 0.4603
[2022-07-07 17:00:32,925 callbacks.py:105 INFO train-abinet] epoch 7 iter 319900: loss = 0.3717,  smooth loss = 0.4707
[2022-07-07 17:01:13,967 callbacks.py:105 INFO train-abinet] epoch 7 iter 319950: loss = 0.4878,  smooth loss = 0.4619
[2022-07-07 17:01:54,796 callbacks.py:105 INFO train-abinet] epoch 7 iter 320000: loss = 0.3678,  smooth loss = 0.4638
[2022-07-07 17:02:36,121 callbacks.py:105 INFO train-abinet] epoch 7 iter 320050: loss = 0.3795,  smooth loss = 0.4564
[2022-07-07 17:03:16,736 callbacks.py:105 INFO train-abinet] epoch 7 iter 320100: loss = 0.4440,  smooth loss = 0.4549
[2022-07-07 17:03:57,719 callbacks.py:105 INFO train-abinet] epoch 7 iter 320150: loss = 0.4299,  smooth loss = 0.4668
[2022-07-07 17:04:38,068 callbacks.py:105 INFO train-abinet] epoch 7 iter 320200: loss = 0.3566,  smooth loss = 0.4706
[2022-07-07 17:05:18,513 callbacks.py:105 INFO train-abinet] epoch 7 iter 320250: loss = 0.5477,  smooth loss = 0.4786
[2022-07-07 17:05:59,645 callbacks.py:105 INFO train-abinet] epoch 7 iter 320300: loss = 0.4319,  smooth loss = 0.4652
[2022-07-07 17:06:40,112 callbacks.py:105 INFO train-abinet] epoch 7 iter 320350: loss = 0.4854,  smooth loss = 0.4745
[2022-07-07 17:07:21,105 callbacks.py:105 INFO train-abinet] epoch 7 iter 320400: loss = 0.4863,  smooth loss = 0.4529
[2022-07-07 17:08:01,700 callbacks.py:105 INFO train-abinet] epoch 7 iter 320450: loss = 0.3707,  smooth loss = 0.4594
[2022-07-07 17:08:42,130 callbacks.py:105 INFO train-abinet] epoch 7 iter 320500: loss = 0.3302,  smooth loss = 0.4755
[2022-07-07 17:09:23,388 callbacks.py:105 INFO train-abinet] epoch 7 iter 320550: loss = 0.4738,  smooth loss = 0.4722
[2022-07-07 17:10:03,739 callbacks.py:105 INFO train-abinet] epoch 7 iter 320600: loss = 0.3743,  smooth loss = 0.4715
[2022-07-07 17:10:45,100 callbacks.py:105 INFO train-abinet] epoch 7 iter 320650: loss = 0.4549,  smooth loss = 0.4586
[2022-07-07 17:11:25,803 callbacks.py:105 INFO train-abinet] epoch 7 iter 320700: loss = 0.5235,  smooth loss = 0.4663
[2022-07-07 17:12:06,806 callbacks.py:105 INFO train-abinet] epoch 7 iter 320750: loss = 0.5408,  smooth loss = 0.4680
[2022-07-07 17:12:47,164 callbacks.py:105 INFO train-abinet] epoch 7 iter 320800: loss = 0.5045,  smooth loss = 0.4613
[2022-07-07 17:13:27,922 callbacks.py:105 INFO train-abinet] epoch 7 iter 320850: loss = 0.3873,  smooth loss = 0.4486
[2022-07-07 17:14:08,577 callbacks.py:105 INFO train-abinet] epoch 7 iter 320900: loss = 0.3720,  smooth loss = 0.4596
[2022-07-07 17:14:49,546 callbacks.py:105 INFO train-abinet] epoch 7 iter 320950: loss = 0.3958,  smooth loss = 0.4589
[2022-07-07 17:15:30,061 callbacks.py:105 INFO train-abinet] epoch 7 iter 321000: loss = 0.5285,  smooth loss = 0.4819
[2022-07-07 17:15:30,062 callbacks.py:114 INFO train-abinet] average data time = 0.0047s, average running time = 0.8597s
█[2022-07-07 17:15:44,172 callbacks.py:123 INFO train-abinet] epoch 7 iter 321000: eval loss = 1.1642,  ccr = 0.9650,  cwr = 0.9262,  ted = 1165.0000,  ned = 233.2807,  ted/w = 0.1607, 
[2022-07-07 17:15:44,174 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_321000
[2022-07-07 17:16:25,748 callbacks.py:105 INFO train-abinet] epoch 7 iter 321050: loss = 0.5044,  smooth loss = 0.4755
[2022-07-07 17:17:06,108 callbacks.py:105 INFO train-abinet] epoch 7 iter 321100: loss = 0.5076,  smooth loss = 0.4679
[2022-07-07 17:17:47,272 callbacks.py:105 INFO train-abinet] epoch 7 iter 321150: loss = 0.4378,  smooth loss = 0.4519
[2022-07-07 17:18:27,468 callbacks.py:105 INFO train-abinet] epoch 7 iter 321200: loss = 0.3580,  smooth loss = 0.4684
[2022-07-07 17:19:08,064 callbacks.py:105 INFO train-abinet] epoch 7 iter 321250: loss = 0.3736,  smooth loss = 0.4678
[2022-07-07 17:19:48,536 callbacks.py:105 INFO train-abinet] epoch 7 iter 321300: loss = 0.4058,  smooth loss = 0.4681
[2022-07-07 17:20:29,366 callbacks.py:105 INFO train-abinet] epoch 7 iter 321350: loss = 0.6042,  smooth loss = 0.4538
[2022-07-07 17:21:09,935 callbacks.py:105 INFO train-abinet] epoch 7 iter 321400: loss = 0.4807,  smooth loss = 0.4503
[2022-07-07 17:21:50,230 callbacks.py:105 INFO train-abinet] epoch 7 iter 321450: loss = 0.4620,  smooth loss = 0.4495
[2022-07-07 17:22:31,228 callbacks.py:105 INFO train-abinet] epoch 7 iter 321500: loss = 0.3958,  smooth loss = 0.4485
[2022-07-07 17:23:11,711 callbacks.py:105 INFO train-abinet] epoch 7 iter 321550: loss = 0.4525,  smooth loss = 0.4612
[2022-07-07 17:23:52,657 callbacks.py:105 INFO train-abinet] epoch 7 iter 321600: loss = 0.4646,  smooth loss = 0.4576
[2022-07-07 17:24:33,147 callbacks.py:105 INFO train-abinet] epoch 7 iter 321650: loss = 0.5485,  smooth loss = 0.4686
[2022-07-07 17:25:14,312 callbacks.py:105 INFO train-abinet] epoch 7 iter 321700: loss = 0.4699,  smooth loss = 0.4616
[2022-07-07 17:25:54,745 callbacks.py:105 INFO train-abinet] epoch 7 iter 321750: loss = 0.5041,  smooth loss = 0.4652
[2022-07-07 17:26:35,265 callbacks.py:105 INFO train-abinet] epoch 7 iter 321800: loss = 0.4438,  smooth loss = 0.4635
[2022-07-07 17:27:16,173 callbacks.py:105 INFO train-abinet] epoch 7 iter 321850: loss = 0.3738,  smooth loss = 0.4641
[2022-07-07 17:27:56,711 callbacks.py:105 INFO train-abinet] epoch 7 iter 321900: loss = 0.4125,  smooth loss = 0.4559
[2022-07-07 17:28:37,846 callbacks.py:105 INFO train-abinet] epoch 7 iter 321950: loss = 0.4915,  smooth loss = 0.4708
[2022-07-07 17:29:18,125 callbacks.py:105 INFO train-abinet] epoch 7 iter 322000: loss = 0.3915,  smooth loss = 0.4720
[2022-07-07 17:29:59,328 callbacks.py:105 INFO train-abinet] epoch 7 iter 322050: loss = 0.5876,  smooth loss = 0.4629
[2022-07-07 17:30:40,006 callbacks.py:105 INFO train-abinet] epoch 7 iter 322100: loss = 0.4469,  smooth loss = 0.4642
[2022-07-07 17:31:20,453 callbacks.py:105 INFO train-abinet] epoch 7 iter 322150: loss = 0.4266,  smooth loss = 0.4583
[2022-07-07 17:32:01,311 callbacks.py:105 INFO train-abinet] epoch 7 iter 322200: loss = 0.3945,  smooth loss = 0.4599
[2022-07-07 17:32:41,805 callbacks.py:105 INFO train-abinet] epoch 7 iter 322250: loss = 0.3524,  smooth loss = 0.4567
[2022-07-07 17:33:23,262 callbacks.py:105 INFO train-abinet] epoch 7 iter 322300: loss = 0.4814,  smooth loss = 0.4550
[2022-07-07 17:34:03,792 callbacks.py:105 INFO train-abinet] epoch 7 iter 322350: loss = 0.5579,  smooth loss = 0.4764
[2022-07-07 17:34:44,852 callbacks.py:105 INFO train-abinet] epoch 7 iter 322400: loss = 0.4524,  smooth loss = 0.4696
[2022-07-07 17:35:25,309 callbacks.py:105 INFO train-abinet] epoch 7 iter 322450: loss = 0.4042,  smooth loss = 0.4571
[2022-07-07 17:36:05,684 callbacks.py:105 INFO train-abinet] epoch 7 iter 322500: loss = 0.5256,  smooth loss = 0.4550
[2022-07-07 17:36:46,634 callbacks.py:105 INFO train-abinet] epoch 7 iter 322550: loss = 0.4017,  smooth loss = 0.4575
[2022-07-07 17:37:27,072 callbacks.py:105 INFO train-abinet] epoch 7 iter 322600: loss = 0.3550,  smooth loss = 0.4585
[2022-07-07 17:38:08,137 callbacks.py:105 INFO train-abinet] epoch 7 iter 322650: loss = 0.4544,  smooth loss = 0.4595
[2022-07-07 17:38:48,658 callbacks.py:105 INFO train-abinet] epoch 7 iter 322700: loss = 0.3610,  smooth loss = 0.4654
[2022-07-07 17:39:29,909 callbacks.py:105 INFO train-abinet] epoch 7 iter 322750: loss = 0.4233,  smooth loss = 0.4720
[2022-07-07 17:40:10,583 callbacks.py:105 INFO train-abinet] epoch 7 iter 322800: loss = 0.4317,  smooth loss = 0.4677
[2022-07-07 17:40:51,450 callbacks.py:105 INFO train-abinet] epoch 7 iter 322850: loss = 0.6104,  smooth loss = 0.4737
[2022-07-07 17:41:31,909 callbacks.py:105 INFO train-abinet] epoch 7 iter 322900: loss = 0.5029,  smooth loss = 0.4576
[2022-07-07 17:42:12,605 callbacks.py:105 INFO train-abinet] epoch 7 iter 322950: loss = 0.3649,  smooth loss = 0.4644
[2022-07-07 17:42:53,540 callbacks.py:105 INFO train-abinet] epoch 7 iter 323000: loss = 0.4184,  smooth loss = 0.4651
[2022-07-07 17:43:33,918 callbacks.py:105 INFO train-abinet] epoch 7 iter 323050: loss = 0.3826,  smooth loss = 0.4650
[2022-07-07 17:44:14,824 callbacks.py:105 INFO train-abinet] epoch 7 iter 323100: loss = 0.4984,  smooth loss = 0.4643
[2022-07-07 17:44:55,483 callbacks.py:105 INFO train-abinet] epoch 7 iter 323150: loss = 0.4249,  smooth loss = 0.4658
[2022-07-07 17:45:36,817 callbacks.py:105 INFO train-abinet] epoch 7 iter 323200: loss = 0.4571,  smooth loss = 0.4568
[2022-07-07 17:46:17,809 callbacks.py:105 INFO train-abinet] epoch 7 iter 323250: loss = 0.3991,  smooth loss = 0.4655
[2022-07-07 17:46:59,116 callbacks.py:105 INFO train-abinet] epoch 7 iter 323300: loss = 0.5109,  smooth loss = 0.4660
[2022-07-07 17:47:40,539 callbacks.py:105 INFO train-abinet] epoch 7 iter 323350: loss = 0.4151,  smooth loss = 0.4604
[2022-07-07 17:48:20,935 callbacks.py:105 INFO train-abinet] epoch 7 iter 323400: loss = 0.5723,  smooth loss = 0.4717
[2022-07-07 17:49:02,322 callbacks.py:105 INFO train-abinet] epoch 7 iter 323450: loss = 0.4405,  smooth loss = 0.4748
[2022-07-07 17:49:43,242 callbacks.py:105 INFO train-abinet] epoch 7 iter 323500: loss = 0.3758,  smooth loss = 0.4610
[2022-07-07 17:50:24,684 callbacks.py:105 INFO train-abinet] epoch 7 iter 323550: loss = 0.5084,  smooth loss = 0.4618
[2022-07-07 17:51:05,611 callbacks.py:105 INFO train-abinet] epoch 7 iter 323600: loss = 0.4911,  smooth loss = 0.4684
[2022-07-07 17:51:46,997 callbacks.py:105 INFO train-abinet] epoch 7 iter 323650: loss = 0.4438,  smooth loss = 0.4584
[2022-07-07 17:52:27,734 callbacks.py:105 INFO train-abinet] epoch 7 iter 323700: loss = 0.5244,  smooth loss = 0.4614
[2022-07-07 17:53:08,696 callbacks.py:105 INFO train-abinet] epoch 7 iter 323750: loss = 0.4445,  smooth loss = 0.4565
[2022-07-07 17:53:49,296 callbacks.py:105 INFO train-abinet] epoch 7 iter 323800: loss = 0.4354,  smooth loss = 0.4611
[2022-07-07 17:54:30,606 callbacks.py:105 INFO train-abinet] epoch 7 iter 323850: loss = 0.5039,  smooth loss = 0.4608
[2022-07-07 17:55:10,845 callbacks.py:105 INFO train-abinet] epoch 7 iter 323900: loss = 0.4139,  smooth loss = 0.4594
[2022-07-07 17:55:52,010 callbacks.py:105 INFO train-abinet] epoch 7 iter 323950: loss = 0.5171,  smooth loss = 0.4532
[2022-07-07 17:56:33,364 callbacks.py:105 INFO train-abinet] epoch 7 iter 324000: loss = 0.4534,  smooth loss = 0.4582
[2022-07-07 17:56:33,364 callbacks.py:114 INFO train-abinet] average data time = 0.0047s, average running time = 0.8593s
█[2022-07-07 17:56:47,225 callbacks.py:123 INFO train-abinet] epoch 7 iter 324000: eval loss = 1.1550,  ccr = 0.9650,  cwr = 0.9273,  ted = 1154.0000,  ned = 233.0278,  ted/w = 0.1592, 
[2022-07-07 17:56:47,227 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_324000
[2022-07-07 17:57:29,330 callbacks.py:105 INFO train-abinet] epoch 7 iter 324050: loss = 0.4919,  smooth loss = 0.4731
[2022-07-07 17:58:10,161 callbacks.py:105 INFO train-abinet] epoch 7 iter 324100: loss = 0.4884,  smooth loss = 0.4514
[2022-07-07 17:58:51,692 callbacks.py:105 INFO train-abinet] epoch 7 iter 324150: loss = 0.5130,  smooth loss = 0.4463
[2022-07-07 17:59:32,912 callbacks.py:105 INFO train-abinet] epoch 7 iter 324200: loss = 0.6429,  smooth loss = 0.4586
[2022-07-07 18:00:13,523 callbacks.py:105 INFO train-abinet] epoch 7 iter 324250: loss = 0.4837,  smooth loss = 0.4649
[2022-07-07 18:00:54,459 callbacks.py:105 INFO train-abinet] epoch 7 iter 324300: loss = 0.3383,  smooth loss = 0.4704
[2022-07-07 18:01:35,033 callbacks.py:105 INFO train-abinet] epoch 7 iter 324350: loss = 0.5011,  smooth loss = 0.4600
[2022-07-07 18:02:15,982 callbacks.py:105 INFO train-abinet] epoch 7 iter 324400: loss = 0.3968,  smooth loss = 0.4651
[2022-07-07 18:02:56,956 callbacks.py:105 INFO train-abinet] epoch 7 iter 324450: loss = 0.5193,  smooth loss = 0.4617
[2022-07-07 18:03:38,224 callbacks.py:105 INFO train-abinet] epoch 7 iter 324500: loss = 0.4479,  smooth loss = 0.4644
[2022-07-07 18:04:18,828 callbacks.py:105 INFO train-abinet] epoch 7 iter 324550: loss = 0.5444,  smooth loss = 0.4653
[2022-07-07 18:05:00,523 callbacks.py:105 INFO train-abinet] epoch 7 iter 324600: loss = 0.3819,  smooth loss = 0.4645
[2022-07-07 18:05:41,855 callbacks.py:105 INFO train-abinet] epoch 7 iter 324650: loss = 0.4499,  smooth loss = 0.4625
[2022-07-07 18:06:22,447 callbacks.py:105 INFO train-abinet] epoch 7 iter 324700: loss = 0.4326,  smooth loss = 0.4575
[2022-07-07 18:07:03,884 callbacks.py:105 INFO train-abinet] epoch 7 iter 324750: loss = 0.4251,  smooth loss = 0.4655
[2022-07-07 18:07:44,412 callbacks.py:105 INFO train-abinet] epoch 7 iter 324800: loss = 0.3288,  smooth loss = 0.4766
[2022-07-07 18:08:25,054 callbacks.py:105 INFO train-abinet] epoch 7 iter 324850: loss = 0.5137,  smooth loss = 0.4734
[2022-07-07 18:09:06,383 callbacks.py:105 INFO train-abinet] epoch 7 iter 324900: loss = 0.4653,  smooth loss = 0.4702
[2022-07-07 18:09:46,856 callbacks.py:105 INFO train-abinet] epoch 7 iter 324950: loss = 0.3758,  smooth loss = 0.4668
[2022-07-07 18:10:28,016 callbacks.py:105 INFO train-abinet] epoch 7 iter 325000: loss = 0.3230,  smooth loss = 0.4686
[2022-07-07 18:11:09,408 callbacks.py:105 INFO train-abinet] epoch 7 iter 325050: loss = 0.4965,  smooth loss = 0.4616
[2022-07-07 18:11:50,117 callbacks.py:105 INFO train-abinet] epoch 7 iter 325100: loss = 0.4989,  smooth loss = 0.4716
[2022-07-07 18:12:31,089 callbacks.py:105 INFO train-abinet] epoch 7 iter 325150: loss = 0.7456,  smooth loss = 0.4817
[2022-07-07 18:13:11,729 callbacks.py:105 INFO train-abinet] epoch 7 iter 325200: loss = 0.5228,  smooth loss = 0.4827
[2022-07-07 18:13:52,829 callbacks.py:105 INFO train-abinet] epoch 7 iter 325250: loss = 0.4889,  smooth loss = 0.4609
[2022-07-07 18:14:33,321 callbacks.py:105 INFO train-abinet] epoch 7 iter 325300: loss = 0.6003,  smooth loss = 0.4640
[2022-07-07 18:15:14,369 callbacks.py:105 INFO train-abinet] epoch 7 iter 325350: loss = 0.4078,  smooth loss = 0.4649
[2022-07-07 18:15:54,875 callbacks.py:105 INFO train-abinet] epoch 7 iter 325400: loss = 0.5628,  smooth loss = 0.4589
[2022-07-07 18:16:35,756 callbacks.py:105 INFO train-abinet] epoch 7 iter 325450: loss = 0.4893,  smooth loss = 0.4507
[2022-07-07 18:17:16,044 callbacks.py:105 INFO train-abinet] epoch 7 iter 325500: loss = 0.5619,  smooth loss = 0.4753
[2022-07-07 18:17:57,205 callbacks.py:105 INFO train-abinet] epoch 7 iter 325550: loss = 0.4664,  smooth loss = 0.4528
[2022-07-07 18:18:38,505 callbacks.py:105 INFO train-abinet] epoch 7 iter 325600: loss = 0.5235,  smooth loss = 0.4647
[2022-07-07 18:19:19,200 callbacks.py:105 INFO train-abinet] epoch 7 iter 325650: loss = 0.4619,  smooth loss = 0.4546
[2022-07-07 18:20:00,296 callbacks.py:105 INFO train-abinet] epoch 7 iter 325700: loss = 0.3619,  smooth loss = 0.4624
[2022-07-07 18:20:40,860 callbacks.py:105 INFO train-abinet] epoch 7 iter 325750: loss = 0.4824,  smooth loss = 0.4634
[2022-07-07 18:21:21,965 callbacks.py:105 INFO train-abinet] epoch 7 iter 325800: loss = 0.3523,  smooth loss = 0.4565
[2022-07-07 18:22:02,739 callbacks.py:105 INFO train-abinet] epoch 7 iter 325850: loss = 0.4724,  smooth loss = 0.4483
[2022-07-07 18:22:43,928 callbacks.py:105 INFO train-abinet] epoch 7 iter 325900: loss = 0.3257,  smooth loss = 0.4583
[2022-07-07 18:23:24,534 callbacks.py:105 INFO train-abinet] epoch 7 iter 325950: loss = 0.4051,  smooth loss = 0.4678
[2022-07-07 18:24:05,519 callbacks.py:105 INFO train-abinet] epoch 7 iter 326000: loss = 0.5716,  smooth loss = 0.4675
[2022-07-07 18:24:46,718 callbacks.py:105 INFO train-abinet] epoch 7 iter 326050: loss = 0.3799,  smooth loss = 0.4609
[2022-07-07 18:25:27,363 callbacks.py:105 INFO train-abinet] epoch 7 iter 326100: loss = 0.3199,  smooth loss = 0.4757
[2022-07-07 18:26:08,440 callbacks.py:105 INFO train-abinet] epoch 7 iter 326150: loss = 0.3946,  smooth loss = 0.4754
[2022-07-07 18:26:49,193 callbacks.py:105 INFO train-abinet] epoch 7 iter 326200: loss = 0.3434,  smooth loss = 0.4637
[2022-07-07 18:27:30,605 callbacks.py:105 INFO train-abinet] epoch 7 iter 326250: loss = 0.4834,  smooth loss = 0.4548
[2022-07-07 18:28:11,755 callbacks.py:105 INFO train-abinet] epoch 7 iter 326300: loss = 0.3855,  smooth loss = 0.4506
[2022-07-07 18:28:52,398 callbacks.py:105 INFO train-abinet] epoch 7 iter 326350: loss = 0.5142,  smooth loss = 0.4556
[2022-07-07 18:29:33,716 callbacks.py:105 INFO train-abinet] epoch 7 iter 326400: loss = 0.6583,  smooth loss = 0.4608
[2022-07-07 18:30:14,799 callbacks.py:105 INFO train-abinet] epoch 7 iter 326450: loss = 0.5056,  smooth loss = 0.4507
[2022-07-07 18:30:55,300 callbacks.py:105 INFO train-abinet] epoch 7 iter 326500: loss = 0.5288,  smooth loss = 0.4558
[2022-07-07 18:31:36,142 callbacks.py:105 INFO train-abinet] epoch 7 iter 326550: loss = 0.4723,  smooth loss = 0.4639
[2022-07-07 18:32:16,787 callbacks.py:105 INFO train-abinet] epoch 7 iter 326600: loss = 0.3585,  smooth loss = 0.4566
[2022-07-07 18:32:57,976 callbacks.py:105 INFO train-abinet] epoch 7 iter 326650: loss = 0.5834,  smooth loss = 0.4693
[2022-07-07 18:33:38,657 callbacks.py:105 INFO train-abinet] epoch 7 iter 326700: loss = 0.5507,  smooth loss = 0.4571
[2022-07-07 18:34:19,702 callbacks.py:105 INFO train-abinet] epoch 7 iter 326750: loss = 0.3913,  smooth loss = 0.4618
[2022-07-07 18:35:00,746 callbacks.py:105 INFO train-abinet] epoch 7 iter 326800: loss = 0.4150,  smooth loss = 0.4744
[2022-07-07 18:35:41,666 callbacks.py:105 INFO train-abinet] epoch 7 iter 326850: loss = 0.4874,  smooth loss = 0.4606
[2022-07-07 18:36:22,268 callbacks.py:105 INFO train-abinet] epoch 7 iter 326900: loss = 0.4903,  smooth loss = 0.4587
[2022-07-07 18:37:03,266 callbacks.py:105 INFO train-abinet] epoch 7 iter 326950: loss = 0.3664,  smooth loss = 0.4707
[2022-07-07 18:37:43,849 callbacks.py:105 INFO train-abinet] epoch 7 iter 327000: loss = 0.4941,  smooth loss = 0.4605
[2022-07-07 18:37:43,850 callbacks.py:114 INFO train-abinet] average data time = 0.0047s, average running time = 0.8590s
█[2022-07-07 18:37:58,012 callbacks.py:123 INFO train-abinet] epoch 7 iter 327000: eval loss = 1.1678,  ccr = 0.9653,  cwr = 0.9272,  ted = 1138.0000,  ned = 231.0423,  ted/w = 0.1570, 
[2022-07-07 18:37:58,014 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_327000
[2022-07-07 18:38:39,518 callbacks.py:105 INFO train-abinet] epoch 7 iter 327050: loss = 0.4641,  smooth loss = 0.4659
[2022-07-07 18:39:20,565 callbacks.py:105 INFO train-abinet] epoch 7 iter 327100: loss = 0.4539,  smooth loss = 0.4600
[2022-07-07 18:40:01,003 callbacks.py:105 INFO train-abinet] epoch 7 iter 327150: loss = 0.4179,  smooth loss = 0.4605
[2022-07-07 18:40:41,961 callbacks.py:105 INFO train-abinet] epoch 7 iter 327200: loss = 0.4657,  smooth loss = 0.4667
[2022-07-07 18:41:22,847 callbacks.py:105 INFO train-abinet] epoch 7 iter 327250: loss = 0.4214,  smooth loss = 0.4668
[2022-07-07 18:42:03,696 callbacks.py:105 INFO train-abinet] epoch 7 iter 327300: loss = 0.4309,  smooth loss = 0.4589
[2022-07-07 18:42:44,446 callbacks.py:105 INFO train-abinet] epoch 7 iter 327350: loss = 0.4158,  smooth loss = 0.4653
[2022-07-07 18:43:26,021 callbacks.py:105 INFO train-abinet] epoch 7 iter 327400: loss = 0.3710,  smooth loss = 0.4576
[2022-07-07 18:44:06,942 callbacks.py:105 INFO train-abinet] epoch 7 iter 327450: loss = 0.4129,  smooth loss = 0.4624
[2022-07-07 18:44:47,937 callbacks.py:105 INFO train-abinet] epoch 7 iter 327500: loss = 0.4368,  smooth loss = 0.4564
[2022-07-07 18:45:28,779 callbacks.py:105 INFO train-abinet] epoch 7 iter 327550: loss = 0.4991,  smooth loss = 0.4594
[2022-07-07 18:46:10,065 callbacks.py:105 INFO train-abinet] epoch 7 iter 327600: loss = 0.4532,  smooth loss = 0.4686
[2022-07-07 18:46:50,802 callbacks.py:105 INFO train-abinet] epoch 7 iter 327650: loss = 0.4386,  smooth loss = 0.4642
[2022-07-07 18:47:31,964 callbacks.py:105 INFO train-abinet] epoch 7 iter 327700: loss = 0.3694,  smooth loss = 0.4637
[2022-07-07 18:48:12,644 callbacks.py:105 INFO train-abinet] epoch 7 iter 327750: loss = 0.4204,  smooth loss = 0.4603
[2022-07-07 18:48:53,772 callbacks.py:105 INFO train-abinet] epoch 7 iter 327800: loss = 0.4250,  smooth loss = 0.4627
[2022-07-07 18:49:34,652 callbacks.py:105 INFO train-abinet] epoch 7 iter 327850: loss = 0.4849,  smooth loss = 0.4679
[2022-07-07 18:50:16,085 callbacks.py:105 INFO train-abinet] epoch 7 iter 327900: loss = 0.4609,  smooth loss = 0.4757
[2022-07-07 18:50:56,745 callbacks.py:105 INFO train-abinet] epoch 7 iter 327950: loss = 0.4359,  smooth loss = 0.4704
[2022-07-07 18:51:38,185 callbacks.py:105 INFO train-abinet] epoch 7 iter 328000: loss = 0.3468,  smooth loss = 0.4689
[2022-07-07 18:52:19,031 callbacks.py:105 INFO train-abinet] epoch 7 iter 328050: loss = 0.5108,  smooth loss = 0.4613
[2022-07-07 18:52:59,945 callbacks.py:105 INFO train-abinet] epoch 7 iter 328100: loss = 0.5017,  smooth loss = 0.4566
[2022-07-07 18:53:40,404 callbacks.py:105 INFO train-abinet] epoch 7 iter 328150: loss = 0.6077,  smooth loss = 0.4636
[2022-07-07 18:54:21,148 callbacks.py:105 INFO train-abinet] epoch 7 iter 328200: loss = 0.4059,  smooth loss = 0.4619
[2022-07-07 18:55:01,928 callbacks.py:105 INFO train-abinet] epoch 7 iter 328250: loss = 0.4651,  smooth loss = 0.4509
[2022-07-07 18:55:43,000 callbacks.py:105 INFO train-abinet] epoch 7 iter 328300: loss = 0.4817,  smooth loss = 0.4551
[2022-07-07 18:56:23,598 callbacks.py:105 INFO train-abinet] epoch 7 iter 328350: loss = 0.5466,  smooth loss = 0.4678
[2022-07-07 18:57:04,841 callbacks.py:105 INFO train-abinet] epoch 7 iter 328400: loss = 0.3422,  smooth loss = 0.4554
[2022-07-07 18:57:45,784 callbacks.py:105 INFO train-abinet] epoch 7 iter 328450: loss = 0.4007,  smooth loss = 0.4576
[2022-07-07 18:58:26,471 callbacks.py:105 INFO train-abinet] epoch 7 iter 328500: loss = 0.5266,  smooth loss = 0.4588
[2022-07-07 18:59:08,201 callbacks.py:105 INFO train-abinet] epoch 7 iter 328550: loss = 0.5076,  smooth loss = 0.4486
[2022-07-07 18:59:49,670 callbacks.py:105 INFO train-abinet] epoch 7 iter 328600: loss = 0.5063,  smooth loss = 0.4564
[2022-07-07 19:00:30,417 callbacks.py:105 INFO train-abinet] epoch 7 iter 328650: loss = 0.4840,  smooth loss = 0.4567
[2022-07-07 19:01:11,374 callbacks.py:105 INFO train-abinet] epoch 7 iter 328700: loss = 0.5762,  smooth loss = 0.4599
[2022-07-07 19:01:52,466 callbacks.py:105 INFO train-abinet] epoch 7 iter 328750: loss = 0.4633,  smooth loss = 0.4597
[2022-07-07 19:02:32,640 callbacks.py:105 INFO train-abinet] epoch 7 iter 328800: loss = 0.3376,  smooth loss = 0.4589
[2022-07-07 19:03:13,001 callbacks.py:105 INFO train-abinet] epoch 7 iter 328850: loss = 0.5064,  smooth loss = 0.4580
[2022-07-07 19:03:53,828 callbacks.py:105 INFO train-abinet] epoch 7 iter 328900: loss = 0.4235,  smooth loss = 0.4618
[2022-07-07 19:04:34,397 callbacks.py:105 INFO train-abinet] epoch 7 iter 328950: loss = 0.5111,  smooth loss = 0.4594
[2022-07-07 19:05:15,231 callbacks.py:105 INFO train-abinet] epoch 7 iter 329000: loss = 0.4855,  smooth loss = 0.4577
[2022-07-07 19:05:56,292 callbacks.py:105 INFO train-abinet] epoch 7 iter 329050: loss = 0.4880,  smooth loss = 0.4547
[2022-07-07 19:06:36,760 callbacks.py:105 INFO train-abinet] epoch 7 iter 329100: loss = 0.3498,  smooth loss = 0.4529
[2022-07-07 19:07:17,434 callbacks.py:105 INFO train-abinet] epoch 7 iter 329150: loss = 0.4965,  smooth loss = 0.4586
[2022-07-07 19:07:58,659 callbacks.py:105 INFO train-abinet] epoch 7 iter 329200: loss = 0.4336,  smooth loss = 0.4587
[2022-07-07 19:08:39,050 callbacks.py:105 INFO train-abinet] epoch 7 iter 329250: loss = 0.4777,  smooth loss = 0.4654
[2022-07-07 19:09:20,374 callbacks.py:105 INFO train-abinet] epoch 7 iter 329300: loss = 0.5016,  smooth loss = 0.4626
[2022-07-07 19:10:01,165 callbacks.py:105 INFO train-abinet] epoch 7 iter 329350: loss = 0.4672,  smooth loss = 0.4695
[2022-07-07 19:10:42,205 callbacks.py:105 INFO train-abinet] epoch 7 iter 329400: loss = 0.4129,  smooth loss = 0.4559
[2022-07-07 19:11:22,850 callbacks.py:105 INFO train-abinet] epoch 7 iter 329450: loss = 0.4325,  smooth loss = 0.4544
[2022-07-07 19:12:04,310 callbacks.py:105 INFO train-abinet] epoch 7 iter 329500: loss = 0.4616,  smooth loss = 0.4602
[2022-07-07 19:12:45,002 callbacks.py:105 INFO train-abinet] epoch 7 iter 329550: loss = 0.4541,  smooth loss = 0.4714
[2022-07-07 19:13:26,277 callbacks.py:105 INFO train-abinet] epoch 7 iter 329600: loss = 0.4656,  smooth loss = 0.4702
[2022-07-07 19:14:07,081 callbacks.py:105 INFO train-abinet] epoch 7 iter 329650: loss = 0.4438,  smooth loss = 0.4660
[2022-07-07 19:14:47,561 callbacks.py:105 INFO train-abinet] epoch 7 iter 329700: loss = 0.4540,  smooth loss = 0.4538
[2022-07-07 19:15:28,803 callbacks.py:105 INFO train-abinet] epoch 7 iter 329750: loss = 0.4980,  smooth loss = 0.4524
[2022-07-07 19:16:09,175 callbacks.py:105 INFO train-abinet] epoch 7 iter 329800: loss = 0.4871,  smooth loss = 0.4612
[2022-07-07 19:16:49,709 callbacks.py:105 INFO train-abinet] epoch 7 iter 329850: loss = 0.4065,  smooth loss = 0.4516
[2022-07-07 19:17:30,728 callbacks.py:105 INFO train-abinet] epoch 7 iter 329900: loss = 0.3781,  smooth loss = 0.4610
[2022-07-07 19:18:11,193 callbacks.py:105 INFO train-abinet] epoch 7 iter 329950: loss = 0.4957,  smooth loss = 0.4674
[2022-07-07 19:18:51,619 callbacks.py:105 INFO train-abinet] epoch 7 iter 330000: loss = 0.4019,  smooth loss = 0.4670
[2022-07-07 19:18:51,620 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8586s
█[2022-07-07 19:19:05,751 callbacks.py:123 INFO train-abinet] epoch 7 iter 330000: eval loss = 1.1582,  ccr = 0.9651,  cwr = 0.9256,  ted = 1176.0000,  ned = 238.3758,  ted/w = 0.1623, 
[2022-07-07 19:19:05,753 callbacks.py:136 INFO train-abinet] Save model train-abinet_7_330000
[2022-07-07 19:19:47,178 callbacks.py:105 INFO train-abinet] epoch 7 iter 330050: loss = 0.4435,  smooth loss = 0.4627
[2022-07-07 19:20:28,029 callbacks.py:105 INFO train-abinet] epoch 7 iter 330100: loss = 0.4716,  smooth loss = 0.4659
[2022-07-07 19:21:08,925 callbacks.py:105 INFO train-abinet] epoch 7 iter 330150: loss = 0.4992,  smooth loss = 0.4616
[2022-07-07 19:21:49,630 callbacks.py:105 INFO train-abinet] epoch 7 iter 330200: loss = 0.3643,  smooth loss = 0.4569
[2022-07-07 19:22:30,168 callbacks.py:105 INFO train-abinet] epoch 7 iter 330250: loss = 0.3560,  smooth loss = 0.4659
[2022-07-07 19:23:11,318 callbacks.py:105 INFO train-abinet] epoch 7 iter 330300: loss = 0.4992,  smooth loss = 0.4551
[2022-07-07 19:23:51,743 callbacks.py:105 INFO train-abinet] epoch 7 iter 330350: loss = 0.4068,  smooth loss = 0.4461
[2022-07-07 19:24:32,956 callbacks.py:105 INFO train-abinet] epoch 7 iter 330400: loss = 0.5167,  smooth loss = 0.4572
[2022-07-07 19:25:13,558 callbacks.py:105 INFO train-abinet] epoch 7 iter 330450: loss = 0.4492,  smooth loss = 0.4610
[2022-07-07 19:25:54,812 callbacks.py:105 INFO train-abinet] epoch 7 iter 330500: loss = 0.4952,  smooth loss = 0.4578
[2022-07-07 19:26:35,508 callbacks.py:105 INFO train-abinet] epoch 7 iter 330550: loss = 0.5419,  smooth loss = 0.4691
[2022-07-07 19:27:16,384 callbacks.py:105 INFO train-abinet] epoch 7 iter 330600: loss = 0.4800,  smooth loss = 0.4725
[2022-07-07 19:27:57,493 callbacks.py:105 INFO train-abinet] epoch 7 iter 330650: loss = 0.6514,  smooth loss = 0.4714
[2022-07-07 19:28:38,387 callbacks.py:105 INFO train-abinet] epoch 7 iter 330700: loss = 0.5007,  smooth loss = 0.4670
[2022-07-07 19:29:18,844 callbacks.py:105 INFO train-abinet] epoch 7 iter 330750: loss = 0.5153,  smooth loss = 0.4802
[2022-07-07 19:29:59,824 callbacks.py:105 INFO train-abinet] epoch 7 iter 330800: loss = 0.5632,  smooth loss = 0.4582
[2022-07-07 19:30:40,119 callbacks.py:105 INFO train-abinet] epoch 7 iter 330850: loss = 0.5106,  smooth loss = 0.4513
[2022-07-07 19:31:20,913 callbacks.py:105 INFO train-abinet] epoch 7 iter 330900: loss = 0.3185,  smooth loss = 0.4569
[2022-07-07 19:32:01,081 callbacks.py:105 INFO train-abinet] epoch 7 iter 330950: loss = 0.3877,  smooth loss = 0.4566
[2022-07-07 19:32:41,334 callbacks.py:105 INFO train-abinet] epoch 7 iter 331000: loss = 0.3430,  smooth loss = 0.4717
[2022-07-07 19:33:22,609 callbacks.py:105 INFO train-abinet] epoch 7 iter 331050: loss = 0.3659,  smooth loss = 0.4639
[2022-07-07 19:34:03,059 callbacks.py:105 INFO train-abinet] epoch 7 iter 331100: loss = 0.4775,  smooth loss = 0.4534
[2022-07-07 19:34:46,203 callbacks.py:105 INFO train-abinet] epoch 7 iter 331150: loss = 0.4751,  smooth loss = 0.4546
█[2022-07-07 19:35:31,279 callbacks.py:105 INFO train-abinet] epoch 8 iter 331200: loss = 0.4439,  smooth loss = 0.4637
[2022-07-07 19:36:12,313 callbacks.py:105 INFO train-abinet] epoch 8 iter 331250: loss = 0.5101,  smooth loss = 0.4572
[2022-07-07 19:36:52,862 callbacks.py:105 INFO train-abinet] epoch 8 iter 331300: loss = 0.5474,  smooth loss = 0.4567
[2022-07-07 19:37:33,362 callbacks.py:105 INFO train-abinet] epoch 8 iter 331350: loss = 0.3450,  smooth loss = 0.4460
[2022-07-07 19:38:14,673 callbacks.py:105 INFO train-abinet] epoch 8 iter 331400: loss = 0.5400,  smooth loss = 0.4616
[2022-07-07 19:38:55,495 callbacks.py:105 INFO train-abinet] epoch 8 iter 331450: loss = 0.4343,  smooth loss = 0.4581
[2022-07-07 19:39:35,982 callbacks.py:105 INFO train-abinet] epoch 8 iter 331500: loss = 0.5360,  smooth loss = 0.4682
[2022-07-07 19:40:17,294 callbacks.py:105 INFO train-abinet] epoch 8 iter 331550: loss = 0.4269,  smooth loss = 0.4429
[2022-07-07 19:40:58,137 callbacks.py:105 INFO train-abinet] epoch 8 iter 331600: loss = 0.5444,  smooth loss = 0.4551
[2022-07-07 19:41:39,192 callbacks.py:105 INFO train-abinet] epoch 8 iter 331650: loss = 0.3639,  smooth loss = 0.4638
[2022-07-07 19:42:19,865 callbacks.py:105 INFO train-abinet] epoch 8 iter 331700: loss = 0.4670,  smooth loss = 0.4607
[2022-07-07 19:43:01,113 callbacks.py:105 INFO train-abinet] epoch 8 iter 331750: loss = 0.3752,  smooth loss = 0.4609
[2022-07-07 19:43:41,677 callbacks.py:105 INFO train-abinet] epoch 8 iter 331800: loss = 0.4157,  smooth loss = 0.4545
[2022-07-07 19:44:22,172 callbacks.py:105 INFO train-abinet] epoch 8 iter 331850: loss = 0.4615,  smooth loss = 0.4558
[2022-07-07 19:45:02,946 callbacks.py:105 INFO train-abinet] epoch 8 iter 331900: loss = 0.4320,  smooth loss = 0.4528
[2022-07-07 19:45:43,401 callbacks.py:105 INFO train-abinet] epoch 8 iter 331950: loss = 0.5407,  smooth loss = 0.4581
[2022-07-07 19:46:23,871 callbacks.py:105 INFO train-abinet] epoch 8 iter 332000: loss = 0.4796,  smooth loss = 0.4594
[2022-07-07 19:47:04,829 callbacks.py:105 INFO train-abinet] epoch 8 iter 332050: loss = 0.5490,  smooth loss = 0.4558
[2022-07-07 19:47:45,499 callbacks.py:105 INFO train-abinet] epoch 8 iter 332100: loss = 0.4759,  smooth loss = 0.4684
[2022-07-07 19:48:26,502 callbacks.py:105 INFO train-abinet] epoch 8 iter 332150: loss = 0.6131,  smooth loss = 0.4686
[2022-07-07 19:49:07,288 callbacks.py:105 INFO train-abinet] epoch 8 iter 332200: loss = 0.4140,  smooth loss = 0.4588
[2022-07-07 19:49:47,892 callbacks.py:105 INFO train-abinet] epoch 8 iter 332250: loss = 0.4640,  smooth loss = 0.4645
[2022-07-07 19:50:28,546 callbacks.py:105 INFO train-abinet] epoch 8 iter 332300: loss = 0.5592,  smooth loss = 0.4626
[2022-07-07 19:51:08,971 callbacks.py:105 INFO train-abinet] epoch 8 iter 332350: loss = 0.4971,  smooth loss = 0.4590
[2022-07-07 19:51:49,669 callbacks.py:105 INFO train-abinet] epoch 8 iter 332400: loss = 0.4193,  smooth loss = 0.4700
[2022-07-07 19:52:31,080 callbacks.py:105 INFO train-abinet] epoch 8 iter 332450: loss = 0.4843,  smooth loss = 0.4696
[2022-07-07 19:53:12,071 callbacks.py:105 INFO train-abinet] epoch 8 iter 332500: loss = 0.4665,  smooth loss = 0.4569
[2022-07-07 19:53:53,135 callbacks.py:105 INFO train-abinet] epoch 8 iter 332550: loss = 0.4047,  smooth loss = 0.4601
[2022-07-07 19:54:34,069 callbacks.py:105 INFO train-abinet] epoch 8 iter 332600: loss = 0.4836,  smooth loss = 0.4491
[2022-07-07 19:55:15,151 callbacks.py:105 INFO train-abinet] epoch 8 iter 332650: loss = 0.3725,  smooth loss = 0.4495
[2022-07-07 19:55:56,133 callbacks.py:105 INFO train-abinet] epoch 8 iter 332700: loss = 0.6008,  smooth loss = 0.4472
[2022-07-07 19:56:37,158 callbacks.py:105 INFO train-abinet] epoch 8 iter 332750: loss = 0.4859,  smooth loss = 0.4517
[2022-07-07 19:57:18,390 callbacks.py:105 INFO train-abinet] epoch 8 iter 332800: loss = 0.4373,  smooth loss = 0.4487
[2022-07-07 19:57:59,498 callbacks.py:105 INFO train-abinet] epoch 8 iter 332850: loss = 0.4817,  smooth loss = 0.4668
[2022-07-07 19:58:40,190 callbacks.py:105 INFO train-abinet] epoch 8 iter 332900: loss = 0.3841,  smooth loss = 0.4561
[2022-07-07 19:59:21,319 callbacks.py:105 INFO train-abinet] epoch 8 iter 332950: loss = 0.5501,  smooth loss = 0.4494
[2022-07-07 20:00:02,217 callbacks.py:105 INFO train-abinet] epoch 8 iter 333000: loss = 0.4778,  smooth loss = 0.4675
[2022-07-07 20:00:02,218 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8583s
█[2022-07-07 20:00:16,699 callbacks.py:123 INFO train-abinet] epoch 8 iter 333000: eval loss = 1.1644,  ccr = 0.9651,  cwr = 0.9274,  ted = 1144.0000,  ned = 231.2360,  ted/w = 0.1578, 
[2022-07-07 20:00:16,701 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_333000
[2022-07-07 20:00:58,382 callbacks.py:105 INFO train-abinet] epoch 8 iter 333050: loss = 0.5586,  smooth loss = 0.4687
[2022-07-07 20:01:39,628 callbacks.py:105 INFO train-abinet] epoch 8 iter 333100: loss = 0.3727,  smooth loss = 0.4653
[2022-07-07 20:02:20,312 callbacks.py:105 INFO train-abinet] epoch 8 iter 333150: loss = 0.4660,  smooth loss = 0.4516
[2022-07-07 20:03:00,555 callbacks.py:105 INFO train-abinet] epoch 8 iter 333200: loss = 0.5262,  smooth loss = 0.4669
[2022-07-07 20:03:41,758 callbacks.py:105 INFO train-abinet] epoch 8 iter 333250: loss = 0.4588,  smooth loss = 0.4717
[2022-07-07 20:04:22,510 callbacks.py:105 INFO train-abinet] epoch 8 iter 333300: loss = 0.3598,  smooth loss = 0.4552
[2022-07-07 20:05:03,779 callbacks.py:105 INFO train-abinet] epoch 8 iter 333350: loss = 0.4389,  smooth loss = 0.4569
[2022-07-07 20:05:44,489 callbacks.py:105 INFO train-abinet] epoch 8 iter 333400: loss = 0.3615,  smooth loss = 0.4764
[2022-07-07 20:06:25,705 callbacks.py:105 INFO train-abinet] epoch 8 iter 333450: loss = 0.4052,  smooth loss = 0.4783
[2022-07-07 20:07:06,710 callbacks.py:105 INFO train-abinet] epoch 8 iter 333500: loss = 0.4703,  smooth loss = 0.4705
[2022-07-07 20:07:47,619 callbacks.py:105 INFO train-abinet] epoch 8 iter 333550: loss = 0.5166,  smooth loss = 0.4661
[2022-07-07 20:08:28,172 callbacks.py:105 INFO train-abinet] epoch 8 iter 333600: loss = 0.4280,  smooth loss = 0.4707
[2022-07-07 20:09:09,047 callbacks.py:105 INFO train-abinet] epoch 8 iter 333650: loss = 0.4245,  smooth loss = 0.4523
[2022-07-07 20:09:49,919 callbacks.py:105 INFO train-abinet] epoch 8 iter 333700: loss = 0.4629,  smooth loss = 0.4528
[2022-07-07 20:10:30,746 callbacks.py:105 INFO train-abinet] epoch 8 iter 333750: loss = 0.3427,  smooth loss = 0.4580
[2022-07-07 20:11:11,107 callbacks.py:105 INFO train-abinet] epoch 8 iter 333800: loss = 0.5881,  smooth loss = 0.4672
[2022-07-07 20:11:51,727 callbacks.py:105 INFO train-abinet] epoch 8 iter 333850: loss = 0.4244,  smooth loss = 0.4692
[2022-07-07 20:12:32,848 callbacks.py:105 INFO train-abinet] epoch 8 iter 333900: loss = 0.5688,  smooth loss = 0.4587
[2022-07-07 20:13:13,217 callbacks.py:105 INFO train-abinet] epoch 8 iter 333950: loss = 0.5011,  smooth loss = 0.4649
[2022-07-07 20:13:53,820 callbacks.py:105 INFO train-abinet] epoch 8 iter 334000: loss = 0.3821,  smooth loss = 0.4661
[2022-07-07 20:14:34,770 callbacks.py:105 INFO train-abinet] epoch 8 iter 334050: loss = 0.4411,  smooth loss = 0.4702
[2022-07-07 20:15:15,106 callbacks.py:105 INFO train-abinet] epoch 8 iter 334100: loss = 0.5153,  smooth loss = 0.4594
[2022-07-07 20:15:55,909 callbacks.py:105 INFO train-abinet] epoch 8 iter 334150: loss = 0.5453,  smooth loss = 0.4498
[2022-07-07 20:16:36,802 callbacks.py:105 INFO train-abinet] epoch 8 iter 334200: loss = 0.3482,  smooth loss = 0.4418
[2022-07-07 20:17:17,292 callbacks.py:105 INFO train-abinet] epoch 8 iter 334250: loss = 0.4472,  smooth loss = 0.4532
[2022-07-07 20:17:58,238 callbacks.py:105 INFO train-abinet] epoch 8 iter 334300: loss = 0.4039,  smooth loss = 0.4526
[2022-07-07 20:18:38,688 callbacks.py:105 INFO train-abinet] epoch 8 iter 334350: loss = 0.4629,  smooth loss = 0.4615
[2022-07-07 20:19:19,040 callbacks.py:105 INFO train-abinet] epoch 8 iter 334400: loss = 0.4419,  smooth loss = 0.4501
[2022-07-07 20:20:00,100 callbacks.py:105 INFO train-abinet] epoch 8 iter 334450: loss = 0.4881,  smooth loss = 0.4661
[2022-07-07 20:20:40,546 callbacks.py:105 INFO train-abinet] epoch 8 iter 334500: loss = 0.6056,  smooth loss = 0.4672
[2022-07-07 20:21:21,055 callbacks.py:105 INFO train-abinet] epoch 8 iter 334550: loss = 0.4073,  smooth loss = 0.4646
[2022-07-07 20:22:02,199 callbacks.py:105 INFO train-abinet] epoch 8 iter 334600: loss = 0.4156,  smooth loss = 0.4659
[2022-07-07 20:22:42,760 callbacks.py:105 INFO train-abinet] epoch 8 iter 334650: loss = 0.4606,  smooth loss = 0.4606
[2022-07-07 20:23:23,497 callbacks.py:105 INFO train-abinet] epoch 8 iter 334700: loss = 0.4531,  smooth loss = 0.4531
[2022-07-07 20:24:04,962 callbacks.py:105 INFO train-abinet] epoch 8 iter 334750: loss = 0.6685,  smooth loss = 0.4674
[2022-07-07 20:24:45,776 callbacks.py:105 INFO train-abinet] epoch 8 iter 334800: loss = 0.4151,  smooth loss = 0.4627
[2022-07-07 20:25:26,741 callbacks.py:105 INFO train-abinet] epoch 8 iter 334850: loss = 0.3639,  smooth loss = 0.4475
[2022-07-07 20:26:07,298 callbacks.py:105 INFO train-abinet] epoch 8 iter 334900: loss = 0.3675,  smooth loss = 0.4465
[2022-07-07 20:26:48,569 callbacks.py:105 INFO train-abinet] epoch 8 iter 334950: loss = 0.4530,  smooth loss = 0.4451
[2022-07-07 20:27:29,460 callbacks.py:105 INFO train-abinet] epoch 8 iter 335000: loss = 0.5529,  smooth loss = 0.4586
[2022-07-07 20:28:10,208 callbacks.py:105 INFO train-abinet] epoch 8 iter 335050: loss = 0.5846,  smooth loss = 0.4612
[2022-07-07 20:28:50,981 callbacks.py:105 INFO train-abinet] epoch 8 iter 335100: loss = 0.5671,  smooth loss = 0.4781
[2022-07-07 20:29:32,328 callbacks.py:105 INFO train-abinet] epoch 8 iter 335150: loss = 0.5823,  smooth loss = 0.4796
[2022-07-07 20:30:13,080 callbacks.py:105 INFO train-abinet] epoch 8 iter 335200: loss = 0.5306,  smooth loss = 0.4691
[2022-07-07 20:30:53,829 callbacks.py:105 INFO train-abinet] epoch 8 iter 335250: loss = 0.4448,  smooth loss = 0.4680
[2022-07-07 20:31:35,486 callbacks.py:105 INFO train-abinet] epoch 8 iter 335300: loss = 0.4424,  smooth loss = 0.4702
[2022-07-07 20:32:16,588 callbacks.py:105 INFO train-abinet] epoch 8 iter 335350: loss = 0.4243,  smooth loss = 0.4559
[2022-07-07 20:32:57,812 callbacks.py:105 INFO train-abinet] epoch 8 iter 335400: loss = 0.4799,  smooth loss = 0.4641
[2022-07-07 20:33:38,455 callbacks.py:105 INFO train-abinet] epoch 8 iter 335450: loss = 0.4629,  smooth loss = 0.4576
[2022-07-07 20:34:19,236 callbacks.py:105 INFO train-abinet] epoch 8 iter 335500: loss = 0.4809,  smooth loss = 0.4658
[2022-07-07 20:35:00,479 callbacks.py:105 INFO train-abinet] epoch 8 iter 335550: loss = 0.4669,  smooth loss = 0.4724
[2022-07-07 20:35:41,319 callbacks.py:105 INFO train-abinet] epoch 8 iter 335600: loss = 0.5902,  smooth loss = 0.4691
[2022-07-07 20:36:22,327 callbacks.py:105 INFO train-abinet] epoch 8 iter 335650: loss = 0.4932,  smooth loss = 0.4664
[2022-07-07 20:37:03,103 callbacks.py:105 INFO train-abinet] epoch 8 iter 335700: loss = 0.4791,  smooth loss = 0.4622
[2022-07-07 20:37:43,686 callbacks.py:105 INFO train-abinet] epoch 8 iter 335750: loss = 0.5532,  smooth loss = 0.4663
[2022-07-07 20:38:24,209 callbacks.py:105 INFO train-abinet] epoch 8 iter 335800: loss = 0.4936,  smooth loss = 0.4499
[2022-07-07 20:39:04,849 callbacks.py:105 INFO train-abinet] epoch 8 iter 335850: loss = 0.4194,  smooth loss = 0.4576
[2022-07-07 20:39:46,008 callbacks.py:105 INFO train-abinet] epoch 8 iter 335900: loss = 0.4761,  smooth loss = 0.4724
[2022-07-07 20:40:26,734 callbacks.py:105 INFO train-abinet] epoch 8 iter 335950: loss = 0.6248,  smooth loss = 0.4631
[2022-07-07 20:41:07,895 callbacks.py:105 INFO train-abinet] epoch 8 iter 336000: loss = 0.5035,  smooth loss = 0.4803
[2022-07-07 20:41:07,896 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8579s
█[2022-07-07 20:41:21,743 callbacks.py:123 INFO train-abinet] epoch 8 iter 336000: eval loss = 1.1713,  ccr = 0.9649,  cwr = 0.9273,  ted = 1149.0000,  ned = 233.1013,  ted/w = 0.1585, 
[2022-07-07 20:41:21,744 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_336000
[2022-07-07 20:42:04,191 callbacks.py:105 INFO train-abinet] epoch 8 iter 336050: loss = 0.3870,  smooth loss = 0.4613
[2022-07-07 20:42:45,648 callbacks.py:105 INFO train-abinet] epoch 8 iter 336100: loss = 0.4258,  smooth loss = 0.4585
[2022-07-07 20:43:26,190 callbacks.py:105 INFO train-abinet] epoch 8 iter 336150: loss = 0.3584,  smooth loss = 0.4577
[2022-07-07 20:44:06,932 callbacks.py:105 INFO train-abinet] epoch 8 iter 336200: loss = 0.5369,  smooth loss = 0.4710
[2022-07-07 20:44:48,273 callbacks.py:105 INFO train-abinet] epoch 8 iter 336250: loss = 0.3787,  smooth loss = 0.4694
[2022-07-07 20:45:28,729 callbacks.py:105 INFO train-abinet] epoch 8 iter 336300: loss = 0.5232,  smooth loss = 0.4624
[2022-07-07 20:46:09,299 callbacks.py:105 INFO train-abinet] epoch 8 iter 336350: loss = 0.4089,  smooth loss = 0.4567
[2022-07-07 20:46:50,047 callbacks.py:105 INFO train-abinet] epoch 8 iter 336400: loss = 0.4646,  smooth loss = 0.4639
[2022-07-07 20:47:30,829 callbacks.py:105 INFO train-abinet] epoch 8 iter 336450: loss = 0.4699,  smooth loss = 0.4649
[2022-07-07 20:48:11,628 callbacks.py:105 INFO train-abinet] epoch 8 iter 336500: loss = 0.4861,  smooth loss = 0.4643
[2022-07-07 20:48:52,298 callbacks.py:105 INFO train-abinet] epoch 8 iter 336550: loss = 0.4208,  smooth loss = 0.4665
[2022-07-07 20:49:33,263 callbacks.py:105 INFO train-abinet] epoch 8 iter 336600: loss = 0.4313,  smooth loss = 0.4593
[2022-07-07 20:50:14,714 callbacks.py:105 INFO train-abinet] epoch 8 iter 336650: loss = 0.4302,  smooth loss = 0.4605
[2022-07-07 20:50:55,781 callbacks.py:105 INFO train-abinet] epoch 8 iter 336700: loss = 0.4811,  smooth loss = 0.4622
[2022-07-07 20:51:37,144 callbacks.py:105 INFO train-abinet] epoch 8 iter 336750: loss = 0.4388,  smooth loss = 0.4611
[2022-07-07 20:52:17,676 callbacks.py:105 INFO train-abinet] epoch 8 iter 336800: loss = 0.5307,  smooth loss = 0.4626
[2022-07-07 20:52:58,192 callbacks.py:105 INFO train-abinet] epoch 8 iter 336850: loss = 0.5312,  smooth loss = 0.4637
[2022-07-07 20:53:39,405 callbacks.py:105 INFO train-abinet] epoch 8 iter 336900: loss = 0.5134,  smooth loss = 0.4648
[2022-07-07 20:54:19,849 callbacks.py:105 INFO train-abinet] epoch 8 iter 336950: loss = 0.3938,  smooth loss = 0.4699
[2022-07-07 20:55:00,647 callbacks.py:105 INFO train-abinet] epoch 8 iter 337000: loss = 0.3777,  smooth loss = 0.4654
[2022-07-07 20:55:41,661 callbacks.py:105 INFO train-abinet] epoch 8 iter 337050: loss = 0.4703,  smooth loss = 0.4602
[2022-07-07 20:56:22,653 callbacks.py:105 INFO train-abinet] epoch 8 iter 337100: loss = 0.4654,  smooth loss = 0.4497
[2022-07-07 20:57:03,457 callbacks.py:105 INFO train-abinet] epoch 8 iter 337150: loss = 0.4130,  smooth loss = 0.4612
[2022-07-07 20:57:45,028 callbacks.py:105 INFO train-abinet] epoch 8 iter 337200: loss = 0.6332,  smooth loss = 0.4633
[2022-07-07 20:58:25,851 callbacks.py:105 INFO train-abinet] epoch 8 iter 337250: loss = 0.3757,  smooth loss = 0.4778
[2022-07-07 20:59:06,904 callbacks.py:105 INFO train-abinet] epoch 8 iter 337300: loss = 0.4803,  smooth loss = 0.4642
[2022-07-07 20:59:47,238 callbacks.py:105 INFO train-abinet] epoch 8 iter 337350: loss = 0.3957,  smooth loss = 0.4565
[2022-07-07 21:00:27,999 callbacks.py:105 INFO train-abinet] epoch 8 iter 337400: loss = 0.4077,  smooth loss = 0.4527
[2022-07-07 21:01:08,374 callbacks.py:105 INFO train-abinet] epoch 8 iter 337450: loss = 0.4464,  smooth loss = 0.4638
[2022-07-07 21:01:49,473 callbacks.py:105 INFO train-abinet] epoch 8 iter 337500: loss = 0.5690,  smooth loss = 0.4759
[2022-07-07 21:02:30,093 callbacks.py:105 INFO train-abinet] epoch 8 iter 337550: loss = 0.4620,  smooth loss = 0.4588
[2022-07-07 21:03:10,284 callbacks.py:105 INFO train-abinet] epoch 8 iter 337600: loss = 0.3873,  smooth loss = 0.4452
[2022-07-07 21:03:51,146 callbacks.py:105 INFO train-abinet] epoch 8 iter 337650: loss = 0.5996,  smooth loss = 0.4544
[2022-07-07 21:04:32,238 callbacks.py:105 INFO train-abinet] epoch 8 iter 337700: loss = 0.5071,  smooth loss = 0.4579
[2022-07-07 21:05:12,763 callbacks.py:105 INFO train-abinet] epoch 8 iter 337750: loss = 0.5476,  smooth loss = 0.4695
[2022-07-07 21:05:53,397 callbacks.py:105 INFO train-abinet] epoch 8 iter 337800: loss = 0.3811,  smooth loss = 0.4689
[2022-07-07 21:06:33,707 callbacks.py:105 INFO train-abinet] epoch 8 iter 337850: loss = 0.4910,  smooth loss = 0.4596
[2022-07-07 21:07:14,408 callbacks.py:105 INFO train-abinet] epoch 8 iter 337900: loss = 0.4641,  smooth loss = 0.4617
[2022-07-07 21:07:55,556 callbacks.py:105 INFO train-abinet] epoch 8 iter 337950: loss = 0.4907,  smooth loss = 0.4577
[2022-07-07 21:08:36,123 callbacks.py:105 INFO train-abinet] epoch 8 iter 338000: loss = 0.4235,  smooth loss = 0.4641
[2022-07-07 21:09:16,485 callbacks.py:105 INFO train-abinet] epoch 8 iter 338050: loss = 0.5972,  smooth loss = 0.4676
[2022-07-07 21:09:57,897 callbacks.py:105 INFO train-abinet] epoch 8 iter 338100: loss = 0.4644,  smooth loss = 0.4701
[2022-07-07 21:10:38,535 callbacks.py:105 INFO train-abinet] epoch 8 iter 338150: loss = 0.3603,  smooth loss = 0.4594
[2022-07-07 21:11:19,280 callbacks.py:105 INFO train-abinet] epoch 8 iter 338200: loss = 0.4972,  smooth loss = 0.4632
[2022-07-07 21:12:00,174 callbacks.py:105 INFO train-abinet] epoch 8 iter 338250: loss = 0.5874,  smooth loss = 0.4638
[2022-07-07 21:12:41,326 callbacks.py:105 INFO train-abinet] epoch 8 iter 338300: loss = 0.4487,  smooth loss = 0.4543
[2022-07-07 21:13:21,876 callbacks.py:105 INFO train-abinet] epoch 8 iter 338350: loss = 0.5216,  smooth loss = 0.4556
[2022-07-07 21:14:02,416 callbacks.py:105 INFO train-abinet] epoch 8 iter 338400: loss = 0.5205,  smooth loss = 0.4597
[2022-07-07 21:14:43,065 callbacks.py:105 INFO train-abinet] epoch 8 iter 338450: loss = 0.3109,  smooth loss = 0.4598
[2022-07-07 21:15:24,773 callbacks.py:105 INFO train-abinet] epoch 8 iter 338500: loss = 0.4255,  smooth loss = 0.4500
[2022-07-07 21:16:05,496 callbacks.py:105 INFO train-abinet] epoch 8 iter 338550: loss = 0.4879,  smooth loss = 0.4576
[2022-07-07 21:16:46,327 callbacks.py:105 INFO train-abinet] epoch 8 iter 338600: loss = 0.4959,  smooth loss = 0.4599
[2022-07-07 21:17:27,461 callbacks.py:105 INFO train-abinet] epoch 8 iter 338650: loss = 0.3999,  smooth loss = 0.4559
[2022-07-07 21:18:09,123 callbacks.py:105 INFO train-abinet] epoch 8 iter 338700: loss = 0.3984,  smooth loss = 0.4642
[2022-07-07 21:18:50,125 callbacks.py:105 INFO train-abinet] epoch 8 iter 338750: loss = 0.5446,  smooth loss = 0.4553
[2022-07-07 21:19:30,835 callbacks.py:105 INFO train-abinet] epoch 8 iter 338800: loss = 0.4309,  smooth loss = 0.4506
[2022-07-07 21:20:11,505 callbacks.py:105 INFO train-abinet] epoch 8 iter 338850: loss = 0.4411,  smooth loss = 0.4527
[2022-07-07 21:20:53,011 callbacks.py:105 INFO train-abinet] epoch 8 iter 338900: loss = 0.3531,  smooth loss = 0.4558
[2022-07-07 21:21:34,137 callbacks.py:105 INFO train-abinet] epoch 8 iter 338950: loss = 0.4928,  smooth loss = 0.4632
[2022-07-07 21:22:14,823 callbacks.py:105 INFO train-abinet] epoch 8 iter 339000: loss = 0.5044,  smooth loss = 0.4629
[2022-07-07 21:22:14,824 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8576s
█[2022-07-07 21:22:29,182 callbacks.py:123 INFO train-abinet] epoch 8 iter 339000: eval loss = 1.1690,  ccr = 0.9640,  cwr = 0.9263,  ted = 1181.0000,  ned = 238.7798,  ted/w = 0.1629, 
[2022-07-07 21:22:29,183 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_339000
[2022-07-07 21:23:10,541 callbacks.py:105 INFO train-abinet] epoch 8 iter 339050: loss = 0.4066,  smooth loss = 0.4680
[2022-07-07 21:23:51,621 callbacks.py:105 INFO train-abinet] epoch 8 iter 339100: loss = 0.3463,  smooth loss = 0.4592
[2022-07-07 21:24:32,324 callbacks.py:105 INFO train-abinet] epoch 8 iter 339150: loss = 0.4510,  smooth loss = 0.4610
[2022-07-07 21:25:13,260 callbacks.py:105 INFO train-abinet] epoch 8 iter 339200: loss = 0.5164,  smooth loss = 0.4597
[2022-07-07 21:25:54,221 callbacks.py:105 INFO train-abinet] epoch 8 iter 339250: loss = 0.4131,  smooth loss = 0.4540
[2022-07-07 21:26:35,235 callbacks.py:105 INFO train-abinet] epoch 8 iter 339300: loss = 0.4323,  smooth loss = 0.4569
[2022-07-07 21:27:16,183 callbacks.py:105 INFO train-abinet] epoch 8 iter 339350: loss = 0.5645,  smooth loss = 0.4603
[2022-07-07 21:27:56,899 callbacks.py:105 INFO train-abinet] epoch 8 iter 339400: loss = 0.4256,  smooth loss = 0.4702
[2022-07-07 21:28:37,587 callbacks.py:105 INFO train-abinet] epoch 8 iter 339450: loss = 0.4415,  smooth loss = 0.4583
[2022-07-07 21:29:18,738 callbacks.py:105 INFO train-abinet] epoch 8 iter 339500: loss = 0.4569,  smooth loss = 0.4676
[2022-07-07 21:29:59,101 callbacks.py:105 INFO train-abinet] epoch 8 iter 339550: loss = 0.4282,  smooth loss = 0.4550
[2022-07-07 21:30:39,884 callbacks.py:105 INFO train-abinet] epoch 8 iter 339600: loss = 0.5215,  smooth loss = 0.4568
[2022-07-07 21:31:21,101 callbacks.py:105 INFO train-abinet] epoch 8 iter 339650: loss = 0.4172,  smooth loss = 0.4601
[2022-07-07 21:32:01,653 callbacks.py:105 INFO train-abinet] epoch 8 iter 339700: loss = 0.4459,  smooth loss = 0.4530
[2022-07-07 21:32:42,783 callbacks.py:105 INFO train-abinet] epoch 8 iter 339750: loss = 0.4560,  smooth loss = 0.4603
[2022-07-07 21:33:23,545 callbacks.py:105 INFO train-abinet] epoch 8 iter 339800: loss = 0.5337,  smooth loss = 0.4535
[2022-07-07 21:34:04,209 callbacks.py:105 INFO train-abinet] epoch 8 iter 339850: loss = 0.4336,  smooth loss = 0.4588
[2022-07-07 21:34:44,928 callbacks.py:105 INFO train-abinet] epoch 8 iter 339900: loss = 0.4881,  smooth loss = 0.4667
[2022-07-07 21:35:25,691 callbacks.py:105 INFO train-abinet] epoch 8 iter 339950: loss = 0.4218,  smooth loss = 0.4561
[2022-07-07 21:36:07,025 callbacks.py:105 INFO train-abinet] epoch 8 iter 340000: loss = 0.4896,  smooth loss = 0.4612
[2022-07-07 21:36:47,745 callbacks.py:105 INFO train-abinet] epoch 8 iter 340050: loss = 0.4504,  smooth loss = 0.4636
[2022-07-07 21:37:28,418 callbacks.py:105 INFO train-abinet] epoch 8 iter 340100: loss = 0.3870,  smooth loss = 0.4620
[2022-07-07 21:38:09,195 callbacks.py:105 INFO train-abinet] epoch 8 iter 340150: loss = 0.3987,  smooth loss = 0.4496
[2022-07-07 21:38:50,029 callbacks.py:105 INFO train-abinet] epoch 8 iter 340200: loss = 0.4559,  smooth loss = 0.4542
[2022-07-07 21:39:31,158 callbacks.py:105 INFO train-abinet] epoch 8 iter 340250: loss = 0.3623,  smooth loss = 0.4523
[2022-07-07 21:40:11,630 callbacks.py:105 INFO train-abinet] epoch 8 iter 340300: loss = 0.4404,  smooth loss = 0.4560
[2022-07-07 21:40:52,633 callbacks.py:105 INFO train-abinet] epoch 8 iter 340350: loss = 0.4024,  smooth loss = 0.4565
[2022-07-07 21:41:33,465 callbacks.py:105 INFO train-abinet] epoch 8 iter 340400: loss = 0.3637,  smooth loss = 0.4565
[2022-07-07 21:42:13,909 callbacks.py:105 INFO train-abinet] epoch 8 iter 340450: loss = 0.3535,  smooth loss = 0.4622
[2022-07-07 21:42:55,008 callbacks.py:105 INFO train-abinet] epoch 8 iter 340500: loss = 0.5280,  smooth loss = 0.4578
[2022-07-07 21:43:35,642 callbacks.py:105 INFO train-abinet] epoch 8 iter 340550: loss = 0.4881,  smooth loss = 0.4459
[2022-07-07 21:44:16,451 callbacks.py:105 INFO train-abinet] epoch 8 iter 340600: loss = 0.6492,  smooth loss = 0.4626
[2022-07-07 21:44:57,230 callbacks.py:105 INFO train-abinet] epoch 8 iter 340650: loss = 0.4191,  smooth loss = 0.4619
[2022-07-07 21:45:38,645 callbacks.py:105 INFO train-abinet] epoch 8 iter 340700: loss = 0.3816,  smooth loss = 0.4508
[2022-07-07 21:46:19,162 callbacks.py:105 INFO train-abinet] epoch 8 iter 340750: loss = 0.5459,  smooth loss = 0.4686
[2022-07-07 21:47:00,094 callbacks.py:105 INFO train-abinet] epoch 8 iter 340800: loss = 0.3867,  smooth loss = 0.4595
[2022-07-07 21:47:40,431 callbacks.py:105 INFO train-abinet] epoch 8 iter 340850: loss = 0.5227,  smooth loss = 0.4766
[2022-07-07 21:48:20,593 callbacks.py:105 INFO train-abinet] epoch 8 iter 340900: loss = 0.4042,  smooth loss = 0.4698
[2022-07-07 21:49:01,333 callbacks.py:105 INFO train-abinet] epoch 8 iter 340950: loss = 0.4655,  smooth loss = 0.4613
[2022-07-07 21:49:42,126 callbacks.py:105 INFO train-abinet] epoch 8 iter 341000: loss = 0.3951,  smooth loss = 0.4701
[2022-07-07 21:50:23,008 callbacks.py:105 INFO train-abinet] epoch 8 iter 341050: loss = 0.4521,  smooth loss = 0.4682
[2022-07-07 21:51:03,490 callbacks.py:105 INFO train-abinet] epoch 8 iter 341100: loss = 0.4832,  smooth loss = 0.4589
[2022-07-07 21:51:44,121 callbacks.py:105 INFO train-abinet] epoch 8 iter 341150: loss = 0.4371,  smooth loss = 0.4573
[2022-07-07 21:52:24,713 callbacks.py:105 INFO train-abinet] epoch 8 iter 341200: loss = 0.5618,  smooth loss = 0.4540
[2022-07-07 21:53:05,999 callbacks.py:105 INFO train-abinet] epoch 8 iter 341250: loss = 0.3879,  smooth loss = 0.4457
[2022-07-07 21:53:46,939 callbacks.py:105 INFO train-abinet] epoch 8 iter 341300: loss = 0.4716,  smooth loss = 0.4664
[2022-07-07 21:54:27,479 callbacks.py:105 INFO train-abinet] epoch 8 iter 341350: loss = 0.4645,  smooth loss = 0.4587
[2022-07-07 21:55:08,184 callbacks.py:105 INFO train-abinet] epoch 8 iter 341400: loss = 0.3904,  smooth loss = 0.4530
[2022-07-07 21:55:49,403 callbacks.py:105 INFO train-abinet] epoch 8 iter 341450: loss = 0.5003,  smooth loss = 0.4511
[2022-07-07 21:56:30,311 callbacks.py:105 INFO train-abinet] epoch 8 iter 341500: loss = 0.5769,  smooth loss = 0.4583
[2022-07-07 21:57:11,164 callbacks.py:105 INFO train-abinet] epoch 8 iter 341550: loss = 0.5468,  smooth loss = 0.4616
[2022-07-07 21:57:51,770 callbacks.py:105 INFO train-abinet] epoch 8 iter 341600: loss = 0.6196,  smooth loss = 0.4617
[2022-07-07 21:58:32,887 callbacks.py:105 INFO train-abinet] epoch 8 iter 341650: loss = 0.3957,  smooth loss = 0.4554
[2022-07-07 21:59:13,384 callbacks.py:105 INFO train-abinet] epoch 8 iter 341700: loss = 0.3874,  smooth loss = 0.4489
[2022-07-07 21:59:54,099 callbacks.py:105 INFO train-abinet] epoch 8 iter 341750: loss = 0.4248,  smooth loss = 0.4532
[2022-07-07 22:00:35,034 callbacks.py:105 INFO train-abinet] epoch 8 iter 341800: loss = 0.3872,  smooth loss = 0.4632
[2022-07-07 22:01:15,757 callbacks.py:105 INFO train-abinet] epoch 8 iter 341850: loss = 0.5371,  smooth loss = 0.4704
[2022-07-07 22:01:56,704 callbacks.py:105 INFO train-abinet] epoch 8 iter 341900: loss = 0.6532,  smooth loss = 0.4630
[2022-07-07 22:02:37,196 callbacks.py:105 INFO train-abinet] epoch 8 iter 341950: loss = 0.4158,  smooth loss = 0.4562
[2022-07-07 22:03:17,927 callbacks.py:105 INFO train-abinet] epoch 8 iter 342000: loss = 0.5179,  smooth loss = 0.4451
[2022-07-07 22:03:17,928 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8572s
█[2022-07-07 22:03:32,318 callbacks.py:123 INFO train-abinet] epoch 8 iter 342000: eval loss = 1.1594,  ccr = 0.9655,  cwr = 0.9281,  ted = 1140.0000,  ned = 230.3845,  ted/w = 0.1573, 
[2022-07-07 22:03:32,320 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_342000
[2022-07-07 22:04:13,699 callbacks.py:105 INFO train-abinet] epoch 8 iter 342050: loss = 0.5451,  smooth loss = 0.4621
[2022-07-07 22:04:54,388 callbacks.py:105 INFO train-abinet] epoch 8 iter 342100: loss = 0.5434,  smooth loss = 0.4637
[2022-07-07 22:05:35,509 callbacks.py:105 INFO train-abinet] epoch 8 iter 342150: loss = 0.4112,  smooth loss = 0.4521
[2022-07-07 22:06:16,139 callbacks.py:105 INFO train-abinet] epoch 8 iter 342200: loss = 0.4753,  smooth loss = 0.4659
[2022-07-07 22:06:56,715 callbacks.py:105 INFO train-abinet] epoch 8 iter 342250: loss = 0.4221,  smooth loss = 0.4682
[2022-07-07 22:07:37,585 callbacks.py:105 INFO train-abinet] epoch 8 iter 342300: loss = 0.4706,  smooth loss = 0.4626
[2022-07-07 22:08:18,378 callbacks.py:105 INFO train-abinet] epoch 8 iter 342350: loss = 0.4107,  smooth loss = 0.4601
[2022-07-07 22:08:59,290 callbacks.py:105 INFO train-abinet] epoch 8 iter 342400: loss = 0.4347,  smooth loss = 0.4574
[2022-07-07 22:09:40,058 callbacks.py:105 INFO train-abinet] epoch 8 iter 342450: loss = 0.4338,  smooth loss = 0.4380
[2022-07-07 22:10:21,186 callbacks.py:105 INFO train-abinet] epoch 8 iter 342500: loss = 0.3769,  smooth loss = 0.4495
[2022-07-07 22:11:01,868 callbacks.py:105 INFO train-abinet] epoch 8 iter 342550: loss = 0.3954,  smooth loss = 0.4555
[2022-07-07 22:11:42,373 callbacks.py:105 INFO train-abinet] epoch 8 iter 342600: loss = 0.5119,  smooth loss = 0.4577
[2022-07-07 22:12:22,830 callbacks.py:105 INFO train-abinet] epoch 8 iter 342650: loss = 0.5603,  smooth loss = 0.4584
[2022-07-07 22:13:03,452 callbacks.py:105 INFO train-abinet] epoch 8 iter 342700: loss = 0.6116,  smooth loss = 0.4676
[2022-07-07 22:13:44,287 callbacks.py:105 INFO train-abinet] epoch 8 iter 342750: loss = 0.5861,  smooth loss = 0.4696
[2022-07-07 22:14:25,311 callbacks.py:105 INFO train-abinet] epoch 8 iter 342800: loss = 0.4624,  smooth loss = 0.4565
[2022-07-07 22:15:05,839 callbacks.py:105 INFO train-abinet] epoch 8 iter 342850: loss = 0.4045,  smooth loss = 0.4538
[2022-07-07 22:15:46,891 callbacks.py:105 INFO train-abinet] epoch 8 iter 342900: loss = 0.3600,  smooth loss = 0.4620
[2022-07-07 22:16:27,451 callbacks.py:105 INFO train-abinet] epoch 8 iter 342950: loss = 0.4501,  smooth loss = 0.4580
[2022-07-07 22:17:09,246 callbacks.py:105 INFO train-abinet] epoch 8 iter 343000: loss = 0.4699,  smooth loss = 0.4605
[2022-07-07 22:17:50,038 callbacks.py:105 INFO train-abinet] epoch 8 iter 343050: loss = 0.2863,  smooth loss = 0.4488
[2022-07-07 22:18:30,706 callbacks.py:105 INFO train-abinet] epoch 8 iter 343100: loss = 0.5863,  smooth loss = 0.4538
[2022-07-07 22:19:11,682 callbacks.py:105 INFO train-abinet] epoch 8 iter 343150: loss = 0.3927,  smooth loss = 0.4599
[2022-07-07 22:19:52,478 callbacks.py:105 INFO train-abinet] epoch 8 iter 343200: loss = 0.4173,  smooth loss = 0.4556
[2022-07-07 22:20:33,630 callbacks.py:105 INFO train-abinet] epoch 8 iter 343250: loss = 0.4881,  smooth loss = 0.4616
[2022-07-07 22:21:14,072 callbacks.py:105 INFO train-abinet] epoch 8 iter 343300: loss = 0.3216,  smooth loss = 0.4700
[2022-07-07 22:21:54,939 callbacks.py:105 INFO train-abinet] epoch 8 iter 343350: loss = 0.4471,  smooth loss = 0.4762
[2022-07-07 22:22:35,446 callbacks.py:105 INFO train-abinet] epoch 8 iter 343400: loss = 0.4045,  smooth loss = 0.4632
[2022-07-07 22:23:15,883 callbacks.py:105 INFO train-abinet] epoch 8 iter 343450: loss = 0.5403,  smooth loss = 0.4590
[2022-07-07 22:23:56,990 callbacks.py:105 INFO train-abinet] epoch 8 iter 343500: loss = 0.3921,  smooth loss = 0.4518
[2022-07-07 22:24:37,390 callbacks.py:105 INFO train-abinet] epoch 8 iter 343550: loss = 0.5432,  smooth loss = 0.4599
[2022-07-07 22:25:17,877 callbacks.py:105 INFO train-abinet] epoch 8 iter 343600: loss = 0.4732,  smooth loss = 0.4487
[2022-07-07 22:25:58,193 callbacks.py:105 INFO train-abinet] epoch 8 iter 343650: loss = 0.3998,  smooth loss = 0.4557
[2022-07-07 22:26:39,419 callbacks.py:105 INFO train-abinet] epoch 8 iter 343700: loss = 0.6904,  smooth loss = 0.4573
[2022-07-07 22:27:20,258 callbacks.py:105 INFO train-abinet] epoch 8 iter 343750: loss = 0.3564,  smooth loss = 0.4482
[2022-07-07 22:28:01,150 callbacks.py:105 INFO train-abinet] epoch 8 iter 343800: loss = 0.5083,  smooth loss = 0.4593
[2022-07-07 22:28:41,792 callbacks.py:105 INFO train-abinet] epoch 8 iter 343850: loss = 0.5927,  smooth loss = 0.4597
[2022-07-07 22:29:22,933 callbacks.py:105 INFO train-abinet] epoch 8 iter 343900: loss = 0.4192,  smooth loss = 0.4655
[2022-07-07 22:30:03,371 callbacks.py:105 INFO train-abinet] epoch 8 iter 343950: loss = 0.4127,  smooth loss = 0.4555
[2022-07-07 22:30:44,078 callbacks.py:105 INFO train-abinet] epoch 8 iter 344000: loss = 0.6133,  smooth loss = 0.4550
[2022-07-07 22:31:24,906 callbacks.py:105 INFO train-abinet] epoch 8 iter 344050: loss = 0.6476,  smooth loss = 0.4625
[2022-07-07 22:32:06,094 callbacks.py:105 INFO train-abinet] epoch 8 iter 344100: loss = 0.4939,  smooth loss = 0.4618
[2022-07-07 22:32:46,743 callbacks.py:105 INFO train-abinet] epoch 8 iter 344150: loss = 0.3762,  smooth loss = 0.4425
[2022-07-07 22:33:27,584 callbacks.py:105 INFO train-abinet] epoch 8 iter 344200: loss = 0.3838,  smooth loss = 0.4608
[2022-07-07 22:34:08,411 callbacks.py:105 INFO train-abinet] epoch 8 iter 344250: loss = 0.4549,  smooth loss = 0.4495
[2022-07-07 22:34:49,495 callbacks.py:105 INFO train-abinet] epoch 8 iter 344300: loss = 0.5067,  smooth loss = 0.4629
[2022-07-07 22:35:30,447 callbacks.py:105 INFO train-abinet] epoch 8 iter 344350: loss = 0.3327,  smooth loss = 0.4576
[2022-07-07 22:36:11,057 callbacks.py:105 INFO train-abinet] epoch 8 iter 344400: loss = 0.4425,  smooth loss = 0.4671
[2022-07-07 22:36:51,713 callbacks.py:105 INFO train-abinet] epoch 8 iter 344450: loss = 0.4295,  smooth loss = 0.4613
[2022-07-07 22:37:32,723 callbacks.py:105 INFO train-abinet] epoch 8 iter 344500: loss = 0.4537,  smooth loss = 0.4625
[2022-07-07 22:38:13,471 callbacks.py:105 INFO train-abinet] epoch 8 iter 344550: loss = 0.4709,  smooth loss = 0.4537
[2022-07-07 22:38:54,200 callbacks.py:105 INFO train-abinet] epoch 8 iter 344600: loss = 0.4279,  smooth loss = 0.4673
[2022-07-07 22:39:34,807 callbacks.py:105 INFO train-abinet] epoch 8 iter 344650: loss = 0.3085,  smooth loss = 0.4554
[2022-07-07 22:40:15,789 callbacks.py:105 INFO train-abinet] epoch 8 iter 344700: loss = 0.5285,  smooth loss = 0.4470
[2022-07-07 22:40:56,661 callbacks.py:105 INFO train-abinet] epoch 8 iter 344750: loss = 0.4194,  smooth loss = 0.4554
[2022-07-07 22:41:37,324 callbacks.py:105 INFO train-abinet] epoch 8 iter 344800: loss = 0.4321,  smooth loss = 0.4639
[2022-07-07 22:42:17,927 callbacks.py:105 INFO train-abinet] epoch 8 iter 344850: loss = 0.4105,  smooth loss = 0.4581
[2022-07-07 22:42:58,471 callbacks.py:105 INFO train-abinet] epoch 8 iter 344900: loss = 0.3170,  smooth loss = 0.4631
[2022-07-07 22:43:39,224 callbacks.py:105 INFO train-abinet] epoch 8 iter 344950: loss = 0.4939,  smooth loss = 0.4474
[2022-07-07 22:44:20,261 callbacks.py:105 INFO train-abinet] epoch 8 iter 345000: loss = 0.3491,  smooth loss = 0.4626
[2022-07-07 22:44:20,262 callbacks.py:114 INFO train-abinet] average data time = 0.0046s, average running time = 0.8569s
█[2022-07-07 22:44:34,040 callbacks.py:123 INFO train-abinet] epoch 8 iter 345000: eval loss = 1.1664,  ccr = 0.9645,  cwr = 0.9269,  ted = 1143.0000,  ned = 229.9011,  ted/w = 0.1577, 
[2022-07-07 22:44:34,042 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_345000
[2022-07-07 22:45:15,229 callbacks.py:105 INFO train-abinet] epoch 8 iter 345050: loss = 0.5855,  smooth loss = 0.4632
[2022-07-07 22:45:56,097 callbacks.py:105 INFO train-abinet] epoch 8 iter 345100: loss = 0.4855,  smooth loss = 0.4639
[2022-07-07 22:46:36,636 callbacks.py:105 INFO train-abinet] epoch 8 iter 345150: loss = 0.4832,  smooth loss = 0.4444
[2022-07-07 22:47:17,111 callbacks.py:105 INFO train-abinet] epoch 8 iter 345200: loss = 0.3981,  smooth loss = 0.4497
[2022-07-07 22:47:58,398 callbacks.py:105 INFO train-abinet] epoch 8 iter 345250: loss = 0.5181,  smooth loss = 0.4548
[2022-07-07 22:48:39,182 callbacks.py:105 INFO train-abinet] epoch 8 iter 345300: loss = 0.4634,  smooth loss = 0.4482
[2022-07-07 22:49:20,406 callbacks.py:105 INFO train-abinet] epoch 8 iter 345350: loss = 0.3266,  smooth loss = 0.4430
[2022-07-07 22:50:01,228 callbacks.py:105 INFO train-abinet] epoch 8 iter 345400: loss = 0.3901,  smooth loss = 0.4388
[2022-07-07 22:50:41,779 callbacks.py:105 INFO train-abinet] epoch 8 iter 345450: loss = 0.4003,  smooth loss = 0.4434
[2022-07-07 22:51:22,548 callbacks.py:105 INFO train-abinet] epoch 8 iter 345500: loss = 0.4318,  smooth loss = 0.4562
[2022-07-07 22:52:03,575 callbacks.py:105 INFO train-abinet] epoch 8 iter 345550: loss = 0.5071,  smooth loss = 0.4517
[2022-07-07 22:52:44,275 callbacks.py:105 INFO train-abinet] epoch 8 iter 345600: loss = 0.3954,  smooth loss = 0.4630
[2022-07-07 22:53:25,181 callbacks.py:105 INFO train-abinet] epoch 8 iter 345650: loss = 0.4726,  smooth loss = 0.4610
[2022-07-07 22:54:05,638 callbacks.py:105 INFO train-abinet] epoch 8 iter 345700: loss = 0.3621,  smooth loss = 0.4613
[2022-07-07 22:54:46,382 callbacks.py:105 INFO train-abinet] epoch 8 iter 345750: loss = 0.4699,  smooth loss = 0.4498
[2022-07-07 22:55:27,655 callbacks.py:105 INFO train-abinet] epoch 8 iter 345800: loss = 0.3892,  smooth loss = 0.4504
[2022-07-07 22:56:08,250 callbacks.py:105 INFO train-abinet] epoch 8 iter 345850: loss = 0.5116,  smooth loss = 0.4616
[2022-07-07 22:56:49,181 callbacks.py:105 INFO train-abinet] epoch 8 iter 345900: loss = 0.5091,  smooth loss = 0.4683
[2022-07-07 22:57:29,739 callbacks.py:105 INFO train-abinet] epoch 8 iter 345950: loss = 0.3216,  smooth loss = 0.4600
[2022-07-07 22:58:10,132 callbacks.py:105 INFO train-abinet] epoch 8 iter 346000: loss = 0.4526,  smooth loss = 0.4493
[2022-07-07 22:58:51,080 callbacks.py:105 INFO train-abinet] epoch 8 iter 346050: loss = 0.3274,  smooth loss = 0.4527
[2022-07-07 22:59:31,926 callbacks.py:105 INFO train-abinet] epoch 8 iter 346100: loss = 0.4230,  smooth loss = 0.4620
[2022-07-07 23:00:12,379 callbacks.py:105 INFO train-abinet] epoch 8 iter 346150: loss = 0.4242,  smooth loss = 0.4544
[2022-07-07 23:00:53,275 callbacks.py:105 INFO train-abinet] epoch 8 iter 346200: loss = 0.4353,  smooth loss = 0.4533
[2022-07-07 23:01:33,741 callbacks.py:105 INFO train-abinet] epoch 8 iter 346250: loss = 0.4378,  smooth loss = 0.4614
[2022-07-07 23:02:14,811 callbacks.py:105 INFO train-abinet] epoch 8 iter 346300: loss = 0.4366,  smooth loss = 0.4504
[2022-07-07 23:02:55,427 callbacks.py:105 INFO train-abinet] epoch 8 iter 346350: loss = 0.3966,  smooth loss = 0.4558
[2022-07-07 23:03:36,091 callbacks.py:105 INFO train-abinet] epoch 8 iter 346400: loss = 0.5098,  smooth loss = 0.4681
[2022-07-07 23:04:16,450 callbacks.py:105 INFO train-abinet] epoch 8 iter 346450: loss = 0.5145,  smooth loss = 0.4739
[2022-07-07 23:04:57,202 callbacks.py:105 INFO train-abinet] epoch 8 iter 346500: loss = 0.4031,  smooth loss = 0.4644
[2022-07-07 23:05:37,822 callbacks.py:105 INFO train-abinet] epoch 8 iter 346550: loss = 0.5031,  smooth loss = 0.4675
[2022-07-07 23:06:18,828 callbacks.py:105 INFO train-abinet] epoch 8 iter 346600: loss = 0.4838,  smooth loss = 0.4672
[2022-07-07 23:06:59,672 callbacks.py:105 INFO train-abinet] epoch 8 iter 346650: loss = 0.4447,  smooth loss = 0.4520
[2022-07-07 23:07:40,275 callbacks.py:105 INFO train-abinet] epoch 8 iter 346700: loss = 0.4962,  smooth loss = 0.4534
[2022-07-07 23:08:21,167 callbacks.py:105 INFO train-abinet] epoch 8 iter 346750: loss = 0.4106,  smooth loss = 0.4584
[2022-07-07 23:09:02,351 callbacks.py:105 INFO train-abinet] epoch 8 iter 346800: loss = 0.5605,  smooth loss = 0.4624
[2022-07-07 23:09:42,895 callbacks.py:105 INFO train-abinet] epoch 8 iter 346850: loss = 0.4163,  smooth loss = 0.4677
[2022-07-07 23:10:23,490 callbacks.py:105 INFO train-abinet] epoch 8 iter 346900: loss = 0.3978,  smooth loss = 0.4599
[2022-07-07 23:11:04,043 callbacks.py:105 INFO train-abinet] epoch 8 iter 346950: loss = 0.4211,  smooth loss = 0.4656
[2022-07-07 23:11:44,458 callbacks.py:105 INFO train-abinet] epoch 8 iter 347000: loss = 0.3509,  smooth loss = 0.4712
[2022-07-07 23:12:25,429 callbacks.py:105 INFO train-abinet] epoch 8 iter 347050: loss = 0.5041,  smooth loss = 0.4684
[2022-07-07 23:13:06,217 callbacks.py:105 INFO train-abinet] epoch 8 iter 347100: loss = 0.4200,  smooth loss = 0.4531
[2022-07-07 23:13:46,789 callbacks.py:105 INFO train-abinet] epoch 8 iter 347150: loss = 0.4451,  smooth loss = 0.4599
[2022-07-07 23:14:27,453 callbacks.py:105 INFO train-abinet] epoch 8 iter 347200: loss = 0.3981,  smooth loss = 0.4579
[2022-07-07 23:15:08,273 callbacks.py:105 INFO train-abinet] epoch 8 iter 347250: loss = 0.4059,  smooth loss = 0.4561
[2022-07-07 23:15:49,649 callbacks.py:105 INFO train-abinet] epoch 8 iter 347300: loss = 0.4728,  smooth loss = 0.4512
[2022-07-07 23:16:30,114 callbacks.py:105 INFO train-abinet] epoch 8 iter 347350: loss = 0.4615,  smooth loss = 0.4544
[2022-07-07 23:17:10,337 callbacks.py:105 INFO train-abinet] epoch 8 iter 347400: loss = 0.4402,  smooth loss = 0.4409
[2022-07-07 23:17:50,986 callbacks.py:105 INFO train-abinet] epoch 8 iter 347450: loss = 0.3709,  smooth loss = 0.4541
[2022-07-07 23:18:32,316 callbacks.py:105 INFO train-abinet] epoch 8 iter 347500: loss = 0.3823,  smooth loss = 0.4493
[2022-07-07 23:19:12,973 callbacks.py:105 INFO train-abinet] epoch 8 iter 347550: loss = 0.4401,  smooth loss = 0.4597
[2022-07-07 23:19:53,982 callbacks.py:105 INFO train-abinet] epoch 8 iter 347600: loss = 0.5624,  smooth loss = 0.4751
[2022-07-07 23:20:34,849 callbacks.py:105 INFO train-abinet] epoch 8 iter 347650: loss = 0.5929,  smooth loss = 0.4578
[2022-07-07 23:21:15,900 callbacks.py:105 INFO train-abinet] epoch 8 iter 347700: loss = 0.5516,  smooth loss = 0.4513
[2022-07-07 23:21:57,202 callbacks.py:105 INFO train-abinet] epoch 8 iter 347750: loss = 0.4724,  smooth loss = 0.4577
[2022-07-07 23:22:38,148 callbacks.py:105 INFO train-abinet] epoch 8 iter 347800: loss = 0.4072,  smooth loss = 0.4544
[2022-07-07 23:23:19,108 callbacks.py:105 INFO train-abinet] epoch 8 iter 347850: loss = 0.4370,  smooth loss = 0.4466
[2022-07-07 23:24:00,613 callbacks.py:105 INFO train-abinet] epoch 8 iter 347900: loss = 0.4566,  smooth loss = 0.4681
[2022-07-07 23:24:41,678 callbacks.py:105 INFO train-abinet] epoch 8 iter 347950: loss = 0.3796,  smooth loss = 0.4568
[2022-07-07 23:25:23,234 callbacks.py:105 INFO train-abinet] epoch 8 iter 348000: loss = 0.5228,  smooth loss = 0.4511
[2022-07-07 23:25:23,235 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8566s
█[2022-07-07 23:25:37,094 callbacks.py:123 INFO train-abinet] epoch 8 iter 348000: eval loss = 1.1671,  ccr = 0.9653,  cwr = 0.9266,  ted = 1155.0000,  ned = 234.9266,  ted/w = 0.1594, 
[2022-07-07 23:25:37,098 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_348000
[2022-07-07 23:26:19,014 callbacks.py:105 INFO train-abinet] epoch 8 iter 348050: loss = 0.3960,  smooth loss = 0.4514
[2022-07-07 23:27:00,526 callbacks.py:105 INFO train-abinet] epoch 8 iter 348100: loss = 0.4417,  smooth loss = 0.4481
[2022-07-07 23:27:41,548 callbacks.py:105 INFO train-abinet] epoch 8 iter 348150: loss = 0.4328,  smooth loss = 0.4566
[2022-07-07 23:28:22,474 callbacks.py:105 INFO train-abinet] epoch 8 iter 348200: loss = 0.4072,  smooth loss = 0.4602
[2022-07-07 23:29:03,978 callbacks.py:105 INFO train-abinet] epoch 8 iter 348250: loss = 0.3875,  smooth loss = 0.4568
[2022-07-07 23:29:45,204 callbacks.py:105 INFO train-abinet] epoch 8 iter 348300: loss = 0.3559,  smooth loss = 0.4557
[2022-07-07 23:30:26,069 callbacks.py:105 INFO train-abinet] epoch 8 iter 348350: loss = 0.5410,  smooth loss = 0.4585
[2022-07-07 23:31:06,798 callbacks.py:105 INFO train-abinet] epoch 8 iter 348400: loss = 0.5080,  smooth loss = 0.4570
[2022-07-07 23:31:48,305 callbacks.py:105 INFO train-abinet] epoch 8 iter 348450: loss = 0.5483,  smooth loss = 0.4566
[2022-07-07 23:32:29,187 callbacks.py:105 INFO train-abinet] epoch 8 iter 348500: loss = 0.3888,  smooth loss = 0.4612
[2022-07-07 23:33:10,095 callbacks.py:105 INFO train-abinet] epoch 8 iter 348550: loss = 0.4430,  smooth loss = 0.4570
[2022-07-07 23:33:51,819 callbacks.py:105 INFO train-abinet] epoch 8 iter 348600: loss = 0.4001,  smooth loss = 0.4534
[2022-07-07 23:34:32,887 callbacks.py:105 INFO train-abinet] epoch 8 iter 348650: loss = 0.4590,  smooth loss = 0.4602
[2022-07-07 23:35:14,232 callbacks.py:105 INFO train-abinet] epoch 8 iter 348700: loss = 0.3733,  smooth loss = 0.4549
[2022-07-07 23:35:55,715 callbacks.py:105 INFO train-abinet] epoch 8 iter 348750: loss = 0.4641,  smooth loss = 0.4661
[2022-07-07 23:36:36,989 callbacks.py:105 INFO train-abinet] epoch 8 iter 348800: loss = 0.3992,  smooth loss = 0.4516
[2022-07-07 23:37:18,447 callbacks.py:105 INFO train-abinet] epoch 8 iter 348850: loss = 0.4745,  smooth loss = 0.4562
[2022-07-07 23:37:59,520 callbacks.py:105 INFO train-abinet] epoch 8 iter 348900: loss = 0.3766,  smooth loss = 0.4534
[2022-07-07 23:38:40,472 callbacks.py:105 INFO train-abinet] epoch 8 iter 348950: loss = 0.5403,  smooth loss = 0.4724
[2022-07-07 23:39:21,096 callbacks.py:105 INFO train-abinet] epoch 8 iter 349000: loss = 0.3360,  smooth loss = 0.4603
[2022-07-07 23:40:02,347 callbacks.py:105 INFO train-abinet] epoch 8 iter 349050: loss = 0.4182,  smooth loss = 0.4626
[2022-07-07 23:40:43,130 callbacks.py:105 INFO train-abinet] epoch 8 iter 349100: loss = 0.4250,  smooth loss = 0.4502
[2022-07-07 23:41:24,512 callbacks.py:105 INFO train-abinet] epoch 8 iter 349150: loss = 0.3791,  smooth loss = 0.4588
[2022-07-07 23:42:05,311 callbacks.py:105 INFO train-abinet] epoch 8 iter 349200: loss = 0.4700,  smooth loss = 0.4488
[2022-07-07 23:42:46,137 callbacks.py:105 INFO train-abinet] epoch 8 iter 349250: loss = 0.4335,  smooth loss = 0.4627
[2022-07-07 23:43:26,740 callbacks.py:105 INFO train-abinet] epoch 8 iter 349300: loss = 0.4678,  smooth loss = 0.4485
[2022-07-07 23:44:08,512 callbacks.py:105 INFO train-abinet] epoch 8 iter 349350: loss = 0.4595,  smooth loss = 0.4529
[2022-07-07 23:44:49,652 callbacks.py:105 INFO train-abinet] epoch 8 iter 349400: loss = 0.5568,  smooth loss = 0.4437
[2022-07-07 23:45:30,607 callbacks.py:105 INFO train-abinet] epoch 8 iter 349450: loss = 0.5558,  smooth loss = 0.4477
[2022-07-07 23:46:11,933 callbacks.py:105 INFO train-abinet] epoch 8 iter 349500: loss = 0.4700,  smooth loss = 0.4559
[2022-07-07 23:46:52,602 callbacks.py:105 INFO train-abinet] epoch 8 iter 349550: loss = 0.5116,  smooth loss = 0.4568
[2022-07-07 23:47:33,564 callbacks.py:105 INFO train-abinet] epoch 8 iter 349600: loss = 0.4211,  smooth loss = 0.4489
[2022-07-07 23:48:14,461 callbacks.py:105 INFO train-abinet] epoch 8 iter 349650: loss = 0.4744,  smooth loss = 0.4647
[2022-07-07 23:48:55,764 callbacks.py:105 INFO train-abinet] epoch 8 iter 349700: loss = 0.4401,  smooth loss = 0.4625
[2022-07-07 23:49:37,446 callbacks.py:105 INFO train-abinet] epoch 8 iter 349750: loss = 0.3634,  smooth loss = 0.4622
[2022-07-07 23:50:18,164 callbacks.py:105 INFO train-abinet] epoch 8 iter 349800: loss = 0.3907,  smooth loss = 0.4675
[2022-07-07 23:50:59,710 callbacks.py:105 INFO train-abinet] epoch 8 iter 349850: loss = 0.4246,  smooth loss = 0.4591
[2022-07-07 23:51:40,720 callbacks.py:105 INFO train-abinet] epoch 8 iter 349900: loss = 0.5726,  smooth loss = 0.4618
[2022-07-07 23:52:21,722 callbacks.py:105 INFO train-abinet] epoch 8 iter 349950: loss = 0.5844,  smooth loss = 0.4598
[2022-07-07 23:53:02,492 callbacks.py:105 INFO train-abinet] epoch 8 iter 350000: loss = 0.4376,  smooth loss = 0.4589
[2022-07-07 23:53:43,675 callbacks.py:105 INFO train-abinet] epoch 8 iter 350050: loss = 0.3502,  smooth loss = 0.4513
[2022-07-07 23:54:24,723 callbacks.py:105 INFO train-abinet] epoch 8 iter 350100: loss = 0.3848,  smooth loss = 0.4553
[2022-07-07 23:55:05,390 callbacks.py:105 INFO train-abinet] epoch 8 iter 350150: loss = 0.5296,  smooth loss = 0.4679
[2022-07-07 23:55:46,701 callbacks.py:105 INFO train-abinet] epoch 8 iter 350200: loss = 0.3830,  smooth loss = 0.4624
[2022-07-07 23:56:27,398 callbacks.py:105 INFO train-abinet] epoch 8 iter 350250: loss = 0.6034,  smooth loss = 0.4601
[2022-07-07 23:57:08,063 callbacks.py:105 INFO train-abinet] epoch 8 iter 350300: loss = 0.5031,  smooth loss = 0.4633
[2022-07-07 23:57:49,407 callbacks.py:105 INFO train-abinet] epoch 8 iter 350350: loss = 0.7042,  smooth loss = 0.4522
[2022-07-07 23:58:30,233 callbacks.py:105 INFO train-abinet] epoch 8 iter 350400: loss = 0.3391,  smooth loss = 0.4640
[2022-07-07 23:59:10,962 callbacks.py:105 INFO train-abinet] epoch 8 iter 350450: loss = 0.4957,  smooth loss = 0.4529
[2022-07-07 23:59:52,263 callbacks.py:105 INFO train-abinet] epoch 8 iter 350500: loss = 0.4434,  smooth loss = 0.4477
[2022-07-08 00:00:33,208 callbacks.py:105 INFO train-abinet] epoch 8 iter 350550: loss = 0.3856,  smooth loss = 0.4574
[2022-07-08 00:01:13,775 callbacks.py:105 INFO train-abinet] epoch 8 iter 350600: loss = 0.5318,  smooth loss = 0.4639
[2022-07-08 00:01:54,824 callbacks.py:105 INFO train-abinet] epoch 8 iter 350650: loss = 0.3508,  smooth loss = 0.4656
[2022-07-08 00:02:35,395 callbacks.py:105 INFO train-abinet] epoch 8 iter 350700: loss = 0.4042,  smooth loss = 0.4588
[2022-07-08 00:03:15,787 callbacks.py:105 INFO train-abinet] epoch 8 iter 350750: loss = 0.3756,  smooth loss = 0.4548
[2022-07-08 00:03:57,134 callbacks.py:105 INFO train-abinet] epoch 8 iter 350800: loss = 0.3984,  smooth loss = 0.4514
[2022-07-08 00:04:37,868 callbacks.py:105 INFO train-abinet] epoch 8 iter 350850: loss = 0.4942,  smooth loss = 0.4560
[2022-07-08 00:05:18,779 callbacks.py:105 INFO train-abinet] epoch 8 iter 350900: loss = 0.5165,  smooth loss = 0.4631
[2022-07-08 00:06:00,282 callbacks.py:105 INFO train-abinet] epoch 8 iter 350950: loss = 0.4462,  smooth loss = 0.4480
[2022-07-08 00:06:41,097 callbacks.py:105 INFO train-abinet] epoch 8 iter 351000: loss = 0.3666,  smooth loss = 0.4622
[2022-07-08 00:06:41,098 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8563s
█[2022-07-08 00:06:54,873 callbacks.py:123 INFO train-abinet] epoch 8 iter 351000: eval loss = 1.1603,  ccr = 0.9651,  cwr = 0.9266,  ted = 1165.0000,  ned = 236.2239,  ted/w = 0.1607, 
[2022-07-08 00:06:54,875 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_351000
[2022-07-08 00:07:37,225 callbacks.py:105 INFO train-abinet] epoch 8 iter 351050: loss = 0.3817,  smooth loss = 0.4525
[2022-07-08 00:08:17,984 callbacks.py:105 INFO train-abinet] epoch 8 iter 351100: loss = 0.3975,  smooth loss = 0.4446
[2022-07-08 00:08:58,947 callbacks.py:105 INFO train-abinet] epoch 8 iter 351150: loss = 0.4016,  smooth loss = 0.4694
[2022-07-08 00:09:40,073 callbacks.py:105 INFO train-abinet] epoch 8 iter 351200: loss = 0.2848,  smooth loss = 0.4536
[2022-07-08 00:10:21,572 callbacks.py:105 INFO train-abinet] epoch 8 iter 351250: loss = 0.5623,  smooth loss = 0.4633
[2022-07-08 00:11:03,046 callbacks.py:105 INFO train-abinet] epoch 8 iter 351300: loss = 0.5351,  smooth loss = 0.4697
[2022-07-08 00:11:43,894 callbacks.py:105 INFO train-abinet] epoch 8 iter 351350: loss = 0.4822,  smooth loss = 0.4527
[2022-07-08 00:12:24,530 callbacks.py:105 INFO train-abinet] epoch 8 iter 351400: loss = 0.5194,  smooth loss = 0.4621
[2022-07-08 00:13:05,159 callbacks.py:105 INFO train-abinet] epoch 8 iter 351450: loss = 0.3478,  smooth loss = 0.4508
[2022-07-08 00:13:46,581 callbacks.py:105 INFO train-abinet] epoch 8 iter 351500: loss = 0.5395,  smooth loss = 0.4679
[2022-07-08 00:14:27,272 callbacks.py:105 INFO train-abinet] epoch 8 iter 351550: loss = 0.4587,  smooth loss = 0.4636
[2022-07-08 00:15:08,429 callbacks.py:105 INFO train-abinet] epoch 8 iter 351600: loss = 0.5351,  smooth loss = 0.4652
[2022-07-08 00:15:49,297 callbacks.py:105 INFO train-abinet] epoch 8 iter 351650: loss = 0.4543,  smooth loss = 0.4561
[2022-07-08 00:16:30,998 callbacks.py:105 INFO train-abinet] epoch 8 iter 351700: loss = 0.4141,  smooth loss = 0.4626
[2022-07-08 00:17:11,594 callbacks.py:105 INFO train-abinet] epoch 8 iter 351750: loss = 0.4670,  smooth loss = 0.4575
[2022-07-08 00:17:52,173 callbacks.py:105 INFO train-abinet] epoch 8 iter 351800: loss = 0.5501,  smooth loss = 0.4627
[2022-07-08 00:18:32,784 callbacks.py:105 INFO train-abinet] epoch 8 iter 351850: loss = 0.4171,  smooth loss = 0.4502
[2022-07-08 00:19:13,275 callbacks.py:105 INFO train-abinet] epoch 8 iter 351900: loss = 0.5231,  smooth loss = 0.4663
[2022-07-08 00:19:54,803 callbacks.py:105 INFO train-abinet] epoch 8 iter 351950: loss = 0.4240,  smooth loss = 0.4522
[2022-07-08 00:20:35,804 callbacks.py:105 INFO train-abinet] epoch 8 iter 352000: loss = 0.4448,  smooth loss = 0.4609
[2022-07-08 00:21:16,325 callbacks.py:105 INFO train-abinet] epoch 8 iter 352050: loss = 0.3646,  smooth loss = 0.4679
[2022-07-08 00:21:57,410 callbacks.py:105 INFO train-abinet] epoch 8 iter 352100: loss = 0.5730,  smooth loss = 0.4669
[2022-07-08 00:22:38,079 callbacks.py:105 INFO train-abinet] epoch 8 iter 352150: loss = 0.4644,  smooth loss = 0.4661
[2022-07-08 00:23:18,760 callbacks.py:105 INFO train-abinet] epoch 8 iter 352200: loss = 0.3391,  smooth loss = 0.4486
[2022-07-08 00:23:59,508 callbacks.py:105 INFO train-abinet] epoch 8 iter 352250: loss = 0.5340,  smooth loss = 0.4576
[2022-07-08 00:24:40,824 callbacks.py:105 INFO train-abinet] epoch 8 iter 352300: loss = 0.5437,  smooth loss = 0.4591
[2022-07-08 00:25:21,462 callbacks.py:105 INFO train-abinet] epoch 8 iter 352350: loss = 0.4815,  smooth loss = 0.4590
[2022-07-08 00:26:02,292 callbacks.py:105 INFO train-abinet] epoch 8 iter 352400: loss = 0.4303,  smooth loss = 0.4540
[2022-07-08 00:26:43,109 callbacks.py:105 INFO train-abinet] epoch 8 iter 352450: loss = 0.4598,  smooth loss = 0.4601
[2022-07-08 00:27:24,777 callbacks.py:105 INFO train-abinet] epoch 8 iter 352500: loss = 0.3334,  smooth loss = 0.4609
[2022-07-08 00:28:05,848 callbacks.py:105 INFO train-abinet] epoch 8 iter 352550: loss = 0.3635,  smooth loss = 0.4525
[2022-07-08 00:28:46,544 callbacks.py:105 INFO train-abinet] epoch 8 iter 352600: loss = 0.5132,  smooth loss = 0.4452
[2022-07-08 00:29:27,391 callbacks.py:105 INFO train-abinet] epoch 8 iter 352650: loss = 0.4776,  smooth loss = 0.4554
[2022-07-08 00:30:08,766 callbacks.py:105 INFO train-abinet] epoch 8 iter 352700: loss = 0.4599,  smooth loss = 0.4696
[2022-07-08 00:30:49,281 callbacks.py:105 INFO train-abinet] epoch 8 iter 352750: loss = 0.4798,  smooth loss = 0.4539
[2022-07-08 00:31:29,711 callbacks.py:105 INFO train-abinet] epoch 8 iter 352800: loss = 0.5104,  smooth loss = 0.4544
[2022-07-08 00:32:09,930 callbacks.py:105 INFO train-abinet] epoch 8 iter 352850: loss = 0.4441,  smooth loss = 0.4581
[2022-07-08 00:32:50,202 callbacks.py:105 INFO train-abinet] epoch 8 iter 352900: loss = 0.4391,  smooth loss = 0.4550
[2022-07-08 00:33:31,113 callbacks.py:105 INFO train-abinet] epoch 8 iter 352950: loss = 0.3499,  smooth loss = 0.4456
[2022-07-08 00:34:11,708 callbacks.py:105 INFO train-abinet] epoch 8 iter 353000: loss = 0.5958,  smooth loss = 0.4414
[2022-07-08 00:34:52,119 callbacks.py:105 INFO train-abinet] epoch 8 iter 353050: loss = 0.4640,  smooth loss = 0.4354
[2022-07-08 00:35:33,406 callbacks.py:105 INFO train-abinet] epoch 8 iter 353100: loss = 0.6021,  smooth loss = 0.4486
[2022-07-08 00:36:14,506 callbacks.py:105 INFO train-abinet] epoch 8 iter 353150: loss = 0.3574,  smooth loss = 0.4479
[2022-07-08 00:36:54,919 callbacks.py:105 INFO train-abinet] epoch 8 iter 353200: loss = 0.4331,  smooth loss = 0.4606
[2022-07-08 00:37:35,865 callbacks.py:105 INFO train-abinet] epoch 8 iter 353250: loss = 0.4169,  smooth loss = 0.4717
[2022-07-08 00:38:17,435 callbacks.py:105 INFO train-abinet] epoch 8 iter 353300: loss = 0.5223,  smooth loss = 0.4672
[2022-07-08 00:38:58,360 callbacks.py:105 INFO train-abinet] epoch 8 iter 353350: loss = 0.5747,  smooth loss = 0.4680
[2022-07-08 00:39:39,247 callbacks.py:105 INFO train-abinet] epoch 8 iter 353400: loss = 0.4400,  smooth loss = 0.4724
[2022-07-08 00:40:19,878 callbacks.py:105 INFO train-abinet] epoch 8 iter 353450: loss = 0.4093,  smooth loss = 0.4600
[2022-07-08 00:41:01,116 callbacks.py:105 INFO train-abinet] epoch 8 iter 353500: loss = 0.5374,  smooth loss = 0.4544
[2022-07-08 00:41:41,528 callbacks.py:105 INFO train-abinet] epoch 8 iter 353550: loss = 0.5063,  smooth loss = 0.4632
[2022-07-08 00:42:22,519 callbacks.py:105 INFO train-abinet] epoch 8 iter 353600: loss = 0.5759,  smooth loss = 0.4633
[2022-07-08 00:43:03,590 callbacks.py:105 INFO train-abinet] epoch 8 iter 353650: loss = 0.4874,  smooth loss = 0.4576
[2022-07-08 00:43:45,227 callbacks.py:105 INFO train-abinet] epoch 8 iter 353700: loss = 0.4188,  smooth loss = 0.4597
[2022-07-08 00:44:26,024 callbacks.py:105 INFO train-abinet] epoch 8 iter 353750: loss = 0.5439,  smooth loss = 0.4554
[2022-07-08 00:45:06,979 callbacks.py:105 INFO train-abinet] epoch 8 iter 353800: loss = 0.4820,  smooth loss = 0.4544
[2022-07-08 00:45:48,118 callbacks.py:105 INFO train-abinet] epoch 8 iter 353850: loss = 0.3576,  smooth loss = 0.4509
[2022-07-08 00:46:29,744 callbacks.py:105 INFO train-abinet] epoch 8 iter 353900: loss = 0.6476,  smooth loss = 0.4589
[2022-07-08 00:47:10,838 callbacks.py:105 INFO train-abinet] epoch 8 iter 353950: loss = 0.4841,  smooth loss = 0.4574
[2022-07-08 00:47:51,603 callbacks.py:105 INFO train-abinet] epoch 8 iter 354000: loss = 0.4487,  smooth loss = 0.4514
[2022-07-08 00:47:51,604 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8560s
█[2022-07-08 00:48:05,776 callbacks.py:123 INFO train-abinet] epoch 8 iter 354000: eval loss = 1.1791,  ccr = 0.9649,  cwr = 0.9276,  ted = 1136.0000,  ned = 230.4874,  ted/w = 0.1567, 
[2022-07-08 00:48:05,777 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_354000
[2022-07-08 00:48:47,654 callbacks.py:105 INFO train-abinet] epoch 8 iter 354050: loss = 0.4012,  smooth loss = 0.4405
[2022-07-08 00:49:28,488 callbacks.py:105 INFO train-abinet] epoch 8 iter 354100: loss = 0.4091,  smooth loss = 0.4569
[2022-07-08 00:50:09,218 callbacks.py:105 INFO train-abinet] epoch 8 iter 354150: loss = 0.5189,  smooth loss = 0.4481
[2022-07-08 00:50:50,112 callbacks.py:105 INFO train-abinet] epoch 8 iter 354200: loss = 0.4605,  smooth loss = 0.4598
[2022-07-08 00:51:30,742 callbacks.py:105 INFO train-abinet] epoch 8 iter 354250: loss = 0.5246,  smooth loss = 0.4583
[2022-07-08 00:52:11,646 callbacks.py:105 INFO train-abinet] epoch 8 iter 354300: loss = 0.4495,  smooth loss = 0.4635
[2022-07-08 00:52:52,249 callbacks.py:105 INFO train-abinet] epoch 8 iter 354350: loss = 0.3535,  smooth loss = 0.4607
[2022-07-08 00:53:32,719 callbacks.py:105 INFO train-abinet] epoch 8 iter 354400: loss = 0.3936,  smooth loss = 0.4492
[2022-07-08 00:54:13,163 callbacks.py:105 INFO train-abinet] epoch 8 iter 354450: loss = 0.5847,  smooth loss = 0.4597
[2022-07-08 00:54:54,519 callbacks.py:105 INFO train-abinet] epoch 8 iter 354500: loss = 0.3681,  smooth loss = 0.4551
[2022-07-08 00:55:35,214 callbacks.py:105 INFO train-abinet] epoch 8 iter 354550: loss = 0.3214,  smooth loss = 0.4573
[2022-07-08 00:56:16,153 callbacks.py:105 INFO train-abinet] epoch 8 iter 354600: loss = 0.3880,  smooth loss = 0.4522
[2022-07-08 00:56:57,082 callbacks.py:105 INFO train-abinet] epoch 8 iter 354650: loss = 0.5678,  smooth loss = 0.4567
[2022-07-08 00:57:38,365 callbacks.py:105 INFO train-abinet] epoch 8 iter 354700: loss = 0.4087,  smooth loss = 0.4629
[2022-07-08 00:58:18,917 callbacks.py:105 INFO train-abinet] epoch 8 iter 354750: loss = 0.4819,  smooth loss = 0.4629
[2022-07-08 00:58:59,680 callbacks.py:105 INFO train-abinet] epoch 8 iter 354800: loss = 0.3910,  smooth loss = 0.4742
[2022-07-08 00:59:40,253 callbacks.py:105 INFO train-abinet] epoch 8 iter 354850: loss = 0.3675,  smooth loss = 0.4607
[2022-07-08 01:00:20,933 callbacks.py:105 INFO train-abinet] epoch 8 iter 354900: loss = 0.3677,  smooth loss = 0.4540
[2022-07-08 01:01:01,428 callbacks.py:105 INFO train-abinet] epoch 8 iter 354950: loss = 0.5749,  smooth loss = 0.4693
[2022-07-08 01:01:42,468 callbacks.py:105 INFO train-abinet] epoch 8 iter 355000: loss = 0.4874,  smooth loss = 0.4677
[2022-07-08 01:02:23,421 callbacks.py:105 INFO train-abinet] epoch 8 iter 355050: loss = 0.4586,  smooth loss = 0.4599
[2022-07-08 01:03:04,072 callbacks.py:105 INFO train-abinet] epoch 8 iter 355100: loss = 0.5471,  smooth loss = 0.4611
[2022-07-08 01:03:44,844 callbacks.py:105 INFO train-abinet] epoch 8 iter 355150: loss = 0.4179,  smooth loss = 0.4572
[2022-07-08 01:04:26,037 callbacks.py:105 INFO train-abinet] epoch 8 iter 355200: loss = 0.3985,  smooth loss = 0.4573
[2022-07-08 01:05:06,728 callbacks.py:105 INFO train-abinet] epoch 8 iter 355250: loss = 0.4669,  smooth loss = 0.4508
[2022-07-08 01:05:47,176 callbacks.py:105 INFO train-abinet] epoch 8 iter 355300: loss = 0.4490,  smooth loss = 0.4578
[2022-07-08 01:06:27,720 callbacks.py:105 INFO train-abinet] epoch 8 iter 355350: loss = 0.6055,  smooth loss = 0.4665
[2022-07-08 01:07:08,388 callbacks.py:105 INFO train-abinet] epoch 8 iter 355400: loss = 0.3862,  smooth loss = 0.4678
[2022-07-08 01:07:49,292 callbacks.py:105 INFO train-abinet] epoch 8 iter 355450: loss = 0.3017,  smooth loss = 0.4541
[2022-07-08 01:08:29,993 callbacks.py:105 INFO train-abinet] epoch 8 iter 355500: loss = 0.4225,  smooth loss = 0.4586
[2022-07-08 01:09:10,652 callbacks.py:105 INFO train-abinet] epoch 8 iter 355550: loss = 0.3545,  smooth loss = 0.4602
[2022-07-08 01:09:51,030 callbacks.py:105 INFO train-abinet] epoch 8 iter 355600: loss = 0.4049,  smooth loss = 0.4774
[2022-07-08 01:10:31,922 callbacks.py:105 INFO train-abinet] epoch 8 iter 355650: loss = 0.4187,  smooth loss = 0.4614
[2022-07-08 01:11:12,162 callbacks.py:105 INFO train-abinet] epoch 8 iter 355700: loss = 0.3704,  smooth loss = 0.4655
[2022-07-08 01:11:52,993 callbacks.py:105 INFO train-abinet] epoch 8 iter 355750: loss = 0.4907,  smooth loss = 0.4605
[2022-07-08 01:12:33,559 callbacks.py:105 INFO train-abinet] epoch 8 iter 355800: loss = 0.5125,  smooth loss = 0.4626
[2022-07-08 01:13:14,501 callbacks.py:105 INFO train-abinet] epoch 8 iter 355850: loss = 0.5278,  smooth loss = 0.4756
[2022-07-08 01:13:54,971 callbacks.py:105 INFO train-abinet] epoch 8 iter 355900: loss = 0.4154,  smooth loss = 0.4685
[2022-07-08 01:14:35,919 callbacks.py:105 INFO train-abinet] epoch 8 iter 355950: loss = 0.4005,  smooth loss = 0.4602
[2022-07-08 01:15:16,015 callbacks.py:105 INFO train-abinet] epoch 8 iter 356000: loss = 0.3874,  smooth loss = 0.4621
[2022-07-08 01:15:57,257 callbacks.py:105 INFO train-abinet] epoch 8 iter 356050: loss = 0.3901,  smooth loss = 0.4619
[2022-07-08 01:16:38,035 callbacks.py:105 INFO train-abinet] epoch 8 iter 356100: loss = 0.4704,  smooth loss = 0.4639
[2022-07-08 01:17:18,953 callbacks.py:105 INFO train-abinet] epoch 8 iter 356150: loss = 0.3703,  smooth loss = 0.4587
[2022-07-08 01:17:59,549 callbacks.py:105 INFO train-abinet] epoch 8 iter 356200: loss = 0.4713,  smooth loss = 0.4575
[2022-07-08 01:18:40,239 callbacks.py:105 INFO train-abinet] epoch 8 iter 356250: loss = 0.4516,  smooth loss = 0.4593
[2022-07-08 01:19:20,772 callbacks.py:105 INFO train-abinet] epoch 8 iter 356300: loss = 0.3723,  smooth loss = 0.4510
[2022-07-08 01:20:01,537 callbacks.py:105 INFO train-abinet] epoch 8 iter 356350: loss = 0.5041,  smooth loss = 0.4471
[2022-07-08 01:20:42,741 callbacks.py:105 INFO train-abinet] epoch 8 iter 356400: loss = 0.3525,  smooth loss = 0.4557
[2022-07-08 01:21:23,700 callbacks.py:105 INFO train-abinet] epoch 8 iter 356450: loss = 0.5810,  smooth loss = 0.4609
[2022-07-08 01:22:04,300 callbacks.py:105 INFO train-abinet] epoch 8 iter 356500: loss = 0.4142,  smooth loss = 0.4531
[2022-07-08 01:22:45,366 callbacks.py:105 INFO train-abinet] epoch 8 iter 356550: loss = 0.4737,  smooth loss = 0.4634
[2022-07-08 01:23:25,905 callbacks.py:105 INFO train-abinet] epoch 8 iter 356600: loss = 0.6058,  smooth loss = 0.4635
[2022-07-08 01:24:06,482 callbacks.py:105 INFO train-abinet] epoch 8 iter 356650: loss = 0.4057,  smooth loss = 0.4607
[2022-07-08 01:24:47,451 callbacks.py:105 INFO train-abinet] epoch 8 iter 356700: loss = 0.3493,  smooth loss = 0.4584
[2022-07-08 01:25:28,577 callbacks.py:105 INFO train-abinet] epoch 8 iter 356750: loss = 0.4073,  smooth loss = 0.4455
[2022-07-08 01:26:09,023 callbacks.py:105 INFO train-abinet] epoch 8 iter 356800: loss = 0.4098,  smooth loss = 0.4414
[2022-07-08 01:26:49,645 callbacks.py:105 INFO train-abinet] epoch 8 iter 356850: loss = 0.6452,  smooth loss = 0.4534
[2022-07-08 01:27:30,245 callbacks.py:105 INFO train-abinet] epoch 8 iter 356900: loss = 0.4254,  smooth loss = 0.4544
[2022-07-08 01:28:10,617 callbacks.py:105 INFO train-abinet] epoch 8 iter 356950: loss = 0.5316,  smooth loss = 0.4605
[2022-07-08 01:28:51,310 callbacks.py:105 INFO train-abinet] epoch 8 iter 357000: loss = 0.4225,  smooth loss = 0.4650
[2022-07-08 01:28:51,311 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8557s
█[2022-07-08 01:29:05,466 callbacks.py:123 INFO train-abinet] epoch 8 iter 357000: eval loss = 1.1557,  ccr = 0.9650,  cwr = 0.9260,  ted = 1141.0000,  ned = 232.7816,  ted/w = 0.1574, 
[2022-07-08 01:29:05,468 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_357000
[2022-07-08 01:29:47,026 callbacks.py:105 INFO train-abinet] epoch 8 iter 357050: loss = 0.4658,  smooth loss = 0.4604
[2022-07-08 01:30:28,188 callbacks.py:105 INFO train-abinet] epoch 8 iter 357100: loss = 0.4585,  smooth loss = 0.4582
[2022-07-08 01:31:08,822 callbacks.py:105 INFO train-abinet] epoch 8 iter 357150: loss = 0.5196,  smooth loss = 0.4628
[2022-07-08 01:31:49,761 callbacks.py:105 INFO train-abinet] epoch 8 iter 357200: loss = 0.4189,  smooth loss = 0.4504
[2022-07-08 01:32:31,353 callbacks.py:105 INFO train-abinet] epoch 8 iter 357250: loss = 0.4144,  smooth loss = 0.4543
[2022-07-08 01:33:11,960 callbacks.py:105 INFO train-abinet] epoch 8 iter 357300: loss = 0.4344,  smooth loss = 0.4515
[2022-07-08 01:33:53,013 callbacks.py:105 INFO train-abinet] epoch 8 iter 357350: loss = 0.5238,  smooth loss = 0.4570
[2022-07-08 01:34:33,799 callbacks.py:105 INFO train-abinet] epoch 8 iter 357400: loss = 0.4795,  smooth loss = 0.4492
[2022-07-08 01:35:14,746 callbacks.py:105 INFO train-abinet] epoch 8 iter 357450: loss = 0.3838,  smooth loss = 0.4399
[2022-07-08 01:35:55,548 callbacks.py:105 INFO train-abinet] epoch 8 iter 357500: loss = 0.3891,  smooth loss = 0.4493
[2022-07-08 01:36:36,391 callbacks.py:105 INFO train-abinet] epoch 8 iter 357550: loss = 0.4731,  smooth loss = 0.4477
[2022-07-08 01:37:17,202 callbacks.py:105 INFO train-abinet] epoch 8 iter 357600: loss = 0.5694,  smooth loss = 0.4600
[2022-07-08 01:37:57,667 callbacks.py:105 INFO train-abinet] epoch 8 iter 357650: loss = 0.4245,  smooth loss = 0.4623
[2022-07-08 01:38:38,869 callbacks.py:105 INFO train-abinet] epoch 8 iter 357700: loss = 0.4691,  smooth loss = 0.4629
[2022-07-08 01:39:19,895 callbacks.py:105 INFO train-abinet] epoch 8 iter 357750: loss = 0.4591,  smooth loss = 0.4617
[2022-07-08 01:40:00,566 callbacks.py:105 INFO train-abinet] epoch 8 iter 357800: loss = 0.3305,  smooth loss = 0.4683
[2022-07-08 01:40:41,671 callbacks.py:105 INFO train-abinet] epoch 8 iter 357850: loss = 0.5273,  smooth loss = 0.4543
[2022-07-08 01:41:22,477 callbacks.py:105 INFO train-abinet] epoch 8 iter 357900: loss = 0.4356,  smooth loss = 0.4511
[2022-07-08 01:42:03,151 callbacks.py:105 INFO train-abinet] epoch 8 iter 357950: loss = 0.3717,  smooth loss = 0.4510
[2022-07-08 01:42:43,884 callbacks.py:105 INFO train-abinet] epoch 8 iter 358000: loss = 0.4485,  smooth loss = 0.4551
[2022-07-08 01:43:24,441 callbacks.py:105 INFO train-abinet] epoch 8 iter 358050: loss = 0.3517,  smooth loss = 0.4665
[2022-07-08 01:44:05,465 callbacks.py:105 INFO train-abinet] epoch 8 iter 358100: loss = 0.4393,  smooth loss = 0.4682
[2022-07-08 01:44:46,056 callbacks.py:105 INFO train-abinet] epoch 8 iter 358150: loss = 0.5619,  smooth loss = 0.4573
[2022-07-08 01:45:26,759 callbacks.py:105 INFO train-abinet] epoch 8 iter 358200: loss = 0.3677,  smooth loss = 0.4491
[2022-07-08 01:46:07,372 callbacks.py:105 INFO train-abinet] epoch 8 iter 358250: loss = 0.3698,  smooth loss = 0.4521
[2022-07-08 01:46:48,446 callbacks.py:105 INFO train-abinet] epoch 8 iter 358300: loss = 0.4037,  smooth loss = 0.4541
[2022-07-08 01:47:29,022 callbacks.py:105 INFO train-abinet] epoch 8 iter 358350: loss = 0.4135,  smooth loss = 0.4446
[2022-07-08 01:48:09,617 callbacks.py:105 INFO train-abinet] epoch 8 iter 358400: loss = 0.4039,  smooth loss = 0.4555
[2022-07-08 01:48:50,143 callbacks.py:105 INFO train-abinet] epoch 8 iter 358450: loss = 0.4772,  smooth loss = 0.4527
[2022-07-08 01:49:31,025 callbacks.py:105 INFO train-abinet] epoch 8 iter 358500: loss = 0.4178,  smooth loss = 0.4588
[2022-07-08 01:50:11,967 callbacks.py:105 INFO train-abinet] epoch 8 iter 358550: loss = 0.4687,  smooth loss = 0.4736
[2022-07-08 01:50:52,459 callbacks.py:105 INFO train-abinet] epoch 8 iter 358600: loss = 0.4004,  smooth loss = 0.4615
[2022-07-08 01:51:33,212 callbacks.py:105 INFO train-abinet] epoch 8 iter 358650: loss = 0.4034,  smooth loss = 0.4504
[2022-07-08 01:52:14,188 callbacks.py:105 INFO train-abinet] epoch 8 iter 358700: loss = 0.5973,  smooth loss = 0.4608
[2022-07-08 01:52:55,412 callbacks.py:105 INFO train-abinet] epoch 8 iter 358750: loss = 0.4883,  smooth loss = 0.4577
[2022-07-08 01:53:36,163 callbacks.py:105 INFO train-abinet] epoch 8 iter 358800: loss = 0.4054,  smooth loss = 0.4567
[2022-07-08 01:54:16,939 callbacks.py:105 INFO train-abinet] epoch 8 iter 358850: loss = 0.5903,  smooth loss = 0.4582
[2022-07-08 01:54:57,729 callbacks.py:105 INFO train-abinet] epoch 8 iter 358900: loss = 0.4855,  smooth loss = 0.4585
[2022-07-08 01:55:38,935 callbacks.py:105 INFO train-abinet] epoch 8 iter 358950: loss = 0.4222,  smooth loss = 0.4612
[2022-07-08 01:56:19,999 callbacks.py:105 INFO train-abinet] epoch 8 iter 359000: loss = 0.5135,  smooth loss = 0.4598
[2022-07-08 01:57:01,235 callbacks.py:105 INFO train-abinet] epoch 8 iter 359050: loss = 0.4793,  smooth loss = 0.4586
[2022-07-08 01:57:42,023 callbacks.py:105 INFO train-abinet] epoch 8 iter 359100: loss = 0.5689,  smooth loss = 0.4640
[2022-07-08 01:58:22,713 callbacks.py:105 INFO train-abinet] epoch 8 iter 359150: loss = 0.3837,  smooth loss = 0.4488
[2022-07-08 01:59:03,539 callbacks.py:105 INFO train-abinet] epoch 8 iter 359200: loss = 0.5590,  smooth loss = 0.4617
[2022-07-08 01:59:44,100 callbacks.py:105 INFO train-abinet] epoch 8 iter 359250: loss = 0.5223,  smooth loss = 0.4686
[2022-07-08 02:00:24,637 callbacks.py:105 INFO train-abinet] epoch 8 iter 359300: loss = 0.4602,  smooth loss = 0.4630
[2022-07-08 02:01:05,241 callbacks.py:105 INFO train-abinet] epoch 8 iter 359350: loss = 0.4772,  smooth loss = 0.4570
[2022-07-08 02:01:45,925 callbacks.py:105 INFO train-abinet] epoch 8 iter 359400: loss = 0.5435,  smooth loss = 0.4549
[2022-07-08 02:02:26,672 callbacks.py:105 INFO train-abinet] epoch 8 iter 359450: loss = 0.4197,  smooth loss = 0.4580
[2022-07-08 02:03:07,350 callbacks.py:105 INFO train-abinet] epoch 8 iter 359500: loss = 0.4248,  smooth loss = 0.4490
[2022-07-08 02:03:48,791 callbacks.py:105 INFO train-abinet] epoch 8 iter 359550: loss = 0.4013,  smooth loss = 0.4535
[2022-07-08 02:04:29,426 callbacks.py:105 INFO train-abinet] epoch 8 iter 359600: loss = 0.3734,  smooth loss = 0.4427
[2022-07-08 02:05:09,950 callbacks.py:105 INFO train-abinet] epoch 8 iter 359650: loss = 0.2905,  smooth loss = 0.4415
[2022-07-08 02:05:50,600 callbacks.py:105 INFO train-abinet] epoch 8 iter 359700: loss = 0.4108,  smooth loss = 0.4518
[2022-07-08 02:06:31,562 callbacks.py:105 INFO train-abinet] epoch 8 iter 359750: loss = 0.4642,  smooth loss = 0.4605
[2022-07-08 02:07:12,101 callbacks.py:105 INFO train-abinet] epoch 8 iter 359800: loss = 0.5379,  smooth loss = 0.4540
[2022-07-08 02:07:52,702 callbacks.py:105 INFO train-abinet] epoch 8 iter 359850: loss = 0.5541,  smooth loss = 0.4648
[2022-07-08 02:08:33,454 callbacks.py:105 INFO train-abinet] epoch 8 iter 359900: loss = 0.3514,  smooth loss = 0.4555
[2022-07-08 02:09:14,269 callbacks.py:105 INFO train-abinet] epoch 8 iter 359950: loss = 0.4334,  smooth loss = 0.4613
[2022-07-08 02:09:55,082 callbacks.py:105 INFO train-abinet] epoch 8 iter 360000: loss = 0.4093,  smooth loss = 0.4578
[2022-07-08 02:09:55,083 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8554s
█[2022-07-08 02:10:09,375 callbacks.py:123 INFO train-abinet] epoch 8 iter 360000: eval loss = 1.1662,  ccr = 0.9655,  cwr = 0.9273,  ted = 1130.0000,  ned = 232.1799,  ted/w = 0.1559, 
[2022-07-08 02:10:09,377 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_360000
[2022-07-08 02:10:51,228 callbacks.py:105 INFO train-abinet] epoch 8 iter 360050: loss = 0.4151,  smooth loss = 0.4589
[2022-07-08 02:11:32,048 callbacks.py:105 INFO train-abinet] epoch 8 iter 360100: loss = 0.4664,  smooth loss = 0.4680
[2022-07-08 02:12:13,060 callbacks.py:105 INFO train-abinet] epoch 8 iter 360150: loss = 0.4316,  smooth loss = 0.4658
[2022-07-08 02:12:53,624 callbacks.py:105 INFO train-abinet] epoch 8 iter 360200: loss = 0.5292,  smooth loss = 0.4592
[2022-07-08 02:13:34,194 callbacks.py:105 INFO train-abinet] epoch 8 iter 360250: loss = 0.3941,  smooth loss = 0.4613
[2022-07-08 02:14:15,375 callbacks.py:105 INFO train-abinet] epoch 8 iter 360300: loss = 0.3541,  smooth loss = 0.4580
[2022-07-08 02:14:56,148 callbacks.py:105 INFO train-abinet] epoch 8 iter 360350: loss = 0.4123,  smooth loss = 0.4615
[2022-07-08 02:15:36,840 callbacks.py:105 INFO train-abinet] epoch 8 iter 360400: loss = 0.4284,  smooth loss = 0.4533
[2022-07-08 02:16:17,448 callbacks.py:105 INFO train-abinet] epoch 8 iter 360450: loss = 0.4057,  smooth loss = 0.4480
[2022-07-08 02:16:58,298 callbacks.py:105 INFO train-abinet] epoch 8 iter 360500: loss = 0.4161,  smooth loss = 0.4567
[2022-07-08 02:17:39,496 callbacks.py:105 INFO train-abinet] epoch 8 iter 360550: loss = 0.5334,  smooth loss = 0.4577
[2022-07-08 02:18:20,079 callbacks.py:105 INFO train-abinet] epoch 8 iter 360600: loss = 0.5056,  smooth loss = 0.4490
[2022-07-08 02:19:01,503 callbacks.py:105 INFO train-abinet] epoch 8 iter 360650: loss = 0.4307,  smooth loss = 0.4518
[2022-07-08 02:19:42,131 callbacks.py:105 INFO train-abinet] epoch 8 iter 360700: loss = 0.4449,  smooth loss = 0.4584
[2022-07-08 02:20:22,616 callbacks.py:105 INFO train-abinet] epoch 8 iter 360750: loss = 0.4004,  smooth loss = 0.4543
[2022-07-08 02:21:03,245 callbacks.py:105 INFO train-abinet] epoch 8 iter 360800: loss = 0.5049,  smooth loss = 0.4513
[2022-07-08 02:21:43,975 callbacks.py:105 INFO train-abinet] epoch 8 iter 360850: loss = 0.3553,  smooth loss = 0.4526
[2022-07-08 02:22:24,488 callbacks.py:105 INFO train-abinet] epoch 8 iter 360900: loss = 0.5266,  smooth loss = 0.4589
[2022-07-08 02:23:05,365 callbacks.py:105 INFO train-abinet] epoch 8 iter 360950: loss = 0.3218,  smooth loss = 0.4571
[2022-07-08 02:23:46,115 callbacks.py:105 INFO train-abinet] epoch 8 iter 361000: loss = 0.4481,  smooth loss = 0.4606
[2022-07-08 02:24:27,000 callbacks.py:105 INFO train-abinet] epoch 8 iter 361050: loss = 0.5667,  smooth loss = 0.4595
[2022-07-08 02:25:07,839 callbacks.py:105 INFO train-abinet] epoch 8 iter 361100: loss = 0.4169,  smooth loss = 0.4518
[2022-07-08 02:25:49,135 callbacks.py:105 INFO train-abinet] epoch 8 iter 361150: loss = 0.4744,  smooth loss = 0.4528
[2022-07-08 02:26:29,886 callbacks.py:105 INFO train-abinet] epoch 8 iter 361200: loss = 0.4815,  smooth loss = 0.4647
[2022-07-08 02:27:10,814 callbacks.py:105 INFO train-abinet] epoch 8 iter 361250: loss = 0.3058,  smooth loss = 0.4542
[2022-07-08 02:27:51,303 callbacks.py:105 INFO train-abinet] epoch 8 iter 361300: loss = 0.5390,  smooth loss = 0.4566
[2022-07-08 02:28:32,010 callbacks.py:105 INFO train-abinet] epoch 8 iter 361350: loss = 0.6233,  smooth loss = 0.4537
[2022-07-08 02:29:12,962 callbacks.py:105 INFO train-abinet] epoch 8 iter 361400: loss = 0.6291,  smooth loss = 0.4569
[2022-07-08 02:29:53,954 callbacks.py:105 INFO train-abinet] epoch 8 iter 361450: loss = 0.6580,  smooth loss = 0.4662
[2022-07-08 02:30:35,142 callbacks.py:105 INFO train-abinet] epoch 8 iter 361500: loss = 0.4552,  smooth loss = 0.4631
[2022-07-08 02:31:15,877 callbacks.py:105 INFO train-abinet] epoch 8 iter 361550: loss = 0.4642,  smooth loss = 0.4530
[2022-07-08 02:31:57,445 callbacks.py:105 INFO train-abinet] epoch 8 iter 361600: loss = 0.3855,  smooth loss = 0.4599
[2022-07-08 02:32:38,649 callbacks.py:105 INFO train-abinet] epoch 8 iter 361650: loss = 0.4330,  smooth loss = 0.4530
[2022-07-08 02:33:19,849 callbacks.py:105 INFO train-abinet] epoch 8 iter 361700: loss = 0.4049,  smooth loss = 0.4555
[2022-07-08 02:34:01,052 callbacks.py:105 INFO train-abinet] epoch 8 iter 361750: loss = 0.5342,  smooth loss = 0.4538
[2022-07-08 02:34:42,006 callbacks.py:105 INFO train-abinet] epoch 8 iter 361800: loss = 0.4572,  smooth loss = 0.4639
[2022-07-08 02:35:23,575 callbacks.py:105 INFO train-abinet] epoch 8 iter 361850: loss = 0.4126,  smooth loss = 0.4483
[2022-07-08 02:36:04,659 callbacks.py:105 INFO train-abinet] epoch 8 iter 361900: loss = 0.4202,  smooth loss = 0.4476
[2022-07-08 02:36:45,773 callbacks.py:105 INFO train-abinet] epoch 8 iter 361950: loss = 0.3437,  smooth loss = 0.4448
[2022-07-08 02:37:26,654 callbacks.py:105 INFO train-abinet] epoch 8 iter 362000: loss = 0.4042,  smooth loss = 0.4582
[2022-07-08 02:38:08,225 callbacks.py:105 INFO train-abinet] epoch 8 iter 362050: loss = 0.4840,  smooth loss = 0.4540
[2022-07-08 02:38:49,057 callbacks.py:105 INFO train-abinet] epoch 8 iter 362100: loss = 0.5019,  smooth loss = 0.4599
[2022-07-08 02:39:30,093 callbacks.py:105 INFO train-abinet] epoch 8 iter 362150: loss = 0.3925,  smooth loss = 0.4712
[2022-07-08 02:40:11,025 callbacks.py:105 INFO train-abinet] epoch 8 iter 362200: loss = 0.4092,  smooth loss = 0.4560
[2022-07-08 02:40:51,834 callbacks.py:105 INFO train-abinet] epoch 8 iter 362250: loss = 0.4500,  smooth loss = 0.4650
[2022-07-08 02:41:32,339 callbacks.py:105 INFO train-abinet] epoch 8 iter 362300: loss = 0.3383,  smooth loss = 0.4543
[2022-07-08 02:42:12,890 callbacks.py:105 INFO train-abinet] epoch 8 iter 362350: loss = 0.4490,  smooth loss = 0.4518
[2022-07-08 02:42:53,618 callbacks.py:105 INFO train-abinet] epoch 8 iter 362400: loss = 0.5988,  smooth loss = 0.4522
[2022-07-08 02:43:34,745 callbacks.py:105 INFO train-abinet] epoch 8 iter 362450: loss = 0.5160,  smooth loss = 0.4564
[2022-07-08 02:44:15,382 callbacks.py:105 INFO train-abinet] epoch 8 iter 362500: loss = 0.4328,  smooth loss = 0.4525
[2022-07-08 02:44:56,048 callbacks.py:105 INFO train-abinet] epoch 8 iter 362550: loss = 0.4238,  smooth loss = 0.4600
[2022-07-08 02:45:36,675 callbacks.py:105 INFO train-abinet] epoch 8 iter 362600: loss = 0.3918,  smooth loss = 0.4605
[2022-07-08 02:46:17,584 callbacks.py:105 INFO train-abinet] epoch 8 iter 362650: loss = 0.4291,  smooth loss = 0.4537
[2022-07-08 02:46:58,213 callbacks.py:105 INFO train-abinet] epoch 8 iter 362700: loss = 0.4487,  smooth loss = 0.4578
[2022-07-08 02:47:38,612 callbacks.py:105 INFO train-abinet] epoch 8 iter 362750: loss = 0.4811,  smooth loss = 0.4625
[2022-07-08 02:48:19,292 callbacks.py:105 INFO train-abinet] epoch 8 iter 362800: loss = 0.4722,  smooth loss = 0.4688
[2022-07-08 02:49:00,237 callbacks.py:105 INFO train-abinet] epoch 8 iter 362850: loss = 0.6915,  smooth loss = 0.4553
[2022-07-08 02:49:41,061 callbacks.py:105 INFO train-abinet] epoch 8 iter 362900: loss = 0.3534,  smooth loss = 0.4471
[2022-07-08 02:50:21,964 callbacks.py:105 INFO train-abinet] epoch 8 iter 362950: loss = 0.4566,  smooth loss = 0.4677
[2022-07-08 02:51:03,407 callbacks.py:105 INFO train-abinet] epoch 8 iter 363000: loss = 0.5765,  smooth loss = 0.4624
[2022-07-08 02:51:03,409 callbacks.py:114 INFO train-abinet] average data time = 0.0045s, average running time = 0.8551s
█[2022-07-08 02:51:17,142 callbacks.py:123 INFO train-abinet] epoch 8 iter 363000: eval loss = 1.1621,  ccr = 0.9646,  cwr = 0.9280,  ted = 1163.0000,  ned = 233.6478,  ted/w = 0.1605, 
[2022-07-08 02:51:17,143 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_363000
[2022-07-08 02:51:58,866 callbacks.py:105 INFO train-abinet] epoch 8 iter 363050: loss = 0.4945,  smooth loss = 0.4591
[2022-07-08 02:52:39,994 callbacks.py:105 INFO train-abinet] epoch 8 iter 363100: loss = 0.4464,  smooth loss = 0.4647
[2022-07-08 02:53:20,584 callbacks.py:105 INFO train-abinet] epoch 8 iter 363150: loss = 0.3278,  smooth loss = 0.4541
[2022-07-08 02:54:01,157 callbacks.py:105 INFO train-abinet] epoch 8 iter 363200: loss = 0.4100,  smooth loss = 0.4524
[2022-07-08 02:54:41,609 callbacks.py:105 INFO train-abinet] epoch 8 iter 363250: loss = 0.5356,  smooth loss = 0.4580
[2022-07-08 02:55:22,694 callbacks.py:105 INFO train-abinet] epoch 8 iter 363300: loss = 0.4801,  smooth loss = 0.4589
[2022-07-08 02:56:03,406 callbacks.py:105 INFO train-abinet] epoch 8 iter 363350: loss = 0.4408,  smooth loss = 0.4630
[2022-07-08 02:56:44,329 callbacks.py:105 INFO train-abinet] epoch 8 iter 363400: loss = 0.5017,  smooth loss = 0.4541
[2022-07-08 02:57:25,079 callbacks.py:105 INFO train-abinet] epoch 8 iter 363450: loss = 0.3961,  smooth loss = 0.4595
[2022-07-08 02:58:05,675 callbacks.py:105 INFO train-abinet] epoch 8 iter 363500: loss = 0.4364,  smooth loss = 0.4657
[2022-07-08 02:58:46,446 callbacks.py:105 INFO train-abinet] epoch 8 iter 363550: loss = 0.3630,  smooth loss = 0.4647
[2022-07-08 02:59:27,184 callbacks.py:105 INFO train-abinet] epoch 8 iter 363600: loss = 0.4776,  smooth loss = 0.4619
[2022-07-08 03:00:08,002 callbacks.py:105 INFO train-abinet] epoch 8 iter 363650: loss = 0.4159,  smooth loss = 0.4569
[2022-07-08 03:00:48,739 callbacks.py:105 INFO train-abinet] epoch 8 iter 363700: loss = 0.3747,  smooth loss = 0.4627
[2022-07-08 03:01:29,972 callbacks.py:105 INFO train-abinet] epoch 8 iter 363750: loss = 0.4039,  smooth loss = 0.4579
[2022-07-08 03:02:11,056 callbacks.py:105 INFO train-abinet] epoch 8 iter 363800: loss = 0.4825,  smooth loss = 0.4554
[2022-07-08 03:02:51,978 callbacks.py:105 INFO train-abinet] epoch 8 iter 363850: loss = 0.3829,  smooth loss = 0.4487
[2022-07-08 03:03:32,851 callbacks.py:105 INFO train-abinet] epoch 8 iter 363900: loss = 0.4612,  smooth loss = 0.4405
[2022-07-08 03:04:13,980 callbacks.py:105 INFO train-abinet] epoch 8 iter 363950: loss = 0.4631,  smooth loss = 0.4550
[2022-07-08 03:04:54,890 callbacks.py:105 INFO train-abinet] epoch 8 iter 364000: loss = 0.5038,  smooth loss = 0.4625
[2022-07-08 03:05:35,975 callbacks.py:105 INFO train-abinet] epoch 8 iter 364050: loss = 0.4021,  smooth loss = 0.4600
[2022-07-08 03:06:17,320 callbacks.py:105 INFO train-abinet] epoch 8 iter 364100: loss = 0.5984,  smooth loss = 0.4557
[2022-07-08 03:06:57,994 callbacks.py:105 INFO train-abinet] epoch 8 iter 364150: loss = 0.4790,  smooth loss = 0.4606
[2022-07-08 03:07:38,857 callbacks.py:105 INFO train-abinet] epoch 8 iter 364200: loss = 0.5114,  smooth loss = 0.4593
[2022-07-08 03:08:19,731 callbacks.py:105 INFO train-abinet] epoch 8 iter 364250: loss = 0.4333,  smooth loss = 0.4543
[2022-07-08 03:09:00,493 callbacks.py:105 INFO train-abinet] epoch 8 iter 364300: loss = 0.4921,  smooth loss = 0.4511
[2022-07-08 03:09:41,899 callbacks.py:105 INFO train-abinet] epoch 8 iter 364350: loss = 0.4667,  smooth loss = 0.4708
[2022-07-08 03:10:23,009 callbacks.py:105 INFO train-abinet] epoch 8 iter 364400: loss = 0.4449,  smooth loss = 0.4586
[2022-07-08 03:11:04,470 callbacks.py:105 INFO train-abinet] epoch 8 iter 364450: loss = 0.4150,  smooth loss = 0.4607
[2022-07-08 03:11:45,986 callbacks.py:105 INFO train-abinet] epoch 8 iter 364500: loss = 0.4672,  smooth loss = 0.4547
[2022-07-08 03:12:26,959 callbacks.py:105 INFO train-abinet] epoch 8 iter 364550: loss = 0.3285,  smooth loss = 0.4616
[2022-07-08 03:13:08,361 callbacks.py:105 INFO train-abinet] epoch 8 iter 364600: loss = 0.4927,  smooth loss = 0.4498
[2022-07-08 03:13:48,993 callbacks.py:105 INFO train-abinet] epoch 8 iter 364650: loss = 0.3824,  smooth loss = 0.4406
[2022-07-08 03:14:32,741 callbacks.py:105 INFO train-abinet] epoch 8 iter 364700: loss = 0.4327,  smooth loss = 0.4458
[2022-07-08 03:15:13,993 callbacks.py:105 INFO train-abinet] epoch 8 iter 364750: loss = 0.4950,  smooth loss = 0.4580
[2022-07-08 03:15:56,781 callbacks.py:105 INFO train-abinet] epoch 8 iter 364800: loss = 0.4338,  smooth loss = 0.4529
[2022-07-08 03:16:37,761 callbacks.py:105 INFO train-abinet] epoch 8 iter 364850: loss = 0.4222,  smooth loss = 0.4646
[2022-07-08 03:17:22,964 callbacks.py:105 INFO train-abinet] epoch 8 iter 364900: loss = 0.4114,  smooth loss = 0.4562
[2022-07-08 03:18:04,295 callbacks.py:105 INFO train-abinet] epoch 8 iter 364950: loss = 0.3977,  smooth loss = 0.4587
[2022-07-08 03:18:45,161 callbacks.py:105 INFO train-abinet] epoch 8 iter 365000: loss = 0.4513,  smooth loss = 0.4554
[2022-07-08 03:19:27,914 callbacks.py:105 INFO train-abinet] epoch 8 iter 365050: loss = 0.3071,  smooth loss = 0.4606
[2022-07-08 03:20:08,676 callbacks.py:105 INFO train-abinet] epoch 8 iter 365100: loss = 0.4239,  smooth loss = 0.4547
[2022-07-08 03:20:49,918 callbacks.py:105 INFO train-abinet] epoch 8 iter 365150: loss = 0.3691,  smooth loss = 0.4519
[2022-07-08 03:21:31,436 callbacks.py:105 INFO train-abinet] epoch 8 iter 365200: loss = 0.5128,  smooth loss = 0.4523
[2022-07-08 03:22:14,125 callbacks.py:105 INFO train-abinet] epoch 8 iter 365250: loss = 0.4722,  smooth loss = 0.4450
[2022-07-08 03:22:56,568 callbacks.py:105 INFO train-abinet] epoch 8 iter 365300: loss = 0.5083,  smooth loss = 0.4431
[2022-07-08 03:23:37,209 callbacks.py:105 INFO train-abinet] epoch 8 iter 365350: loss = 0.4374,  smooth loss = 0.4471
[2022-07-08 03:24:18,501 callbacks.py:105 INFO train-abinet] epoch 8 iter 365400: loss = 0.3485,  smooth loss = 0.4501
[2022-07-08 03:24:59,388 callbacks.py:105 INFO train-abinet] epoch 8 iter 365450: loss = 0.4448,  smooth loss = 0.4448
[2022-07-08 03:25:40,076 callbacks.py:105 INFO train-abinet] epoch 8 iter 365500: loss = 0.4761,  smooth loss = 0.4470
[2022-07-08 03:26:21,135 callbacks.py:105 INFO train-abinet] epoch 8 iter 365550: loss = 0.4381,  smooth loss = 0.4448
[2022-07-08 03:27:02,472 callbacks.py:105 INFO train-abinet] epoch 8 iter 365600: loss = 0.4203,  smooth loss = 0.4471
[2022-07-08 03:27:44,140 callbacks.py:105 INFO train-abinet] epoch 8 iter 365650: loss = 0.5051,  smooth loss = 0.4613
[2022-07-08 03:28:25,317 callbacks.py:105 INFO train-abinet] epoch 8 iter 365700: loss = 0.5344,  smooth loss = 0.4568
[2022-07-08 03:29:06,417 callbacks.py:105 INFO train-abinet] epoch 8 iter 365750: loss = 0.5427,  smooth loss = 0.4507
[2022-07-08 03:29:47,341 callbacks.py:105 INFO train-abinet] epoch 8 iter 365800: loss = 0.5439,  smooth loss = 0.4631
[2022-07-08 03:30:29,009 callbacks.py:105 INFO train-abinet] epoch 8 iter 365850: loss = 0.5459,  smooth loss = 0.4639
[2022-07-08 03:31:10,177 callbacks.py:105 INFO train-abinet] epoch 8 iter 365900: loss = 0.3801,  smooth loss = 0.4593
[2022-07-08 03:31:52,626 callbacks.py:105 INFO train-abinet] epoch 8 iter 365950: loss = 0.3097,  smooth loss = 0.4609
[2022-07-08 03:32:34,963 callbacks.py:105 INFO train-abinet] epoch 8 iter 366000: loss = 0.4809,  smooth loss = 0.4641
[2022-07-08 03:32:34,964 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8548s
█[2022-07-08 03:32:49,198 callbacks.py:123 INFO train-abinet] epoch 8 iter 366000: eval loss = 1.1642,  ccr = 0.9652,  cwr = 0.9283,  ted = 1135.0000,  ned = 230.9630,  ted/w = 0.1566, 
[2022-07-08 03:32:49,200 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_366000
[2022-07-08 03:33:31,094 callbacks.py:105 INFO train-abinet] epoch 8 iter 366050: loss = 0.3912,  smooth loss = 0.4456
[2022-07-08 03:34:14,000 callbacks.py:105 INFO train-abinet] epoch 8 iter 366100: loss = 0.4177,  smooth loss = 0.4507
[2022-07-08 03:34:55,088 callbacks.py:105 INFO train-abinet] epoch 8 iter 366150: loss = 0.3775,  smooth loss = 0.4635
[2022-07-08 03:35:36,141 callbacks.py:105 INFO train-abinet] epoch 8 iter 366200: loss = 0.4861,  smooth loss = 0.4619
[2022-07-08 03:36:16,921 callbacks.py:105 INFO train-abinet] epoch 8 iter 366250: loss = 0.5858,  smooth loss = 0.4534
[2022-07-08 03:36:57,626 callbacks.py:105 INFO train-abinet] epoch 8 iter 366300: loss = 0.3609,  smooth loss = 0.4587
[2022-07-08 03:37:39,096 callbacks.py:105 INFO train-abinet] epoch 8 iter 366350: loss = 0.4067,  smooth loss = 0.4630
[2022-07-08 03:38:20,032 callbacks.py:105 INFO train-abinet] epoch 8 iter 366400: loss = 0.4115,  smooth loss = 0.4572
[2022-07-08 03:39:00,813 callbacks.py:105 INFO train-abinet] epoch 8 iter 366450: loss = 0.4821,  smooth loss = 0.4523
[2022-07-08 03:39:41,569 callbacks.py:105 INFO train-abinet] epoch 8 iter 366500: loss = 0.5652,  smooth loss = 0.4522
[2022-07-08 03:40:25,208 callbacks.py:105 INFO train-abinet] epoch 8 iter 366550: loss = 0.4222,  smooth loss = 0.4536
[2022-07-08 03:41:05,949 callbacks.py:105 INFO train-abinet] epoch 8 iter 366600: loss = 0.4120,  smooth loss = 0.4516
[2022-07-08 03:41:46,629 callbacks.py:105 INFO train-abinet] epoch 8 iter 366650: loss = 0.3579,  smooth loss = 0.4694
[2022-07-08 03:42:27,219 callbacks.py:105 INFO train-abinet] epoch 8 iter 366700: loss = 0.4446,  smooth loss = 0.4641
[2022-07-08 03:43:08,439 callbacks.py:105 INFO train-abinet] epoch 8 iter 366750: loss = 0.5447,  smooth loss = 0.4610
[2022-07-08 03:43:48,996 callbacks.py:105 INFO train-abinet] epoch 8 iter 366800: loss = 0.4899,  smooth loss = 0.4632
[2022-07-08 03:44:29,595 callbacks.py:105 INFO train-abinet] epoch 8 iter 366850: loss = 0.5729,  smooth loss = 0.4588
[2022-07-08 03:45:10,681 callbacks.py:105 INFO train-abinet] epoch 8 iter 366900: loss = 0.4146,  smooth loss = 0.4653
[2022-07-08 03:45:51,396 callbacks.py:105 INFO train-abinet] epoch 8 iter 366950: loss = 0.3586,  smooth loss = 0.4484
[2022-07-08 03:46:32,539 callbacks.py:105 INFO train-abinet] epoch 8 iter 367000: loss = 0.4121,  smooth loss = 0.4598
[2022-07-08 03:47:13,258 callbacks.py:105 INFO train-abinet] epoch 8 iter 367050: loss = 0.5621,  smooth loss = 0.4700
[2022-07-08 03:47:53,911 callbacks.py:105 INFO train-abinet] epoch 8 iter 367100: loss = 0.5813,  smooth loss = 0.4600
[2022-07-08 03:48:34,585 callbacks.py:105 INFO train-abinet] epoch 8 iter 367150: loss = 0.4458,  smooth loss = 0.4579
[2022-07-08 03:49:15,943 callbacks.py:105 INFO train-abinet] epoch 8 iter 367200: loss = 0.4768,  smooth loss = 0.4660
[2022-07-08 03:49:56,579 callbacks.py:105 INFO train-abinet] epoch 8 iter 367250: loss = 0.3994,  smooth loss = 0.4531
[2022-07-08 03:50:37,400 callbacks.py:105 INFO train-abinet] epoch 8 iter 367300: loss = 0.4029,  smooth loss = 0.4603
[2022-07-08 03:51:18,002 callbacks.py:105 INFO train-abinet] epoch 8 iter 367350: loss = 0.4003,  smooth loss = 0.4741
[2022-07-08 03:51:58,946 callbacks.py:105 INFO train-abinet] epoch 8 iter 367400: loss = 0.4785,  smooth loss = 0.4549
[2022-07-08 03:52:40,371 callbacks.py:105 INFO train-abinet] epoch 8 iter 367450: loss = 0.3713,  smooth loss = 0.4467
[2022-07-08 03:53:20,959 callbacks.py:105 INFO train-abinet] epoch 8 iter 367500: loss = 0.3545,  smooth loss = 0.4522
[2022-07-08 03:54:01,624 callbacks.py:105 INFO train-abinet] epoch 8 iter 367550: loss = 0.5182,  smooth loss = 0.4469
[2022-07-08 03:54:42,317 callbacks.py:105 INFO train-abinet] epoch 8 iter 367600: loss = 0.4179,  smooth loss = 0.4578
[2022-07-08 03:55:23,179 callbacks.py:105 INFO train-abinet] epoch 8 iter 367650: loss = 0.4573,  smooth loss = 0.4528
[2022-07-08 03:56:04,411 callbacks.py:105 INFO train-abinet] epoch 8 iter 367700: loss = 0.4885,  smooth loss = 0.4539
[2022-07-08 03:56:45,369 callbacks.py:105 INFO train-abinet] epoch 8 iter 367750: loss = 0.5762,  smooth loss = 0.4520
[2022-07-08 03:57:25,896 callbacks.py:105 INFO train-abinet] epoch 8 iter 367800: loss = 0.4559,  smooth loss = 0.4576
[2022-07-08 03:58:07,545 callbacks.py:105 INFO train-abinet] epoch 8 iter 367850: loss = 0.5586,  smooth loss = 0.4710
[2022-07-08 03:58:48,316 callbacks.py:105 INFO train-abinet] epoch 8 iter 367900: loss = 0.4979,  smooth loss = 0.4612
[2022-07-08 03:59:29,580 callbacks.py:105 INFO train-abinet] epoch 8 iter 367950: loss = 0.4253,  smooth loss = 0.4495
[2022-07-08 04:00:10,453 callbacks.py:105 INFO train-abinet] epoch 8 iter 368000: loss = 0.4155,  smooth loss = 0.4570
[2022-07-08 04:00:51,341 callbacks.py:105 INFO train-abinet] epoch 8 iter 368050: loss = 0.3706,  smooth loss = 0.4468
[2022-07-08 04:01:32,219 callbacks.py:105 INFO train-abinet] epoch 8 iter 368100: loss = 0.4436,  smooth loss = 0.4512
[2022-07-08 04:02:13,827 callbacks.py:105 INFO train-abinet] epoch 8 iter 368150: loss = 0.3635,  smooth loss = 0.4524
[2022-07-08 04:02:55,040 callbacks.py:105 INFO train-abinet] epoch 8 iter 368200: loss = 0.4665,  smooth loss = 0.4605
[2022-07-08 04:03:36,058 callbacks.py:105 INFO train-abinet] epoch 8 iter 368250: loss = 0.4890,  smooth loss = 0.4510
[2022-07-08 04:04:16,859 callbacks.py:105 INFO train-abinet] epoch 8 iter 368300: loss = 0.3931,  smooth loss = 0.4549
[2022-07-08 04:04:58,621 callbacks.py:105 INFO train-abinet] epoch 8 iter 368350: loss = 0.4708,  smooth loss = 0.4689
[2022-07-08 04:05:39,696 callbacks.py:105 INFO train-abinet] epoch 8 iter 368400: loss = 0.3705,  smooth loss = 0.4545
[2022-07-08 04:06:20,734 callbacks.py:105 INFO train-abinet] epoch 8 iter 368450: loss = 0.4337,  smooth loss = 0.4613
[2022-07-08 04:07:01,756 callbacks.py:105 INFO train-abinet] epoch 8 iter 368500: loss = 0.3489,  smooth loss = 0.4675
[2022-07-08 04:07:43,429 callbacks.py:105 INFO train-abinet] epoch 8 iter 368550: loss = 0.4253,  smooth loss = 0.4678
[2022-07-08 04:08:24,290 callbacks.py:105 INFO train-abinet] epoch 8 iter 368600: loss = 0.4588,  smooth loss = 0.4709
[2022-07-08 04:09:05,213 callbacks.py:105 INFO train-abinet] epoch 8 iter 368650: loss = 0.5981,  smooth loss = 0.4795
[2022-07-08 04:09:46,358 callbacks.py:105 INFO train-abinet] epoch 8 iter 368700: loss = 0.3922,  smooth loss = 0.4623
[2022-07-08 04:10:27,834 callbacks.py:105 INFO train-abinet] epoch 8 iter 368750: loss = 0.4057,  smooth loss = 0.4583
[2022-07-08 04:11:08,743 callbacks.py:105 INFO train-abinet] epoch 8 iter 368800: loss = 0.4063,  smooth loss = 0.4478
[2022-07-08 04:11:49,658 callbacks.py:105 INFO train-abinet] epoch 8 iter 368850: loss = 0.4097,  smooth loss = 0.4478
[2022-07-08 04:12:30,828 callbacks.py:105 INFO train-abinet] epoch 8 iter 368900: loss = 0.3749,  smooth loss = 0.4407
[2022-07-08 04:13:12,243 callbacks.py:105 INFO train-abinet] epoch 8 iter 368950: loss = 0.5219,  smooth loss = 0.4547
[2022-07-08 04:13:53,129 callbacks.py:105 INFO train-abinet] epoch 8 iter 369000: loss = 0.3499,  smooth loss = 0.4614
[2022-07-08 04:13:53,130 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8546s
█[2022-07-08 04:14:06,837 callbacks.py:123 INFO train-abinet] epoch 8 iter 369000: eval loss = 1.1639,  ccr = 0.9651,  cwr = 0.9278,  ted = 1125.0000,  ned = 230.5196,  ted/w = 0.1552, 
[2022-07-08 04:14:06,839 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_369000
[2022-07-08 04:14:49,574 callbacks.py:105 INFO train-abinet] epoch 8 iter 369050: loss = 0.4018,  smooth loss = 0.4555
[2022-07-08 04:15:30,210 callbacks.py:105 INFO train-abinet] epoch 8 iter 369100: loss = 0.3489,  smooth loss = 0.4547
[2022-07-08 04:16:11,331 callbacks.py:105 INFO train-abinet] epoch 8 iter 369150: loss = 0.4836,  smooth loss = 0.4585
[2022-07-08 04:16:51,948 callbacks.py:105 INFO train-abinet] epoch 8 iter 369200: loss = 0.3902,  smooth loss = 0.4477
[2022-07-08 04:17:32,835 callbacks.py:105 INFO train-abinet] epoch 8 iter 369250: loss = 0.4335,  smooth loss = 0.4561
[2022-07-08 04:18:14,391 callbacks.py:105 INFO train-abinet] epoch 8 iter 369300: loss = 0.4720,  smooth loss = 0.4514
[2022-07-08 04:18:54,970 callbacks.py:105 INFO train-abinet] epoch 8 iter 369350: loss = 0.4630,  smooth loss = 0.4570
[2022-07-08 04:19:35,696 callbacks.py:105 INFO train-abinet] epoch 8 iter 369400: loss = 0.3670,  smooth loss = 0.4520
[2022-07-08 04:20:16,529 callbacks.py:105 INFO train-abinet] epoch 8 iter 369450: loss = 0.3946,  smooth loss = 0.4616
[2022-07-08 04:20:58,088 callbacks.py:105 INFO train-abinet] epoch 8 iter 369500: loss = 0.4555,  smooth loss = 0.4531
[2022-07-08 04:21:39,002 callbacks.py:105 INFO train-abinet] epoch 8 iter 369550: loss = 0.4335,  smooth loss = 0.4449
[2022-07-08 04:22:20,052 callbacks.py:105 INFO train-abinet] epoch 8 iter 369600: loss = 0.3982,  smooth loss = 0.4561
[2022-07-08 04:23:00,977 callbacks.py:105 INFO train-abinet] epoch 8 iter 369650: loss = 0.3804,  smooth loss = 0.4589
[2022-07-08 04:23:41,671 callbacks.py:105 INFO train-abinet] epoch 8 iter 369700: loss = 0.4564,  smooth loss = 0.4511
[2022-07-08 04:24:22,927 callbacks.py:105 INFO train-abinet] epoch 8 iter 369750: loss = 0.5785,  smooth loss = 0.4504
[2022-07-08 04:25:03,651 callbacks.py:105 INFO train-abinet] epoch 8 iter 369800: loss = 0.4714,  smooth loss = 0.4562
[2022-07-08 04:25:44,074 callbacks.py:105 INFO train-abinet] epoch 8 iter 369850: loss = 0.3282,  smooth loss = 0.4574
[2022-07-08 04:26:24,914 callbacks.py:105 INFO train-abinet] epoch 8 iter 369900: loss = 0.4780,  smooth loss = 0.4612
[2022-07-08 04:27:05,597 callbacks.py:105 INFO train-abinet] epoch 8 iter 369950: loss = 0.5691,  smooth loss = 0.4691
[2022-07-08 04:27:46,187 callbacks.py:105 INFO train-abinet] epoch 8 iter 370000: loss = 0.5163,  smooth loss = 0.4648
[2022-07-08 04:28:27,488 callbacks.py:105 INFO train-abinet] epoch 8 iter 370050: loss = 0.4921,  smooth loss = 0.4701
[2022-07-08 04:29:08,422 callbacks.py:105 INFO train-abinet] epoch 8 iter 370100: loss = 0.6115,  smooth loss = 0.4537
[2022-07-08 04:29:49,345 callbacks.py:105 INFO train-abinet] epoch 8 iter 370150: loss = 0.4123,  smooth loss = 0.4607
[2022-07-08 04:30:30,203 callbacks.py:105 INFO train-abinet] epoch 8 iter 370200: loss = 0.5041,  smooth loss = 0.4718
[2022-07-08 04:31:11,424 callbacks.py:105 INFO train-abinet] epoch 8 iter 370250: loss = 0.5820,  smooth loss = 0.4671
[2022-07-08 04:31:51,974 callbacks.py:105 INFO train-abinet] epoch 8 iter 370300: loss = 0.4028,  smooth loss = 0.4619
[2022-07-08 04:32:32,378 callbacks.py:105 INFO train-abinet] epoch 8 iter 370350: loss = 0.3865,  smooth loss = 0.4566
[2022-07-08 04:33:13,039 callbacks.py:105 INFO train-abinet] epoch 8 iter 370400: loss = 0.5691,  smooth loss = 0.4452
[2022-07-08 04:33:53,787 callbacks.py:105 INFO train-abinet] epoch 8 iter 370450: loss = 0.6354,  smooth loss = 0.4454
[2022-07-08 04:34:34,615 callbacks.py:105 INFO train-abinet] epoch 8 iter 370500: loss = 0.5331,  smooth loss = 0.4645
[2022-07-08 04:35:15,098 callbacks.py:105 INFO train-abinet] epoch 8 iter 370550: loss = 0.4218,  smooth loss = 0.4596
[2022-07-08 04:35:55,696 callbacks.py:105 INFO train-abinet] epoch 8 iter 370600: loss = 0.4359,  smooth loss = 0.4593
[2022-07-08 04:36:36,776 callbacks.py:105 INFO train-abinet] epoch 8 iter 370650: loss = 0.3905,  smooth loss = 0.4511
[2022-07-08 04:37:17,454 callbacks.py:105 INFO train-abinet] epoch 8 iter 370700: loss = 0.3783,  smooth loss = 0.4516
[2022-07-08 04:37:57,804 callbacks.py:105 INFO train-abinet] epoch 8 iter 370750: loss = 0.4728,  smooth loss = 0.4595
[2022-07-08 04:38:38,343 callbacks.py:105 INFO train-abinet] epoch 8 iter 370800: loss = 0.4366,  smooth loss = 0.4588
[2022-07-08 04:39:19,122 callbacks.py:105 INFO train-abinet] epoch 8 iter 370850: loss = 0.3833,  smooth loss = 0.4625
[2022-07-08 04:40:00,124 callbacks.py:105 INFO train-abinet] epoch 8 iter 370900: loss = 0.4111,  smooth loss = 0.4617
[2022-07-08 04:40:40,889 callbacks.py:105 INFO train-abinet] epoch 8 iter 370950: loss = 0.3948,  smooth loss = 0.4705
[2022-07-08 04:41:21,669 callbacks.py:105 INFO train-abinet] epoch 8 iter 371000: loss = 0.3644,  smooth loss = 0.4505
[2022-07-08 04:42:02,318 callbacks.py:105 INFO train-abinet] epoch 8 iter 371050: loss = 0.5400,  smooth loss = 0.4446
[2022-07-08 04:42:43,004 callbacks.py:105 INFO train-abinet] epoch 8 iter 371100: loss = 0.4138,  smooth loss = 0.4623
[2022-07-08 04:43:23,333 callbacks.py:105 INFO train-abinet] epoch 8 iter 371150: loss = 0.4696,  smooth loss = 0.4708
[2022-07-08 04:44:04,358 callbacks.py:105 INFO train-abinet] epoch 8 iter 371200: loss = 0.4768,  smooth loss = 0.4586
[2022-07-08 04:44:45,351 callbacks.py:105 INFO train-abinet] epoch 8 iter 371250: loss = 0.3308,  smooth loss = 0.4530
[2022-07-08 04:45:25,879 callbacks.py:105 INFO train-abinet] epoch 8 iter 371300: loss = 0.3533,  smooth loss = 0.4637
[2022-07-08 04:46:06,606 callbacks.py:105 INFO train-abinet] epoch 8 iter 371350: loss = 0.4832,  smooth loss = 0.4579
[2022-07-08 04:46:47,073 callbacks.py:105 INFO train-abinet] epoch 8 iter 371400: loss = 0.3712,  smooth loss = 0.4495
[2022-07-08 04:47:28,133 callbacks.py:105 INFO train-abinet] epoch 8 iter 371450: loss = 0.5747,  smooth loss = 0.4564
[2022-07-08 04:48:09,078 callbacks.py:105 INFO train-abinet] epoch 8 iter 371500: loss = 0.4536,  smooth loss = 0.4557
[2022-07-08 04:48:49,794 callbacks.py:105 INFO train-abinet] epoch 8 iter 371550: loss = 0.3518,  smooth loss = 0.4445
[2022-07-08 04:49:30,970 callbacks.py:105 INFO train-abinet] epoch 8 iter 371600: loss = 0.5580,  smooth loss = 0.4516
[2022-07-08 04:50:12,477 callbacks.py:105 INFO train-abinet] epoch 8 iter 371650: loss = 0.4270,  smooth loss = 0.4612
[2022-07-08 04:50:52,940 callbacks.py:105 INFO train-abinet] epoch 8 iter 371700: loss = 0.5402,  smooth loss = 0.4559
[2022-07-08 04:51:33,858 callbacks.py:105 INFO train-abinet] epoch 8 iter 371750: loss = 0.3343,  smooth loss = 0.4611
[2022-07-08 04:52:14,831 callbacks.py:105 INFO train-abinet] epoch 8 iter 371800: loss = 0.4117,  smooth loss = 0.4500
[2022-07-08 04:52:55,766 callbacks.py:105 INFO train-abinet] epoch 8 iter 371850: loss = 0.4352,  smooth loss = 0.4441
[2022-07-08 04:53:37,493 callbacks.py:105 INFO train-abinet] epoch 8 iter 371900: loss = 0.3888,  smooth loss = 0.4525
[2022-07-08 04:54:19,229 callbacks.py:105 INFO train-abinet] epoch 8 iter 371950: loss = 0.4124,  smooth loss = 0.4537
[2022-07-08 04:55:00,473 callbacks.py:105 INFO train-abinet] epoch 8 iter 372000: loss = 0.5404,  smooth loss = 0.4572
[2022-07-08 04:55:00,474 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8543s
█[2022-07-08 04:55:14,703 callbacks.py:123 INFO train-abinet] epoch 8 iter 372000: eval loss = 1.1612,  ccr = 0.9653,  cwr = 0.9269,  ted = 1138.0000,  ned = 231.3875,  ted/w = 0.1570, 
[2022-07-08 04:55:14,704 callbacks.py:136 INFO train-abinet] Save model train-abinet_8_372000
[2022-07-08 04:55:57,023 callbacks.py:105 INFO train-abinet] epoch 8 iter 372050: loss = 0.4232,  smooth loss = 0.4474
[2022-07-08 04:56:38,235 callbacks.py:105 INFO train-abinet] epoch 8 iter 372100: loss = 0.4729,  smooth loss = 0.4504
[2022-07-08 04:57:19,960 callbacks.py:105 INFO train-abinet] epoch 8 iter 372150: loss = 0.4267,  smooth loss = 0.4513
[2022-07-08 04:58:01,617 callbacks.py:105 INFO train-abinet] epoch 8 iter 372200: loss = 0.5222,  smooth loss = 0.4587
[2022-07-08 04:58:42,982 callbacks.py:105 INFO train-abinet] epoch 8 iter 372250: loss = 0.4865,  smooth loss = 0.4650
[2022-07-08 04:59:24,174 callbacks.py:105 INFO train-abinet] epoch 8 iter 372300: loss = 0.4537,  smooth loss = 0.4668
[2022-07-08 05:00:05,476 callbacks.py:105 INFO train-abinet] epoch 8 iter 372350: loss = 0.4505,  smooth loss = 0.4522
[2022-07-08 05:00:46,527 callbacks.py:105 INFO train-abinet] epoch 8 iter 372400: loss = 0.3669,  smooth loss = 0.4383
[2022-07-08 05:01:28,462 callbacks.py:105 INFO train-abinet] epoch 8 iter 372450: loss = 0.4241,  smooth loss = 0.4550
[2022-07-08 05:02:09,931 callbacks.py:105 INFO train-abinet] epoch 8 iter 372500: loss = 0.4533,  smooth loss = 0.4588
█[2022-07-08 05:02:58,434 callbacks.py:105 INFO train-abinet] epoch 9 iter 372550: loss = 0.4154,  smooth loss = 0.4620
[2022-07-08 05:03:40,166 callbacks.py:105 INFO train-abinet] epoch 9 iter 372600: loss = 0.3986,  smooth loss = 0.4686
[2022-07-08 05:04:21,076 callbacks.py:105 INFO train-abinet] epoch 9 iter 372650: loss = 0.3514,  smooth loss = 0.4574
[2022-07-08 05:05:02,473 callbacks.py:105 INFO train-abinet] epoch 9 iter 372700: loss = 0.4330,  smooth loss = 0.4371
[2022-07-08 05:05:43,854 callbacks.py:105 INFO train-abinet] epoch 9 iter 372750: loss = 0.5272,  smooth loss = 0.4481
[2022-07-08 05:06:25,319 callbacks.py:105 INFO train-abinet] epoch 9 iter 372800: loss = 0.4387,  smooth loss = 0.4480
[2022-07-08 05:07:06,362 callbacks.py:105 INFO train-abinet] epoch 9 iter 372850: loss = 0.3556,  smooth loss = 0.4459
[2022-07-08 05:07:47,367 callbacks.py:105 INFO train-abinet] epoch 9 iter 372900: loss = 0.5311,  smooth loss = 0.4508
[2022-07-08 05:08:29,124 callbacks.py:105 INFO train-abinet] epoch 9 iter 372950: loss = 0.5542,  smooth loss = 0.4500
[2022-07-08 05:09:11,753 callbacks.py:105 INFO train-abinet] epoch 9 iter 373000: loss = 0.3965,  smooth loss = 0.4401
[2022-07-08 05:09:54,076 callbacks.py:105 INFO train-abinet] epoch 9 iter 373050: loss = 0.5161,  smooth loss = 0.4562
[2022-07-08 05:10:35,793 callbacks.py:105 INFO train-abinet] epoch 9 iter 373100: loss = 0.5594,  smooth loss = 0.4579
[2022-07-08 05:11:16,948 callbacks.py:105 INFO train-abinet] epoch 9 iter 373150: loss = 0.4510,  smooth loss = 0.4617
[2022-07-08 05:11:58,563 callbacks.py:105 INFO train-abinet] epoch 9 iter 373200: loss = 0.5077,  smooth loss = 0.4504
[2022-07-08 05:12:40,066 callbacks.py:105 INFO train-abinet] epoch 9 iter 373250: loss = 0.5350,  smooth loss = 0.4573
[2022-07-08 05:13:21,632 callbacks.py:105 INFO train-abinet] epoch 9 iter 373300: loss = 0.3595,  smooth loss = 0.4521
[2022-07-08 05:14:04,318 callbacks.py:105 INFO train-abinet] epoch 9 iter 373350: loss = 0.4492,  smooth loss = 0.4485
[2022-07-08 05:14:45,677 callbacks.py:105 INFO train-abinet] epoch 9 iter 373400: loss = 0.4463,  smooth loss = 0.4453
[2022-07-08 05:15:27,008 callbacks.py:105 INFO train-abinet] epoch 9 iter 373450: loss = 0.4045,  smooth loss = 0.4557
[2022-07-08 05:16:07,047 callbacks.py:105 INFO train-abinet] epoch 9 iter 373500: loss = 0.4768,  smooth loss = 0.4529
[2022-07-08 05:16:47,877 callbacks.py:105 INFO train-abinet] epoch 9 iter 373550: loss = 0.4726,  smooth loss = 0.4496
[2022-07-08 05:17:29,619 callbacks.py:105 INFO train-abinet] epoch 9 iter 373600: loss = 0.3974,  smooth loss = 0.4607
[2022-07-08 05:18:11,215 callbacks.py:105 INFO train-abinet] epoch 9 iter 373650: loss = 0.5055,  smooth loss = 0.4535
[2022-07-08 05:18:53,461 callbacks.py:105 INFO train-abinet] epoch 9 iter 373700: loss = 0.4645,  smooth loss = 0.4413
[2022-07-08 05:19:35,099 callbacks.py:105 INFO train-abinet] epoch 9 iter 373750: loss = 0.4095,  smooth loss = 0.4538
[2022-07-08 05:20:17,063 callbacks.py:105 INFO train-abinet] epoch 9 iter 373800: loss = 0.4396,  smooth loss = 0.4523
[2022-07-08 05:20:58,936 callbacks.py:105 INFO train-abinet] epoch 9 iter 373850: loss = 0.4896,  smooth loss = 0.4632
[2022-07-08 05:21:40,495 callbacks.py:105 INFO train-abinet] epoch 9 iter 373900: loss = 0.3715,  smooth loss = 0.4509
[2022-07-08 05:22:22,034 callbacks.py:105 INFO train-abinet] epoch 9 iter 373950: loss = 0.4040,  smooth loss = 0.4491
[2022-07-08 05:23:03,885 callbacks.py:105 INFO train-abinet] epoch 9 iter 374000: loss = 0.3951,  smooth loss = 0.4505
[2022-07-08 05:23:45,628 callbacks.py:105 INFO train-abinet] epoch 9 iter 374050: loss = 0.4424,  smooth loss = 0.4486
[2022-07-08 05:24:27,920 callbacks.py:105 INFO train-abinet] epoch 9 iter 374100: loss = 0.3061,  smooth loss = 0.4621
[2022-07-08 05:25:09,838 callbacks.py:105 INFO train-abinet] epoch 9 iter 374150: loss = 0.3759,  smooth loss = 0.4442
[2022-07-08 05:25:52,187 callbacks.py:105 INFO train-abinet] epoch 9 iter 374200: loss = 0.4822,  smooth loss = 0.4447
[2022-07-08 05:26:33,895 callbacks.py:105 INFO train-abinet] epoch 9 iter 374250: loss = 0.3806,  smooth loss = 0.4466
[2022-07-08 05:27:15,467 callbacks.py:105 INFO train-abinet] epoch 9 iter 374300: loss = 0.4352,  smooth loss = 0.4454
[2022-07-08 05:27:57,114 callbacks.py:105 INFO train-abinet] epoch 9 iter 374350: loss = 0.3247,  smooth loss = 0.4448
[2022-07-08 05:28:38,656 callbacks.py:105 INFO train-abinet] epoch 9 iter 374400: loss = 0.3885,  smooth loss = 0.4538
[2022-07-08 05:29:20,855 callbacks.py:105 INFO train-abinet] epoch 9 iter 374450: loss = 0.5125,  smooth loss = 0.4629
[2022-07-08 05:30:03,078 callbacks.py:105 INFO train-abinet] epoch 9 iter 374500: loss = 0.4920,  smooth loss = 0.4692
[2022-07-08 05:30:45,724 callbacks.py:105 INFO train-abinet] epoch 9 iter 374550: loss = 0.6284,  smooth loss = 0.4628
[2022-07-08 05:31:27,975 callbacks.py:105 INFO train-abinet] epoch 9 iter 374600: loss = 0.5066,  smooth loss = 0.4572
[2022-07-08 05:32:09,515 callbacks.py:105 INFO train-abinet] epoch 9 iter 374650: loss = 0.3491,  smooth loss = 0.4506
[2022-07-08 05:32:52,214 callbacks.py:105 INFO train-abinet] epoch 9 iter 374700: loss = 0.6553,  smooth loss = 0.4569
[2022-07-08 05:33:33,576 callbacks.py:105 INFO train-abinet] epoch 9 iter 374750: loss = 0.4826,  smooth loss = 0.4462
[2022-07-08 05:34:14,365 callbacks.py:105 INFO train-abinet] epoch 9 iter 374800: loss = 0.4846,  smooth loss = 0.4558
[2022-07-08 05:34:55,389 callbacks.py:105 INFO train-abinet] epoch 9 iter 374850: loss = 0.6058,  smooth loss = 0.4571
[2022-07-08 05:35:36,941 callbacks.py:105 INFO train-abinet] epoch 9 iter 374900: loss = 0.5824,  smooth loss = 0.4610
[2022-07-08 05:36:18,086 callbacks.py:105 INFO train-abinet] epoch 9 iter 374950: loss = 0.4160,  smooth loss = 0.4514
[2022-07-08 05:36:59,391 callbacks.py:105 INFO train-abinet] epoch 9 iter 375000: loss = 0.4088,  smooth loss = 0.4645
[2022-07-08 05:36:59,392 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8542s
█[2022-07-08 05:37:13,743 callbacks.py:123 INFO train-abinet] epoch 9 iter 375000: eval loss = 1.1671,  ccr = 0.9652,  cwr = 0.9274,  ted = 1133.0000,  ned = 232.1632,  ted/w = 0.1563, 
[2022-07-08 05:37:13,744 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_375000
[2022-07-08 05:37:55,864 callbacks.py:105 INFO train-abinet] epoch 9 iter 375050: loss = 0.4395,  smooth loss = 0.4620
[2022-07-08 05:38:36,987 callbacks.py:105 INFO train-abinet] epoch 9 iter 375100: loss = 0.3591,  smooth loss = 0.4603
[2022-07-08 05:39:19,656 callbacks.py:105 INFO train-abinet] epoch 9 iter 375150: loss = 0.3655,  smooth loss = 0.4482
[2022-07-08 05:40:02,204 callbacks.py:105 INFO train-abinet] epoch 9 iter 375200: loss = 0.5185,  smooth loss = 0.4540
[2022-07-08 05:40:44,247 callbacks.py:105 INFO train-abinet] epoch 9 iter 375250: loss = 0.4628,  smooth loss = 0.4515
[2022-07-08 05:41:27,010 callbacks.py:105 INFO train-abinet] epoch 9 iter 375300: loss = 0.5290,  smooth loss = 0.4520
[2022-07-08 05:42:09,014 callbacks.py:105 INFO train-abinet] epoch 9 iter 375350: loss = 0.4482,  smooth loss = 0.4627
[2022-07-08 05:42:51,085 callbacks.py:105 INFO train-abinet] epoch 9 iter 375400: loss = 0.4231,  smooth loss = 0.4589
[2022-07-08 05:43:33,062 callbacks.py:105 INFO train-abinet] epoch 9 iter 375450: loss = 0.3098,  smooth loss = 0.4579
[2022-07-08 05:44:15,699 callbacks.py:105 INFO train-abinet] epoch 9 iter 375500: loss = 0.5411,  smooth loss = 0.4623
[2022-07-08 05:44:57,826 callbacks.py:105 INFO train-abinet] epoch 9 iter 375550: loss = 0.5370,  smooth loss = 0.4625
[2022-07-08 05:45:39,893 callbacks.py:105 INFO train-abinet] epoch 9 iter 375600: loss = 0.4129,  smooth loss = 0.4454
[2022-07-08 05:46:21,794 callbacks.py:105 INFO train-abinet] epoch 9 iter 375650: loss = 0.3702,  smooth loss = 0.4328
[2022-07-08 05:47:04,434 callbacks.py:105 INFO train-abinet] epoch 9 iter 375700: loss = 0.5314,  smooth loss = 0.4563
[2022-07-08 05:47:46,500 callbacks.py:105 INFO train-abinet] epoch 9 iter 375750: loss = 0.3943,  smooth loss = 0.4530
[2022-07-08 05:48:28,477 callbacks.py:105 INFO train-abinet] epoch 9 iter 375800: loss = 0.5210,  smooth loss = 0.4579
[2022-07-08 05:49:10,468 callbacks.py:105 INFO train-abinet] epoch 9 iter 375850: loss = 0.3981,  smooth loss = 0.4540
[2022-07-08 05:49:52,795 callbacks.py:105 INFO train-abinet] epoch 9 iter 375900: loss = 0.4675,  smooth loss = 0.4531
[2022-07-08 05:50:33,923 callbacks.py:105 INFO train-abinet] epoch 9 iter 375950: loss = 0.4087,  smooth loss = 0.4604
[2022-07-08 05:51:15,247 callbacks.py:105 INFO train-abinet] epoch 9 iter 376000: loss = 0.4635,  smooth loss = 0.4597
[2022-07-08 05:51:56,980 callbacks.py:105 INFO train-abinet] epoch 9 iter 376050: loss = 0.4191,  smooth loss = 0.4466
[2022-07-08 05:52:38,513 callbacks.py:105 INFO train-abinet] epoch 9 iter 376100: loss = 0.5007,  smooth loss = 0.4562
[2022-07-08 05:53:21,063 callbacks.py:105 INFO train-abinet] epoch 9 iter 376150: loss = 0.4995,  smooth loss = 0.4557
[2022-07-08 05:54:02,356 callbacks.py:105 INFO train-abinet] epoch 9 iter 376200: loss = 0.4664,  smooth loss = 0.4661
[2022-07-08 05:54:44,215 callbacks.py:105 INFO train-abinet] epoch 9 iter 376250: loss = 0.3510,  smooth loss = 0.4544
[2022-07-08 05:55:26,085 callbacks.py:105 INFO train-abinet] epoch 9 iter 376300: loss = 0.3992,  smooth loss = 0.4601
[2022-07-08 05:56:08,002 callbacks.py:105 INFO train-abinet] epoch 9 iter 376350: loss = 0.4959,  smooth loss = 0.4501
[2022-07-08 05:56:49,641 callbacks.py:105 INFO train-abinet] epoch 9 iter 376400: loss = 0.3975,  smooth loss = 0.4476
[2022-07-08 05:57:31,436 callbacks.py:105 INFO train-abinet] epoch 9 iter 376450: loss = 0.4379,  smooth loss = 0.4521
[2022-07-08 05:58:12,850 callbacks.py:105 INFO train-abinet] epoch 9 iter 376500: loss = 0.3806,  smooth loss = 0.4439
[2022-07-08 05:58:54,962 callbacks.py:105 INFO train-abinet] epoch 9 iter 376550: loss = 0.4577,  smooth loss = 0.4519
[2022-07-08 05:59:36,663 callbacks.py:105 INFO train-abinet] epoch 9 iter 376600: loss = 0.4317,  smooth loss = 0.4548
[2022-07-08 06:00:18,345 callbacks.py:105 INFO train-abinet] epoch 9 iter 376650: loss = 0.5685,  smooth loss = 0.4688
[2022-07-08 06:00:59,747 callbacks.py:105 INFO train-abinet] epoch 9 iter 376700: loss = 0.4862,  smooth loss = 0.4660
[2022-07-08 06:01:42,096 callbacks.py:105 INFO train-abinet] epoch 9 iter 376750: loss = 0.5278,  smooth loss = 0.4641
[2022-07-08 06:02:23,945 callbacks.py:105 INFO train-abinet] epoch 9 iter 376800: loss = 0.4569,  smooth loss = 0.4559
[2022-07-08 06:03:14,769 callbacks.py:105 INFO train-abinet] epoch 9 iter 376850: loss = 0.3403,  smooth loss = 0.4557
[2022-07-08 06:03:56,243 callbacks.py:105 INFO train-abinet] epoch 9 iter 376900: loss = 0.4855,  smooth loss = 0.4443
[2022-07-08 06:04:37,997 callbacks.py:105 INFO train-abinet] epoch 9 iter 376950: loss = 0.4581,  smooth loss = 0.4428
[2022-07-08 06:05:19,860 callbacks.py:105 INFO train-abinet] epoch 9 iter 377000: loss = 0.6192,  smooth loss = 0.4662
[2022-07-08 06:06:01,353 callbacks.py:105 INFO train-abinet] epoch 9 iter 377050: loss = 0.3686,  smooth loss = 0.4444
[2022-07-08 06:06:42,385 callbacks.py:105 INFO train-abinet] epoch 9 iter 377100: loss = 0.4714,  smooth loss = 0.4608
[2022-07-08 06:07:23,830 callbacks.py:105 INFO train-abinet] epoch 9 iter 377150: loss = 0.4341,  smooth loss = 0.4595
[2022-07-08 06:08:05,364 callbacks.py:105 INFO train-abinet] epoch 9 iter 377200: loss = 0.3667,  smooth loss = 0.4477
[2022-07-08 06:08:46,369 callbacks.py:105 INFO train-abinet] epoch 9 iter 377250: loss = 0.4909,  smooth loss = 0.4548
[2022-07-08 06:09:27,143 callbacks.py:105 INFO train-abinet] epoch 9 iter 377300: loss = 0.5113,  smooth loss = 0.4575
[2022-07-08 06:10:07,958 callbacks.py:105 INFO train-abinet] epoch 9 iter 377350: loss = 0.4197,  smooth loss = 0.4457
[2022-07-08 06:10:48,617 callbacks.py:105 INFO train-abinet] epoch 9 iter 377400: loss = 0.4639,  smooth loss = 0.4423
[2022-07-08 06:11:29,781 callbacks.py:105 INFO train-abinet] epoch 9 iter 377450: loss = 0.4895,  smooth loss = 0.4473
[2022-07-08 06:12:10,612 callbacks.py:105 INFO train-abinet] epoch 9 iter 377500: loss = 0.3874,  smooth loss = 0.4507
[2022-07-08 06:12:52,980 callbacks.py:105 INFO train-abinet] epoch 9 iter 377550: loss = 0.5768,  smooth loss = 0.4554
[2022-07-08 06:13:34,148 callbacks.py:105 INFO train-abinet] epoch 9 iter 377600: loss = 0.3847,  smooth loss = 0.4497
[2022-07-08 06:14:15,171 callbacks.py:105 INFO train-abinet] epoch 9 iter 377650: loss = 0.4223,  smooth loss = 0.4426
[2022-07-08 06:14:56,146 callbacks.py:105 INFO train-abinet] epoch 9 iter 377700: loss = 0.4370,  smooth loss = 0.4603
[2022-07-08 06:15:38,038 callbacks.py:105 INFO train-abinet] epoch 9 iter 377750: loss = 0.5075,  smooth loss = 0.4627
[2022-07-08 06:16:18,724 callbacks.py:105 INFO train-abinet] epoch 9 iter 377800: loss = 0.4887,  smooth loss = 0.4579
[2022-07-08 06:17:02,147 callbacks.py:105 INFO train-abinet] epoch 9 iter 377850: loss = 0.4809,  smooth loss = 0.4622
[2022-07-08 06:17:43,554 callbacks.py:105 INFO train-abinet] epoch 9 iter 377900: loss = 0.4186,  smooth loss = 0.4666
[2022-07-08 06:18:27,721 callbacks.py:105 INFO train-abinet] epoch 9 iter 377950: loss = 0.5441,  smooth loss = 0.4701
[2022-07-08 06:19:09,432 callbacks.py:105 INFO train-abinet] epoch 9 iter 378000: loss = 0.4883,  smooth loss = 0.4594
[2022-07-08 06:19:09,433 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8540s
█[2022-07-08 06:19:23,943 callbacks.py:123 INFO train-abinet] epoch 9 iter 378000: eval loss = 1.1658,  ccr = 0.9653,  cwr = 0.9269,  ted = 1140.0000,  ned = 234.0225,  ted/w = 0.1573, 
[2022-07-08 06:19:23,945 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_378000
[2022-07-08 06:20:06,716 callbacks.py:105 INFO train-abinet] epoch 9 iter 378050: loss = 0.3256,  smooth loss = 0.4576
[2022-07-08 06:20:48,724 callbacks.py:105 INFO train-abinet] epoch 9 iter 378100: loss = 0.4692,  smooth loss = 0.4496
[2022-07-08 06:21:31,961 callbacks.py:105 INFO train-abinet] epoch 9 iter 378150: loss = 0.3994,  smooth loss = 0.4527
[2022-07-08 06:22:16,555 callbacks.py:105 INFO train-abinet] epoch 9 iter 378200: loss = 0.4961,  smooth loss = 0.4621
[2022-07-08 06:23:01,272 callbacks.py:105 INFO train-abinet] epoch 9 iter 378250: loss = 0.3783,  smooth loss = 0.4607
[2022-07-08 06:23:43,353 callbacks.py:105 INFO train-abinet] epoch 9 iter 378300: loss = 0.3695,  smooth loss = 0.4453
[2022-07-08 06:24:25,590 callbacks.py:105 INFO train-abinet] epoch 9 iter 378350: loss = 0.4765,  smooth loss = 0.4533
[2022-07-08 06:25:07,118 callbacks.py:105 INFO train-abinet] epoch 9 iter 378400: loss = 0.4678,  smooth loss = 0.4563
[2022-07-08 06:25:47,808 callbacks.py:105 INFO train-abinet] epoch 9 iter 378450: loss = 0.3545,  smooth loss = 0.4507
[2022-07-08 06:26:28,984 callbacks.py:105 INFO train-abinet] epoch 9 iter 378500: loss = 0.4213,  smooth loss = 0.4430
[2022-07-08 06:27:10,395 callbacks.py:105 INFO train-abinet] epoch 9 iter 378550: loss = 0.5713,  smooth loss = 0.4650
[2022-07-08 06:27:52,061 callbacks.py:105 INFO train-abinet] epoch 9 iter 378600: loss = 0.3491,  smooth loss = 0.4640
[2022-07-08 06:28:33,485 callbacks.py:105 INFO train-abinet] epoch 9 iter 378650: loss = 0.5486,  smooth loss = 0.4479
[2022-07-08 06:29:14,766 callbacks.py:105 INFO train-abinet] epoch 9 iter 378700: loss = 0.4951,  smooth loss = 0.4592
[2022-07-08 06:29:56,253 callbacks.py:105 INFO train-abinet] epoch 9 iter 378750: loss = 0.4918,  smooth loss = 0.4594
[2022-07-08 06:30:37,878 callbacks.py:105 INFO train-abinet] epoch 9 iter 378800: loss = 0.5198,  smooth loss = 0.4534
[2022-07-08 06:31:19,737 callbacks.py:105 INFO train-abinet] epoch 9 iter 378850: loss = 0.4629,  smooth loss = 0.4567
[2022-07-08 06:32:00,739 callbacks.py:105 INFO train-abinet] epoch 9 iter 378900: loss = 0.4754,  smooth loss = 0.4579
[2022-07-08 06:32:41,999 callbacks.py:105 INFO train-abinet] epoch 9 iter 378950: loss = 0.4075,  smooth loss = 0.4616
[2022-07-08 06:33:23,724 callbacks.py:105 INFO train-abinet] epoch 9 iter 379000: loss = 0.4344,  smooth loss = 0.4709
[2022-07-08 06:34:05,198 callbacks.py:105 INFO train-abinet] epoch 9 iter 379050: loss = 0.3985,  smooth loss = 0.4604
[2022-07-08 06:34:46,326 callbacks.py:105 INFO train-abinet] epoch 9 iter 379100: loss = 0.5082,  smooth loss = 0.4662
[2022-07-08 06:35:29,905 callbacks.py:105 INFO train-abinet] epoch 9 iter 379150: loss = 0.5485,  smooth loss = 0.4688
[2022-07-08 06:36:10,980 callbacks.py:105 INFO train-abinet] epoch 9 iter 379200: loss = 0.4443,  smooth loss = 0.4466
[2022-07-08 06:36:51,992 callbacks.py:105 INFO train-abinet] epoch 9 iter 379250: loss = 0.4542,  smooth loss = 0.4514
[2022-07-08 06:37:32,986 callbacks.py:105 INFO train-abinet] epoch 9 iter 379300: loss = 0.4630,  smooth loss = 0.4560
[2022-07-08 06:38:13,891 callbacks.py:105 INFO train-abinet] epoch 9 iter 379350: loss = 0.4740,  smooth loss = 0.4526
[2022-07-08 06:38:55,367 callbacks.py:105 INFO train-abinet] epoch 9 iter 379400: loss = 0.4587,  smooth loss = 0.4522
[2022-07-08 06:39:36,500 callbacks.py:105 INFO train-abinet] epoch 9 iter 379450: loss = 0.4736,  smooth loss = 0.4671
[2022-07-08 06:40:18,064 callbacks.py:105 INFO train-abinet] epoch 9 iter 379500: loss = 0.8390,  smooth loss = 0.4518
[2022-07-08 06:40:59,943 callbacks.py:105 INFO train-abinet] epoch 9 iter 379550: loss = 0.4495,  smooth loss = 0.4483
[2022-07-08 06:41:41,226 callbacks.py:105 INFO train-abinet] epoch 9 iter 379600: loss = 0.3683,  smooth loss = 0.4479
[2022-07-08 06:42:22,448 callbacks.py:105 INFO train-abinet] epoch 9 iter 379650: loss = 0.3713,  smooth loss = 0.4415
[2022-07-08 06:43:03,784 callbacks.py:105 INFO train-abinet] epoch 9 iter 379700: loss = 0.4214,  smooth loss = 0.4589
[2022-07-08 06:43:44,978 callbacks.py:105 INFO train-abinet] epoch 9 iter 379750: loss = 0.4633,  smooth loss = 0.4545
[2022-07-08 06:44:25,557 callbacks.py:105 INFO train-abinet] epoch 9 iter 379800: loss = 0.5433,  smooth loss = 0.4478
[2022-07-08 06:45:06,547 callbacks.py:105 INFO train-abinet] epoch 9 iter 379850: loss = 0.4715,  smooth loss = 0.4577
[2022-07-08 06:45:47,930 callbacks.py:105 INFO train-abinet] epoch 9 iter 379900: loss = 0.5004,  smooth loss = 0.4583
[2022-07-08 06:46:28,929 callbacks.py:105 INFO train-abinet] epoch 9 iter 379950: loss = 0.5169,  smooth loss = 0.4623
[2022-07-08 06:47:09,696 callbacks.py:105 INFO train-abinet] epoch 9 iter 380000: loss = 0.4162,  smooth loss = 0.4613
[2022-07-08 06:47:50,801 callbacks.py:105 INFO train-abinet] epoch 9 iter 380050: loss = 0.4342,  smooth loss = 0.4506
[2022-07-08 06:48:32,221 callbacks.py:105 INFO train-abinet] epoch 9 iter 380100: loss = 0.3830,  smooth loss = 0.4629
[2022-07-08 06:49:13,021 callbacks.py:105 INFO train-abinet] epoch 9 iter 380150: loss = 0.4108,  smooth loss = 0.4618
[2022-07-08 06:49:53,942 callbacks.py:105 INFO train-abinet] epoch 9 iter 380200: loss = 0.5545,  smooth loss = 0.4535
[2022-07-08 06:50:34,774 callbacks.py:105 INFO train-abinet] epoch 9 iter 380250: loss = 0.5152,  smooth loss = 0.4570
[2022-07-08 06:51:14,291 callbacks.py:105 INFO train-abinet] epoch 9 iter 380300: loss = 0.4610,  smooth loss = 0.4531
[2022-07-08 06:51:54,928 callbacks.py:105 INFO train-abinet] epoch 9 iter 380350: loss = 0.5237,  smooth loss = 0.4569
[2022-07-08 06:52:36,606 callbacks.py:105 INFO train-abinet] epoch 9 iter 380400: loss = 0.4985,  smooth loss = 0.4469
[2022-07-08 06:53:17,810 callbacks.py:105 INFO train-abinet] epoch 9 iter 380450: loss = 0.4156,  smooth loss = 0.4465
[2022-07-08 06:53:59,269 callbacks.py:105 INFO train-abinet] epoch 9 iter 380500: loss = 0.3493,  smooth loss = 0.4534
[2022-07-08 06:54:39,256 callbacks.py:105 INFO train-abinet] epoch 9 iter 380550: loss = 0.3740,  smooth loss = 0.4540
[2022-07-08 06:55:20,606 callbacks.py:105 INFO train-abinet] epoch 9 iter 380600: loss = 0.3912,  smooth loss = 0.4490
[2022-07-08 06:56:02,436 callbacks.py:105 INFO train-abinet] epoch 9 iter 380650: loss = 0.5223,  smooth loss = 0.4544
[2022-07-08 06:56:44,301 callbacks.py:105 INFO train-abinet] epoch 9 iter 380700: loss = 0.4178,  smooth loss = 0.4540
[2022-07-08 06:57:26,761 callbacks.py:105 INFO train-abinet] epoch 9 iter 380750: loss = 0.3747,  smooth loss = 0.4622
[2022-07-08 06:58:08,269 callbacks.py:105 INFO train-abinet] epoch 9 iter 380800: loss = 0.4170,  smooth loss = 0.4616
[2022-07-08 06:58:49,689 callbacks.py:105 INFO train-abinet] epoch 9 iter 380850: loss = 0.3879,  smooth loss = 0.4497
[2022-07-08 06:59:30,391 callbacks.py:105 INFO train-abinet] epoch 9 iter 380900: loss = 0.5351,  smooth loss = 0.4521
[2022-07-08 07:00:10,476 callbacks.py:105 INFO train-abinet] epoch 9 iter 380950: loss = 0.4590,  smooth loss = 0.4495
[2022-07-08 07:00:51,911 callbacks.py:105 INFO train-abinet] epoch 9 iter 381000: loss = 0.5138,  smooth loss = 0.4575
[2022-07-08 07:00:51,912 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8539s
█[2022-07-08 07:01:06,395 callbacks.py:123 INFO train-abinet] epoch 9 iter 381000: eval loss = 1.1754,  ccr = 0.9649,  cwr = 0.9281,  ted = 1133.0000,  ned = 230.3291,  ted/w = 0.1563, 
[2022-07-08 07:01:06,396 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_381000
[2022-07-08 07:01:49,140 callbacks.py:105 INFO train-abinet] epoch 9 iter 381050: loss = 0.4222,  smooth loss = 0.4586
[2022-07-08 07:02:35,661 callbacks.py:105 INFO train-abinet] epoch 9 iter 381100: loss = 0.4331,  smooth loss = 0.4563
[2022-07-08 07:03:17,555 callbacks.py:105 INFO train-abinet] epoch 9 iter 381150: loss = 0.4509,  smooth loss = 0.4639
[2022-07-08 07:03:59,933 callbacks.py:105 INFO train-abinet] epoch 9 iter 381200: loss = 0.4533,  smooth loss = 0.4591
[2022-07-08 07:04:45,463 callbacks.py:105 INFO train-abinet] epoch 9 iter 381250: loss = 0.4552,  smooth loss = 0.4616
[2022-07-08 07:05:26,676 callbacks.py:105 INFO train-abinet] epoch 9 iter 381300: loss = 0.2968,  smooth loss = 0.4486
[2022-07-08 07:06:08,102 callbacks.py:105 INFO train-abinet] epoch 9 iter 381350: loss = 0.4670,  smooth loss = 0.4525
[2022-07-08 07:06:49,459 callbacks.py:105 INFO train-abinet] epoch 9 iter 381400: loss = 0.5980,  smooth loss = 0.4483
[2022-07-08 07:07:31,353 callbacks.py:105 INFO train-abinet] epoch 9 iter 381450: loss = 0.3971,  smooth loss = 0.4478
[2022-07-08 07:08:13,029 callbacks.py:105 INFO train-abinet] epoch 9 iter 381500: loss = 0.3802,  smooth loss = 0.4531
[2022-07-08 07:08:54,838 callbacks.py:105 INFO train-abinet] epoch 9 iter 381550: loss = 0.4682,  smooth loss = 0.4431
[2022-07-08 07:09:36,488 callbacks.py:105 INFO train-abinet] epoch 9 iter 381600: loss = 0.4737,  smooth loss = 0.4465
[2022-07-08 07:10:19,295 callbacks.py:105 INFO train-abinet] epoch 9 iter 381650: loss = 0.5041,  smooth loss = 0.4453
[2022-07-08 07:11:04,961 callbacks.py:105 INFO train-abinet] epoch 9 iter 381700: loss = 0.3522,  smooth loss = 0.4577
[2022-07-08 07:11:46,222 callbacks.py:105 INFO train-abinet] epoch 9 iter 381750: loss = 0.4207,  smooth loss = 0.4523
[2022-07-08 07:12:27,661 callbacks.py:105 INFO train-abinet] epoch 9 iter 381800: loss = 0.4522,  smooth loss = 0.4545
[2022-07-08 07:13:08,115 callbacks.py:105 INFO train-abinet] epoch 9 iter 381850: loss = 0.4817,  smooth loss = 0.4474
[2022-07-08 07:13:49,353 callbacks.py:105 INFO train-abinet] epoch 9 iter 381900: loss = 0.4364,  smooth loss = 0.4673
[2022-07-08 07:14:30,619 callbacks.py:105 INFO train-abinet] epoch 9 iter 381950: loss = 0.3801,  smooth loss = 0.4626
[2022-07-08 07:15:17,127 callbacks.py:105 INFO train-abinet] epoch 9 iter 382000: loss = 0.4193,  smooth loss = 0.4481
[2022-07-08 07:15:58,115 callbacks.py:105 INFO train-abinet] epoch 9 iter 382050: loss = 0.5003,  smooth loss = 0.4582
[2022-07-08 07:16:41,150 callbacks.py:105 INFO train-abinet] epoch 9 iter 382100: loss = 0.4436,  smooth loss = 0.4617
[2022-07-08 07:17:24,288 callbacks.py:105 INFO train-abinet] epoch 9 iter 382150: loss = 0.5195,  smooth loss = 0.4628
[2022-07-08 07:18:06,834 callbacks.py:105 INFO train-abinet] epoch 9 iter 382200: loss = 0.5469,  smooth loss = 0.4495
[2022-07-08 07:18:47,800 callbacks.py:105 INFO train-abinet] epoch 9 iter 382250: loss = 0.3993,  smooth loss = 0.4533
[2022-07-08 07:19:28,654 callbacks.py:105 INFO train-abinet] epoch 9 iter 382300: loss = 0.4949,  smooth loss = 0.4529
[2022-07-08 07:20:10,010 callbacks.py:105 INFO train-abinet] epoch 9 iter 382350: loss = 0.4499,  smooth loss = 0.4545
[2022-07-08 07:20:51,111 callbacks.py:105 INFO train-abinet] epoch 9 iter 382400: loss = 0.4674,  smooth loss = 0.4407
[2022-07-08 07:21:33,023 callbacks.py:105 INFO train-abinet] epoch 9 iter 382450: loss = 0.5296,  smooth loss = 0.4498
[2022-07-08 07:22:13,901 callbacks.py:105 INFO train-abinet] epoch 9 iter 382500: loss = 0.3839,  smooth loss = 0.4544
[2022-07-08 07:22:55,413 callbacks.py:105 INFO train-abinet] epoch 9 iter 382550: loss = 0.4377,  smooth loss = 0.4576
[2022-07-08 07:23:36,440 callbacks.py:105 INFO train-abinet] epoch 9 iter 382600: loss = 0.4181,  smooth loss = 0.4486
[2022-07-08 07:24:18,140 callbacks.py:105 INFO train-abinet] epoch 9 iter 382650: loss = 0.5276,  smooth loss = 0.4548
[2022-07-08 07:24:59,419 callbacks.py:105 INFO train-abinet] epoch 9 iter 382700: loss = 0.5695,  smooth loss = 0.4556
[2022-07-08 07:25:41,088 callbacks.py:105 INFO train-abinet] epoch 9 iter 382750: loss = 0.3797,  smooth loss = 0.4530
[2022-07-08 07:26:22,260 callbacks.py:105 INFO train-abinet] epoch 9 iter 382800: loss = 0.5226,  smooth loss = 0.4567
[2022-07-08 07:27:03,228 callbacks.py:105 INFO train-abinet] epoch 9 iter 382850: loss = 0.4775,  smooth loss = 0.4549
[2022-07-08 07:27:44,136 callbacks.py:105 INFO train-abinet] epoch 9 iter 382900: loss = 0.3863,  smooth loss = 0.4493
[2022-07-08 07:28:24,836 callbacks.py:105 INFO train-abinet] epoch 9 iter 382950: loss = 0.5132,  smooth loss = 0.4556
[2022-07-08 07:29:07,368 callbacks.py:105 INFO train-abinet] epoch 9 iter 383000: loss = 0.6234,  smooth loss = 0.4579
[2022-07-08 07:29:53,701 callbacks.py:105 INFO train-abinet] epoch 9 iter 383050: loss = 0.5361,  smooth loss = 0.4619
[2022-07-08 07:30:39,893 callbacks.py:105 INFO train-abinet] epoch 9 iter 383100: loss = 0.4107,  smooth loss = 0.4447
[2022-07-08 07:31:24,976 callbacks.py:105 INFO train-abinet] epoch 9 iter 383150: loss = 0.5364,  smooth loss = 0.4637
[2022-07-08 07:32:06,410 callbacks.py:105 INFO train-abinet] epoch 9 iter 383200: loss = 0.5337,  smooth loss = 0.4546
[2022-07-08 07:32:47,950 callbacks.py:105 INFO train-abinet] epoch 9 iter 383250: loss = 0.4251,  smooth loss = 0.4520
[2022-07-08 07:33:29,119 callbacks.py:105 INFO train-abinet] epoch 9 iter 383300: loss = 0.5399,  smooth loss = 0.4725
[2022-07-08 07:34:10,174 callbacks.py:105 INFO train-abinet] epoch 9 iter 383350: loss = 0.4870,  smooth loss = 0.4625
[2022-07-08 07:34:51,150 callbacks.py:105 INFO train-abinet] epoch 9 iter 383400: loss = 0.4819,  smooth loss = 0.4602
[2022-07-08 07:35:32,317 callbacks.py:105 INFO train-abinet] epoch 9 iter 383450: loss = 0.5651,  smooth loss = 0.4539
[2022-07-08 07:36:13,192 callbacks.py:105 INFO train-abinet] epoch 9 iter 383500: loss = 0.3791,  smooth loss = 0.4548
[2022-07-08 07:36:54,889 callbacks.py:105 INFO train-abinet] epoch 9 iter 383550: loss = 0.3836,  smooth loss = 0.4573
[2022-07-08 07:37:35,520 callbacks.py:105 INFO train-abinet] epoch 9 iter 383600: loss = 0.4653,  smooth loss = 0.4515
[2022-07-08 07:38:16,381 callbacks.py:105 INFO train-abinet] epoch 9 iter 383650: loss = 0.6040,  smooth loss = 0.4592
[2022-07-08 07:38:57,328 callbacks.py:105 INFO train-abinet] epoch 9 iter 383700: loss = 0.3364,  smooth loss = 0.4552
[2022-07-08 07:39:38,218 callbacks.py:105 INFO train-abinet] epoch 9 iter 383750: loss = 0.3193,  smooth loss = 0.4562
[2022-07-08 07:40:18,989 callbacks.py:105 INFO train-abinet] epoch 9 iter 383800: loss = 0.4402,  smooth loss = 0.4636
[2022-07-08 07:41:00,323 callbacks.py:105 INFO train-abinet] epoch 9 iter 383850: loss = 0.5282,  smooth loss = 0.4575
[2022-07-08 07:41:41,925 callbacks.py:105 INFO train-abinet] epoch 9 iter 383900: loss = 0.4438,  smooth loss = 0.4633
[2022-07-08 07:42:23,084 callbacks.py:105 INFO train-abinet] epoch 9 iter 383950: loss = 0.4858,  smooth loss = 0.4748
[2022-07-08 07:43:04,548 callbacks.py:105 INFO train-abinet] epoch 9 iter 384000: loss = 0.4374,  smooth loss = 0.4578
[2022-07-08 07:43:04,549 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8538s
█[2022-07-08 07:43:18,924 callbacks.py:123 INFO train-abinet] epoch 9 iter 384000: eval loss = 1.1734,  ccr = 0.9646,  cwr = 0.9266,  ted = 1151.0000,  ned = 232.1961,  ted/w = 0.1588, 
[2022-07-08 07:43:18,926 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_384000
[2022-07-08 07:44:00,206 callbacks.py:105 INFO train-abinet] epoch 9 iter 384050: loss = 0.4369,  smooth loss = 0.4602
[2022-07-08 07:44:41,181 callbacks.py:105 INFO train-abinet] epoch 9 iter 384100: loss = 0.5465,  smooth loss = 0.4681
[2022-07-08 07:45:22,113 callbacks.py:105 INFO train-abinet] epoch 9 iter 384150: loss = 0.5028,  smooth loss = 0.4537
[2022-07-08 07:46:02,890 callbacks.py:105 INFO train-abinet] epoch 9 iter 384200: loss = 0.4136,  smooth loss = 0.4638
[2022-07-08 07:46:44,028 callbacks.py:105 INFO train-abinet] epoch 9 iter 384250: loss = 0.5562,  smooth loss = 0.4575
[2022-07-08 07:47:24,473 callbacks.py:105 INFO train-abinet] epoch 9 iter 384300: loss = 0.5098,  smooth loss = 0.4491
[2022-07-08 07:48:05,834 callbacks.py:105 INFO train-abinet] epoch 9 iter 384350: loss = 0.5360,  smooth loss = 0.4573
[2022-07-08 07:48:46,846 callbacks.py:105 INFO train-abinet] epoch 9 iter 384400: loss = 0.4697,  smooth loss = 0.4720
[2022-07-08 07:49:28,345 callbacks.py:105 INFO train-abinet] epoch 9 iter 384450: loss = 0.3994,  smooth loss = 0.4550
[2022-07-08 07:50:08,720 callbacks.py:105 INFO train-abinet] epoch 9 iter 384500: loss = 0.3031,  smooth loss = 0.4388
[2022-07-08 07:50:50,080 callbacks.py:105 INFO train-abinet] epoch 9 iter 384550: loss = 0.4362,  smooth loss = 0.4440
[2022-07-08 07:51:31,607 callbacks.py:105 INFO train-abinet] epoch 9 iter 384600: loss = 0.3961,  smooth loss = 0.4497
[2022-07-08 07:52:12,847 callbacks.py:105 INFO train-abinet] epoch 9 iter 384650: loss = 0.5775,  smooth loss = 0.4542
[2022-07-08 07:52:53,975 callbacks.py:105 INFO train-abinet] epoch 9 iter 384700: loss = 0.4727,  smooth loss = 0.4412
[2022-07-08 07:53:34,489 callbacks.py:105 INFO train-abinet] epoch 9 iter 384750: loss = 0.4723,  smooth loss = 0.4625
[2022-07-08 07:54:15,947 callbacks.py:105 INFO train-abinet] epoch 9 iter 384800: loss = 0.5304,  smooth loss = 0.4546
[2022-07-08 07:54:57,145 callbacks.py:105 INFO train-abinet] epoch 9 iter 384850: loss = 0.4931,  smooth loss = 0.4537
[2022-07-08 07:55:38,138 callbacks.py:105 INFO train-abinet] epoch 9 iter 384900: loss = 0.5217,  smooth loss = 0.4588
[2022-07-08 07:56:19,487 callbacks.py:105 INFO train-abinet] epoch 9 iter 384950: loss = 0.3480,  smooth loss = 0.4518
[2022-07-08 07:57:01,235 callbacks.py:105 INFO train-abinet] epoch 9 iter 385000: loss = 0.4588,  smooth loss = 0.4619
[2022-07-08 07:57:42,746 callbacks.py:105 INFO train-abinet] epoch 9 iter 385050: loss = 0.3678,  smooth loss = 0.4577
[2022-07-08 07:58:23,290 callbacks.py:105 INFO train-abinet] epoch 9 iter 385100: loss = 0.4095,  smooth loss = 0.4597
[2022-07-08 07:59:04,225 callbacks.py:105 INFO train-abinet] epoch 9 iter 385150: loss = 0.4626,  smooth loss = 0.4610
[2022-07-08 07:59:45,096 callbacks.py:105 INFO train-abinet] epoch 9 iter 385200: loss = 0.4665,  smooth loss = 0.4566
[2022-07-08 08:00:26,190 callbacks.py:105 INFO train-abinet] epoch 9 iter 385250: loss = 0.4755,  smooth loss = 0.4532
[2022-07-08 08:01:07,025 callbacks.py:105 INFO train-abinet] epoch 9 iter 385300: loss = 0.5522,  smooth loss = 0.4520
[2022-07-08 08:01:48,338 callbacks.py:105 INFO train-abinet] epoch 9 iter 385350: loss = 0.4047,  smooth loss = 0.4561
[2022-07-08 08:02:29,698 callbacks.py:105 INFO train-abinet] epoch 9 iter 385400: loss = 0.3861,  smooth loss = 0.4670
[2022-07-08 08:03:11,126 callbacks.py:105 INFO train-abinet] epoch 9 iter 385450: loss = 0.3978,  smooth loss = 0.4499
[2022-07-08 08:03:52,729 callbacks.py:105 INFO train-abinet] epoch 9 iter 385500: loss = 0.4908,  smooth loss = 0.4402
[2022-07-08 08:04:33,415 callbacks.py:105 INFO train-abinet] epoch 9 iter 385550: loss = 0.4433,  smooth loss = 0.4326
[2022-07-08 08:05:14,212 callbacks.py:105 INFO train-abinet] epoch 9 iter 385600: loss = 0.3917,  smooth loss = 0.4357
[2022-07-08 08:05:55,029 callbacks.py:105 INFO train-abinet] epoch 9 iter 385650: loss = 0.4049,  smooth loss = 0.4579
[2022-07-08 08:06:36,196 callbacks.py:105 INFO train-abinet] epoch 9 iter 385700: loss = 0.4023,  smooth loss = 0.4596
[2022-07-08 08:07:17,528 callbacks.py:105 INFO train-abinet] epoch 9 iter 385750: loss = 0.4956,  smooth loss = 0.4502
[2022-07-08 08:07:58,460 callbacks.py:105 INFO train-abinet] epoch 9 iter 385800: loss = 0.4818,  smooth loss = 0.4499
[2022-07-08 08:08:39,363 callbacks.py:105 INFO train-abinet] epoch 9 iter 385850: loss = 0.3206,  smooth loss = 0.4511
[2022-07-08 08:09:20,419 callbacks.py:105 INFO train-abinet] epoch 9 iter 385900: loss = 0.5236,  smooth loss = 0.4416
[2022-07-08 08:10:01,442 callbacks.py:105 INFO train-abinet] epoch 9 iter 385950: loss = 0.3544,  smooth loss = 0.4394
[2022-07-08 08:10:42,554 callbacks.py:105 INFO train-abinet] epoch 9 iter 386000: loss = 0.3965,  smooth loss = 0.4526
[2022-07-08 08:11:23,585 callbacks.py:105 INFO train-abinet] epoch 9 iter 386050: loss = 0.4252,  smooth loss = 0.4532
[2022-07-08 08:12:05,231 callbacks.py:105 INFO train-abinet] epoch 9 iter 386100: loss = 0.4262,  smooth loss = 0.4493
[2022-07-08 08:12:46,443 callbacks.py:105 INFO train-abinet] epoch 9 iter 386150: loss = 0.2845,  smooth loss = 0.4458
[2022-07-08 08:13:27,928 callbacks.py:105 INFO train-abinet] epoch 9 iter 386200: loss = 0.5002,  smooth loss = 0.4551
[2022-07-08 08:14:08,813 callbacks.py:105 INFO train-abinet] epoch 9 iter 386250: loss = 0.4452,  smooth loss = 0.4578
[2022-07-08 08:14:49,990 callbacks.py:105 INFO train-abinet] epoch 9 iter 386300: loss = 0.4345,  smooth loss = 0.4597
[2022-07-08 08:15:30,951 callbacks.py:105 INFO train-abinet] epoch 9 iter 386350: loss = 0.5302,  smooth loss = 0.4601
[2022-07-08 08:16:11,939 callbacks.py:105 INFO train-abinet] epoch 9 iter 386400: loss = 0.4950,  smooth loss = 0.4585
[2022-07-08 08:16:53,583 callbacks.py:105 INFO train-abinet] epoch 9 iter 386450: loss = 0.6143,  smooth loss = 0.4396
[2022-07-08 08:17:34,639 callbacks.py:105 INFO train-abinet] epoch 9 iter 386500: loss = 0.4470,  smooth loss = 0.4570
[2022-07-08 08:18:15,836 callbacks.py:105 INFO train-abinet] epoch 9 iter 386550: loss = 0.4228,  smooth loss = 0.4593
[2022-07-08 08:18:56,865 callbacks.py:105 INFO train-abinet] epoch 9 iter 386600: loss = 0.4641,  smooth loss = 0.4533
[2022-07-08 08:19:37,694 callbacks.py:105 INFO train-abinet] epoch 9 iter 386650: loss = 0.3787,  smooth loss = 0.4537
[2022-07-08 08:20:18,715 callbacks.py:105 INFO train-abinet] epoch 9 iter 386700: loss = 0.4687,  smooth loss = 0.4645
[2022-07-08 08:21:00,014 callbacks.py:105 INFO train-abinet] epoch 9 iter 386750: loss = 0.4352,  smooth loss = 0.4727
[2022-07-08 08:21:40,927 callbacks.py:105 INFO train-abinet] epoch 9 iter 386800: loss = 0.3455,  smooth loss = 0.4591
[2022-07-08 08:22:21,862 callbacks.py:105 INFO train-abinet] epoch 9 iter 386850: loss = 0.4176,  smooth loss = 0.4525
[2022-07-08 08:23:02,669 callbacks.py:105 INFO train-abinet] epoch 9 iter 386900: loss = 0.5177,  smooth loss = 0.4588
[2022-07-08 08:23:43,497 callbacks.py:105 INFO train-abinet] epoch 9 iter 386950: loss = 0.4102,  smooth loss = 0.4565
[2022-07-08 08:24:24,148 callbacks.py:105 INFO train-abinet] epoch 9 iter 387000: loss = 0.5845,  smooth loss = 0.4492
[2022-07-08 08:24:24,148 callbacks.py:114 INFO train-abinet] average data time = 0.0044s, average running time = 0.8535s
█[2022-07-08 08:24:38,529 callbacks.py:123 INFO train-abinet] epoch 9 iter 387000: eval loss = 1.1596,  ccr = 0.9655,  cwr = 0.9292,  ted = 1133.0000,  ned = 228.1953,  ted/w = 0.1563, 
[2022-07-08 08:24:38,531 callbacks.py:130 INFO train-abinet] Better model found at epoch 9, iter 387000 with accuracy value: 0.9292.
[2022-07-08 08:24:39,695 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_387000
[2022-07-08 08:25:21,418 callbacks.py:105 INFO train-abinet] epoch 9 iter 387050: loss = 0.5322,  smooth loss = 0.4598
[2022-07-08 08:26:02,150 callbacks.py:105 INFO train-abinet] epoch 9 iter 387100: loss = 0.4541,  smooth loss = 0.4508
[2022-07-08 08:26:42,183 callbacks.py:105 INFO train-abinet] epoch 9 iter 387150: loss = 0.4368,  smooth loss = 0.4453
[2022-07-08 08:27:23,004 callbacks.py:105 INFO train-abinet] epoch 9 iter 387200: loss = 0.5086,  smooth loss = 0.4500
[2022-07-08 08:28:03,941 callbacks.py:105 INFO train-abinet] epoch 9 iter 387250: loss = 0.3898,  smooth loss = 0.4519
[2022-07-08 08:28:44,845 callbacks.py:105 INFO train-abinet] epoch 9 iter 387300: loss = 0.4916,  smooth loss = 0.4594
[2022-07-08 08:29:25,649 callbacks.py:105 INFO train-abinet] epoch 9 iter 387350: loss = 0.4649,  smooth loss = 0.4490
[2022-07-08 08:30:07,045 callbacks.py:105 INFO train-abinet] epoch 9 iter 387400: loss = 0.4046,  smooth loss = 0.4544
[2022-07-08 08:30:48,441 callbacks.py:105 INFO train-abinet] epoch 9 iter 387450: loss = 0.3406,  smooth loss = 0.4565
[2022-07-08 08:31:30,093 callbacks.py:105 INFO train-abinet] epoch 9 iter 387500: loss = 0.4591,  smooth loss = 0.4453
[2022-07-08 08:32:10,830 callbacks.py:105 INFO train-abinet] epoch 9 iter 387550: loss = 0.5932,  smooth loss = 0.4504
[2022-07-08 08:32:52,448 callbacks.py:105 INFO train-abinet] epoch 9 iter 387600: loss = 0.4530,  smooth loss = 0.4527
[2022-07-08 08:33:34,040 callbacks.py:105 INFO train-abinet] epoch 9 iter 387650: loss = 0.4080,  smooth loss = 0.4432
[2022-07-08 08:34:15,827 callbacks.py:105 INFO train-abinet] epoch 9 iter 387700: loss = 0.5437,  smooth loss = 0.4587
[2022-07-08 08:34:56,653 callbacks.py:105 INFO train-abinet] epoch 9 iter 387750: loss = 0.4515,  smooth loss = 0.4526
[2022-07-08 08:35:38,109 callbacks.py:105 INFO train-abinet] epoch 9 iter 387800: loss = 0.3942,  smooth loss = 0.4515
[2022-07-08 08:36:19,525 callbacks.py:105 INFO train-abinet] epoch 9 iter 387850: loss = 0.4681,  smooth loss = 0.4383
[2022-07-08 08:37:00,760 callbacks.py:105 INFO train-abinet] epoch 9 iter 387900: loss = 0.5197,  smooth loss = 0.4501
[2022-07-08 08:37:42,100 callbacks.py:105 INFO train-abinet] epoch 9 iter 387950: loss = 0.5682,  smooth loss = 0.4612
[2022-07-08 08:38:22,674 callbacks.py:105 INFO train-abinet] epoch 9 iter 388000: loss = 0.5303,  smooth loss = 0.4538
[2022-07-08 08:39:03,489 callbacks.py:105 INFO train-abinet] epoch 9 iter 388050: loss = 0.4883,  smooth loss = 0.4545
[2022-07-08 08:39:44,921 callbacks.py:105 INFO train-abinet] epoch 9 iter 388100: loss = 0.5411,  smooth loss = 0.4633
[2022-07-08 08:40:26,277 callbacks.py:105 INFO train-abinet] epoch 9 iter 388150: loss = 0.5040,  smooth loss = 0.4709
[2022-07-08 08:41:06,960 callbacks.py:105 INFO train-abinet] epoch 9 iter 388200: loss = 0.4300,  smooth loss = 0.4572
[2022-07-08 08:41:48,225 callbacks.py:105 INFO train-abinet] epoch 9 iter 388250: loss = 0.2387,  smooth loss = 0.4425
[2022-07-08 08:42:29,789 callbacks.py:105 INFO train-abinet] epoch 9 iter 388300: loss = 0.4777,  smooth loss = 0.4519
[2022-07-08 08:43:11,158 callbacks.py:105 INFO train-abinet] epoch 9 iter 388350: loss = 0.3880,  smooth loss = 0.4634
[2022-07-08 08:43:52,530 callbacks.py:105 INFO train-abinet] epoch 9 iter 388400: loss = 0.4145,  smooth loss = 0.4517
[2022-07-08 08:44:33,375 callbacks.py:105 INFO train-abinet] epoch 9 iter 388450: loss = 0.5066,  smooth loss = 0.4478
[2022-07-08 08:45:14,668 callbacks.py:105 INFO train-abinet] epoch 9 iter 388500: loss = 0.5067,  smooth loss = 0.4552
[2022-07-08 08:45:56,105 callbacks.py:105 INFO train-abinet] epoch 9 iter 388550: loss = 0.4786,  smooth loss = 0.4434
[2022-07-08 08:46:37,531 callbacks.py:105 INFO train-abinet] epoch 9 iter 388600: loss = 0.3715,  smooth loss = 0.4392
[2022-07-08 08:47:18,423 callbacks.py:105 INFO train-abinet] epoch 9 iter 388650: loss = 0.4222,  smooth loss = 0.4538
[2022-07-08 08:47:59,776 callbacks.py:105 INFO train-abinet] epoch 9 iter 388700: loss = 0.3203,  smooth loss = 0.4619
[2022-07-08 08:48:41,303 callbacks.py:105 INFO train-abinet] epoch 9 iter 388750: loss = 0.3458,  smooth loss = 0.4614
[2022-07-08 08:49:22,736 callbacks.py:105 INFO train-abinet] epoch 9 iter 388800: loss = 0.4295,  smooth loss = 0.4649
[2022-07-08 08:50:04,503 callbacks.py:105 INFO train-abinet] epoch 9 iter 388850: loss = 0.3793,  smooth loss = 0.4575
[2022-07-08 08:50:45,245 callbacks.py:105 INFO train-abinet] epoch 9 iter 388900: loss = 0.3832,  smooth loss = 0.4660
[2022-07-08 08:51:26,807 callbacks.py:105 INFO train-abinet] epoch 9 iter 388950: loss = 0.6412,  smooth loss = 0.4651
[2022-07-08 08:52:08,232 callbacks.py:105 INFO train-abinet] epoch 9 iter 389000: loss = 0.4082,  smooth loss = 0.4569
[2022-07-08 08:52:49,407 callbacks.py:105 INFO train-abinet] epoch 9 iter 389050: loss = 0.4278,  smooth loss = 0.4502
[2022-07-08 08:53:30,285 callbacks.py:105 INFO train-abinet] epoch 9 iter 389100: loss = 0.4188,  smooth loss = 0.4536
[2022-07-08 08:54:11,918 callbacks.py:105 INFO train-abinet] epoch 9 iter 389150: loss = 0.4447,  smooth loss = 0.4544
[2022-07-08 08:54:53,336 callbacks.py:105 INFO train-abinet] epoch 9 iter 389200: loss = 0.6386,  smooth loss = 0.4608
[2022-07-08 08:55:34,758 callbacks.py:105 INFO train-abinet] epoch 9 iter 389250: loss = 0.4055,  smooth loss = 0.4628
[2022-07-08 08:56:16,467 callbacks.py:105 INFO train-abinet] epoch 9 iter 389300: loss = 0.4889,  smooth loss = 0.4674
[2022-07-08 08:56:57,019 callbacks.py:105 INFO train-abinet] epoch 9 iter 389350: loss = 0.3773,  smooth loss = 0.4469
[2022-07-08 08:57:38,455 callbacks.py:105 INFO train-abinet] epoch 9 iter 389400: loss = 0.3427,  smooth loss = 0.4448
[2022-07-08 08:58:19,764 callbacks.py:105 INFO train-abinet] epoch 9 iter 389450: loss = 0.5580,  smooth loss = 0.4469
[2022-07-08 08:59:01,141 callbacks.py:105 INFO train-abinet] epoch 9 iter 389500: loss = 0.4386,  smooth loss = 0.4466
[2022-07-08 08:59:42,469 callbacks.py:105 INFO train-abinet] epoch 9 iter 389550: loss = 0.3948,  smooth loss = 0.4576
[2022-07-08 09:00:23,407 callbacks.py:105 INFO train-abinet] epoch 9 iter 389600: loss = 0.4616,  smooth loss = 0.4667
[2022-07-08 09:01:04,347 callbacks.py:105 INFO train-abinet] epoch 9 iter 389650: loss = 0.3856,  smooth loss = 0.4612
[2022-07-08 09:01:45,108 callbacks.py:105 INFO train-abinet] epoch 9 iter 389700: loss = 0.5152,  smooth loss = 0.4475
[2022-07-08 09:02:25,846 callbacks.py:105 INFO train-abinet] epoch 9 iter 389750: loss = 0.5401,  smooth loss = 0.4505
[2022-07-08 09:03:06,707 callbacks.py:105 INFO train-abinet] epoch 9 iter 389800: loss = 0.5025,  smooth loss = 0.4549
[2022-07-08 09:03:48,141 callbacks.py:105 INFO train-abinet] epoch 9 iter 389850: loss = 0.4373,  smooth loss = 0.4598
[2022-07-08 09:04:29,177 callbacks.py:105 INFO train-abinet] epoch 9 iter 389900: loss = 0.3774,  smooth loss = 0.4516
[2022-07-08 09:05:09,778 callbacks.py:105 INFO train-abinet] epoch 9 iter 389950: loss = 0.5075,  smooth loss = 0.4470
[2022-07-08 09:05:50,635 callbacks.py:105 INFO train-abinet] epoch 9 iter 390000: loss = 0.4250,  smooth loss = 0.4433
[2022-07-08 09:05:50,636 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8533s
█[2022-07-08 09:06:04,430 callbacks.py:123 INFO train-abinet] epoch 9 iter 390000: eval loss = 1.1717,  ccr = 0.9657,  cwr = 0.9276,  ted = 1133.0000,  ned = 230.8130,  ted/w = 0.1563, 
[2022-07-08 09:06:04,432 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_390000
[2022-07-08 09:06:46,306 callbacks.py:105 INFO train-abinet] epoch 9 iter 390050: loss = 0.4347,  smooth loss = 0.4531
[2022-07-08 09:07:27,212 callbacks.py:105 INFO train-abinet] epoch 9 iter 390100: loss = 0.6452,  smooth loss = 0.4575
[2022-07-08 09:08:08,043 callbacks.py:105 INFO train-abinet] epoch 9 iter 390150: loss = 0.5779,  smooth loss = 0.4579
[2022-07-08 09:08:48,795 callbacks.py:105 INFO train-abinet] epoch 9 iter 390200: loss = 0.3786,  smooth loss = 0.4547
[2022-07-08 09:09:29,594 callbacks.py:105 INFO train-abinet] epoch 9 iter 390250: loss = 0.4626,  smooth loss = 0.4486
[2022-07-08 09:10:10,273 callbacks.py:105 INFO train-abinet] epoch 9 iter 390300: loss = 0.4237,  smooth loss = 0.4634
[2022-07-08 09:10:51,484 callbacks.py:105 INFO train-abinet] epoch 9 iter 390350: loss = 0.5460,  smooth loss = 0.4561
[2022-07-08 09:11:32,433 callbacks.py:105 INFO train-abinet] epoch 9 iter 390400: loss = 0.5626,  smooth loss = 0.4575
[2022-07-08 09:12:12,964 callbacks.py:105 INFO train-abinet] epoch 9 iter 390450: loss = 0.4797,  smooth loss = 0.4596
[2022-07-08 09:12:53,516 callbacks.py:105 INFO train-abinet] epoch 9 iter 390500: loss = 0.4958,  smooth loss = 0.4549
[2022-07-08 09:13:34,711 callbacks.py:105 INFO train-abinet] epoch 9 iter 390550: loss = 0.3668,  smooth loss = 0.4469
[2022-07-08 09:14:15,203 callbacks.py:105 INFO train-abinet] epoch 9 iter 390600: loss = 0.4312,  smooth loss = 0.4449
[2022-07-08 09:14:55,881 callbacks.py:105 INFO train-abinet] epoch 9 iter 390650: loss = 0.5156,  smooth loss = 0.4582
[2022-07-08 09:15:36,652 callbacks.py:105 INFO train-abinet] epoch 9 iter 390700: loss = 0.5779,  smooth loss = 0.4537
[2022-07-08 09:16:17,422 callbacks.py:105 INFO train-abinet] epoch 9 iter 390750: loss = 0.3891,  smooth loss = 0.4472
[2022-07-08 09:16:58,358 callbacks.py:105 INFO train-abinet] epoch 9 iter 390800: loss = 0.5098,  smooth loss = 0.4483
[2022-07-08 09:17:39,063 callbacks.py:105 INFO train-abinet] epoch 9 iter 390850: loss = 0.3629,  smooth loss = 0.4568
[2022-07-08 09:18:19,715 callbacks.py:105 INFO train-abinet] epoch 9 iter 390900: loss = 0.4149,  smooth loss = 0.4523
[2022-07-08 09:18:59,962 callbacks.py:105 INFO train-abinet] epoch 9 iter 390950: loss = 0.4091,  smooth loss = 0.4533
[2022-07-08 09:19:40,905 callbacks.py:105 INFO train-abinet] epoch 9 iter 391000: loss = 0.4863,  smooth loss = 0.4688
[2022-07-08 09:20:21,814 callbacks.py:105 INFO train-abinet] epoch 9 iter 391050: loss = 0.4126,  smooth loss = 0.4510
[2022-07-08 09:21:02,704 callbacks.py:105 INFO train-abinet] epoch 9 iter 391100: loss = 0.3595,  smooth loss = 0.4493
[2022-07-08 09:21:43,336 callbacks.py:105 INFO train-abinet] epoch 9 iter 391150: loss = 0.4770,  smooth loss = 0.4574
[2022-07-08 09:22:24,417 callbacks.py:105 INFO train-abinet] epoch 9 iter 391200: loss = 0.5015,  smooth loss = 0.4642
[2022-07-08 09:23:05,245 callbacks.py:105 INFO train-abinet] epoch 9 iter 391250: loss = 0.5762,  smooth loss = 0.4725
[2022-07-08 09:23:46,208 callbacks.py:105 INFO train-abinet] epoch 9 iter 391300: loss = 0.4598,  smooth loss = 0.4736
[2022-07-08 09:24:27,012 callbacks.py:105 INFO train-abinet] epoch 9 iter 391350: loss = 0.4149,  smooth loss = 0.4563
[2022-07-08 09:25:07,559 callbacks.py:105 INFO train-abinet] epoch 9 iter 391400: loss = 0.5128,  smooth loss = 0.4490
[2022-07-08 09:25:48,250 callbacks.py:105 INFO train-abinet] epoch 9 iter 391450: loss = 0.4312,  smooth loss = 0.4510
[2022-07-08 09:26:28,975 callbacks.py:105 INFO train-abinet] epoch 9 iter 391500: loss = 0.3929,  smooth loss = 0.4553
[2022-07-08 09:27:09,861 callbacks.py:105 INFO train-abinet] epoch 9 iter 391550: loss = 0.4597,  smooth loss = 0.4582
[2022-07-08 09:27:50,302 callbacks.py:105 INFO train-abinet] epoch 9 iter 391600: loss = 0.4892,  smooth loss = 0.4511
[2022-07-08 09:28:31,356 callbacks.py:105 INFO train-abinet] epoch 9 iter 391650: loss = 0.4628,  smooth loss = 0.4461
[2022-07-08 09:29:12,243 callbacks.py:105 INFO train-abinet] epoch 9 iter 391700: loss = 0.5329,  smooth loss = 0.4529
[2022-07-08 09:29:53,594 callbacks.py:105 INFO train-abinet] epoch 9 iter 391750: loss = 0.4731,  smooth loss = 0.4488
[2022-07-08 09:30:35,002 callbacks.py:105 INFO train-abinet] epoch 9 iter 391800: loss = 0.3916,  smooth loss = 0.4297
[2022-07-08 09:31:15,838 callbacks.py:105 INFO train-abinet] epoch 9 iter 391850: loss = 0.5614,  smooth loss = 0.4458
[2022-07-08 09:31:56,979 callbacks.py:105 INFO train-abinet] epoch 9 iter 391900: loss = 0.4839,  smooth loss = 0.4525
[2022-07-08 09:32:38,085 callbacks.py:105 INFO train-abinet] epoch 9 iter 391950: loss = 0.4787,  smooth loss = 0.4439
[2022-07-08 09:33:19,548 callbacks.py:105 INFO train-abinet] epoch 9 iter 392000: loss = 0.3227,  smooth loss = 0.4336
[2022-07-08 09:34:00,843 callbacks.py:105 INFO train-abinet] epoch 9 iter 392050: loss = 0.5004,  smooth loss = 0.4395
[2022-07-08 09:34:42,003 callbacks.py:105 INFO train-abinet] epoch 9 iter 392100: loss = 0.4909,  smooth loss = 0.4540
[2022-07-08 09:35:22,719 callbacks.py:105 INFO train-abinet] epoch 9 iter 392150: loss = 0.4550,  smooth loss = 0.4630
[2022-07-08 09:36:03,408 callbacks.py:105 INFO train-abinet] epoch 9 iter 392200: loss = 0.3686,  smooth loss = 0.4550
[2022-07-08 09:36:44,388 callbacks.py:105 INFO train-abinet] epoch 9 iter 392250: loss = 0.4380,  smooth loss = 0.4493
[2022-07-08 09:37:25,299 callbacks.py:105 INFO train-abinet] epoch 9 iter 392300: loss = 0.4607,  smooth loss = 0.4463
[2022-07-08 09:38:06,589 callbacks.py:105 INFO train-abinet] epoch 9 iter 392350: loss = 0.5574,  smooth loss = 0.4418
[2022-07-08 09:38:47,618 callbacks.py:105 INFO train-abinet] epoch 9 iter 392400: loss = 0.3399,  smooth loss = 0.4400
[2022-07-08 09:39:28,745 callbacks.py:105 INFO train-abinet] epoch 9 iter 392450: loss = 0.5516,  smooth loss = 0.4494
[2022-07-08 09:40:09,627 callbacks.py:105 INFO train-abinet] epoch 9 iter 392500: loss = 0.4735,  smooth loss = 0.4576
[2022-07-08 09:40:51,089 callbacks.py:105 INFO train-abinet] epoch 9 iter 392550: loss = 0.5379,  smooth loss = 0.4496
[2022-07-08 09:41:31,573 callbacks.py:105 INFO train-abinet] epoch 9 iter 392600: loss = 0.4997,  smooth loss = 0.4633
[2022-07-08 09:42:12,800 callbacks.py:105 INFO train-abinet] epoch 9 iter 392650: loss = 0.4068,  smooth loss = 0.4534
[2022-07-08 09:42:53,661 callbacks.py:105 INFO train-abinet] epoch 9 iter 392700: loss = 0.4093,  smooth loss = 0.4429
[2022-07-08 09:43:34,519 callbacks.py:105 INFO train-abinet] epoch 9 iter 392750: loss = 0.4995,  smooth loss = 0.4449
[2022-07-08 09:44:15,604 callbacks.py:105 INFO train-abinet] epoch 9 iter 392800: loss = 0.5111,  smooth loss = 0.4466
[2022-07-08 09:44:56,774 callbacks.py:105 INFO train-abinet] epoch 9 iter 392850: loss = 0.4728,  smooth loss = 0.4452
[2022-07-08 09:45:38,323 callbacks.py:105 INFO train-abinet] epoch 9 iter 392900: loss = 0.3463,  smooth loss = 0.4494
[2022-07-08 09:46:19,240 callbacks.py:105 INFO train-abinet] epoch 9 iter 392950: loss = 0.5064,  smooth loss = 0.4343
[2022-07-08 09:47:00,706 callbacks.py:105 INFO train-abinet] epoch 9 iter 393000: loss = 0.4295,  smooth loss = 0.4632
[2022-07-08 09:47:00,707 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8531s
█[2022-07-08 09:47:15,258 callbacks.py:123 INFO train-abinet] epoch 9 iter 393000: eval loss = 1.1624,  ccr = 0.9656,  cwr = 0.9284,  ted = 1137.0000,  ned = 232.6896,  ted/w = 0.1569, 
[2022-07-08 09:47:15,260 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_393000
[2022-07-08 09:47:57,716 callbacks.py:105 INFO train-abinet] epoch 9 iter 393050: loss = 0.5125,  smooth loss = 0.4597
[2022-07-08 09:48:39,102 callbacks.py:105 INFO train-abinet] epoch 9 iter 393100: loss = 0.5346,  smooth loss = 0.4673
[2022-07-08 09:49:20,319 callbacks.py:105 INFO train-abinet] epoch 9 iter 393150: loss = 0.5667,  smooth loss = 0.4523
[2022-07-08 09:50:02,547 callbacks.py:105 INFO train-abinet] epoch 9 iter 393200: loss = 0.5355,  smooth loss = 0.4508
[2022-07-08 09:50:43,853 callbacks.py:105 INFO train-abinet] epoch 9 iter 393250: loss = 0.4985,  smooth loss = 0.4537
[2022-07-08 09:51:25,457 callbacks.py:105 INFO train-abinet] epoch 9 iter 393300: loss = 0.5635,  smooth loss = 0.4567
[2022-07-08 09:52:07,518 callbacks.py:105 INFO train-abinet] epoch 9 iter 393350: loss = 0.4165,  smooth loss = 0.4596
[2022-07-08 09:52:48,664 callbacks.py:105 INFO train-abinet] epoch 9 iter 393400: loss = 0.4452,  smooth loss = 0.4504
[2022-07-08 09:53:30,096 callbacks.py:105 INFO train-abinet] epoch 9 iter 393450: loss = 0.5993,  smooth loss = 0.4633
[2022-07-08 09:54:12,137 callbacks.py:105 INFO train-abinet] epoch 9 iter 393500: loss = 0.4730,  smooth loss = 0.4592
[2022-07-08 09:54:53,753 callbacks.py:105 INFO train-abinet] epoch 9 iter 393550: loss = 0.4387,  smooth loss = 0.4538
[2022-07-08 09:55:34,993 callbacks.py:105 INFO train-abinet] epoch 9 iter 393600: loss = 0.3023,  smooth loss = 0.4415
[2022-07-08 09:56:16,956 callbacks.py:105 INFO train-abinet] epoch 9 iter 393650: loss = 0.4115,  smooth loss = 0.4494
[2022-07-08 09:56:58,341 callbacks.py:105 INFO train-abinet] epoch 9 iter 393700: loss = 0.5342,  smooth loss = 0.4501
[2022-07-08 09:57:39,572 callbacks.py:105 INFO train-abinet] epoch 9 iter 393750: loss = 0.4408,  smooth loss = 0.4498
[2022-07-08 09:58:21,709 callbacks.py:105 INFO train-abinet] epoch 9 iter 393800: loss = 0.4403,  smooth loss = 0.4672
[2022-07-08 09:59:03,240 callbacks.py:105 INFO train-abinet] epoch 9 iter 393850: loss = 0.3867,  smooth loss = 0.4726
[2022-07-08 09:59:45,137 callbacks.py:105 INFO train-abinet] epoch 9 iter 393900: loss = 0.4997,  smooth loss = 0.4580
[2022-07-08 10:00:26,977 callbacks.py:105 INFO train-abinet] epoch 9 iter 393950: loss = 0.4471,  smooth loss = 0.4593
[2022-07-08 10:01:08,388 callbacks.py:105 INFO train-abinet] epoch 9 iter 394000: loss = 0.4559,  smooth loss = 0.4538
[2022-07-08 10:01:49,639 callbacks.py:105 INFO train-abinet] epoch 9 iter 394050: loss = 0.4657,  smooth loss = 0.4493
[2022-07-08 10:02:31,919 callbacks.py:105 INFO train-abinet] epoch 9 iter 394100: loss = 0.5001,  smooth loss = 0.4574
[2022-07-08 10:03:13,013 callbacks.py:105 INFO train-abinet] epoch 9 iter 394150: loss = 0.5605,  smooth loss = 0.4609
[2022-07-08 10:03:54,377 callbacks.py:105 INFO train-abinet] epoch 9 iter 394200: loss = 0.4073,  smooth loss = 0.4571
[2022-07-08 10:04:36,259 callbacks.py:105 INFO train-abinet] epoch 9 iter 394250: loss = 0.4783,  smooth loss = 0.4674
[2022-07-08 10:05:17,609 callbacks.py:105 INFO train-abinet] epoch 9 iter 394300: loss = 0.3459,  smooth loss = 0.4650
[2022-07-08 10:05:58,941 callbacks.py:105 INFO train-abinet] epoch 9 iter 394350: loss = 0.5897,  smooth loss = 0.4618
[2022-07-08 10:06:41,025 callbacks.py:105 INFO train-abinet] epoch 9 iter 394400: loss = 0.5249,  smooth loss = 0.4682
[2022-07-08 10:07:22,717 callbacks.py:105 INFO train-abinet] epoch 9 iter 394450: loss = 0.4552,  smooth loss = 0.4747
[2022-07-08 10:08:04,213 callbacks.py:105 INFO train-abinet] epoch 9 iter 394500: loss = 0.5390,  smooth loss = 0.4705
[2022-07-08 10:08:46,142 callbacks.py:105 INFO train-abinet] epoch 9 iter 394550: loss = 0.6310,  smooth loss = 0.4666
[2022-07-08 10:09:27,657 callbacks.py:105 INFO train-abinet] epoch 9 iter 394600: loss = 0.4151,  smooth loss = 0.4547
[2022-07-08 10:10:09,312 callbacks.py:105 INFO train-abinet] epoch 9 iter 394650: loss = 0.5636,  smooth loss = 0.4475
[2022-07-08 10:10:51,583 callbacks.py:105 INFO train-abinet] epoch 9 iter 394700: loss = 0.4513,  smooth loss = 0.4456
[2022-07-08 10:11:33,174 callbacks.py:105 INFO train-abinet] epoch 9 iter 394750: loss = 0.5399,  smooth loss = 0.4527
[2022-07-08 10:12:14,459 callbacks.py:105 INFO train-abinet] epoch 9 iter 394800: loss = 0.4042,  smooth loss = 0.4504
[2022-07-08 10:12:56,711 callbacks.py:105 INFO train-abinet] epoch 9 iter 394850: loss = 0.3910,  smooth loss = 0.4522
[2022-07-08 10:13:38,262 callbacks.py:105 INFO train-abinet] epoch 9 iter 394900: loss = 0.3878,  smooth loss = 0.4456
[2022-07-08 10:14:19,418 callbacks.py:105 INFO train-abinet] epoch 9 iter 394950: loss = 0.4572,  smooth loss = 0.4591
[2022-07-08 10:15:01,603 callbacks.py:105 INFO train-abinet] epoch 9 iter 395000: loss = 0.4486,  smooth loss = 0.4526
[2022-07-08 10:15:42,853 callbacks.py:105 INFO train-abinet] epoch 9 iter 395050: loss = 0.4445,  smooth loss = 0.4368
[2022-07-08 10:16:24,187 callbacks.py:105 INFO train-abinet] epoch 9 iter 395100: loss = 0.4225,  smooth loss = 0.4489
[2022-07-08 10:17:05,526 callbacks.py:105 INFO train-abinet] epoch 9 iter 395150: loss = 0.4812,  smooth loss = 0.4487
[2022-07-08 10:17:47,587 callbacks.py:105 INFO train-abinet] epoch 9 iter 395200: loss = 0.4284,  smooth loss = 0.4452
[2022-07-08 10:18:29,037 callbacks.py:105 INFO train-abinet] epoch 9 iter 395250: loss = 0.3626,  smooth loss = 0.4425
[2022-07-08 10:19:10,637 callbacks.py:105 INFO train-abinet] epoch 9 iter 395300: loss = 0.4206,  smooth loss = 0.4514
[2022-07-08 10:19:52,807 callbacks.py:105 INFO train-abinet] epoch 9 iter 395350: loss = 0.5251,  smooth loss = 0.4535
[2022-07-08 10:20:34,355 callbacks.py:105 INFO train-abinet] epoch 9 iter 395400: loss = 0.5638,  smooth loss = 0.4734
[2022-07-08 10:21:15,787 callbacks.py:105 INFO train-abinet] epoch 9 iter 395450: loss = 0.5022,  smooth loss = 0.4644
[2022-07-08 10:21:57,920 callbacks.py:105 INFO train-abinet] epoch 9 iter 395500: loss = 0.4490,  smooth loss = 0.4610
[2022-07-08 10:22:39,510 callbacks.py:105 INFO train-abinet] epoch 9 iter 395550: loss = 0.3539,  smooth loss = 0.4524
[2022-07-08 10:23:21,122 callbacks.py:105 INFO train-abinet] epoch 9 iter 395600: loss = 0.4311,  smooth loss = 0.4546
[2022-07-08 10:24:03,228 callbacks.py:105 INFO train-abinet] epoch 9 iter 395650: loss = 0.4558,  smooth loss = 0.4475
[2022-07-08 10:24:44,736 callbacks.py:105 INFO train-abinet] epoch 9 iter 395700: loss = 0.4512,  smooth loss = 0.4474
[2022-07-08 10:25:26,280 callbacks.py:105 INFO train-abinet] epoch 9 iter 395750: loss = 0.3831,  smooth loss = 0.4515
[2022-07-08 10:26:08,150 callbacks.py:105 INFO train-abinet] epoch 9 iter 395800: loss = 0.4117,  smooth loss = 0.4510
[2022-07-08 10:26:49,362 callbacks.py:105 INFO train-abinet] epoch 9 iter 395850: loss = 0.4758,  smooth loss = 0.4430
[2022-07-08 10:27:30,647 callbacks.py:105 INFO train-abinet] epoch 9 iter 395900: loss = 0.5161,  smooth loss = 0.4574
[2022-07-08 10:28:11,775 callbacks.py:105 INFO train-abinet] epoch 9 iter 395950: loss = 0.3740,  smooth loss = 0.4565
[2022-07-08 10:28:53,146 callbacks.py:105 INFO train-abinet] epoch 9 iter 396000: loss = 0.3310,  smooth loss = 0.4500
[2022-07-08 10:28:53,148 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8530s
█[2022-07-08 10:29:06,880 callbacks.py:123 INFO train-abinet] epoch 9 iter 396000: eval loss = 1.1742,  ccr = 0.9650,  cwr = 0.9266,  ted = 1139.0000,  ned = 232.4874,  ted/w = 0.1571, 
[2022-07-08 10:29:06,881 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_396000
[2022-07-08 10:29:48,669 callbacks.py:105 INFO train-abinet] epoch 9 iter 396050: loss = 0.4032,  smooth loss = 0.4556
[2022-07-08 10:30:30,051 callbacks.py:105 INFO train-abinet] epoch 9 iter 396100: loss = 0.4675,  smooth loss = 0.4616
[2022-07-08 10:31:10,943 callbacks.py:105 INFO train-abinet] epoch 9 iter 396150: loss = 0.4173,  smooth loss = 0.4596
[2022-07-08 10:31:51,852 callbacks.py:105 INFO train-abinet] epoch 9 iter 396200: loss = 0.3955,  smooth loss = 0.4512
[2022-07-08 10:32:32,183 callbacks.py:105 INFO train-abinet] epoch 9 iter 396250: loss = 0.4142,  smooth loss = 0.4532
[2022-07-08 10:33:13,097 callbacks.py:105 INFO train-abinet] epoch 9 iter 396300: loss = 0.3136,  smooth loss = 0.4574
[2022-07-08 10:33:54,126 callbacks.py:105 INFO train-abinet] epoch 9 iter 396350: loss = 0.4611,  smooth loss = 0.4484
[2022-07-08 10:34:36,328 callbacks.py:105 INFO train-abinet] epoch 9 iter 396400: loss = 0.3542,  smooth loss = 0.4445
[2022-07-08 10:35:17,266 callbacks.py:105 INFO train-abinet] epoch 9 iter 396450: loss = 0.3712,  smooth loss = 0.4441
[2022-07-08 10:35:58,684 callbacks.py:105 INFO train-abinet] epoch 9 iter 396500: loss = 0.3846,  smooth loss = 0.4504
[2022-07-08 10:36:41,015 callbacks.py:105 INFO train-abinet] epoch 9 iter 396550: loss = 0.5005,  smooth loss = 0.4603
[2022-07-08 10:37:22,441 callbacks.py:105 INFO train-abinet] epoch 9 iter 396600: loss = 0.5393,  smooth loss = 0.4591
[2022-07-08 10:38:03,978 callbacks.py:105 INFO train-abinet] epoch 9 iter 396650: loss = 0.6004,  smooth loss = 0.4538
[2022-07-08 10:38:46,344 callbacks.py:105 INFO train-abinet] epoch 9 iter 396700: loss = 0.3504,  smooth loss = 0.4493
[2022-07-08 10:39:27,527 callbacks.py:105 INFO train-abinet] epoch 9 iter 396750: loss = 0.4709,  smooth loss = 0.4612
[2022-07-08 10:40:08,612 callbacks.py:105 INFO train-abinet] epoch 9 iter 396800: loss = 0.4384,  smooth loss = 0.4598
[2022-07-08 10:40:50,451 callbacks.py:105 INFO train-abinet] epoch 9 iter 396850: loss = 0.5978,  smooth loss = 0.4682
[2022-07-08 10:41:31,656 callbacks.py:105 INFO train-abinet] epoch 9 iter 396900: loss = 0.4126,  smooth loss = 0.4593
[2022-07-08 10:42:12,917 callbacks.py:105 INFO train-abinet] epoch 9 iter 396950: loss = 0.6647,  smooth loss = 0.4690
[2022-07-08 10:42:55,010 callbacks.py:105 INFO train-abinet] epoch 9 iter 397000: loss = 0.5059,  smooth loss = 0.4581
[2022-07-08 10:43:36,739 callbacks.py:105 INFO train-abinet] epoch 9 iter 397050: loss = 0.3983,  smooth loss = 0.4525
[2022-07-08 10:44:17,953 callbacks.py:105 INFO train-abinet] epoch 9 iter 397100: loss = 0.4206,  smooth loss = 0.4530
[2022-07-08 10:44:59,676 callbacks.py:105 INFO train-abinet] epoch 9 iter 397150: loss = 0.5801,  smooth loss = 0.4586
[2022-07-08 10:45:41,025 callbacks.py:105 INFO train-abinet] epoch 9 iter 397200: loss = 0.5343,  smooth loss = 0.4559
[2022-07-08 10:46:22,256 callbacks.py:105 INFO train-abinet] epoch 9 iter 397250: loss = 0.4643,  smooth loss = 0.4617
[2022-07-08 10:47:04,583 callbacks.py:105 INFO train-abinet] epoch 9 iter 397300: loss = 0.3932,  smooth loss = 0.4540
[2022-07-08 10:47:45,955 callbacks.py:105 INFO train-abinet] epoch 9 iter 397350: loss = 0.4276,  smooth loss = 0.4613
[2022-07-08 10:48:27,600 callbacks.py:105 INFO train-abinet] epoch 9 iter 397400: loss = 0.3956,  smooth loss = 0.4608
[2022-07-08 10:49:09,508 callbacks.py:105 INFO train-abinet] epoch 9 iter 397450: loss = 0.4090,  smooth loss = 0.4568
[2022-07-08 10:49:50,709 callbacks.py:105 INFO train-abinet] epoch 9 iter 397500: loss = 0.4255,  smooth loss = 0.4596
[2022-07-08 10:50:31,835 callbacks.py:105 INFO train-abinet] epoch 9 iter 397550: loss = 0.4802,  smooth loss = 0.4404
[2022-07-08 10:51:14,098 callbacks.py:105 INFO train-abinet] epoch 9 iter 397600: loss = 0.4311,  smooth loss = 0.4580
[2022-07-08 10:51:55,423 callbacks.py:105 INFO train-abinet] epoch 9 iter 397650: loss = 0.3660,  smooth loss = 0.4455
[2022-07-08 10:52:36,825 callbacks.py:105 INFO train-abinet] epoch 9 iter 397700: loss = 0.4540,  smooth loss = 0.4494
[2022-07-08 10:53:18,695 callbacks.py:105 INFO train-abinet] epoch 9 iter 397750: loss = 0.4774,  smooth loss = 0.4624
[2022-07-08 10:53:59,961 callbacks.py:105 INFO train-abinet] epoch 9 iter 397800: loss = 0.3862,  smooth loss = 0.4563
[2022-07-08 10:54:41,579 callbacks.py:105 INFO train-abinet] epoch 9 iter 397850: loss = 0.4541,  smooth loss = 0.4557
[2022-07-08 10:55:23,675 callbacks.py:105 INFO train-abinet] epoch 9 iter 397900: loss = 0.2759,  smooth loss = 0.4455
[2022-07-08 10:56:05,330 callbacks.py:105 INFO train-abinet] epoch 9 iter 397950: loss = 0.5267,  smooth loss = 0.4646
[2022-07-08 10:56:46,812 callbacks.py:105 INFO train-abinet] epoch 9 iter 398000: loss = 0.4710,  smooth loss = 0.4659
[2022-07-08 10:57:29,099 callbacks.py:105 INFO train-abinet] epoch 9 iter 398050: loss = 0.3992,  smooth loss = 0.4664
[2022-07-08 10:58:10,398 callbacks.py:105 INFO train-abinet] epoch 9 iter 398100: loss = 0.3750,  smooth loss = 0.4661
[2022-07-08 10:58:51,959 callbacks.py:105 INFO train-abinet] epoch 9 iter 398150: loss = 0.4016,  smooth loss = 0.4613
[2022-07-08 10:59:34,203 callbacks.py:105 INFO train-abinet] epoch 9 iter 398200: loss = 0.5390,  smooth loss = 0.4646
[2022-07-08 11:00:16,020 callbacks.py:105 INFO train-abinet] epoch 9 iter 398250: loss = 0.5860,  smooth loss = 0.4658
[2022-07-08 11:00:57,446 callbacks.py:105 INFO train-abinet] epoch 9 iter 398300: loss = 0.4560,  smooth loss = 0.4647
[2022-07-08 11:01:39,625 callbacks.py:105 INFO train-abinet] epoch 9 iter 398350: loss = 0.4564,  smooth loss = 0.4490
[2022-07-08 11:02:21,054 callbacks.py:105 INFO train-abinet] epoch 9 iter 398400: loss = 0.5034,  smooth loss = 0.4575
[2022-07-08 11:03:02,734 callbacks.py:105 INFO train-abinet] epoch 9 iter 398450: loss = 0.4774,  smooth loss = 0.4493
[2022-07-08 11:03:43,897 callbacks.py:105 INFO train-abinet] epoch 9 iter 398500: loss = 0.3797,  smooth loss = 0.4631
[2022-07-08 11:04:25,372 callbacks.py:105 INFO train-abinet] epoch 9 iter 398550: loss = 0.4899,  smooth loss = 0.4576
[2022-07-08 11:05:06,717 callbacks.py:105 INFO train-abinet] epoch 9 iter 398600: loss = 0.4429,  smooth loss = 0.4557
[2022-07-08 11:05:48,109 callbacks.py:105 INFO train-abinet] epoch 9 iter 398650: loss = 0.5673,  smooth loss = 0.4608
[2022-07-08 11:06:29,640 callbacks.py:105 INFO train-abinet] epoch 9 iter 398700: loss = 0.4483,  smooth loss = 0.4464
[2022-07-08 11:07:10,314 callbacks.py:105 INFO train-abinet] epoch 9 iter 398750: loss = 0.5256,  smooth loss = 0.4572
[2022-07-08 11:07:51,771 callbacks.py:105 INFO train-abinet] epoch 9 iter 398800: loss = 0.4434,  smooth loss = 0.4532
[2022-07-08 11:08:33,132 callbacks.py:105 INFO train-abinet] epoch 9 iter 398850: loss = 0.4964,  smooth loss = 0.4500
[2022-07-08 11:09:14,643 callbacks.py:105 INFO train-abinet] epoch 9 iter 398900: loss = 0.5131,  smooth loss = 0.4551
[2022-07-08 11:09:55,767 callbacks.py:105 INFO train-abinet] epoch 9 iter 398950: loss = 0.4344,  smooth loss = 0.4501
[2022-07-08 11:10:36,624 callbacks.py:105 INFO train-abinet] epoch 9 iter 399000: loss = 0.4564,  smooth loss = 0.4653
[2022-07-08 11:10:36,625 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8528s
█[2022-07-08 11:10:50,264 callbacks.py:123 INFO train-abinet] epoch 9 iter 399000: eval loss = 1.1715,  ccr = 0.9654,  cwr = 0.9283,  ted = 1126.0000,  ned = 227.7435,  ted/w = 0.1554, 
[2022-07-08 11:10:50,266 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_399000
[2022-07-08 11:11:32,990 callbacks.py:105 INFO train-abinet] epoch 9 iter 399050: loss = 0.4847,  smooth loss = 0.4583
[2022-07-08 11:12:14,596 callbacks.py:105 INFO train-abinet] epoch 9 iter 399100: loss = 0.4291,  smooth loss = 0.4511
[2022-07-08 11:12:55,510 callbacks.py:105 INFO train-abinet] epoch 9 iter 399150: loss = 0.4139,  smooth loss = 0.4400
[2022-07-08 11:13:36,934 callbacks.py:105 INFO train-abinet] epoch 9 iter 399200: loss = 0.4930,  smooth loss = 0.4396
[2022-07-08 11:14:17,508 callbacks.py:105 INFO train-abinet] epoch 9 iter 399250: loss = 0.4661,  smooth loss = 0.4462
[2022-07-08 11:14:58,665 callbacks.py:105 INFO train-abinet] epoch 9 iter 399300: loss = 0.4913,  smooth loss = 0.4713
[2022-07-08 11:15:39,707 callbacks.py:105 INFO train-abinet] epoch 9 iter 399350: loss = 0.4217,  smooth loss = 0.4559
[2022-07-08 11:16:21,040 callbacks.py:105 INFO train-abinet] epoch 9 iter 399400: loss = 0.4244,  smooth loss = 0.4535
[2022-07-08 11:17:02,552 callbacks.py:105 INFO train-abinet] epoch 9 iter 399450: loss = 0.3600,  smooth loss = 0.4292
[2022-07-08 11:17:43,825 callbacks.py:105 INFO train-abinet] epoch 9 iter 399500: loss = 0.3255,  smooth loss = 0.4539
[2022-07-08 11:18:24,722 callbacks.py:105 INFO train-abinet] epoch 9 iter 399550: loss = 0.4790,  smooth loss = 0.4534
[2022-07-08 11:19:05,645 callbacks.py:105 INFO train-abinet] epoch 9 iter 399600: loss = 0.6209,  smooth loss = 0.4516
[2022-07-08 11:19:46,450 callbacks.py:105 INFO train-abinet] epoch 9 iter 399650: loss = 0.5854,  smooth loss = 0.4566
[2022-07-08 11:20:27,587 callbacks.py:105 INFO train-abinet] epoch 9 iter 399700: loss = 0.4419,  smooth loss = 0.4466
[2022-07-08 11:21:08,094 callbacks.py:105 INFO train-abinet] epoch 9 iter 399750: loss = 0.4393,  smooth loss = 0.4497
[2022-07-08 11:21:48,928 callbacks.py:105 INFO train-abinet] epoch 9 iter 399800: loss = 0.3632,  smooth loss = 0.4566
[2022-07-08 11:22:29,970 callbacks.py:105 INFO train-abinet] epoch 9 iter 399850: loss = 0.4568,  smooth loss = 0.4469
[2022-07-08 11:23:11,171 callbacks.py:105 INFO train-abinet] epoch 9 iter 399900: loss = 0.5208,  smooth loss = 0.4532
[2022-07-08 11:23:51,875 callbacks.py:105 INFO train-abinet] epoch 9 iter 399950: loss = 0.4136,  smooth loss = 0.4612
[2022-07-08 11:24:33,243 callbacks.py:105 INFO train-abinet] epoch 9 iter 400000: loss = 0.4436,  smooth loss = 0.4580
[2022-07-08 11:25:16,037 callbacks.py:105 INFO train-abinet] epoch 9 iter 400050: loss = 0.4933,  smooth loss = 0.4620
[2022-07-08 11:25:57,056 callbacks.py:105 INFO train-abinet] epoch 9 iter 400100: loss = 0.5661,  smooth loss = 0.4535
[2022-07-08 11:26:37,940 callbacks.py:105 INFO train-abinet] epoch 9 iter 400150: loss = 0.4680,  smooth loss = 0.4561
[2022-07-08 11:27:19,002 callbacks.py:105 INFO train-abinet] epoch 9 iter 400200: loss = 0.4726,  smooth loss = 0.4593
[2022-07-08 11:27:59,916 callbacks.py:105 INFO train-abinet] epoch 9 iter 400250: loss = 0.4489,  smooth loss = 0.4572
[2022-07-08 11:28:40,170 callbacks.py:105 INFO train-abinet] epoch 9 iter 400300: loss = 0.3436,  smooth loss = 0.4589
[2022-07-08 11:29:21,752 callbacks.py:105 INFO train-abinet] epoch 9 iter 400350: loss = 0.5234,  smooth loss = 0.4488
[2022-07-08 11:30:03,118 callbacks.py:105 INFO train-abinet] epoch 9 iter 400400: loss = 0.3576,  smooth loss = 0.4530
[2022-07-08 11:30:44,478 callbacks.py:105 INFO train-abinet] epoch 9 iter 400450: loss = 0.3602,  smooth loss = 0.4501
[2022-07-08 11:31:25,786 callbacks.py:105 INFO train-abinet] epoch 9 iter 400500: loss = 0.4160,  smooth loss = 0.4625
[2022-07-08 11:32:06,387 callbacks.py:105 INFO train-abinet] epoch 9 iter 400550: loss = 0.5044,  smooth loss = 0.4650
[2022-07-08 11:32:47,922 callbacks.py:105 INFO train-abinet] epoch 9 iter 400600: loss = 0.5716,  smooth loss = 0.4539
[2022-07-08 11:33:30,067 callbacks.py:105 INFO train-abinet] epoch 9 iter 400650: loss = 0.3910,  smooth loss = 0.4497
[2022-07-08 11:34:11,416 callbacks.py:105 INFO train-abinet] epoch 9 iter 400700: loss = 0.4838,  smooth loss = 0.4400
[2022-07-08 11:34:52,743 callbacks.py:105 INFO train-abinet] epoch 9 iter 400750: loss = 0.4433,  smooth loss = 0.4498
[2022-07-08 11:35:34,717 callbacks.py:105 INFO train-abinet] epoch 9 iter 400800: loss = 0.5934,  smooth loss = 0.4509
[2022-07-08 11:36:16,025 callbacks.py:105 INFO train-abinet] epoch 9 iter 400850: loss = 0.4043,  smooth loss = 0.4522
[2022-07-08 11:36:57,364 callbacks.py:105 INFO train-abinet] epoch 9 iter 400900: loss = 0.4378,  smooth loss = 0.4509
[2022-07-08 11:37:38,144 callbacks.py:105 INFO train-abinet] epoch 9 iter 400950: loss = 0.4589,  smooth loss = 0.4595
[2022-07-08 11:38:19,890 callbacks.py:105 INFO train-abinet] epoch 9 iter 401000: loss = 0.3429,  smooth loss = 0.4457
[2022-07-08 11:39:01,228 callbacks.py:105 INFO train-abinet] epoch 9 iter 401050: loss = 0.4283,  smooth loss = 0.4552
[2022-07-08 11:39:42,425 callbacks.py:105 INFO train-abinet] epoch 9 iter 401100: loss = 0.4349,  smooth loss = 0.4573
[2022-07-08 11:40:23,208 callbacks.py:105 INFO train-abinet] epoch 9 iter 401150: loss = 0.4178,  smooth loss = 0.4569
[2022-07-08 11:41:04,472 callbacks.py:105 INFO train-abinet] epoch 9 iter 401200: loss = 0.4273,  smooth loss = 0.4575
[2022-07-08 11:41:45,494 callbacks.py:105 INFO train-abinet] epoch 9 iter 401250: loss = 0.4262,  smooth loss = 0.4508
[2022-07-08 11:42:26,892 callbacks.py:105 INFO train-abinet] epoch 9 iter 401300: loss = 0.3877,  smooth loss = 0.4476
[2022-07-08 11:43:08,195 callbacks.py:105 INFO train-abinet] epoch 9 iter 401350: loss = 0.4993,  smooth loss = 0.4583
[2022-07-08 11:43:48,745 callbacks.py:105 INFO train-abinet] epoch 9 iter 401400: loss = 0.5121,  smooth loss = 0.4482
[2022-07-08 11:44:29,988 callbacks.py:105 INFO train-abinet] epoch 9 iter 401450: loss = 0.4484,  smooth loss = 0.4465
[2022-07-08 11:45:11,258 callbacks.py:105 INFO train-abinet] epoch 9 iter 401500: loss = 0.4148,  smooth loss = 0.4554
[2022-07-08 11:45:52,393 callbacks.py:105 INFO train-abinet] epoch 9 iter 401550: loss = 0.4189,  smooth loss = 0.4513
[2022-07-08 11:46:33,979 callbacks.py:105 INFO train-abinet] epoch 9 iter 401600: loss = 0.4936,  smooth loss = 0.4524
[2022-07-08 11:47:14,806 callbacks.py:105 INFO train-abinet] epoch 9 iter 401650: loss = 0.4902,  smooth loss = 0.4579
[2022-07-08 11:47:57,281 callbacks.py:105 INFO train-abinet] epoch 9 iter 401700: loss = 0.4955,  smooth loss = 0.4510
[2022-07-08 11:48:38,481 callbacks.py:105 INFO train-abinet] epoch 9 iter 401750: loss = 0.5015,  smooth loss = 0.4543
[2022-07-08 11:49:19,364 callbacks.py:105 INFO train-abinet] epoch 9 iter 401800: loss = 0.4968,  smooth loss = 0.4552
[2022-07-08 11:50:00,309 callbacks.py:105 INFO train-abinet] epoch 9 iter 401850: loss = 0.4270,  smooth loss = 0.4547
[2022-07-08 11:50:41,922 callbacks.py:105 INFO train-abinet] epoch 9 iter 401900: loss = 0.3565,  smooth loss = 0.4450
[2022-07-08 11:51:23,156 callbacks.py:105 INFO train-abinet] epoch 9 iter 401950: loss = 0.4219,  smooth loss = 0.4445
[2022-07-08 11:52:04,497 callbacks.py:105 INFO train-abinet] epoch 9 iter 402000: loss = 0.5114,  smooth loss = 0.4561
[2022-07-08 11:52:04,498 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8526s
█[2022-07-08 11:52:18,991 callbacks.py:123 INFO train-abinet] epoch 9 iter 402000: eval loss = 1.1680,  ccr = 0.9660,  cwr = 0.9277,  ted = 1118.0000,  ned = 229.9252,  ted/w = 0.1542, 
[2022-07-08 11:52:18,992 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_402000
[2022-07-08 11:53:01,215 callbacks.py:105 INFO train-abinet] epoch 9 iter 402050: loss = 0.4998,  smooth loss = 0.4433
[2022-07-08 11:53:42,281 callbacks.py:105 INFO train-abinet] epoch 9 iter 402100: loss = 0.4919,  smooth loss = 0.4528
[2022-07-08 11:54:23,688 callbacks.py:105 INFO train-abinet] epoch 9 iter 402150: loss = 0.4769,  smooth loss = 0.4501
[2022-07-08 11:55:05,251 callbacks.py:105 INFO train-abinet] epoch 9 iter 402200: loss = 0.4414,  smooth loss = 0.4443
[2022-07-08 11:55:46,098 callbacks.py:105 INFO train-abinet] epoch 9 iter 402250: loss = 0.5160,  smooth loss = 0.4447
[2022-07-08 11:56:27,016 callbacks.py:105 INFO train-abinet] epoch 9 iter 402300: loss = 0.3056,  smooth loss = 0.4397
[2022-07-08 11:57:09,015 callbacks.py:105 INFO train-abinet] epoch 9 iter 402350: loss = 0.5853,  smooth loss = 0.4390
[2022-07-08 11:57:50,012 callbacks.py:105 INFO train-abinet] epoch 9 iter 402400: loss = 0.3453,  smooth loss = 0.4438
[2022-07-08 11:58:30,914 callbacks.py:105 INFO train-abinet] epoch 9 iter 402450: loss = 0.4911,  smooth loss = 0.4631
[2022-07-08 11:59:12,675 callbacks.py:105 INFO train-abinet] epoch 9 iter 402500: loss = 0.4883,  smooth loss = 0.4515
[2022-07-08 11:59:54,461 callbacks.py:105 INFO train-abinet] epoch 9 iter 402550: loss = 0.4618,  smooth loss = 0.4606
[2022-07-08 12:00:35,664 callbacks.py:105 INFO train-abinet] epoch 9 iter 402600: loss = 0.4619,  smooth loss = 0.4691
[2022-07-08 12:01:16,968 callbacks.py:105 INFO train-abinet] epoch 9 iter 402650: loss = 0.5052,  smooth loss = 0.4707
[2022-07-08 12:01:58,451 callbacks.py:105 INFO train-abinet] epoch 9 iter 402700: loss = 0.5108,  smooth loss = 0.4564
[2022-07-08 12:02:39,326 callbacks.py:105 INFO train-abinet] epoch 9 iter 402750: loss = 0.6115,  smooth loss = 0.4594
[2022-07-08 12:03:21,595 callbacks.py:105 INFO train-abinet] epoch 9 iter 402800: loss = 0.4189,  smooth loss = 0.4656
[2022-07-08 12:04:03,084 callbacks.py:105 INFO train-abinet] epoch 9 iter 402850: loss = 0.4388,  smooth loss = 0.4574
[2022-07-08 12:04:44,446 callbacks.py:105 INFO train-abinet] epoch 9 iter 402900: loss = 0.3898,  smooth loss = 0.4565
[2022-07-08 12:05:25,849 callbacks.py:105 INFO train-abinet] epoch 9 iter 402950: loss = 0.5120,  smooth loss = 0.4592
[2022-07-08 12:06:07,656 callbacks.py:105 INFO train-abinet] epoch 9 iter 403000: loss = 0.4304,  smooth loss = 0.4606
[2022-07-08 12:06:48,470 callbacks.py:105 INFO train-abinet] epoch 9 iter 403050: loss = 0.5446,  smooth loss = 0.4521
[2022-07-08 12:07:29,248 callbacks.py:105 INFO train-abinet] epoch 9 iter 403100: loss = 0.3880,  smooth loss = 0.4619
[2022-07-08 12:08:10,043 callbacks.py:105 INFO train-abinet] epoch 9 iter 403150: loss = 0.5783,  smooth loss = 0.4602
[2022-07-08 12:08:51,096 callbacks.py:105 INFO train-abinet] epoch 9 iter 403200: loss = 0.4326,  smooth loss = 0.4623
[2022-07-08 12:09:31,532 callbacks.py:105 INFO train-abinet] epoch 9 iter 403250: loss = 0.3516,  smooth loss = 0.4611
[2022-07-08 12:10:12,723 callbacks.py:105 INFO train-abinet] epoch 9 iter 403300: loss = 0.5494,  smooth loss = 0.4630
[2022-07-08 12:10:54,032 callbacks.py:105 INFO train-abinet] epoch 9 iter 403350: loss = 0.4053,  smooth loss = 0.4585
[2022-07-08 12:11:35,539 callbacks.py:105 INFO train-abinet] epoch 9 iter 403400: loss = 0.3529,  smooth loss = 0.4615
[2022-07-08 12:12:17,107 callbacks.py:105 INFO train-abinet] epoch 9 iter 403450: loss = 0.3999,  smooth loss = 0.4607
[2022-07-08 12:12:57,550 callbacks.py:105 INFO train-abinet] epoch 9 iter 403500: loss = 0.4941,  smooth loss = 0.4551
[2022-07-08 12:13:38,967 callbacks.py:105 INFO train-abinet] epoch 9 iter 403550: loss = 0.5003,  smooth loss = 0.4570
[2022-07-08 12:14:20,586 callbacks.py:105 INFO train-abinet] epoch 9 iter 403600: loss = 0.4572,  smooth loss = 0.4565
[2022-07-08 12:15:01,894 callbacks.py:105 INFO train-abinet] epoch 9 iter 403650: loss = 0.4826,  smooth loss = 0.4486
[2022-07-08 12:15:42,533 callbacks.py:105 INFO train-abinet] epoch 9 iter 403700: loss = 0.4856,  smooth loss = 0.4499
[2022-07-08 12:16:23,591 callbacks.py:105 INFO train-abinet] epoch 9 iter 403750: loss = 0.4264,  smooth loss = 0.4498
[2022-07-08 12:17:04,857 callbacks.py:105 INFO train-abinet] epoch 9 iter 403800: loss = 0.3595,  smooth loss = 0.4578
[2022-07-08 12:17:46,461 callbacks.py:105 INFO train-abinet] epoch 9 iter 403850: loss = 0.4507,  smooth loss = 0.4633
[2022-07-08 12:18:28,051 callbacks.py:105 INFO train-abinet] epoch 9 iter 403900: loss = 0.5199,  smooth loss = 0.4655
[2022-07-08 12:19:09,890 callbacks.py:105 INFO train-abinet] epoch 9 iter 403950: loss = 0.4239,  smooth loss = 0.4522
[2022-07-08 12:19:51,273 callbacks.py:105 INFO train-abinet] epoch 9 iter 404000: loss = 0.4037,  smooth loss = 0.4535
[2022-07-08 12:20:32,833 callbacks.py:105 INFO train-abinet] epoch 9 iter 404050: loss = 0.5697,  smooth loss = 0.4469
[2022-07-08 12:21:13,311 callbacks.py:105 INFO train-abinet] epoch 9 iter 404100: loss = 0.6117,  smooth loss = 0.4488
[2022-07-08 12:21:54,697 callbacks.py:105 INFO train-abinet] epoch 9 iter 404150: loss = 0.5019,  smooth loss = 0.4545
[2022-07-08 12:22:36,030 callbacks.py:105 INFO train-abinet] epoch 9 iter 404200: loss = 0.4371,  smooth loss = 0.4508
[2022-07-08 12:23:17,548 callbacks.py:105 INFO train-abinet] epoch 9 iter 404250: loss = 0.4261,  smooth loss = 0.4550
[2022-07-08 12:23:58,219 callbacks.py:105 INFO train-abinet] epoch 9 iter 404300: loss = 0.5028,  smooth loss = 0.4476
[2022-07-08 12:24:39,709 callbacks.py:105 INFO train-abinet] epoch 9 iter 404350: loss = 0.4419,  smooth loss = 0.4605
[2022-07-08 12:25:21,335 callbacks.py:105 INFO train-abinet] epoch 9 iter 404400: loss = 0.5637,  smooth loss = 0.4493
[2022-07-08 12:26:02,490 callbacks.py:105 INFO train-abinet] epoch 9 iter 404450: loss = 0.4562,  smooth loss = 0.4645
[2022-07-08 12:26:43,481 callbacks.py:105 INFO train-abinet] epoch 9 iter 404500: loss = 0.5111,  smooth loss = 0.4481
[2022-07-08 12:27:25,120 callbacks.py:105 INFO train-abinet] epoch 9 iter 404550: loss = 0.4181,  smooth loss = 0.4531
[2022-07-08 12:28:06,467 callbacks.py:105 INFO train-abinet] epoch 9 iter 404600: loss = 0.3827,  smooth loss = 0.4449
[2022-07-08 12:28:47,788 callbacks.py:105 INFO train-abinet] epoch 9 iter 404650: loss = 0.3205,  smooth loss = 0.4585
[2022-07-08 12:29:28,754 callbacks.py:105 INFO train-abinet] epoch 9 iter 404700: loss = 0.3424,  smooth loss = 0.4583
[2022-07-08 12:30:09,781 callbacks.py:105 INFO train-abinet] epoch 9 iter 404750: loss = 0.4147,  smooth loss = 0.4514
[2022-07-08 12:30:51,034 callbacks.py:105 INFO train-abinet] epoch 9 iter 404800: loss = 0.4649,  smooth loss = 0.4489
[2022-07-08 12:31:32,021 callbacks.py:105 INFO train-abinet] epoch 9 iter 404850: loss = 0.3365,  smooth loss = 0.4596
[2022-07-08 12:32:13,149 callbacks.py:105 INFO train-abinet] epoch 9 iter 404900: loss = 0.5888,  smooth loss = 0.4503
[2022-07-08 12:32:53,819 callbacks.py:105 INFO train-abinet] epoch 9 iter 404950: loss = 0.5154,  smooth loss = 0.4517
[2022-07-08 12:33:34,656 callbacks.py:105 INFO train-abinet] epoch 9 iter 405000: loss = 0.4711,  smooth loss = 0.4447
[2022-07-08 12:33:34,657 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8524s
█[2022-07-08 12:33:48,385 callbacks.py:123 INFO train-abinet] epoch 9 iter 405000: eval loss = 1.1706,  ccr = 0.9660,  cwr = 0.9288,  ted = 1115.0000,  ned = 227.8581,  ted/w = 0.1538, 
[2022-07-08 12:33:48,386 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_405000
[2022-07-08 12:34:30,136 callbacks.py:105 INFO train-abinet] epoch 9 iter 405050: loss = 0.5979,  smooth loss = 0.4476
[2022-07-08 12:35:11,266 callbacks.py:105 INFO train-abinet] epoch 9 iter 405100: loss = 0.5150,  smooth loss = 0.4384
[2022-07-08 12:35:51,378 callbacks.py:105 INFO train-abinet] epoch 9 iter 405150: loss = 0.4923,  smooth loss = 0.4467
[2022-07-08 12:36:32,151 callbacks.py:105 INFO train-abinet] epoch 9 iter 405200: loss = 0.5070,  smooth loss = 0.4464
[2022-07-08 12:37:13,077 callbacks.py:105 INFO train-abinet] epoch 9 iter 405250: loss = 0.4479,  smooth loss = 0.4499
[2022-07-08 12:37:54,012 callbacks.py:105 INFO train-abinet] epoch 9 iter 405300: loss = 0.4090,  smooth loss = 0.4491
[2022-07-08 12:38:35,149 callbacks.py:105 INFO train-abinet] epoch 9 iter 405350: loss = 0.4185,  smooth loss = 0.4385
[2022-07-08 12:39:15,669 callbacks.py:105 INFO train-abinet] epoch 9 iter 405400: loss = 0.4375,  smooth loss = 0.4442
[2022-07-08 12:39:56,997 callbacks.py:105 INFO train-abinet] epoch 9 iter 405450: loss = 0.4930,  smooth loss = 0.4447
[2022-07-08 12:40:38,564 callbacks.py:105 INFO train-abinet] epoch 9 iter 405500: loss = 0.4397,  smooth loss = 0.4404
[2022-07-08 12:41:19,845 callbacks.py:105 INFO train-abinet] epoch 9 iter 405550: loss = 0.4831,  smooth loss = 0.4553
[2022-07-08 12:42:00,324 callbacks.py:105 INFO train-abinet] epoch 9 iter 405600: loss = 0.4677,  smooth loss = 0.4623
[2022-07-08 12:42:41,419 callbacks.py:105 INFO train-abinet] epoch 9 iter 405650: loss = 0.5154,  smooth loss = 0.4449
[2022-07-08 12:43:22,500 callbacks.py:105 INFO train-abinet] epoch 9 iter 405700: loss = 0.5796,  smooth loss = 0.4417
[2022-07-08 12:44:03,884 callbacks.py:105 INFO train-abinet] epoch 9 iter 405750: loss = 0.3727,  smooth loss = 0.4482
[2022-07-08 12:44:45,324 callbacks.py:105 INFO train-abinet] epoch 9 iter 405800: loss = 0.3875,  smooth loss = 0.4437
[2022-07-08 12:45:25,983 callbacks.py:105 INFO train-abinet] epoch 9 iter 405850: loss = 0.5356,  smooth loss = 0.4424
[2022-07-08 12:46:07,374 callbacks.py:105 INFO train-abinet] epoch 9 iter 405900: loss = 0.4539,  smooth loss = 0.4411
[2022-07-08 12:46:48,800 callbacks.py:105 INFO train-abinet] epoch 9 iter 405950: loss = 0.4212,  smooth loss = 0.4591
[2022-07-08 12:47:30,075 callbacks.py:105 INFO train-abinet] epoch 9 iter 406000: loss = 0.3885,  smooth loss = 0.4498
[2022-07-08 12:48:10,768 callbacks.py:105 INFO train-abinet] epoch 9 iter 406050: loss = 0.5707,  smooth loss = 0.4578
[2022-07-08 12:48:52,310 callbacks.py:105 INFO train-abinet] epoch 9 iter 406100: loss = 0.5226,  smooth loss = 0.4528
[2022-07-08 12:49:34,047 callbacks.py:105 INFO train-abinet] epoch 9 iter 406150: loss = 0.4623,  smooth loss = 0.4538
[2022-07-08 12:50:15,295 callbacks.py:105 INFO train-abinet] epoch 9 iter 406200: loss = 0.4340,  smooth loss = 0.4433
[2022-07-08 12:50:56,426 callbacks.py:105 INFO train-abinet] epoch 9 iter 406250: loss = 0.4814,  smooth loss = 0.4377
[2022-07-08 12:51:37,007 callbacks.py:105 INFO train-abinet] epoch 9 iter 406300: loss = 0.4449,  smooth loss = 0.4564
[2022-07-08 12:52:18,713 callbacks.py:105 INFO train-abinet] epoch 9 iter 406350: loss = 0.5089,  smooth loss = 0.4417
[2022-07-08 12:53:00,102 callbacks.py:105 INFO train-abinet] epoch 9 iter 406400: loss = 0.4795,  smooth loss = 0.4545
[2022-07-08 12:53:41,316 callbacks.py:105 INFO train-abinet] epoch 9 iter 406450: loss = 0.3675,  smooth loss = 0.4555
[2022-07-08 12:54:22,097 callbacks.py:105 INFO train-abinet] epoch 9 iter 406500: loss = 0.4269,  smooth loss = 0.4533
[2022-07-08 12:55:03,345 callbacks.py:105 INFO train-abinet] epoch 9 iter 406550: loss = 0.6450,  smooth loss = 0.4441
[2022-07-08 12:55:44,742 callbacks.py:105 INFO train-abinet] epoch 9 iter 406600: loss = 0.5060,  smooth loss = 0.4539
[2022-07-08 12:56:25,832 callbacks.py:105 INFO train-abinet] epoch 9 iter 406650: loss = 0.4669,  smooth loss = 0.4537
[2022-07-08 12:57:06,915 callbacks.py:105 INFO train-abinet] epoch 9 iter 406700: loss = 0.4231,  smooth loss = 0.4515
[2022-07-08 12:57:47,409 callbacks.py:105 INFO train-abinet] epoch 9 iter 406750: loss = 0.4911,  smooth loss = 0.4511
[2022-07-08 12:58:28,930 callbacks.py:105 INFO train-abinet] epoch 9 iter 406800: loss = 0.4219,  smooth loss = 0.4414
[2022-07-08 12:59:10,436 callbacks.py:105 INFO train-abinet] epoch 9 iter 406850: loss = 0.5924,  smooth loss = 0.4559
[2022-07-08 12:59:52,046 callbacks.py:105 INFO train-abinet] epoch 9 iter 406900: loss = 0.4000,  smooth loss = 0.4426
[2022-07-08 13:00:32,787 callbacks.py:105 INFO train-abinet] epoch 9 iter 406950: loss = 0.4560,  smooth loss = 0.4573
[2022-07-08 13:01:14,000 callbacks.py:105 INFO train-abinet] epoch 9 iter 407000: loss = 0.5400,  smooth loss = 0.4529
[2022-07-08 13:01:55,288 callbacks.py:105 INFO train-abinet] epoch 9 iter 407050: loss = 0.4406,  smooth loss = 0.4647
[2022-07-08 13:02:36,715 callbacks.py:105 INFO train-abinet] epoch 9 iter 407100: loss = 0.4634,  smooth loss = 0.4584
[2022-07-08 13:03:17,767 callbacks.py:105 INFO train-abinet] epoch 9 iter 407150: loss = 0.4646,  smooth loss = 0.4613
[2022-07-08 13:03:58,663 callbacks.py:105 INFO train-abinet] epoch 9 iter 407200: loss = 0.4755,  smooth loss = 0.4555
[2022-07-08 13:04:40,186 callbacks.py:105 INFO train-abinet] epoch 9 iter 407250: loss = 0.4286,  smooth loss = 0.4579
[2022-07-08 13:05:21,680 callbacks.py:105 INFO train-abinet] epoch 9 iter 407300: loss = 0.5559,  smooth loss = 0.4538
[2022-07-08 13:06:03,250 callbacks.py:105 INFO train-abinet] epoch 9 iter 407350: loss = 0.3860,  smooth loss = 0.4609
[2022-07-08 13:06:44,350 callbacks.py:105 INFO train-abinet] epoch 9 iter 407400: loss = 0.3566,  smooth loss = 0.4547
[2022-07-08 13:07:25,758 callbacks.py:105 INFO train-abinet] epoch 9 iter 407450: loss = 0.4824,  smooth loss = 0.4491
[2022-07-08 13:08:07,264 callbacks.py:105 INFO train-abinet] epoch 9 iter 407500: loss = 0.4290,  smooth loss = 0.4584
[2022-07-08 13:08:48,481 callbacks.py:105 INFO train-abinet] epoch 9 iter 407550: loss = 0.4143,  smooth loss = 0.4572
[2022-07-08 13:09:30,013 callbacks.py:105 INFO train-abinet] epoch 9 iter 407600: loss = 0.3979,  smooth loss = 0.4492
[2022-07-08 13:10:10,841 callbacks.py:105 INFO train-abinet] epoch 9 iter 407650: loss = 0.3514,  smooth loss = 0.4468
[2022-07-08 13:10:52,615 callbacks.py:105 INFO train-abinet] epoch 9 iter 407700: loss = 0.4596,  smooth loss = 0.4504
[2022-07-08 13:11:34,727 callbacks.py:105 INFO train-abinet] epoch 9 iter 407750: loss = 0.5755,  smooth loss = 0.4538
[2022-07-08 13:12:16,615 callbacks.py:105 INFO train-abinet] epoch 9 iter 407800: loss = 0.3668,  smooth loss = 0.4540
[2022-07-08 13:12:57,919 callbacks.py:105 INFO train-abinet] epoch 9 iter 407850: loss = 0.4297,  smooth loss = 0.4438
[2022-07-08 13:13:40,501 callbacks.py:105 INFO train-abinet] epoch 9 iter 407900: loss = 0.5045,  smooth loss = 0.4515
[2022-07-08 13:14:22,435 callbacks.py:105 INFO train-abinet] epoch 9 iter 407950: loss = 0.5020,  smooth loss = 0.4425
[2022-07-08 13:15:04,249 callbacks.py:105 INFO train-abinet] epoch 9 iter 408000: loss = 0.3990,  smooth loss = 0.4579
[2022-07-08 13:15:04,250 callbacks.py:114 INFO train-abinet] average data time = 0.0043s, average running time = 0.8522s
█[2022-07-08 13:15:18,294 callbacks.py:123 INFO train-abinet] epoch 9 iter 408000: eval loss = 1.1728,  ccr = 0.9652,  cwr = 0.9276,  ted = 1131.0000,  ned = 229.4867,  ted/w = 0.1560, 
[2022-07-08 13:15:18,297 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_408000
[2022-07-08 13:16:02,440 callbacks.py:105 INFO train-abinet] epoch 9 iter 408050: loss = 0.4803,  smooth loss = 0.4502
[2022-07-08 13:16:43,994 callbacks.py:105 INFO train-abinet] epoch 9 iter 408100: loss = 0.4388,  smooth loss = 0.4420
[2022-07-08 13:17:25,330 callbacks.py:105 INFO train-abinet] epoch 9 iter 408150: loss = 0.4655,  smooth loss = 0.4466
[2022-07-08 13:18:06,368 callbacks.py:105 INFO train-abinet] epoch 9 iter 408200: loss = 0.4800,  smooth loss = 0.4518
[2022-07-08 13:18:47,698 callbacks.py:105 INFO train-abinet] epoch 9 iter 408250: loss = 0.4099,  smooth loss = 0.4426
[2022-07-08 13:19:28,518 callbacks.py:105 INFO train-abinet] epoch 9 iter 408300: loss = 0.4198,  smooth loss = 0.4495
[2022-07-08 13:20:09,713 callbacks.py:105 INFO train-abinet] epoch 9 iter 408350: loss = 0.4433,  smooth loss = 0.4613
[2022-07-08 13:20:51,360 callbacks.py:105 INFO train-abinet] epoch 9 iter 408400: loss = 0.5009,  smooth loss = 0.4558
[2022-07-08 13:21:33,268 callbacks.py:105 INFO train-abinet] epoch 9 iter 408450: loss = 0.3549,  smooth loss = 0.4471
[2022-07-08 13:22:14,836 callbacks.py:105 INFO train-abinet] epoch 9 iter 408500: loss = 0.4723,  smooth loss = 0.4594
[2022-07-08 13:22:56,276 callbacks.py:105 INFO train-abinet] epoch 9 iter 408550: loss = 0.3577,  smooth loss = 0.4655
[2022-07-08 13:23:37,057 callbacks.py:105 INFO train-abinet] epoch 9 iter 408600: loss = 0.4149,  smooth loss = 0.4667
[2022-07-08 13:24:18,909 callbacks.py:105 INFO train-abinet] epoch 9 iter 408650: loss = 0.5245,  smooth loss = 0.4635
[2022-07-08 13:25:01,007 callbacks.py:105 INFO train-abinet] epoch 9 iter 408700: loss = 0.3110,  smooth loss = 0.4575
[2022-07-08 13:25:42,888 callbacks.py:105 INFO train-abinet] epoch 9 iter 408750: loss = 0.4908,  smooth loss = 0.4532
[2022-07-08 13:26:24,126 callbacks.py:105 INFO train-abinet] epoch 9 iter 408800: loss = 0.3490,  smooth loss = 0.4618
[2022-07-08 13:27:06,233 callbacks.py:105 INFO train-abinet] epoch 9 iter 408850: loss = 0.4316,  smooth loss = 0.4578
[2022-07-08 13:27:48,347 callbacks.py:105 INFO train-abinet] epoch 9 iter 408900: loss = 0.4702,  smooth loss = 0.4475
[2022-07-08 13:28:30,347 callbacks.py:105 INFO train-abinet] epoch 9 iter 408950: loss = 0.3187,  smooth loss = 0.4453
[2022-07-08 13:29:12,479 callbacks.py:105 INFO train-abinet] epoch 9 iter 409000: loss = 0.4517,  smooth loss = 0.4412
[2022-07-08 13:29:54,163 callbacks.py:105 INFO train-abinet] epoch 9 iter 409050: loss = 0.5394,  smooth loss = 0.4532
[2022-07-08 13:30:35,974 callbacks.py:105 INFO train-abinet] epoch 9 iter 409100: loss = 0.5195,  smooth loss = 0.4567
[2022-07-08 13:31:17,826 callbacks.py:105 INFO train-abinet] epoch 9 iter 409150: loss = 0.4403,  smooth loss = 0.4576
[2022-07-08 13:31:59,856 callbacks.py:105 INFO train-abinet] epoch 9 iter 409200: loss = 0.5454,  smooth loss = 0.4497
[2022-07-08 13:32:41,161 callbacks.py:105 INFO train-abinet] epoch 9 iter 409250: loss = 0.4252,  smooth loss = 0.4432
[2022-07-08 13:33:23,023 callbacks.py:105 INFO train-abinet] epoch 9 iter 409300: loss = 0.2768,  smooth loss = 0.4461
[2022-07-08 13:34:05,295 callbacks.py:105 INFO train-abinet] epoch 9 iter 409350: loss = 0.4149,  smooth loss = 0.4475
[2022-07-08 13:34:47,331 callbacks.py:105 INFO train-abinet] epoch 9 iter 409400: loss = 0.4130,  smooth loss = 0.4598
[2022-07-08 13:35:29,784 callbacks.py:105 INFO train-abinet] epoch 9 iter 409450: loss = 0.5553,  smooth loss = 0.4595
[2022-07-08 13:36:10,958 callbacks.py:105 INFO train-abinet] epoch 9 iter 409500: loss = 0.4383,  smooth loss = 0.4523
[2022-07-08 13:36:53,202 callbacks.py:105 INFO train-abinet] epoch 9 iter 409550: loss = 0.5668,  smooth loss = 0.4598
[2022-07-08 13:37:35,471 callbacks.py:105 INFO train-abinet] epoch 9 iter 409600: loss = 0.5108,  smooth loss = 0.4618
[2022-07-08 13:38:17,348 callbacks.py:105 INFO train-abinet] epoch 9 iter 409650: loss = 0.6293,  smooth loss = 0.4554
[2022-07-08 13:38:58,459 callbacks.py:105 INFO train-abinet] epoch 9 iter 409700: loss = 0.4690,  smooth loss = 0.4490
[2022-07-08 13:39:40,404 callbacks.py:105 INFO train-abinet] epoch 9 iter 409750: loss = 0.5111,  smooth loss = 0.4480
[2022-07-08 13:40:22,195 callbacks.py:105 INFO train-abinet] epoch 9 iter 409800: loss = 0.5235,  smooth loss = 0.4629
[2022-07-08 13:41:03,690 callbacks.py:105 INFO train-abinet] epoch 9 iter 409850: loss = 0.4288,  smooth loss = 0.4414
[2022-07-08 13:41:45,163 callbacks.py:105 INFO train-abinet] epoch 9 iter 409900: loss = 0.3478,  smooth loss = 0.4448
[2022-07-08 13:42:26,086 callbacks.py:105 INFO train-abinet] epoch 9 iter 409950: loss = 0.5337,  smooth loss = 0.4610
[2022-07-08 13:43:07,831 callbacks.py:105 INFO train-abinet] epoch 9 iter 410000: loss = 0.3435,  smooth loss = 0.4537
[2022-07-08 13:43:50,067 callbacks.py:105 INFO train-abinet] epoch 9 iter 410050: loss = 0.4940,  smooth loss = 0.4553
[2022-07-08 13:44:32,882 callbacks.py:105 INFO train-abinet] epoch 9 iter 410100: loss = 0.4667,  smooth loss = 0.4601
[2022-07-08 13:45:14,632 callbacks.py:105 INFO train-abinet] epoch 9 iter 410150: loss = 0.4068,  smooth loss = 0.4602
[2022-07-08 13:45:56,808 callbacks.py:105 INFO train-abinet] epoch 9 iter 410200: loss = 0.4305,  smooth loss = 0.4563
[2022-07-08 13:46:39,745 callbacks.py:105 INFO train-abinet] epoch 9 iter 410250: loss = 0.4654,  smooth loss = 0.4485
[2022-07-08 13:47:22,004 callbacks.py:105 INFO train-abinet] epoch 9 iter 410300: loss = 0.4131,  smooth loss = 0.4466
[2022-07-08 13:48:04,039 callbacks.py:105 INFO train-abinet] epoch 9 iter 410350: loss = 0.3052,  smooth loss = 0.4480
[2022-07-08 13:48:45,231 callbacks.py:105 INFO train-abinet] epoch 9 iter 410400: loss = 0.4044,  smooth loss = 0.4512
[2022-07-08 13:49:27,638 callbacks.py:105 INFO train-abinet] epoch 9 iter 410450: loss = 0.4155,  smooth loss = 0.4625
[2022-07-08 13:50:09,423 callbacks.py:105 INFO train-abinet] epoch 9 iter 410500: loss = 0.4768,  smooth loss = 0.4478
[2022-07-08 13:50:50,770 callbacks.py:105 INFO train-abinet] epoch 9 iter 410550: loss = 0.4253,  smooth loss = 0.4416
[2022-07-08 13:51:32,076 callbacks.py:105 INFO train-abinet] epoch 9 iter 410600: loss = 0.4283,  smooth loss = 0.4421
[2022-07-08 13:52:14,006 callbacks.py:105 INFO train-abinet] epoch 9 iter 410650: loss = 0.6343,  smooth loss = 0.4509
[2022-07-08 13:52:56,376 callbacks.py:105 INFO train-abinet] epoch 9 iter 410700: loss = 0.3434,  smooth loss = 0.4425
[2022-07-08 13:53:38,629 callbacks.py:105 INFO train-abinet] epoch 9 iter 410750: loss = 0.4104,  smooth loss = 0.4416
[2022-07-08 13:54:20,695 callbacks.py:105 INFO train-abinet] epoch 9 iter 410800: loss = 0.5431,  smooth loss = 0.4457
[2022-07-08 13:55:02,174 callbacks.py:105 INFO train-abinet] epoch 9 iter 410850: loss = 0.4695,  smooth loss = 0.4493
[2022-07-08 13:55:44,611 callbacks.py:105 INFO train-abinet] epoch 9 iter 410900: loss = 0.6633,  smooth loss = 0.4517
[2022-07-08 13:56:26,548 callbacks.py:105 INFO train-abinet] epoch 9 iter 410950: loss = 0.5123,  smooth loss = 0.4682
[2022-07-08 13:57:09,272 callbacks.py:105 INFO train-abinet] epoch 9 iter 411000: loss = 0.4111,  smooth loss = 0.4645
[2022-07-08 13:57:09,273 callbacks.py:114 INFO train-abinet] average data time = 0.0042s, average running time = 0.8521s
█[2022-07-08 13:57:23,267 callbacks.py:123 INFO train-abinet] epoch 9 iter 411000: eval loss = 1.1726,  ccr = 0.9658,  cwr = 0.9285,  ted = 1122.0000,  ned = 230.9983,  ted/w = 0.1548, 
[2022-07-08 13:57:23,269 callbacks.py:136 INFO train-abinet] Save model train-abinet_9_411000
[2022-07-08 13:58:06,913 callbacks.py:105 INFO train-abinet] epoch 9 iter 411050: loss = 0.4796,  smooth loss = 0.4546
[2022-07-08 13:58:48,766 callbacks.py:105 INFO train-abinet] epoch 9 iter 411100: loss = 0.4498,  smooth loss = 0.4455
[2022-07-08 13:59:29,877 callbacks.py:105 INFO train-abinet] epoch 9 iter 411150: loss = 0.4943,  smooth loss = 0.4441
[2022-07-08 14:00:10,969 callbacks.py:105 INFO train-abinet] epoch 9 iter 411200: loss = 0.3999,  smooth loss = 0.4358
[2022-07-08 14:00:52,012 callbacks.py:105 INFO train-abinet] epoch 9 iter 411250: loss = 0.4155,  smooth loss = 0.4543
[2022-07-08 14:01:32,348 callbacks.py:105 INFO train-abinet] epoch 9 iter 411300: loss = 0.4073,  smooth loss = 0.4539
[2022-07-08 14:02:15,222 callbacks.py:105 INFO train-abinet] epoch 9 iter 411350: loss = 0.5186,  smooth loss = 0.4463
[2022-07-08 14:02:56,585 callbacks.py:105 INFO train-abinet] epoch 9 iter 411400: loss = 0.3995,  smooth loss = 0.4539
[2022-07-08 14:03:38,600 callbacks.py:105 INFO train-abinet] epoch 9 iter 411450: loss = 0.4127,  smooth loss = 0.4551
[2022-07-08 14:04:20,550 callbacks.py:105 INFO train-abinet] epoch 9 iter 411500: loss = 0.5031,  smooth loss = 0.4580
[2022-07-08 14:05:02,292 callbacks.py:105 INFO train-abinet] epoch 9 iter 411550: loss = 0.3428,  smooth loss = 0.4398
[2022-07-08 14:05:43,734 callbacks.py:105 INFO train-abinet] epoch 9 iter 411600: loss = 0.5618,  smooth loss = 0.4537
[2022-07-08 14:06:25,949 callbacks.py:105 INFO train-abinet] epoch 9 iter 411650: loss = 0.5163,  smooth loss = 0.4695
[2022-07-08 14:07:08,378 callbacks.py:105 INFO train-abinet] epoch 9 iter 411700: loss = 0.3139,  smooth loss = 0.4570
[2022-07-08 14:07:50,427 callbacks.py:105 INFO train-abinet] epoch 9 iter 411750: loss = 0.4546,  smooth loss = 0.4617
[2022-07-08 14:08:32,491 callbacks.py:105 INFO train-abinet] epoch 9 iter 411800: loss = 0.4644,  smooth loss = 0.4489
[2022-07-08 14:09:14,717 callbacks.py:105 INFO train-abinet] epoch 9 iter 411850: loss = 0.4115,  smooth loss = 0.4618
[2022-07-08 14:09:56,360 callbacks.py:105 INFO train-abinet] epoch 9 iter 411900: loss = 0.3900,  smooth loss = 0.4584
[2022-07-08 14:10:39,522 callbacks.py:105 INFO train-abinet] epoch 9 iter 411950: loss = 0.3899,  smooth loss = 0.4511
[2022-07-08 14:11:21,017 callbacks.py:105 INFO train-abinet] epoch 9 iter 412000: loss = 0.4311,  smooth loss = 0.4514
[2022-07-08 14:12:02,707 callbacks.py:105 INFO train-abinet] epoch 9 iter 412050: loss = 0.5415,  smooth loss = 0.4515
[2022-07-08 14:12:44,809 callbacks.py:105 INFO train-abinet] epoch 9 iter 412100: loss = 0.4851,  smooth loss = 0.4628
[2022-07-08 14:13:27,002 callbacks.py:105 INFO train-abinet] epoch 9 iter 412150: loss = 0.4477,  smooth loss = 0.4665
[2022-07-08 14:14:09,179 callbacks.py:105 INFO train-abinet] epoch 9 iter 412200: loss = 0.4201,  smooth loss = 0.4665
[2022-07-08 14:14:51,350 callbacks.py:105 INFO train-abinet] epoch 9 iter 412250: loss = 0.4240,  smooth loss = 0.4496
[2022-07-08 14:15:32,515 callbacks.py:105 INFO train-abinet] epoch 9 iter 412300: loss = 0.3650,  smooth loss = 0.4449
[2022-07-08 14:16:13,652 callbacks.py:105 INFO train-abinet] epoch 9 iter 412350: loss = 0.3845,  smooth loss = 0.4605
[2022-07-08 14:16:55,331 callbacks.py:105 INFO train-abinet] epoch 9 iter 412400: loss = 0.5465,  smooth loss = 0.4551
[2022-07-08 14:17:37,109 callbacks.py:105 INFO train-abinet] epoch 9 iter 412450: loss = 0.3775,  smooth loss = 0.4528
[2022-07-08 14:18:17,935 callbacks.py:105 INFO train-abinet] epoch 9 iter 412500: loss = 0.2919,  smooth loss = 0.4510
[2022-07-08 14:18:59,106 callbacks.py:105 INFO train-abinet] epoch 9 iter 412550: loss = 0.5060,  smooth loss = 0.4540
[2022-07-08 14:19:40,795 callbacks.py:105 INFO train-abinet] epoch 9 iter 412600: loss = 0.4033,  smooth loss = 0.4588
[2022-07-08 14:20:22,724 callbacks.py:105 INFO train-abinet] epoch 9 iter 412650: loss = 0.4874,  smooth loss = 0.4598
[2022-07-08 14:21:05,049 callbacks.py:105 INFO train-abinet] epoch 9 iter 412700: loss = 0.4956,  smooth loss = 0.4562
[2022-07-08 14:21:46,862 callbacks.py:105 INFO train-abinet] epoch 9 iter 412750: loss = 0.4539,  smooth loss = 0.4362
[2022-07-08 14:22:28,389 callbacks.py:105 INFO train-abinet] epoch 9 iter 412800: loss = 0.6099,  smooth loss = 0.4509
[2022-07-08 14:23:10,347 callbacks.py:105 INFO train-abinet] epoch 9 iter 412850: loss = 0.4887,  smooth loss = 0.4490
[2022-07-08 14:23:51,925 callbacks.py:105 INFO train-abinet] epoch 9 iter 412900: loss = 0.4856,  smooth loss = 0.4470
[2022-07-08 14:24:32,636 callbacks.py:105 INFO train-abinet] epoch 9 iter 412950: loss = 0.4246,  smooth loss = 0.4455
[2022-07-08 14:25:13,972 callbacks.py:105 INFO train-abinet] epoch 9 iter 413000: loss = 0.4850,  smooth loss = 0.4546
[2022-07-08 14:25:55,333 callbacks.py:105 INFO train-abinet] epoch 9 iter 413050: loss = 0.3926,  smooth loss = 0.4421
[2022-07-08 14:26:36,545 callbacks.py:105 INFO train-abinet] epoch 9 iter 413100: loss = 0.5089,  smooth loss = 0.4484
[2022-07-08 14:27:17,994 callbacks.py:105 INFO train-abinet] epoch 9 iter 413150: loss = 0.3685,  smooth loss = 0.4563
[2022-07-08 14:27:58,555 callbacks.py:105 INFO train-abinet] epoch 9 iter 413200: loss = 0.4910,  smooth loss = 0.4571
[2022-07-08 14:28:40,271 callbacks.py:105 INFO train-abinet] epoch 9 iter 413250: loss = 0.3013,  smooth loss = 0.4520
[2022-07-08 14:29:21,721 callbacks.py:105 INFO train-abinet] epoch 9 iter 413300: loss = 0.4064,  smooth loss = 0.4489
[2022-07-08 14:30:03,301 callbacks.py:105 INFO train-abinet] epoch 9 iter 413350: loss = 0.3887,  smooth loss = 0.4499
[2022-07-08 14:30:44,337 callbacks.py:105 INFO train-abinet] epoch 9 iter 413400: loss = 0.3834,  smooth loss = 0.4491
[2022-07-08 14:31:25,987 callbacks.py:105 INFO train-abinet] epoch 9 iter 413450: loss = 0.3881,  smooth loss = 0.4511
[2022-07-08 14:32:07,601 callbacks.py:105 INFO train-abinet] epoch 9 iter 413500: loss = 0.5170,  smooth loss = 0.4553
[2022-07-08 14:32:49,016 callbacks.py:105 INFO train-abinet] epoch 9 iter 413550: loss = 0.3662,  smooth loss = 0.4509
[2022-07-08 14:33:30,225 callbacks.py:105 INFO train-abinet] epoch 9 iter 413600: loss = 0.3692,  smooth loss = 0.4509
[2022-07-08 14:34:10,929 callbacks.py:105 INFO train-abinet] epoch 9 iter 413650: loss = 0.4234,  smooth loss = 0.4486
[2022-07-08 14:34:52,119 callbacks.py:105 INFO train-abinet] epoch 9 iter 413700: loss = 0.6106,  smooth loss = 0.4554
[2022-07-08 14:35:33,891 callbacks.py:105 INFO train-abinet] epoch 9 iter 413750: loss = 0.4529,  smooth loss = 0.4571
[2022-07-08 14:36:15,373 callbacks.py:105 INFO train-abinet] epoch 9 iter 413800: loss = 0.4152,  smooth loss = 0.4527
[2022-07-08 14:36:55,927 callbacks.py:105 INFO train-abinet] epoch 9 iter 413850: loss = 0.4542,  smooth loss = 0.4525
[2022-07-08 14:37:37,330 callbacks.py:105 INFO train-abinet] epoch 9 iter 413900: loss = 0.3617,  smooth loss = 0.4534
